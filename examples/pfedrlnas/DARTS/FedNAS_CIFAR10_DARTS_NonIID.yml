clients:
    # Type
    type: simple

    # The total number of clients
    total_clients: 100

    # The number of clients selected in each round
    per_round: 30

    # Should the clients compute test accuracy locally?
    do_test: true

    random_seed: 1

server:
    address: 127.0.0.1
    port: 8003
    do_test: false
    random_seed: 1

    checkpoint_path: /data/dixi/plato/models/pfednas/cifar10_noniid/
    model_path: /data/dixi/plato/models/pfednas/cifar10_noniid/

data:
    # The training and testing dataset
    datasource:  CIFAR10

    data_path: /data/dixi

    # Number of samples in each partition
    partition_size: 600
    test_partition_size: 600

    sampler: noniid
##    # IID or non-IID?
##
##    # The concentration parameter for the Dirichlet distribution
    concentration: 0.3
##
    testset_sampler: noniid
##
##    # The random seed for sampling data
    random_seed: 1

trainer:
    # The type of the trainer
    type: basic

    # The maximum number of training rounds
    rounds: 120

    # The maximum number of clients running concurrently
    max_concurrency: 5

    # The target accuracy
    target_accuracy: 0.92

    # Number of epochs for local training in each communication round
    epochs: 3
    batch_size: 64
    optimizer: SGD
    loss_criterion: CrossEntropyLoss
    lr_scheduler: CosineAnnealingLR
    global_lr_scheduler: false
    model_name: darts

algorithm:
    # Aggregation algorithm
    type: fedavg
    
results:
    result_path: /data/dixi/plato/results/pfednas/cifar10_noniid/
parameters:
    learning_rate:
        base_lr: 0.025
    lr_scheduler:
        eta_min: 0.001
        T_max: 100
    optimizer:
        lr:  0.025
        momentum: 0.9 
        weight_decay: 0.0003
    model:
        C: 3
        num_classes: 10
        layers: 8
    architect:
        # Darts lr: 0.0003 weight_decay 0.001
        # ProxyLessNas: 0.01 weight_decay: 0
        #FedRLNAS: 0.003 weight_dacey 0.0001
        learning_rate: 0.5
        weight_decay: 0
        baseline_decay: 0.9
        pretrain_path: /data/dixi/plato/pretrained/cifar10/checkpoint.pth
#        natural: true
#        value_net:
#           learning_rate: 0.01
#        warmup: 20
#        personalize_last: true