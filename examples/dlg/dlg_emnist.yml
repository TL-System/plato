clients:
    # The total number of clients
    total_clients: 1

    # The number of clients selected in each round
    per_round: 1

    # Should the clients compute test accuracy locally?
    do_test: false

    random_seed: 1

server:
    address: 127.0.0.1
    port: 8000
    simulate_wall_time: true

    random_seed: 1

data:
    # The training and testing dataset
    datasource: EMNIST

    # Number of samples in each partition
    partition_size: 1

    # IID or non-IID?
    sampler: iid

    # The concentration parameter for the Dirichlet distribution
    concentration: 1

    # The random seed for sampling data
    random_seed: 1

trainer:
    # The maximum number of training rounds
    rounds: 1

    # The maximum number of clients running concurrently
    max_concurrency: 4

    # The target accuracy
    target_accuracy: 1.0

    # Number of epoches for local training in each communication round
    epochs: 1
    batch_size: 1
    optimizer: SGD
    learning_rate: 0.01
    momentum: 0.0
    weight_decay: 0.0

    # The machine learning model
    model_name: dlg
    num_classes: 47

algorithm:
    # Aggregation algorithm
    type: fedavg

    ## Data reconstruction related configurations
    # Choose from DLG (default), iDLG, csDLG
    attack_method: csDLG
    # For calculating the loss between dummy and target gradients/updates
    # Choose from l2, l1, max, sim, simlocal
    cost_fn: sim
    # Weight for adding total data variation to the loss
    total_variation: 0.0
    # Learning rate of the optimizer to reconstruct data
    lr: 1

    # in a particular communication round (starting from 1)
    attack_round: 1
    # One particular client, e.g., the first selected client
    victim_client: 0
    num_iters: 300
    log_interval: 30

    # Whether or not use customized initialization for model weights
    init_params: true
    # Whether sharing gradients or model weights
    share_gradients: false
    # Do reconstruction by directly matching weights when it's true,
    # otherwise by matching gradients calculated from updates
    match_weights: true
    # Matching weights (absolute) or weight updates (delta)
    use_updates: true
    # The number of times the attack will be attempted
    trials: 5

    ## Defense related
    # Choose from GradDefense, Soteria, GC (model compression), DP (differential privacy), Outpost (ours)...
    defense: Outpost
    # for Outpost
    beta: 0.125  # controls iteration decay speed
    phi: 40  # the amount (%) of perturbation
    prune_base: 80  # for pruning
    noise_base: 0.8  # controls scale for gaussian noise
    # for GradDefense
    clip: true
    slices_num: 10
    perturb_slices_num: 5
    scale: 0.01
    Q: 6
    # for Soteria
    threshold: 50
    # for GC
    prune_pct: 80

    # The random seed for dummy data and label
    random_seed: 1

results:
    result_path: results/EMNIST/DLG

    # Write the following parameter(s) into a CSV
    types: round, accuracy, elapsed_time, round_time

    # Plot results (x_axis-y_axis)
    plot: round-accuracy, elapsed_time-accuracy

    # DLG related parameters
    # The specific subprocess number to use with plot.py
    # subprocess: 79618
    # The specific trial number to plot
    # trial: 6
