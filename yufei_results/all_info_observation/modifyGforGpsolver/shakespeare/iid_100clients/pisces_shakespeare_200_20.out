The configuration filename is: ./pisces_shakespeare_bert.yml
 
clients:
# Type
type: simple

# The total number of clients
total_clients: 100

# The number of clients selected in each round
per_round: 10

# Should the clients compute test accuracy locally?
do_test: false

speed_simulation: true

# The distribution of client speeds
simulation_distribution:
distribution: zipf # zipf is used.
s: 1.2

# The maximum amount of time for clients to sleep after each epoch
#max_sleep_time: 10

# Should clients really go to sleep, or should we just simulate the sleep times?
sleep_simulation: true

# If we are simulating client training times, what is the average training time?
avg_training_time: 10

random_seed: 1

server:
address: 127.0.0.1
port: 2000
simulate_wall_time: true
synchronous: false
minimum_clients_aggregated: 5
staleness_bound: 10
exploration_factor: 0.9
staleness_factor: 0.5
exploration_decaying_factor: 0.98
min_explore_factor: 0.3
staleness_penalty_factor: 0.5
random_seed: 1
checkpoint_path: checkpoints/huggingface/fedavg
model_path: models/huggingface/fedavg

data:
# The training and testing dataset
datasource: HuggingFace
dataset_name: tiny_shakespeare

# Number of samples in each partition
partition_size: 1009

# IID or non-IID?
sampler: iid


# The random seed for sampling data
random_seed: 1

trainer:
# The type of the trainer
type: HuggingFace

# The maximum number of training rounds
rounds: 100

# The maximum number of clients running concurrently
max_concurrency: 1

# The target perplexity
target_perplexity: 20

# The machine learning model
model_type: huggingface
model_name: bert-base-uncased

# Number of epoches for local training in each communication round
epochs: 5
batch_size: 32
optimizer: SGD

algorithm:
# Aggregation algorithm
type: fedavg

parameters:
optimizer:
lr: 0.01
momentum: 0.9
weight_decay: 0.0

results:
# Write the following parameter(s) into a CSV
types: round, elapsed_time, accuracy
result_path: /data/ykang/plato/results/Pisces/Shakespeare/verify

[INFO][21:06:25]: [93m[1m[3350301] Logging runtime results to: /data/ykang/plato/results/Pisces/Shakespeare/verify/3350301.csv.[0m
[INFO][21:06:25]: [Server #3350301] Started training on 100 clients with 10 per round.
[INFO][21:06:25]: [Server #3350301] Configuring the server...
[INFO][21:06:25]: Training: 100 rounds or perplexity below 20.0

If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO][21:06:28]: Algorithm: fedavg
[INFO][21:06:28]: Data source: HuggingFace
[INFO][21:06:28]: Dataset: tiny_shakespeare
[WARNING][21:06:28]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (258335 > 512). Running this sequence through the model will result in indexing errors
^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:29]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:29]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:29]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[INFO][21:06:29]: Starting client #1's process.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[INFO][21:06:29]: Starting client #2's process.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[INFO][21:06:29]: Setting the random seed for selecting clients: 1
[INFO][21:06:29]: Starting a server at address 127.0.0.1 and port 2000.
[INFO][21:06:32]: Starting a custom client #2
[INFO][21:06:32]: Starting a custom client #1
If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO][21:06:34]: Algorithm: fedavg
[INFO][21:06:34]: Algorithm: fedavg
[INFO][21:06:39]: [Client #2] Contacting the server.
[INFO][21:06:39]: [Client #2] Connecting to the server at http://127.0.0.1:2000.
[INFO][21:06:39]: [Client #1] Contacting the server.
[INFO][21:06:39]: [Client #1] Connecting to the server at http://127.0.0.1:2000.
[INFO][21:06:39]: 127.0.0.1 [22/Nov/2022:02:06:39 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1669082799.68042 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.3"
[INFO][21:06:39]: 127.0.0.1 [22/Nov/2022:02:06:39 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1669082799.6859283 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.3"
[INFO][21:06:39]: [Server #3350301] A new client just connected.
[INFO][21:06:39]: [Client #2] Connected to the server.
[INFO][21:06:39]: [Client #2] Waiting to be selected.
[INFO][21:06:39]: [Server #3350301] New client with id #2 arrived.
[INFO][21:06:39]: [Server #3350301] A new client just connected.
[INFO][21:06:39]: [Client #1] Connected to the server.
[INFO][21:06:39]: [Client #1] Waiting to be selected.
[INFO][21:06:39]: [Server #3350301] New client with id #1 arrived.
[INFO][21:06:39]: [Server #3350301] Starting training.
[INFO][21:06:39]: [93m[1m
[Server #3350301] Starting round 1/100.[0m
[INFO][21:06:39]: [Server #3350301] Selected clients: [18, 73, 98, 9, 33, 16, 64, 58, 61, 84]
[INFO][21:06:39]: [Server #3350301] Selecting client #64 for training.
[INFO][21:06:39]: [Server #3350301] Sending the current model to client #64 (simulated).
[INFO][21:06:43]: [Server #3350301] Sending 507.38 MB of payload data to client #64 (simulated).
[INFO][21:06:43]: [Server #3350301] Selecting client #33 for training.
[INFO][21:06:43]: [Server #3350301] Sending the current model to client #33 (simulated).
[INFO][21:06:47]: [Server #3350301] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][21:06:47]: [Client #64] Selected by the server.
[INFO][21:06:47]: [Client #33] Selected by the server.
[INFO][21:06:47]: [Client #64] Loading its data source...
[INFO][21:06:47]: Data source: HuggingFace
[INFO][21:06:47]: Dataset: tiny_shakespeare
[INFO][21:06:47]: [Client #33] Loading its data source...
[INFO][21:06:47]: Data source: HuggingFace
[INFO][21:06:47]: Dataset: tiny_shakespeare
[WARNING][21:06:47]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
[WARNING][21:06:47]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (258335 > 512). Running this sequence through the model will result in indexing errors
^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.
Token indices sequence length is longer than the specified maximum sequence length for this model (258335 > 512). Running this sequence through the model will result in indexing errors
^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:48]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s][WARNING][21:06:48]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:48]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:48]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:48]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][21:06:48]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[INFO][21:06:48]: [Client #33] Dataset size: 2018
[INFO][21:06:48]: [Client #33] Sampler: iid
[WARNING][21:06:48]: Loading cached processed dataset at /data/ykang/plato/data/tiny_shakespeare_None/validation/cache-2765a19ac0aad0ea.arrow
[INFO][21:06:48]: [Client #64] Dataset size: 2018
[INFO][21:06:48]: [Client #64] Sampler: iid
[INFO][21:06:50]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:06:50]: [Client #33] Start to process inbound data.
[INFO][21:06:50]: [Client #64] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:06:50]: [Client #64] Start to process inbound data.
[INFO][21:06:51]: [93m[1m[Client #33] Started training in communication round #1.[0m
[INFO][21:06:51]: [93m[1m[Client #64] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:21,  4.29s/it]  2%|â–         | 1/48 [00:04<03:24,  4.36s/it]  4%|â–         | 2/48 [00:04<01:40,  2.18s/it]  4%|â–         | 2/48 [00:05<01:42,  2.24s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.37it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.37it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.36it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.36it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.36it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.36it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.38it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][21:07:36]: [Client #64] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_64_3350395.pth.
{'train_runtime': 38.9481, 'train_samples_per_second': 155.438, 'train_steps_per_second': 1.232, 'train_loss': 5.610925674438477, 'epoch': 3.0}
[INFO][21:07:36]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3350396.pth.
{'train_runtime': 39.0387, 'train_samples_per_second': 155.077, 'train_steps_per_second': 1.23, 'train_loss': 5.7235056559244795, 'epoch': 3.0}
[INFO][21:07:37]: [Client #64] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_64_3350395.pth.
[INFO][21:07:38]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3350396.pth.
[INFO][21:07:38]: [Client #64] Model trained.
[INFO][21:07:38]: [Client #64] Inbound data has been processed.
[INFO][21:07:38]: [Client #64] Outbound data is ready to be sent after being processed.
[INFO][21:07:38]: [Client #33] Model trained.
[INFO][21:07:38]: [Client #33] Inbound data has been processed.
[INFO][21:07:38]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][21:07:44]: [Client #64] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:07:45]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:07:46]: [Server #3350301] Received 507.38 MB of payload data from client #64 (simulated).
[INFO][21:07:47]: [Server #3350301] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][21:07:47]: [Server #3350301] Selecting client #98 for training.
[INFO][21:07:47]: [Server #3350301] Sending the current model to client #98 (simulated).
[INFO][21:07:50]: [Server #3350301] Sending 507.38 MB of payload data to client #98 (simulated).
[INFO][21:07:50]: [Server #3350301] Selecting client #73 for training.
[INFO][21:07:50]: [Server #3350301] Sending the current model to client #73 (simulated).
[INFO][21:07:54]: [Server #3350301] Sending 507.38 MB of payload data to client #73 (simulated).
[INFO][21:07:54]: [Client #98] Selected by the server.
[INFO][21:07:54]: [Client #98] Loading its data source...
[INFO][21:07:54]: [Client #73] Selected by the server.
[INFO][21:07:54]: [Client #98] Dataset size: 2018
[INFO][21:07:54]: [Client #73] Loading its data source...
[INFO][21:07:54]: [Client #98] Sampler: iid
[INFO][21:07:54]: [Client #73] Dataset size: 2018
[INFO][21:07:54]: [Client #73] Sampler: iid
[INFO][21:07:55]: [Client #73] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:07:55]: [Client #73] Start to process inbound data.
[INFO][21:07:55]: [Client #98] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:07:55]: [Client #98] Start to process inbound data.
[INFO][21:07:56]: [93m[1m[Client #73] Started training in communication round #1.[0m
[INFO][21:07:56]: [93m[1m[Client #98] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  2%|â–         | 1/48 [00:04<03:21,  4.30s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.51s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
[INFO][21:08:41]: [Client #98] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_98_3350395.pth.
{'train_runtime': 38.879, 'train_samples_per_second': 155.714, 'train_steps_per_second': 1.235, 'train_loss': 5.6021677652994795, 'epoch': 3.0}
[INFO][21:08:41]: [Client #73] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_73_3350396.pth.
{'train_runtime': 38.9239, 'train_samples_per_second': 155.534, 'train_steps_per_second': 1.233, 'train_loss': 5.668891906738281, 'epoch': 3.0}
[INFO][21:08:42]: [Client #98] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_98_3350395.pth.
[INFO][21:08:42]: [Client #73] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_73_3350396.pth.
[INFO][21:08:42]: [Client #98] Model trained.
[INFO][21:08:42]: [Client #98] Inbound data has been processed.
[INFO][21:08:42]: [Client #98] Outbound data is ready to be sent after being processed.
[INFO][21:08:43]: [Client #73] Model trained.
[INFO][21:08:43]: [Client #73] Inbound data has been processed.
[INFO][21:08:43]: [Client #73] Outbound data is ready to be sent after being processed.
[INFO][21:08:48]: [Client #98] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:08:49]: [Client #73] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:08:49]: [Server #3350301] Received 507.38 MB of payload data from client #98 (simulated).
[INFO][21:08:50]: [Server #3350301] Received 507.38 MB of payload data from client #73 (simulated).
[INFO][21:08:50]: [Server #3350301] Selecting client #16 for training.
[INFO][21:08:50]: [Server #3350301] Sending the current model to client #16 (simulated).
[INFO][21:08:54]: [Server #3350301] Sending 507.38 MB of payload data to client #16 (simulated).
[INFO][21:08:54]: [Server #3350301] Selecting client #9 for training.
[INFO][21:08:54]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][21:08:58]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][21:08:58]: [Client #16] Selected by the server.
[INFO][21:08:58]: [Client #16] Loading its data source...
[INFO][21:08:58]: [Client #16] Dataset size: 2018
[INFO][21:08:58]: [Client #16] Sampler: iid
[INFO][21:08:58]: [Client #9] Selected by the server.
[INFO][21:08:58]: [Client #9] Loading its data source...
[INFO][21:08:58]: [Client #9] Dataset size: 2018
[INFO][21:08:58]: [Client #9] Sampler: iid
[INFO][21:08:59]: [Client #16] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:08:59]: [Client #16] Start to process inbound data.
[INFO][21:08:59]: [93m[1m[Client #16] Started training in communication round #1.[0m
[INFO][21:08:59]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:08:59]: [Client #9] Start to process inbound data.
[INFO][21:08:59]: [93m[1m[Client #9] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  4%|â–         | 2/48 [00:05<01:42,  2.24s/it]  4%|â–         | 2/48 [00:05<01:53,  2.47s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.71s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.47s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.26s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:47,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.12s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.00it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.00s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:36,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.07it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.03it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.04it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:27,  1.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:27,  1.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.11it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:12,  1.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
[INFO][21:09:52]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350396.pth.
{'train_runtime': 47.7387, 'train_samples_per_second': 126.815, 'train_steps_per_second': 1.005, 'train_loss': 5.615034739176433, 'epoch': 3.0}
[INFO][21:09:53]: [Client #16] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_16_3350395.pth.
{'train_runtime': 47.8842, 'train_samples_per_second': 126.43, 'train_steps_per_second': 1.002, 'train_loss': 5.631868362426758, 'epoch': 3.0}
[INFO][21:09:53]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350396.pth.
[INFO][21:09:54]: [Client #16] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_16_3350395.pth.
[INFO][21:09:54]: [Client #9] Model trained.
[INFO][21:09:54]: [Client #9] Inbound data has been processed.
[INFO][21:09:54]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][21:09:54]: [Client #16] Model trained.
[INFO][21:09:54]: [Client #16] Inbound data has been processed.
[INFO][21:09:54]: [Client #16] Outbound data is ready to be sent after being processed.
[INFO][21:10:00]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:10:00]: [Client #16] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:10:01]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][21:10:02]: [Server #3350301] Received 507.38 MB of payload data from client #16 (simulated).
[INFO][21:10:02]: [Server #3350301] Selecting client #18 for training.
[INFO][21:10:02]: [Server #3350301] Sending the current model to client #18 (simulated).
[INFO][21:10:06]: [Server #3350301] Sending 507.38 MB of payload data to client #18 (simulated).
[INFO][21:10:06]: [Server #3350301] Selecting client #61 for training.
[INFO][21:10:06]: [Server #3350301] Sending the current model to client #61 (simulated).
[INFO][21:10:10]: [Server #3350301] Sending 507.38 MB of payload data to client #61 (simulated).
[INFO][21:10:10]: [Client #18] Selected by the server.
[INFO][21:10:10]: [Client #18] Loading its data source...
[INFO][21:10:10]: [Client #61] Selected by the server.
[INFO][21:10:10]: [Client #61] Loading its data source...
[INFO][21:10:10]: [Client #18] Dataset size: 2018
[INFO][21:10:10]: [Client #18] Sampler: iid
[INFO][21:10:10]: [Client #61] Dataset size: 2018
[INFO][21:10:10]: [Client #61] Sampler: iid
[INFO][21:10:11]: [Client #18] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:10:11]: [Client #18] Start to process inbound data.
[INFO][21:10:11]: [Client #61] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:10:11]: [Client #61] Start to process inbound data.
[INFO][21:10:11]: [93m[1m[Client #61] Started training in communication round #1.[0m
[INFO][21:10:12]: [93m[1m[Client #18] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.13s/it]  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][21:10:56]: [Client #61] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_61_3350396.pth.
{'train_runtime': 39.0549, 'train_samples_per_second': 155.013, 'train_steps_per_second': 1.229, 'train_loss': 5.624550501505534, 'epoch': 3.0}
[INFO][21:10:56]: [Client #18] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_18_3350395.pth.
{'train_runtime': 39.0358, 'train_samples_per_second': 155.089, 'train_steps_per_second': 1.23, 'train_loss': 5.62820561726888, 'epoch': 3.0}
[INFO][21:10:57]: [Client #61] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_61_3350396.pth.
[INFO][21:10:57]: [Client #18] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_18_3350395.pth.
[INFO][21:10:58]: [Client #61] Model trained.
[INFO][21:10:58]: [Client #61] Inbound data has been processed.
[INFO][21:10:58]: [Client #61] Outbound data is ready to be sent after being processed.
[INFO][21:10:58]: [Client #18] Model trained.
[INFO][21:10:58]: [Client #18] Inbound data has been processed.
[INFO][21:10:58]: [Client #18] Outbound data is ready to be sent after being processed.
[INFO][21:11:04]: [Client #61] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:11:04]: [Client #18] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:11:05]: [Server #3350301] Received 507.38 MB of payload data from client #61 (simulated).
[INFO][21:11:06]: [Server #3350301] Received 507.38 MB of payload data from client #18 (simulated).
[INFO][21:11:06]: [Server #3350301] Selecting client #84 for training.
[INFO][21:11:06]: [Server #3350301] Sending the current model to client #84 (simulated).
[INFO][21:11:10]: [Server #3350301] Sending 507.38 MB of payload data to client #84 (simulated).
[INFO][21:11:10]: [Client #84] Selected by the server.
[INFO][21:11:10]: [Client #84] Loading its data source...
[INFO][21:11:10]: [Client #84] Dataset size: 2018
[INFO][21:11:10]: [Client #84] Sampler: iid
[INFO][21:11:11]: [Client #84] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:11:11]: [Client #84] Start to process inbound data.
[INFO][21:11:11]: [93m[1m[Client #84] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:58,  3.81s/it]  4%|â–         | 2/48 [00:04<01:25,  1.85s/it]  6%|â–‹         | 3/48 [00:04<00:55,  1.22s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.08it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:28,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:15,  2.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.13it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.10it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:11:43]: [Client #84] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_84_3350395.pth.
{'train_runtime': 26.0631, 'train_samples_per_second': 232.282, 'train_steps_per_second': 1.842, 'train_loss': 5.627942403157552, 'epoch': 3.0}
[INFO][21:11:44]: [Client #84] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_84_3350395.pth.
[INFO][21:11:44]: [Client #84] Model trained.
[INFO][21:11:44]: [Client #84] Inbound data has been processed.
[INFO][21:11:44]: [Client #84] Outbound data is ready to be sent after being processed.
[INFO][21:11:48]: [Client #84] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:11:49]: [Server #3350301] Received 507.38 MB of payload data from client #84 (simulated).
[INFO][21:11:49]: [Server #3350301] Selecting client #58 for training.
[INFO][21:11:49]: [Server #3350301] Sending the current model to client #58 (simulated).
[INFO][21:11:52]: [Server #3350301] Sending 507.38 MB of payload data to client #58 (simulated).
[INFO][21:11:52]: [Client #58] Selected by the server.
[INFO][21:11:52]: [Client #58] Loading its data source...
[INFO][21:11:52]: [Client #58] Dataset size: 2018
[INFO][21:11:52]: [Client #58] Sampler: iid
[INFO][21:11:53]: [Client #58] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:11:53]: [Client #58] Start to process inbound data.
[INFO][21:11:54]: [93m[1m[Client #58] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:59,  3.83s/it]  4%|â–         | 2/48 [00:04<01:25,  1.86s/it]  6%|â–‹         | 3/48 [00:04<00:55,  1.23s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.07it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.30it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:28,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.00it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:12:25]: [Client #58] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_58_3350395.pth.
{'train_runtime': 26.0967, 'train_samples_per_second': 231.984, 'train_steps_per_second': 1.839, 'train_loss': 5.619614919026692, 'epoch': 3.0}
[INFO][21:12:26]: [Client #58] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_58_3350395.pth.
[INFO][21:12:26]: [Client #58] Model trained.
[INFO][21:12:26]: [Client #58] Inbound data has been processed.
[INFO][21:12:26]: [Client #58] Outbound data is ready to be sent after being processed.
[INFO][21:12:30]: [Client #58] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:12:31]: [Server #3350301] Received 507.38 MB of payload data from client #58 (simulated).
[INFO][21:12:31]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][21:12:31]: [Server #3350301] Adding client #33 to the list of clients for aggregation.
[INFO][21:12:31]: [Server #3350301] Adding client #61 to the list of clients for aggregation.
[INFO][21:12:31]: [Server #3350301] Adding client #18 to the list of clients for aggregation.
[INFO][21:12:31]: [Server #3350301] Adding client #16 to the list of clients for aggregation.
[INFO][21:12:31]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:12:31]: [Server #3350301] Updated weights have been received.
[INFO][21:12:32]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:12:32]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:12:32]: [Server #3350301] Started model testing.
======== Running on http://127.0.0.1:2000 ========
(Press CTRL+C to quit)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.50it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.56it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.89it/s]
[INFO][21:12:42]: [93m[1m[Server #3350301] Global model perplexity: 144.99
[0m
[INFO][21:12:42]: [Server #3350301] All client reports have been processed.
[INFO][21:12:42]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_1.pth.
[INFO][21:12:45]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_1.pth.
[INFO][21:12:45]: [93m[1m
[Server #3350301] Starting round 2/100.[0m
[INFO][21:12:45]: [Server #3350301] Selected clients: [53, 30, 14, 70, 4]
[INFO][21:12:45]: [Server #3350301] Selecting client #4 for training.
[INFO][21:12:45]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][21:12:48]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][21:12:48]: [Server #3350301] Selecting client #53 for training.
[INFO][21:12:48]: [Server #3350301] Sending the current model to client #53 (simulated).
[INFO][21:12:51]: [Server #3350301] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][21:12:51]: [Client #4] Selected by the server.
[INFO][21:12:51]: [Client #4] Loading its data source...
[INFO][21:12:51]: [Client #4] Dataset size: 2018
[INFO][21:12:51]: [Client #4] Sampler: iid
[INFO][21:12:51]: [Client #53] Selected by the server.
[INFO][21:12:51]: [Client #53] Loading its data source...
[INFO][21:12:51]: [Client #53] Dataset size: 2018
[INFO][21:12:51]: [Client #53] Sampler: iid
[INFO][21:12:53]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:12:53]: [Client #4] Start to process inbound data.
[INFO][21:12:53]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:12:53]: [Client #53] Start to process inbound data.
[INFO][21:12:53]: [93m[1m[Client #4] Started training in communication round #2.[0m
[INFO][21:12:53]: [93m[1m[Client #53] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  2%|â–         | 1/48 [00:04<03:21,  4.29s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  4%|â–         | 2/48 [00:05<01:40,  2.19s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.35it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.35it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][21:13:38]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3350396.pth.
{'train_runtime': 39.0889, 'train_samples_per_second': 154.878, 'train_steps_per_second': 1.228, 'train_loss': 4.631869951883952, 'epoch': 3.0}
[INFO][21:13:38]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.0559, 'train_samples_per_second': 155.008, 'train_steps_per_second': 1.229, 'train_loss': 4.656889279683431, 'epoch': 3.0}
[INFO][21:13:39]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3350396.pth.
[INFO][21:13:39]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][21:13:40]: [Client #53] Model trained.
[INFO][21:13:40]: [Client #53] Inbound data has been processed.
[INFO][21:13:40]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][21:13:40]: [Client #4] Model trained.
[INFO][21:13:40]: [Client #4] Inbound data has been processed.
[INFO][21:13:40]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][21:13:46]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:13:46]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:13:47]: [Server #3350301] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][21:13:47]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][21:13:47]: [Server #3350301] Selecting client #70 for training.
[INFO][21:13:47]: [Server #3350301] Sending the current model to client #70 (simulated).
[INFO][21:13:50]: [Server #3350301] Sending 507.38 MB of payload data to client #70 (simulated).
[INFO][21:13:50]: [Client #70] Selected by the server.
[INFO][21:13:50]: [Client #70] Loading its data source...
[INFO][21:13:50]: [Client #70] Dataset size: 2018
[INFO][21:13:50]: [Client #70] Sampler: iid
[INFO][21:13:52]: [Client #70] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:13:52]: [Client #70] Start to process inbound data.
[INFO][21:13:52]: [93m[1m[Client #70] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:56,  3.76s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.08it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.00it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.20it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:14:23]: [Client #70] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_70_3350395.pth.
{'train_runtime': 26.0647, 'train_samples_per_second': 232.268, 'train_steps_per_second': 1.842, 'train_loss': 4.636425018310547, 'epoch': 3.0}
[INFO][21:14:24]: [Client #70] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_70_3350395.pth.
[INFO][21:14:25]: [Client #70] Model trained.
[INFO][21:14:25]: [Client #70] Inbound data has been processed.
[INFO][21:14:25]: [Client #70] Outbound data is ready to be sent after being processed.
[INFO][21:14:28]: [Client #70] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:14:29]: [Server #3350301] Received 507.38 MB of payload data from client #70 (simulated).
[INFO][21:14:29]: [Server #3350301] Selecting client #30 for training.
[INFO][21:14:29]: [Server #3350301] Sending the current model to client #30 (simulated).
[INFO][21:14:32]: [Server #3350301] Sending 507.38 MB of payload data to client #30 (simulated).
[INFO][21:14:32]: [Client #30] Selected by the server.
[INFO][21:14:32]: [Client #30] Loading its data source...
[INFO][21:14:32]: [Client #30] Dataset size: 2018
[INFO][21:14:32]: [Client #30] Sampler: iid
[INFO][21:14:33]: [Client #30] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:14:33]: [Client #30] Start to process inbound data.
[INFO][21:14:34]: [93m[1m[Client #30] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:56,  3.75s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.78it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.87it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:08<00:17,  2.02it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.04it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:15,  2.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:17<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.13it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  1.85it/s]
[INFO][21:15:05]: [Client #30] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_30_3350395.pth.
{'train_runtime': 25.9957, 'train_samples_per_second': 232.885, 'train_steps_per_second': 1.846, 'train_loss': 4.65073839823405, 'epoch': 3.0}
[INFO][21:15:06]: [Client #30] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_30_3350395.pth.
[INFO][21:15:06]: [Client #30] Model trained.
[INFO][21:15:06]: [Client #30] Inbound data has been processed.
[INFO][21:15:06]: [Client #30] Outbound data is ready to be sent after being processed.
[INFO][21:15:10]: [Client #30] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:15:11]: [Server #3350301] Received 507.38 MB of payload data from client #30 (simulated).
[INFO][21:15:11]: [Server #3350301] Selecting client #14 for training.
[INFO][21:15:11]: [Server #3350301] Sending the current model to client #14 (simulated).
[INFO][21:15:14]: [Server #3350301] Sending 507.38 MB of payload data to client #14 (simulated).
[INFO][21:15:14]: [Client #14] Selected by the server.
[INFO][21:15:14]: [Client #14] Loading its data source...
[INFO][21:15:14]: [Client #14] Dataset size: 2018
[INFO][21:15:14]: [Client #14] Sampler: iid
[INFO][21:15:15]: [Client #14] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:15:15]: [Client #14] Start to process inbound data.
[INFO][21:15:15]: [93m[1m[Client #14] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:56,  3.75s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.78it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.87it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:15,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.13it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  1.85it/s]
[INFO][21:15:47]: [Client #14] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3350395.pth.
{'train_runtime': 26.0013, 'train_samples_per_second': 232.834, 'train_steps_per_second': 1.846, 'train_loss': 4.655802090962728, 'epoch': 3.0}
[INFO][21:15:48]: [Client #14] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3350395.pth.
[INFO][21:15:48]: [Client #14] Model trained.
[INFO][21:15:48]: [Client #14] Inbound data has been processed.
[INFO][21:15:48]: [Client #14] Outbound data is ready to be sent after being processed.
[INFO][21:15:52]: [Client #14] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:15:52]: [Server #3350301] Received 507.38 MB of payload data from client #14 (simulated).
[INFO][21:15:52]: [Server #3350301] Adding client #14 to the list of clients for aggregation.
[INFO][21:15:52]: [Server #3350301] Adding client #53 to the list of clients for aggregation.
[INFO][21:15:52]: [Server #3350301] Adding client #70 to the list of clients for aggregation.
[INFO][21:15:52]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][21:15:52]: [Server #3350301] Adding client #84 to the list of clients for aggregation.
[INFO][21:15:52]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:15:52]: [Server #3350301] Updated weights have been received.
[INFO][21:15:53]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:15:54]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:15:54]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.92it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.54it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.87it/s]
[INFO][21:16:03]: [93m[1m[Server #3350301] Global model perplexity: 80.44
[0m
[INFO][21:16:03]: [Server #3350301] All client reports have been processed.
[INFO][21:16:03]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_2.pth.
[INFO][21:16:06]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_2.pth.
[INFO][21:16:06]: [93m[1m
[Server #3350301] Starting round 3/100.[0m
[INFO][21:16:06]: [Server #3350301] Selected clients: [59, 67, 92, 1, 69]
[INFO][21:16:06]: [Server #3350301] Selecting client #92 for training.
[INFO][21:16:06]: [Server #3350301] Sending the current model to client #92 (simulated).
[INFO][21:16:10]: [Server #3350301] Sending 507.38 MB of payload data to client #92 (simulated).
[INFO][21:16:10]: [Server #3350301] Selecting client #1 for training.
[INFO][21:16:10]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:16:13]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:16:13]: [Client #92] Selected by the server.
[INFO][21:16:13]: [Client #92] Loading its data source...
[INFO][21:16:13]: [Client #92] Dataset size: 2018
[INFO][21:16:13]: [Client #92] Sampler: iid
[INFO][21:16:13]: [Client #1] Selected by the server.
[INFO][21:16:13]: [Client #1] Loading its data source...
[INFO][21:16:13]: [Client #1] Dataset size: 2018
[INFO][21:16:13]: [Client #1] Sampler: iid
[INFO][21:16:14]: [Client #92] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:16:14]: [Client #92] Start to process inbound data.
[INFO][21:16:14]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:16:14]: [Client #1] Start to process inbound data.
[INFO][21:16:15]: [93m[1m[Client #92] Started training in communication round #3.[0m
[INFO][21:16:15]: [93m[1m[Client #1] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:21,  4.28s/it]  2%|â–         | 1/48 [00:04<03:24,  4.34s/it]  4%|â–         | 2/48 [00:05<01:41,  2.21s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.57s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][21:17:00]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.0831, 'train_samples_per_second': 154.901, 'train_steps_per_second': 1.228, 'train_loss': 4.354474385579427, 'epoch': 3.0}
[INFO][21:17:00]: [Client #92] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_92_3350395.pth.
{'train_runtime': 39.1893, 'train_samples_per_second': 154.481, 'train_steps_per_second': 1.225, 'train_loss': 4.327249526977539, 'epoch': 3.0}
[INFO][21:17:01]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:17:01]: [Client #92] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_92_3350395.pth.
[INFO][21:17:01]: [Client #1] Model trained.
[INFO][21:17:01]: [Client #1] Inbound data has been processed.
[INFO][21:17:01]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:17:01]: [Client #92] Model trained.
[INFO][21:17:01]: [Client #92] Inbound data has been processed.
[INFO][21:17:01]: [Client #92] Outbound data is ready to be sent after being processed.
[INFO][21:17:08]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:17:08]: [Client #92] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:17:09]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:17:10]: [Server #3350301] Received 507.38 MB of payload data from client #92 (simulated).
[INFO][21:17:10]: [Server #3350301] Selecting client #67 for training.
[INFO][21:17:10]: [Server #3350301] Sending the current model to client #67 (simulated).
[INFO][21:17:13]: [Server #3350301] Sending 507.38 MB of payload data to client #67 (simulated).
[INFO][21:17:13]: [Server #3350301] Selecting client #69 for training.
[INFO][21:17:13]: [Server #3350301] Sending the current model to client #69 (simulated).
[INFO][21:17:17]: [Server #3350301] Sending 507.38 MB of payload data to client #69 (simulated).
[INFO][21:17:17]: [Client #67] Selected by the server.
[INFO][21:17:17]: [Client #67] Loading its data source...
[INFO][21:17:17]: [Client #67] Dataset size: 2018
[INFO][21:17:17]: [Client #69] Selected by the server.
[INFO][21:17:17]: [Client #67] Sampler: iid
[INFO][21:17:17]: [Client #69] Loading its data source...
[INFO][21:17:17]: [Client #69] Dataset size: 2018
[INFO][21:17:17]: [Client #69] Sampler: iid
[INFO][21:17:18]: [Client #67] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:17:18]: [Client #67] Start to process inbound data.
[INFO][21:17:18]: [Client #69] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:17:18]: [Client #69] Start to process inbound data.
[INFO][21:17:19]: [93m[1m[Client #69] Started training in communication round #3.[0m
[INFO][21:17:19]: [93m[1m[Client #67] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  2%|â–         | 1/48 [00:04<03:21,  4.29s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:22,  1.32it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][21:18:04]: [Client #67] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_67_3350395.pth.
{'train_runtime': 39.0168, 'train_samples_per_second': 155.164, 'train_steps_per_second': 1.23, 'train_loss': 4.335953712463379, 'epoch': 3.0}
[INFO][21:18:04]: [Client #69] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3350396.pth.
{'train_runtime': 39.1024, 'train_samples_per_second': 154.824, 'train_steps_per_second': 1.228, 'train_loss': 4.3340098063151045, 'epoch': 3.0}
[INFO][21:18:05]: [Client #67] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_67_3350395.pth.
[INFO][21:18:05]: [Client #69] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3350396.pth.
[INFO][21:18:05]: [Client #67] Model trained.
[INFO][21:18:05]: [Client #67] Inbound data has been processed.
[INFO][21:18:05]: [Client #67] Outbound data is ready to be sent after being processed.
[INFO][21:18:06]: [Client #69] Model trained.
[INFO][21:18:06]: [Client #69] Inbound data has been processed.
[INFO][21:18:06]: [Client #69] Outbound data is ready to be sent after being processed.
[INFO][21:18:12]: [Client #67] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:18:12]: [Client #69] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:18:13]: [Server #3350301] Received 507.38 MB of payload data from client #67 (simulated).
[INFO][21:18:13]: [Server #3350301] Received 507.38 MB of payload data from client #69 (simulated).
[INFO][21:18:13]: [Server #3350301] Selecting client #59 for training.
[INFO][21:18:13]: [Server #3350301] Sending the current model to client #59 (simulated).
[INFO][21:18:17]: [Server #3350301] Sending 507.38 MB of payload data to client #59 (simulated).
[INFO][21:18:17]: [Client #59] Selected by the server.
[INFO][21:18:17]: [Client #59] Loading its data source...
[INFO][21:18:17]: [Client #59] Dataset size: 2018
[INFO][21:18:17]: [Client #59] Sampler: iid
[INFO][21:18:18]: [Client #59] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:18:18]: [Client #59] Start to process inbound data.
[INFO][21:18:18]: [93m[1m[Client #59] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:57,  3.77s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.08it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:15,  2.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:18:50]: [Client #59] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_59_3350395.pth.
{'train_runtime': 26.0457, 'train_samples_per_second': 232.438, 'train_steps_per_second': 1.843, 'train_loss': 4.317082405090332, 'epoch': 3.0}
[INFO][21:18:50]: [Client #59] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_59_3350395.pth.
[INFO][21:18:51]: [Client #59] Model trained.
[INFO][21:18:51]: [Client #59] Inbound data has been processed.
[INFO][21:18:51]: [Client #59] Outbound data is ready to be sent after being processed.
[INFO][21:18:54]: [Client #59] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:18:55]: [Server #3350301] Received 507.38 MB of payload data from client #59 (simulated).
[INFO][21:18:55]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:18:55]: [Server #3350301] Adding client #59 to the list of clients for aggregation.
[INFO][21:18:55]: [Server #3350301] Adding client #69 to the list of clients for aggregation.
[INFO][21:18:55]: [Server #3350301] Adding client #58 to the list of clients for aggregation.
[INFO][21:18:55]: [Server #3350301] Adding client #64 to the list of clients for aggregation.
[INFO][21:18:55]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:18:55]: [Server #3350301] Updated weights have been received.
[INFO][21:18:56]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:18:56]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:18:56]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.43it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.80it/s]
[INFO][21:19:06]: [93m[1m[Server #3350301] Global model perplexity: 70.30
[0m
[INFO][21:19:06]: [Server #3350301] All client reports have been processed.
[INFO][21:19:06]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_3.pth.
[INFO][21:19:08]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_3.pth.
[INFO][21:19:08]: [93m[1m
[Server #3350301] Starting round 4/100.[0m
[INFO][21:19:08]: [Server #3350301] Selected clients: [1, 2, 3, 43, 38]
[INFO][21:19:08]: [Server #3350301] Selecting client #2 for training.
[INFO][21:19:08]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][21:19:12]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][21:19:12]: [Server #3350301] Selecting client #1 for training.
[INFO][21:19:12]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:19:15]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:19:15]: [Client #2] Selected by the server.
[INFO][21:19:15]: [Client #2] Loading its data source...
[INFO][21:19:15]: [Client #2] Dataset size: 2018
[INFO][21:19:15]: [Client #2] Sampler: iid
[INFO][21:19:15]: [Client #1] Selected by the server.
[INFO][21:19:15]: [Client #1] Loading its data source...
[INFO][21:19:15]: [Client #1] Dataset size: 2018
[INFO][21:19:15]: [Client #1] Sampler: iid
[INFO][21:19:16]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:19:16]: [Client #2] Start to process inbound data.
[INFO][21:19:17]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:19:17]: [Client #1] Start to process inbound data.
[INFO][21:19:17]: [93m[1m[Client #2] Started training in communication round #4.[0m
[INFO][21:19:17]: [93m[1m[Client #1] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<03:04,  3.93s/it]  4%|â–         | 2/48 [00:04<01:27,  1.91s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  6%|â–‹         | 3/48 [00:05<01:02,  1.39s/it]  2%|â–         | 1/48 [00:04<03:50,  4.91s/it]  8%|â–Š         | 4/48 [00:05<00:49,  1.12s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it] 10%|â–ˆ         | 5/48 [00:06<00:42,  1.02it/s]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.10it/s]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:34,  1.17it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:08<00:32,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:30,  1.27it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.30it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:11<00:27,  1.31it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.33it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:14<00:22,  1.41it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:16<00:21,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:17<00:21,  1.33it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:20<00:17,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:23<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.41it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:28<00:09,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:31<00:06,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:34<00:03,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:02,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:37<00:00,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.37it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.52it/s][INFO][21:20:01]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 38.5962, 'train_samples_per_second': 156.855, 'train_steps_per_second': 1.244, 'train_loss': 4.218624114990234, 'epoch': 3.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.72it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][21:20:02]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][21:20:02]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2724, 'train_samples_per_second': 154.154, 'train_steps_per_second': 1.222, 'train_loss': 4.173041343688965, 'epoch': 3.0}
[INFO][21:20:02]: [Client #2] Model trained.
[INFO][21:20:02]: [Client #2] Inbound data has been processed.
[INFO][21:20:02]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][21:20:03]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:20:04]: [Client #1] Model trained.
[INFO][21:20:04]: [Client #1] Inbound data has been processed.
[INFO][21:20:04]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:20:07]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:20:08]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][21:20:09]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:20:10]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:20:10]: [Server #3350301] Selecting client #38 for training.
[INFO][21:20:10]: [Server #3350301] Sending the current model to client #38 (simulated).
[INFO][21:20:13]: [Server #3350301] Sending 507.38 MB of payload data to client #38 (simulated).
[INFO][21:20:13]: [Server #3350301] Selecting client #3 for training.
[INFO][21:20:13]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][21:20:17]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][21:20:17]: [Client #38] Selected by the server.
[INFO][21:20:17]: [Client #38] Loading its data source...
[INFO][21:20:17]: [Client #3] Selected by the server.
[INFO][21:20:17]: [Client #38] Dataset size: 2018
[INFO][21:20:17]: [Client #3] Loading its data source...
[INFO][21:20:17]: [Client #38] Sampler: iid
[INFO][21:20:17]: [Client #3] Dataset size: 2018
[INFO][21:20:17]: [Client #3] Sampler: iid
[INFO][21:20:18]: [Client #38] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:20:18]: [Client #38] Start to process inbound data.
[INFO][21:20:18]: [93m[1m[Client #38] Started training in communication round #4.[0m
[INFO][21:20:18]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:20:18]: [Client #3] Start to process inbound data.
[INFO][21:20:19]: [93m[1m[Client #3] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<03:01,  3.87s/it]  4%|â–         | 2/48 [00:04<01:26,  1.89s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  2%|â–         | 1/48 [00:04<03:42,  4.74s/it]  8%|â–Š         | 4/48 [00:05<00:51,  1.16s/it]  4%|â–         | 2/48 [00:05<01:57,  2.55s/it] 10%|â–ˆ         | 5/48 [00:06<00:48,  1.12s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.80s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:44,  1.07s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.44s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:41,  1.01s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:38,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.12s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:37,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.06s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:35,  1.08it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:33,  1.09it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:31,  1.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:31,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:34,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:26,  1.16it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:29,  1.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:24,  1.22it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:26,  1.23it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:23,  1.25it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:25,  1.23it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:23,  1.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.31it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:22,  1.28it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.32it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:21,  1.28it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:19,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:19,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:12,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.31it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:14,  1.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.30it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:13,  1.29it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.28it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:10,  1.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:09,  1.32it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:31<00:10,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.17it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.47it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.60it/s][INFO][21:21:04]: [Client #38] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_38_3350395.pth.
{'train_runtime': 40.9909, 'train_samples_per_second': 147.691, 'train_steps_per_second': 1.171, 'train_loss': 4.240309079488118, 'epoch': 3.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.79it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.16it/s]
[INFO][21:21:05]: [Client #38] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_38_3350395.pth.
[INFO][21:21:06]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 41.4974, 'train_samples_per_second': 145.889, 'train_steps_per_second': 1.157, 'train_loss': 4.21219539642334, 'epoch': 3.0}
[INFO][21:21:06]: [Client #38] Model trained.
[INFO][21:21:06]: [Client #38] Inbound data has been processed.
[INFO][21:21:06]: [Client #38] Outbound data is ready to be sent after being processed.
[INFO][21:21:07]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][21:21:08]: [Client #3] Model trained.
[INFO][21:21:08]: [Client #3] Inbound data has been processed.
[INFO][21:21:08]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][21:21:10]: [Client #38] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:21:10]: [Server #3350301] Received 507.38 MB of payload data from client #38 (simulated).
[INFO][21:21:12]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:21:13]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][21:21:13]: [Server #3350301] Selecting client #43 for training.
[INFO][21:21:13]: [Server #3350301] Sending the current model to client #43 (simulated).
[INFO][21:21:16]: [Server #3350301] Sending 507.38 MB of payload data to client #43 (simulated).
[INFO][21:21:16]: [Client #43] Selected by the server.
[INFO][21:21:16]: [Client #43] Loading its data source...
[INFO][21:21:16]: [Client #43] Dataset size: 2018
[INFO][21:21:16]: [Client #43] Sampler: iid
[INFO][21:21:17]: [Client #43] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:21:17]: [Client #43] Start to process inbound data.
[INFO][21:21:17]: [93m[1m[Client #43] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:57,  3.78s/it]  4%|â–         | 2/48 [00:04<01:24,  1.84s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.22s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.08it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:28,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:21,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.92it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:21:49]: [Client #43] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3350395.pth.
{'train_runtime': 26.0753, 'train_samples_per_second': 232.174, 'train_steps_per_second': 1.841, 'train_loss': 4.191775639851888, 'epoch': 3.0}
[INFO][21:21:50]: [Client #43] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3350395.pth.
[INFO][21:21:50]: [Client #43] Model trained.
[INFO][21:21:50]: [Client #43] Inbound data has been processed.
[INFO][21:21:50]: [Client #43] Outbound data is ready to be sent after being processed.
[INFO][21:21:54]: [Client #43] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:21:55]: [Server #3350301] Received 507.38 MB of payload data from client #43 (simulated).
[INFO][21:21:55]: [Server #3350301] Adding client #73 to the list of clients for aggregation.
[INFO][21:21:55]: [Server #3350301] Adding client #98 to the list of clients for aggregation.
[INFO][21:21:55]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:21:55]: [Server #3350301] Adding client #43 to the list of clients for aggregation.
[INFO][21:21:55]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][21:21:55]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:21:55]: [Server #3350301] Updated weights have been received.
[INFO][21:21:55]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:21:56]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:21:56]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.67it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.93it/s]
[INFO][21:22:05]: [93m[1m[Server #3350301] Global model perplexity: 63.89
[0m
[INFO][21:22:05]: [Server #3350301] All client reports have been processed.
[INFO][21:22:05]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_4.pth.
[INFO][21:22:08]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_4.pth.
[INFO][21:22:08]: [93m[1m
[Server #3350301] Starting round 5/100.[0m
[INFO][21:22:08]: [Server #3350301] Selected clients: [97, 20, 51, 6, 5]
[INFO][21:22:08]: [Server #3350301] Selecting client #20 for training.
[INFO][21:22:08]: [Server #3350301] Sending the current model to client #20 (simulated).
[INFO][21:22:12]: [Server #3350301] Sending 507.38 MB of payload data to client #20 (simulated).
[INFO][21:22:12]: [Server #3350301] Selecting client #97 for training.
[INFO][21:22:12]: [Server #3350301] Sending the current model to client #97 (simulated).
[INFO][21:22:15]: [Server #3350301] Sending 507.38 MB of payload data to client #97 (simulated).
[INFO][21:22:15]: [Client #20] Selected by the server.
[INFO][21:22:15]: [Client #20] Loading its data source...
[INFO][21:22:15]: [Client #20] Dataset size: 2018
[INFO][21:22:15]: [Client #20] Sampler: iid
[INFO][21:22:15]: [Client #97] Selected by the server.
[INFO][21:22:15]: [Client #97] Loading its data source...
[INFO][21:22:15]: [Client #97] Dataset size: 2018
[INFO][21:22:15]: [Client #97] Sampler: iid
[INFO][21:22:16]: [Client #20] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:22:16]: [Client #20] Start to process inbound data.
[INFO][21:22:16]: [Client #97] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:22:16]: [Client #97] Start to process inbound data.
[INFO][21:22:16]: [93m[1m[Client #20] Started training in communication round #5.[0m
[INFO][21:22:16]: [93m[1m[Client #97] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:29,  4.45s/it]  2%|â–         | 1/48 [00:04<03:32,  4.51s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.39s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.41s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.21s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.07s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:39,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
[INFO][21:23:02]: [Client #20] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_20_3350395.pth.
{'train_runtime': 39.9582, 'train_samples_per_second': 151.508, 'train_steps_per_second': 1.201, 'train_loss': 4.146114667256673, 'epoch': 3.0}
[INFO][21:23:02]: [Client #97] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_97_3350396.pth.
{'train_runtime': 40.0885, 'train_samples_per_second': 151.016, 'train_steps_per_second': 1.197, 'train_loss': 4.140454292297363, 'epoch': 3.0}
[INFO][21:23:03]: [Client #20] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_20_3350395.pth.
[INFO][21:23:03]: [Client #97] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_97_3350396.pth.
[INFO][21:23:04]: [Client #20] Model trained.
[INFO][21:23:04]: [Client #20] Inbound data has been processed.
[INFO][21:23:04]: [Client #20] Outbound data is ready to be sent after being processed.
[INFO][21:23:04]: [Client #97] Model trained.
[INFO][21:23:04]: [Client #97] Inbound data has been processed.
[INFO][21:23:04]: [Client #97] Outbound data is ready to be sent after being processed.
[INFO][21:23:10]: [Client #20] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:23:10]: [Client #97] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:23:11]: [Server #3350301] Received 507.38 MB of payload data from client #20 (simulated).
[INFO][21:23:12]: [Server #3350301] Received 507.38 MB of payload data from client #97 (simulated).
[INFO][21:23:12]: [Server #3350301] Selecting client #6 for training.
[INFO][21:23:12]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][21:23:15]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][21:23:15]: [Server #3350301] Selecting client #51 for training.
[INFO][21:23:15]: [Server #3350301] Sending the current model to client #51 (simulated).
[INFO][21:23:19]: [Server #3350301] Sending 507.38 MB of payload data to client #51 (simulated).
[INFO][21:23:19]: [Client #6] Selected by the server.
[INFO][21:23:19]: [Client #6] Loading its data source...
[INFO][21:23:19]: [Client #6] Dataset size: 2018
[INFO][21:23:19]: [Client #6] Sampler: iid
[INFO][21:23:19]: [Client #51] Selected by the server.
[INFO][21:23:19]: [Client #51] Loading its data source...
[INFO][21:23:19]: [Client #51] Dataset size: 2018
[INFO][21:23:19]: [Client #51] Sampler: iid
[INFO][21:23:20]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:23:20]: [Client #6] Start to process inbound data.
[INFO][21:23:20]: [Client #51] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:23:20]: [Client #51] Start to process inbound data.
[INFO][21:23:21]: [93m[1m[Client #51] Started training in communication round #5.[0m
[INFO][21:23:21]: [93m[1m[Client #6] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:23,  4.34s/it]  2%|â–         | 1/48 [00:04<03:25,  4.37s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:05<01:44,  2.28s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.59s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.23s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.07s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.30it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.31it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:19,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.30it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:24:06]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.4398, 'train_samples_per_second': 153.5, 'train_steps_per_second': 1.217, 'train_loss': 4.161855061848958, 'epoch': 3.0}
[INFO][21:24:06]: [Client #51] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_51_3350396.pth.
{'train_runtime': 39.5355, 'train_samples_per_second': 153.128, 'train_steps_per_second': 1.214, 'train_loss': 4.11631965637207, 'epoch': 3.0}
[INFO][21:24:07]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][21:24:07]: [Client #51] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_51_3350396.pth.
[INFO][21:24:07]: [Client #6] Model trained.
[INFO][21:24:07]: [Client #6] Inbound data has been processed.
[INFO][21:24:07]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][21:24:07]: [Client #51] Model trained.
[INFO][21:24:07]: [Client #51] Inbound data has been processed.
[INFO][21:24:07]: [Client #51] Outbound data is ready to be sent after being processed.
[INFO][21:24:13]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:24:14]: [Client #51] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:24:14]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][21:24:15]: [Server #3350301] Received 507.38 MB of payload data from client #51 (simulated).
[INFO][21:24:15]: [Server #3350301] Selecting client #5 for training.
[INFO][21:24:15]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][21:24:18]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][21:24:18]: [Client #5] Selected by the server.
[INFO][21:24:18]: [Client #5] Loading its data source...
[INFO][21:24:18]: [Client #5] Dataset size: 2018
[INFO][21:24:18]: [Client #5] Sampler: iid
[INFO][21:24:20]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:24:20]: [Client #5] Start to process inbound data.
[INFO][21:24:20]: [93m[1m[Client #5] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:55,  3.73s/it]  4%|â–         | 2/48 [00:04<01:23,  1.82s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.92it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.00it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:24:51]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 26.0388, 'train_samples_per_second': 232.499, 'train_steps_per_second': 1.843, 'train_loss': 4.12453015645345, 'epoch': 3.0}
[INFO][21:24:52]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][21:24:52]: [Client #5] Model trained.
[INFO][21:24:52]: [Client #5] Inbound data has been processed.
[INFO][21:24:52]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][21:24:56]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:24:57]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][21:24:57]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][21:24:57]: [Server #3350301] Adding client #30 to the list of clients for aggregation.
[INFO][21:24:57]: [Server #3350301] Adding client #38 to the list of clients for aggregation.
[INFO][21:24:57]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][21:24:57]: [Server #3350301] Adding client #97 to the list of clients for aggregation.
[INFO][21:24:57]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:24:57]: [Server #3350301] Updated weights have been received.
[INFO][21:24:57]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:24:58]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:24:58]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.46it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.49it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.84it/s]
[INFO][21:25:07]: [93m[1m[Server #3350301] Global model perplexity: 54.20
[0m
[INFO][21:25:07]: [Server #3350301] All client reports have been processed.
[INFO][21:25:08]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_5.pth.
[INFO][21:25:10]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_5.pth.
[INFO][21:25:10]: [93m[1m
[Server #3350301] Starting round 6/100.[0m
[INFO][21:25:10]: [Server #3350301] Selected clients: [1, 2, 8, 95, 3]
[INFO][21:25:10]: [Server #3350301] Selecting client #2 for training.
[INFO][21:25:10]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][21:25:14]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][21:25:14]: [Server #3350301] Selecting client #1 for training.
[INFO][21:25:14]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:25:17]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:25:17]: [Client #2] Selected by the server.
[INFO][21:25:17]: [Client #2] Loading its data source...
[INFO][21:25:17]: [Client #2] Dataset size: 2018
[INFO][21:25:17]: [Client #2] Sampler: iid
[INFO][21:25:17]: [Client #1] Selected by the server.
[INFO][21:25:17]: [Client #1] Loading its data source...
[INFO][21:25:17]: [Client #1] Dataset size: 2018
[INFO][21:25:17]: [Client #1] Sampler: iid
[INFO][21:25:18]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:25:18]: [Client #2] Start to process inbound data.
[INFO][21:25:18]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:25:18]: [Client #1] Start to process inbound data.
[INFO][21:25:19]: [93m[1m[Client #2] Started training in communication round #6.[0m
[INFO][21:25:19]: [93m[1m[Client #1] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:34,  4.57s/it]  2%|â–         | 1/48 [00:04<03:36,  4.60s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.71s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.00it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:26:04]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.6726, 'train_samples_per_second': 152.599, 'train_steps_per_second': 1.21, 'train_loss': 3.9642505645751953, 'epoch': 3.0}
[INFO][21:26:04]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.7677, 'train_samples_per_second': 152.234, 'train_steps_per_second': 1.207, 'train_loss': 4.007867813110352, 'epoch': 3.0}
[INFO][21:26:05]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:26:05]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][21:26:05]: [Client #1] Model trained.
[INFO][21:26:05]: [Client #1] Inbound data has been processed.
[INFO][21:26:05]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:26:06]: [Client #2] Model trained.
[INFO][21:26:06]: [Client #2] Inbound data has been processed.
[INFO][21:26:06]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][21:26:12]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:26:12]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:26:13]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:26:14]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][21:26:14]: [Server #3350301] Selecting client #8 for training.
[INFO][21:26:14]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][21:26:17]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][21:26:17]: [Server #3350301] Selecting client #3 for training.
[INFO][21:26:17]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][21:26:21]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][21:26:21]: [Client #8] Selected by the server.
[INFO][21:26:21]: [Client #8] Loading its data source...
[INFO][21:26:21]: [Client #3] Selected by the server.
[INFO][21:26:21]: [Client #8] Dataset size: 2018
[INFO][21:26:21]: [Client #8] Sampler: iid
[INFO][21:26:21]: [Client #3] Loading its data source...
[INFO][21:26:21]: [Client #3] Dataset size: 2018
[INFO][21:26:21]: [Client #3] Sampler: iid
[INFO][21:26:22]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:26:22]: [Client #3] Start to process inbound data.
[INFO][21:26:22]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:26:22]: [Client #8] Start to process inbound data.
[INFO][21:26:23]: [93m[1m[Client #3] Started training in communication round #6.[0m
[INFO][21:26:23]: [93m[1m[Client #8] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:28,  4.45s/it]  2%|â–         | 1/48 [00:04<03:30,  4.47s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][21:27:08]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.2934, 'train_samples_per_second': 154.072, 'train_steps_per_second': 1.222, 'train_loss': 4.055720329284668, 'epoch': 3.0}
[INFO][21:27:08]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.38, 'train_samples_per_second': 153.733, 'train_steps_per_second': 1.219, 'train_loss': 3.973893483479818, 'epoch': 3.0}
[INFO][21:27:09]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][21:27:09]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][21:27:09]: [Client #8] Model trained.
[INFO][21:27:09]: [Client #8] Inbound data has been processed.
[INFO][21:27:09]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][21:27:09]: [Client #3] Model trained.
[INFO][21:27:09]: [Client #3] Inbound data has been processed.
[INFO][21:27:09]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][21:27:15]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:27:16]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:27:16]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][21:27:17]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][21:27:17]: [Server #3350301] Selecting client #95 for training.
[INFO][21:27:17]: [Server #3350301] Sending the current model to client #95 (simulated).
[INFO][21:27:21]: [Server #3350301] Sending 507.38 MB of payload data to client #95 (simulated).
[INFO][21:27:21]: [Client #95] Selected by the server.
[INFO][21:27:21]: [Client #95] Loading its data source...
[INFO][21:27:21]: [Client #95] Dataset size: 2018
[INFO][21:27:21]: [Client #95] Sampler: iid
[INFO][21:27:22]: [Client #95] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:27:22]: [Client #95] Start to process inbound data.
[INFO][21:27:22]: [93m[1m[Client #95] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:56,  3.75s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.08it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:27:53]: [Client #95] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_95_3350395.pth.
{'train_runtime': 26.0362, 'train_samples_per_second': 232.522, 'train_steps_per_second': 1.844, 'train_loss': 4.031405448913574, 'epoch': 3.0}
[INFO][21:27:54]: [Client #95] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_95_3350395.pth.
[INFO][21:27:55]: [Client #95] Model trained.
[INFO][21:27:55]: [Client #95] Inbound data has been processed.
[INFO][21:27:55]: [Client #95] Outbound data is ready to be sent after being processed.
[INFO][21:27:58]: [Client #95] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:27:59]: [Server #3350301] Received 507.38 MB of payload data from client #95 (simulated).
[INFO][21:27:59]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:27:59]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][21:27:59]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][21:27:59]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][21:27:59]: [Server #3350301] Adding client #67 to the list of clients for aggregation.
[INFO][21:27:59]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:27:59]: [Server #3350301] Updated weights have been received.
[INFO][21:28:00]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:28:00]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:28:00]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.57it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.86it/s]
[INFO][21:28:10]: [93m[1m[Server #3350301] Global model perplexity: 48.45
[0m
[INFO][21:28:10]: [Server #3350301] All client reports have been processed.
[INFO][21:28:10]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_6.pth.
[INFO][21:28:12]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_6.pth.
[INFO][21:28:12]: [93m[1m
[Server #3350301] Starting round 7/100.[0m
[INFO][21:28:12]: [Server #3350301] Selected clients: [1, 2, 74, 42, 80]
[INFO][21:28:12]: [Server #3350301] Selecting client #80 for training.
[INFO][21:28:12]: [Server #3350301] Sending the current model to client #80 (simulated).
[INFO][21:28:16]: [Server #3350301] Sending 507.38 MB of payload data to client #80 (simulated).
[INFO][21:28:16]: [Server #3350301] Selecting client #1 for training.
[INFO][21:28:16]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:28:19]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:28:19]: [Client #80] Selected by the server.
[INFO][21:28:19]: [Client #80] Loading its data source...
[INFO][21:28:19]: [Client #80] Dataset size: 2018
[INFO][21:28:19]: [Client #1] Selected by the server.
[INFO][21:28:19]: [Client #80] Sampler: iid
[INFO][21:28:19]: [Client #1] Loading its data source...
[INFO][21:28:19]: [Client #1] Dataset size: 2018
[INFO][21:28:19]: [Client #1] Sampler: iid
[INFO][21:28:21]: [Client #80] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:28:21]: [Client #80] Start to process inbound data.
[INFO][21:28:21]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:28:21]: [Client #1] Start to process inbound data.
[INFO][21:28:22]: [93m[1m[Client #1] Started training in communication round #7.[0m
[INFO][21:28:22]: [93m[1m[Client #80] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  2%|â–         | 1/48 [00:04<03:45,  4.81s/it]  4%|â–         | 2/48 [00:04<01:40,  2.18s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][21:29:06]: [Client #80] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_80_3350395.pth.
{'train_runtime': 39.1069, 'train_samples_per_second': 154.806, 'train_steps_per_second': 1.227, 'train_loss': 3.938819249471029, 'epoch': 3.0}
[INFO][21:29:07]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4747, 'train_samples_per_second': 153.364, 'train_steps_per_second': 1.216, 'train_loss': 3.817382494608561, 'epoch': 3.0}
[INFO][21:29:07]: [Client #80] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_80_3350395.pth.
[INFO][21:29:08]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:29:08]: [Client #80] Model trained.
[INFO][21:29:08]: [Client #80] Inbound data has been processed.
[INFO][21:29:08]: [Client #80] Outbound data is ready to be sent after being processed.
[INFO][21:29:08]: [Client #1] Model trained.
[INFO][21:29:08]: [Client #1] Inbound data has been processed.
[INFO][21:29:08]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:29:14]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:29:14]: [Client #80] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:29:15]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:29:16]: [Server #3350301] Received 507.38 MB of payload data from client #80 (simulated).
[INFO][21:29:16]: [Server #3350301] Selecting client #2 for training.
[INFO][21:29:16]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][21:29:20]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][21:29:20]: [Client #2] Selected by the server.
[INFO][21:29:20]: [Client #2] Loading its data source...
[INFO][21:29:20]: [Client #2] Dataset size: 2018
[INFO][21:29:20]: [Client #2] Sampler: iid
[INFO][21:29:21]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:29:21]: [Client #2] Start to process inbound data.
[INFO][21:29:21]: [93m[1m[Client #2] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:55,  3.73s/it]  4%|â–         | 2/48 [00:04<01:23,  1.82s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.20s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.78it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:08<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:15,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:17<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  1.85it/s]
[INFO][21:29:52]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 25.9909, 'train_samples_per_second': 232.927, 'train_steps_per_second': 1.847, 'train_loss': 3.848435401916504, 'epoch': 3.0}
[INFO][21:29:53]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][21:29:54]: [Client #2] Model trained.
[INFO][21:29:54]: [Client #2] Inbound data has been processed.
[INFO][21:29:54]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][21:29:57]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:29:58]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][21:29:58]: [Server #3350301] Selecting client #74 for training.
[INFO][21:29:58]: [Server #3350301] Sending the current model to client #74 (simulated).
[INFO][21:30:02]: [Server #3350301] Sending 507.38 MB of payload data to client #74 (simulated).
[INFO][21:30:02]: [Client #74] Selected by the server.
[INFO][21:30:02]: [Client #74] Loading its data source...
[INFO][21:30:02]: [Client #74] Dataset size: 2018
[INFO][21:30:02]: [Client #74] Sampler: iid
[INFO][21:30:03]: [Client #74] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:30:03]: [Client #74] Start to process inbound data.
[INFO][21:30:03]: [93m[1m[Client #74] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:55,  3.73s/it]  4%|â–         | 2/48 [00:04<01:23,  1.82s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.20s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:08<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:15,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.15it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.83it/s]
[INFO][21:30:35]: [Client #74] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_74_3350395.pth.
{'train_runtime': 26.2885, 'train_samples_per_second': 230.291, 'train_steps_per_second': 1.826, 'train_loss': 3.9588244756062827, 'epoch': 3.0}
[INFO][21:30:36]: [Client #74] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_74_3350395.pth.
[INFO][21:30:36]: [Client #74] Model trained.
[INFO][21:30:36]: [Client #74] Inbound data has been processed.
[INFO][21:30:36]: [Client #74] Outbound data is ready to be sent after being processed.
[INFO][21:30:40]: [Client #74] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:30:40]: [Server #3350301] Received 507.38 MB of payload data from client #74 (simulated).
[INFO][21:30:40]: [Server #3350301] Selecting client #42 for training.
[INFO][21:30:40]: [Server #3350301] Sending the current model to client #42 (simulated).
[INFO][21:30:44]: [Server #3350301] Sending 507.38 MB of payload data to client #42 (simulated).
[INFO][21:30:44]: [Client #42] Selected by the server.
[INFO][21:30:44]: [Client #42] Loading its data source...
[INFO][21:30:44]: [Client #42] Dataset size: 2018
[INFO][21:30:44]: [Client #42] Sampler: iid
[INFO][21:30:45]: [Client #42] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:30:45]: [Client #42] Start to process inbound data.
[INFO][21:30:45]: [93m[1m[Client #42] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:54,  3.72s/it]  4%|â–         | 2/48 [00:04<01:23,  1.81s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.20s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.78it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.87it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:08<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:17<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:25<00:00,  1.85it/s]
[INFO][21:31:17]: [Client #42] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_42_3350395.pth.
{'train_runtime': 25.9979, 'train_samples_per_second': 232.865, 'train_steps_per_second': 1.846, 'train_loss': 3.9733673731486, 'epoch': 3.0}
[INFO][21:31:17]: [Client #42] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_42_3350395.pth.
[INFO][21:31:18]: [Client #42] Model trained.
[INFO][21:31:18]: [Client #42] Inbound data has been processed.
[INFO][21:31:18]: [Client #42] Outbound data is ready to be sent after being processed.
[INFO][21:31:22]: [Client #42] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:31:23]: [Server #3350301] Received 507.38 MB of payload data from client #42 (simulated).
[INFO][21:31:23]: [Server #3350301] Adding client #92 to the list of clients for aggregation.
[INFO][21:31:23]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][21:31:23]: [Server #3350301] Adding client #95 to the list of clients for aggregation.
[INFO][21:31:23]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:31:23]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][21:31:23]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:31:23]: [Server #3350301] Updated weights have been received.
[INFO][21:31:23]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:31:24]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:31:24]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.55it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.86it/s]
[INFO][21:31:33]: [93m[1m[Server #3350301] Global model perplexity: 45.76
[0m
[INFO][21:31:33]: [Server #3350301] All client reports have been processed.
[INFO][21:31:34]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_7.pth.
[INFO][21:31:36]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_7.pth.
[INFO][21:31:36]: [93m[1m
[Server #3350301] Starting round 8/100.[0m
[INFO][21:31:36]: [Server #3350301] Selected clients: [1, 11, 45, 86, 94]
[INFO][21:31:36]: [Server #3350301] Selecting client #86 for training.
[INFO][21:31:36]: [Server #3350301] Sending the current model to client #86 (simulated).
[INFO][21:31:40]: [Server #3350301] Sending 507.38 MB of payload data to client #86 (simulated).
[INFO][21:31:40]: [Server #3350301] Selecting client #1 for training.
[INFO][21:31:40]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:31:43]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:31:43]: [Client #86] Selected by the server.
[INFO][21:31:43]: [Client #86] Loading its data source...
[INFO][21:31:43]: [Client #86] Dataset size: 2018
[INFO][21:31:43]: [Client #86] Sampler: iid
[INFO][21:31:43]: [Client #1] Selected by the server.
[INFO][21:31:43]: [Client #1] Loading its data source...
[INFO][21:31:43]: [Client #1] Dataset size: 2018
[INFO][21:31:43]: [Client #1] Sampler: iid
[INFO][21:31:44]: [Client #86] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:31:44]: [Client #86] Start to process inbound data.
[INFO][21:31:44]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:31:44]: [Client #1] Start to process inbound data.
[INFO][21:31:45]: [93m[1m[Client #1] Started training in communication round #8.[0m
[INFO][21:31:45]: [93m[1m[Client #86] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:25,  4.38s/it]  2%|â–         | 1/48 [00:04<03:29,  4.45s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.67s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it]  8%|â–Š         | 4/48 [00:06<00:57,  1.30s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:32:30]: [Client #86] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_86_3350395.pth.
{'train_runtime': 39.6256, 'train_samples_per_second': 152.78, 'train_steps_per_second': 1.211, 'train_loss': 3.8882935841878257, 'epoch': 3.0}
[INFO][21:32:30]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.7738, 'train_samples_per_second': 152.211, 'train_steps_per_second': 1.207, 'train_loss': 3.7335516611735025, 'epoch': 3.0}
[INFO][21:32:31]: [Client #86] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_86_3350395.pth.
[INFO][21:32:32]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:32:32]: [Client #86] Model trained.
[INFO][21:32:32]: [Client #86] Inbound data has been processed.
[INFO][21:32:32]: [Client #86] Outbound data is ready to be sent after being processed.
[INFO][21:32:33]: [Client #1] Model trained.
[INFO][21:32:33]: [Client #1] Inbound data has been processed.
[INFO][21:32:33]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:32:37]: [Client #86] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:32:38]: [Server #3350301] Received 507.38 MB of payload data from client #86 (simulated).
[INFO][21:32:39]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:32:39]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:32:39]: [Server #3350301] Selecting client #94 for training.
[INFO][21:32:39]: [Server #3350301] Sending the current model to client #94 (simulated).
[INFO][21:32:43]: [Server #3350301] Sending 507.38 MB of payload data to client #94 (simulated).
[INFO][21:32:43]: [Server #3350301] Selecting client #11 for training.
[INFO][21:32:43]: [Server #3350301] Sending the current model to client #11 (simulated).
[INFO][21:32:46]: [Server #3350301] Sending 507.38 MB of payload data to client #11 (simulated).
[INFO][21:32:46]: [Client #94] Selected by the server.
[INFO][21:32:46]: [Client #94] Loading its data source...
[INFO][21:32:46]: [Client #94] Dataset size: 2018
[INFO][21:32:46]: [Client #11] Selected by the server.
[INFO][21:32:46]: [Client #94] Sampler: iid
[INFO][21:32:46]: [Client #11] Loading its data source...
[INFO][21:32:46]: [Client #11] Dataset size: 2018
[INFO][21:32:46]: [Client #11] Sampler: iid
[INFO][21:32:47]: [Client #11] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:32:47]: [Client #11] Start to process inbound data.
[INFO][21:32:47]: [Client #94] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:32:47]: [Client #94] Start to process inbound data.
[INFO][21:32:48]: [93m[1m[Client #94] Started training in communication round #8.[0m
[INFO][21:32:48]: [93m[1m[Client #11] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.13s/it]  2%|â–         | 1/48 [00:04<03:20,  4.27s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:40,  2.19s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:13,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.30it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.29it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.30it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][21:33:33]: [Client #11] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_11_3350396.pth.
{'train_runtime': 39.1556, 'train_samples_per_second': 154.614, 'train_steps_per_second': 1.226, 'train_loss': 3.8912480672200522, 'epoch': 3.0}
[INFO][21:33:33]: [Client #94] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_94_3350395.pth.
{'train_runtime': 39.2327, 'train_samples_per_second': 154.31, 'train_steps_per_second': 1.223, 'train_loss': 3.9265270233154297, 'epoch': 3.0}
[INFO][21:33:34]: [Client #11] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_11_3350396.pth.
[INFO][21:33:34]: [Client #94] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_94_3350395.pth.
[INFO][21:33:35]: [Client #11] Model trained.
[INFO][21:33:35]: [Client #11] Inbound data has been processed.
[INFO][21:33:35]: [Client #11] Outbound data is ready to be sent after being processed.
[INFO][21:33:35]: [Client #94] Model trained.
[INFO][21:33:35]: [Client #94] Inbound data has been processed.
[INFO][21:33:35]: [Client #94] Outbound data is ready to be sent after being processed.
[INFO][21:33:41]: [Client #94] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:33:41]: [Client #11] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:33:41]: [Server #3350301] Received 507.38 MB of payload data from client #94 (simulated).
[INFO][21:33:42]: [Server #3350301] Received 507.38 MB of payload data from client #11 (simulated).
[INFO][21:33:42]: [Server #3350301] Selecting client #45 for training.
[INFO][21:33:42]: [Server #3350301] Sending the current model to client #45 (simulated).
[INFO][21:33:46]: [Server #3350301] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][21:33:46]: [Client #45] Selected by the server.
[INFO][21:33:46]: [Client #45] Loading its data source...
[INFO][21:33:46]: [Client #45] Dataset size: 2018
[INFO][21:33:46]: [Client #45] Sampler: iid
[INFO][21:33:47]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:33:47]: [Client #45] Start to process inbound data.
[INFO][21:33:47]: [93m[1m[Client #45] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:56,  3.76s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.08it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:34:18]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3350395.pth.
{'train_runtime': 26.0364, 'train_samples_per_second': 232.52, 'train_steps_per_second': 1.844, 'train_loss': 3.8776890436808267, 'epoch': 3.0}
[INFO][21:34:19]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3350395.pth.
[INFO][21:34:19]: [Client #45] Model trained.
[INFO][21:34:19]: [Client #45] Inbound data has been processed.
[INFO][21:34:19]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][21:34:23]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:34:24]: [Server #3350301] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][21:34:24]: [Server #3350301] Adding client #42 to the list of clients for aggregation.
[INFO][21:34:24]: [Server #3350301] Adding client #80 to the list of clients for aggregation.
[INFO][21:34:24]: [Server #3350301] Adding client #74 to the list of clients for aggregation.
[INFO][21:34:24]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:34:24]: [Server #3350301] Adding client #45 to the list of clients for aggregation.
[INFO][21:34:24]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:34:24]: [Server #3350301] Updated weights have been received.
[INFO][21:34:24]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:34:25]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:34:25]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.70it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.93it/s]
[INFO][21:34:34]: [93m[1m[Server #3350301] Global model perplexity: 41.56
[0m
[INFO][21:34:34]: [Server #3350301] All client reports have been processed.
[INFO][21:34:34]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_8.pth.
[INFO][21:34:37]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_8.pth.
[INFO][21:34:37]: [93m[1m
[Server #3350301] Starting round 9/100.[0m
[INFO][21:34:37]: [Server #3350301] Selected clients: [1, 56, 27, 37, 71]
[INFO][21:34:37]: [Server #3350301] Selecting client #56 for training.
[INFO][21:34:37]: [Server #3350301] Sending the current model to client #56 (simulated).
[INFO][21:34:40]: [Server #3350301] Sending 507.38 MB of payload data to client #56 (simulated).
[INFO][21:34:40]: [Server #3350301] Selecting client #1 for training.
[INFO][21:34:40]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:34:44]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:34:44]: [Client #56] Selected by the server.
[INFO][21:34:44]: [Client #56] Loading its data source...
[INFO][21:34:44]: [Client #56] Dataset size: 2018
[INFO][21:34:44]: [Client #1] Selected by the server.
[INFO][21:34:44]: [Client #56] Sampler: iid
[INFO][21:34:44]: [Client #1] Loading its data source...
[INFO][21:34:44]: [Client #1] Dataset size: 2018
[INFO][21:34:44]: [Client #1] Sampler: iid
[INFO][21:34:45]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:34:45]: [Client #1] Start to process inbound data.
[INFO][21:34:45]: [Client #56] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:34:45]: [Client #56] Start to process inbound data.
[INFO][21:34:46]: [93m[1m[Client #56] Started training in communication round #9.[0m
[INFO][21:34:46]: [93m[1m[Client #1] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.19s/it]  2%|â–         | 1/48 [00:04<03:25,  4.37s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:45,  2.30s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.16s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.19s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:46,  1.10s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.02s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:39,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:37,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:39,  1.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:37,  1.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:38,  1.05s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:36,  1.02s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:35,  1.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:29,  1.14it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:29,  1.14it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:27,  1.20it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:27,  1.19it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:25,  1.27it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:24,  1.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:24,  1.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:23,  1.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:23,  1.28it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:22,  1.31it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:22,  1.30it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:21,  1.32it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:21,  1.30it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.29it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.31it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:18,  1.30it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:31<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.17it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.16it/s]
[INFO][21:35:33]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 41.1687, 'train_samples_per_second': 147.054, 'train_steps_per_second': 1.166, 'train_loss': 3.610451062520345, 'epoch': 3.0}
[INFO][21:35:33]: [Client #56] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_56_3350395.pth.
{'train_runtime': 41.4481, 'train_samples_per_second': 146.062, 'train_steps_per_second': 1.158, 'train_loss': 3.8348957697550454, 'epoch': 3.0}
[INFO][21:35:34]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:35:34]: [Client #56] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_56_3350395.pth.
[INFO][21:35:34]: [Client #1] Model trained.
[INFO][21:35:34]: [Client #1] Inbound data has been processed.
[INFO][21:35:34]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:35:34]: [Client #56] Model trained.
[INFO][21:35:34]: [Client #56] Inbound data has been processed.
[INFO][21:35:34]: [Client #56] Outbound data is ready to be sent after being processed.
[INFO][21:35:40]: [Client #56] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:35:41]: [Server #3350301] Received 507.38 MB of payload data from client #56 (simulated).
[INFO][21:35:41]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:35:42]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:35:42]: [Server #3350301] Selecting client #37 for training.
[INFO][21:35:42]: [Server #3350301] Sending the current model to client #37 (simulated).
[INFO][21:35:45]: [Server #3350301] Sending 507.38 MB of payload data to client #37 (simulated).
[INFO][21:35:45]: [Server #3350301] Selecting client #71 for training.
[INFO][21:35:45]: [Server #3350301] Sending the current model to client #71 (simulated).
[INFO][21:35:49]: [Server #3350301] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][21:35:49]: [Client #37] Selected by the server.
[INFO][21:35:49]: [Client #37] Loading its data source...
[INFO][21:35:49]: [Client #37] Dataset size: 2018
[INFO][21:35:49]: [Client #37] Sampler: iid
[INFO][21:35:49]: [Client #71] Selected by the server.
[INFO][21:35:49]: [Client #71] Loading its data source...
[INFO][21:35:49]: [Client #71] Dataset size: 2018
[INFO][21:35:49]: [Client #71] Sampler: iid
[INFO][21:35:50]: [Client #37] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:35:50]: [Client #37] Start to process inbound data.
[INFO][21:35:50]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:35:50]: [Client #71] Start to process inbound data.
[INFO][21:35:50]: [93m[1m[Client #37] Started training in communication round #9.[0m
[INFO][21:35:50]: [93m[1m[Client #71] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.13s/it]  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.33it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][21:36:35]: [Client #37] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3350395.pth.
{'train_runtime': 39.1011, 'train_samples_per_second': 154.83, 'train_steps_per_second': 1.228, 'train_loss': 3.796930948893229, 'epoch': 3.0}
[INFO][21:36:35]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3350396.pth.
{'train_runtime': 39.1175, 'train_samples_per_second': 154.764, 'train_steps_per_second': 1.227, 'train_loss': 3.8104079564412436, 'epoch': 3.0}
[INFO][21:36:36]: [Client #37] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3350395.pth.
[INFO][21:36:36]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3350396.pth.
[INFO][21:36:36]: [Client #37] Model trained.
[INFO][21:36:36]: [Client #37] Inbound data has been processed.
[INFO][21:36:36]: [Client #37] Outbound data is ready to be sent after being processed.
[INFO][21:36:36]: [Client #71] Model trained.
[INFO][21:36:36]: [Client #71] Inbound data has been processed.
[INFO][21:36:36]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][21:36:42]: [Client #37] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:36:43]: [Server #3350301] Received 507.38 MB of payload data from client #37 (simulated).
[INFO][21:36:43]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:36:44]: [Server #3350301] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][21:36:44]: [Server #3350301] Selecting client #27 for training.
[INFO][21:36:44]: [Server #3350301] Sending the current model to client #27 (simulated).
[INFO][21:36:48]: [Server #3350301] Sending 507.38 MB of payload data to client #27 (simulated).
[INFO][21:36:48]: [Client #27] Selected by the server.
[INFO][21:36:48]: [Client #27] Loading its data source...
[INFO][21:36:48]: [Client #27] Dataset size: 2018
[INFO][21:36:48]: [Client #27] Sampler: iid
[INFO][21:36:49]: [Client #27] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:36:49]: [Client #27] Start to process inbound data.
[INFO][21:36:49]: [93m[1m[Client #27] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:56,  3.75s/it]  4%|â–         | 2/48 [00:04<01:24,  1.83s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.22s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.07it/s] 10%|â–ˆ         | 5/48 [00:05<00:33,  1.29it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:28,  1.48it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:25,  1.63it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.74it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.96it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][21:37:21]: [Client #27] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_27_3350395.pth.
{'train_runtime': 26.5631, 'train_samples_per_second': 227.91, 'train_steps_per_second': 1.807, 'train_loss': 3.7983582814534507, 'epoch': 3.0}
[INFO][21:37:22]: [Client #27] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_27_3350395.pth.
[INFO][21:37:23]: [Client #27] Model trained.
[INFO][21:37:23]: [Client #27] Inbound data has been processed.
[INFO][21:37:23]: [Client #27] Outbound data is ready to be sent after being processed.
[INFO][21:37:26]: [Client #27] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:37:27]: [Server #3350301] Received 507.38 MB of payload data from client #27 (simulated).
[INFO][21:37:27]: [Server #3350301] Adding client #94 to the list of clients for aggregation.
[INFO][21:37:27]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:37:27]: [Server #3350301] Adding client #37 to the list of clients for aggregation.
[INFO][21:37:27]: [Server #3350301] Adding client #71 to the list of clients for aggregation.
[INFO][21:37:27]: [Server #3350301] Adding client #27 to the list of clients for aggregation.
[INFO][21:37:27]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:37:27]: [Server #3350301] Updated weights have been received.
[INFO][21:37:27]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:37:28]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:37:28]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.23it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.64it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.89it/s]
[INFO][21:37:37]: [93m[1m[Server #3350301] Global model perplexity: 38.46
[0m
[INFO][21:37:37]: [Server #3350301] All client reports have been processed.
[INFO][21:37:38]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_9.pth.
[INFO][21:37:40]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_9.pth.
[INFO][21:37:40]: [93m[1m
[Server #3350301] Starting round 10/100.[0m
[INFO][21:37:40]: [Server #3350301] Selected clients: [28, 83, 50, 34, 7]
[INFO][21:37:40]: [Server #3350301] Selecting client #34 for training.
[INFO][21:37:40]: [Server #3350301] Sending the current model to client #34 (simulated).
[INFO][21:37:43]: [Server #3350301] Sending 507.38 MB of payload data to client #34 (simulated).
[INFO][21:37:43]: [Server #3350301] Selecting client #83 for training.
[INFO][21:37:44]: [Server #3350301] Sending the current model to client #83 (simulated).
[INFO][21:37:47]: [Server #3350301] Sending 507.38 MB of payload data to client #83 (simulated).
[INFO][21:37:47]: [Client #34] Selected by the server.
[INFO][21:37:47]: [Client #34] Loading its data source...
[INFO][21:37:47]: [Client #34] Dataset size: 2018
[INFO][21:37:47]: [Client #34] Sampler: iid
[INFO][21:37:47]: [Client #83] Selected by the server.
[INFO][21:37:47]: [Client #83] Loading its data source...
[INFO][21:37:47]: [Client #83] Dataset size: 2018
[INFO][21:37:47]: [Client #83] Sampler: iid
[INFO][21:37:48]: [Client #34] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:37:48]: [Client #34] Start to process inbound data.
[INFO][21:37:48]: [Client #83] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:37:48]: [Client #83] Start to process inbound data.
[INFO][21:37:48]: [93m[1m[Client #34] Started training in communication round #10.[0m
[INFO][21:37:49]: [93m[1m[Client #83] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:59,  3.82s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:30,  1.97s/it]  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  6%|â–‹         | 3/48 [00:05<01:05,  1.45s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.19s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.41s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.08s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.02s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.13s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:38,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.05s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:37,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.01s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:36,  1.05it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:34,  1.08it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:33,  1.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:31,  1.11it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.11it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:26,  1.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:24,  1.21it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:26,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:22,  1.26it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:24,  1.23it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:21,  1.30it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:22,  1.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.31it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:21,  1.28it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:19,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:17,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:19,  1.30it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:12,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.37it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:31<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:05,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.17it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.67it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.16it/s]
[INFO][21:38:35]: [Client #34] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_34_3350395.pth.
{'train_runtime': 41.0065, 'train_samples_per_second': 147.635, 'train_steps_per_second': 1.171, 'train_loss': 3.7563680013020835, 'epoch': 3.0}
[INFO][21:38:36]: [Client #34] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_34_3350395.pth.
[INFO][21:38:36]: [Client #83] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_83_3350396.pth.
{'train_runtime': 41.4955, 'train_samples_per_second': 145.895, 'train_steps_per_second': 1.157, 'train_loss': 3.7160619099934897, 'epoch': 3.0}
[INFO][21:38:37]: [Client #34] Model trained.
[INFO][21:38:37]: [Client #34] Inbound data has been processed.
[INFO][21:38:37]: [Client #34] Outbound data is ready to be sent after being processed.
[INFO][21:38:37]: [Client #83] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_83_3350396.pth.
[INFO][21:38:38]: [Client #83] Model trained.
[INFO][21:38:38]: [Client #83] Inbound data has been processed.
[INFO][21:38:38]: [Client #83] Outbound data is ready to be sent after being processed.
[INFO][21:38:41]: [Client #34] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:38:42]: [Server #3350301] Received 507.38 MB of payload data from client #34 (simulated).
[INFO][21:38:43]: [Client #83] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:38:44]: [Server #3350301] Received 507.38 MB of payload data from client #83 (simulated).
[INFO][21:38:44]: [Server #3350301] Selecting client #50 for training.
[INFO][21:38:44]: [Server #3350301] Sending the current model to client #50 (simulated).
[INFO][21:38:47]: [Server #3350301] Sending 507.38 MB of payload data to client #50 (simulated).
[INFO][21:38:47]: [Server #3350301] Selecting client #7 for training.
[INFO][21:38:47]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][21:38:50]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][21:38:50]: [Client #50] Selected by the server.
[INFO][21:38:50]: [Client #50] Loading its data source...
[INFO][21:38:50]: [Client #50] Dataset size: 2018
[INFO][21:38:50]: [Client #50] Sampler: iid
[INFO][21:38:50]: [Client #7] Selected by the server.
[INFO][21:38:50]: [Client #7] Loading its data source...
[INFO][21:38:50]: [Client #7] Dataset size: 2018
[INFO][21:38:50]: [Client #7] Sampler: iid
[INFO][21:38:52]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:38:52]: [Client #7] Start to process inbound data.
[INFO][21:38:52]: [93m[1m[Client #7] Started training in communication round #10.[0m
[INFO][21:38:52]: [Client #50] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:38:52]: [Client #50] Start to process inbound data.
[INFO][21:38:52]: [93m[1m[Client #50] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<03:03,  3.90s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  2%|â–         | 1/48 [00:04<03:31,  4.51s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.73s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.36s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:41,  1.02it/s] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.15s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.01s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:19,  1.31it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:39:37]: [Client #50] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_50_3350395.pth.
{'train_runtime': 39.1567, 'train_samples_per_second': 154.61, 'train_steps_per_second': 1.226, 'train_loss': 3.7465168635050454, 'epoch': 3.0}
[INFO][21:39:37]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.6473, 'train_samples_per_second': 152.696, 'train_steps_per_second': 1.211, 'train_loss': 3.71192200978597, 'epoch': 3.0}
[INFO][21:39:38]: [Client #50] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_50_3350395.pth.
[INFO][21:39:38]: [Client #50] Model trained.
[INFO][21:39:38]: [Client #50] Inbound data has been processed.
[INFO][21:39:38]: [Client #50] Outbound data is ready to be sent after being processed.
[INFO][21:39:38]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][21:39:39]: [Client #7] Model trained.
[INFO][21:39:39]: [Client #7] Inbound data has been processed.
[INFO][21:39:39]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][21:39:42]: [Client #50] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:39:43]: [Server #3350301] Received 507.38 MB of payload data from client #50 (simulated).
[INFO][21:39:44]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:39:45]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][21:39:45]: [Server #3350301] Selecting client #28 for training.
[INFO][21:39:45]: [Server #3350301] Sending the current model to client #28 (simulated).
[INFO][21:39:48]: [Server #3350301] Sending 507.38 MB of payload data to client #28 (simulated).
[INFO][21:39:48]: [Client #28] Selected by the server.
[INFO][21:39:48]: [Client #28] Loading its data source...
[INFO][21:39:48]: [Client #28] Dataset size: 2018
[INFO][21:39:48]: [Client #28] Sampler: iid
[INFO][21:39:49]: [Client #28] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:39:49]: [Client #28] Start to process inbound data.
[INFO][21:39:50]: [93m[1m[Client #28] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:55,  3.72s/it]  4%|â–         | 2/48 [00:04<01:23,  1.81s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.20s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.87it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:08<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:40:21]: [Client #28] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_28_3350395.pth.
{'train_runtime': 26.044, 'train_samples_per_second': 232.452, 'train_steps_per_second': 1.843, 'train_loss': 3.755483309427897, 'epoch': 3.0}
[INFO][21:40:22]: [Client #28] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_28_3350395.pth.
[INFO][21:40:22]: [Client #28] Model trained.
[INFO][21:40:22]: [Client #28] Inbound data has been processed.
[INFO][21:40:22]: [Client #28] Outbound data is ready to be sent after being processed.
[INFO][21:40:26]: [Client #28] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:40:26]: [Server #3350301] Received 507.38 MB of payload data from client #28 (simulated).
[INFO][21:40:26]: [Server #3350301] Adding client #20 to the list of clients for aggregation.
[INFO][21:40:26]: [Server #3350301] Adding client #51 to the list of clients for aggregation.
[INFO][21:40:26]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][21:40:26]: [Server #3350301] Adding client #28 to the list of clients for aggregation.
[INFO][21:40:26]: [Server #3350301] Adding client #34 to the list of clients for aggregation.
[INFO][21:40:26]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:40:26]: [Server #3350301] Updated weights have been received.
[INFO][21:40:27]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:40:27]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:40:27]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.51it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.72it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.93it/s]
[INFO][21:40:37]: [93m[1m[Server #3350301] Global model perplexity: 37.33
[0m
[INFO][21:40:37]: [Server #3350301] All client reports have been processed.
[INFO][21:40:37]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_10.pth.
[INFO][21:40:40]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_10.pth.
[INFO][21:40:40]: [93m[1m
[Server #3350301] Starting round 11/100.[0m
[INFO][21:40:40]: [Server #3350301] Selected clients: [1, 52, 100, 68, 79]
[INFO][21:40:40]: [Server #3350301] Selecting client #100 for training.
[INFO][21:40:40]: [Server #3350301] Sending the current model to client #100 (simulated).
[INFO][21:40:43]: [Server #3350301] Sending 507.38 MB of payload data to client #100 (simulated).
[INFO][21:40:43]: [Server #3350301] Selecting client #1 for training.
[INFO][21:40:43]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:40:46]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:40:46]: [Client #100] Selected by the server.
[INFO][21:40:46]: [Client #100] Loading its data source...
[INFO][21:40:46]: [Client #100] Dataset size: 2018
[INFO][21:40:46]: [Client #100] Sampler: iid
[INFO][21:40:46]: [Client #1] Selected by the server.
[INFO][21:40:46]: [Client #1] Loading its data source...
[INFO][21:40:46]: [Client #1] Dataset size: 2018
[INFO][21:40:46]: [Client #1] Sampler: iid
[INFO][21:40:47]: [Client #100] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:40:47]: [Client #100] Start to process inbound data.
[INFO][21:40:48]: [93m[1m[Client #100] Started training in communication round #11.[0m
[INFO][21:40:48]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:40:48]: [Client #1] Start to process inbound data.
[INFO][21:40:49]: [93m[1m[Client #1] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:59,  3.83s/it]  4%|â–         | 2/48 [00:04<01:26,  1.88s/it]  6%|â–‹         | 3/48 [00:04<00:56,  1.26s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  8%|â–Š         | 4/48 [00:05<00:46,  1.05s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it] 10%|â–ˆ         | 5/48 [00:06<00:39,  1.08it/s]  4%|â–         | 2/48 [00:05<01:57,  2.55s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.10it/s]  6%|â–‹         | 3/48 [00:06<01:20,  1.78s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:37,  1.09it/s]  8%|â–Š         | 4/48 [00:07<01:03,  1.45s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:37,  1.06it/s] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.28s/it] 19%|â–ˆâ–‰        | 9/48 [00:09<00:36,  1.08it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:49,  1.17s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:36,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:45,  1.12s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:35,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:42,  1.06s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:33,  1.07it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.00s/it] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:32,  1.08it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:31,  1.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:29,  1.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:35,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:29,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:26,  1.15it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:24,  1.21it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:28,  1.17it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:23,  1.25it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:25,  1.28it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:24,  1.27it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.31it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:23,  1.27it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:22,  1.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:21,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:20,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:19,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:18,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:17,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:14,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.38it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:13,  1.32it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.40it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:31<00:10,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:06,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.48it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.62it/s][INFO][21:41:34]: [Client #100] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_100_3350395.pth.
{'train_runtime': 40.2969, 'train_samples_per_second': 150.235, 'train_steps_per_second': 1.191, 'train_loss': 3.714843432108561, 'epoch': 3.0}
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.90it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.17it/s]
[INFO][21:41:35]: [Client #100] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_100_3350395.pth.
[INFO][21:41:35]: [Client #100] Model trained.
[INFO][21:41:35]: [Client #100] Inbound data has been processed.
[INFO][21:41:35]: [Client #100] Outbound data is ready to be sent after being processed.
[INFO][21:41:36]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 41.1743, 'train_samples_per_second': 147.034, 'train_steps_per_second': 1.166, 'train_loss': 3.4865039189656577, 'epoch': 3.0}
[INFO][21:41:37]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:41:37]: [Client #1] Model trained.
[INFO][21:41:37]: [Client #1] Inbound data has been processed.
[INFO][21:41:37]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:41:38]: [Client #100] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:41:39]: [Server #3350301] Received 507.38 MB of payload data from client #100 (simulated).
[INFO][21:41:41]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:41:42]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:41:42]: [Server #3350301] Selecting client #68 for training.
[INFO][21:41:42]: [Server #3350301] Sending the current model to client #68 (simulated).
[INFO][21:41:45]: [Server #3350301] Sending 507.38 MB of payload data to client #68 (simulated).
[INFO][21:41:45]: [Server #3350301] Selecting client #79 for training.
[INFO][21:41:45]: [Server #3350301] Sending the current model to client #79 (simulated).
[INFO][21:41:48]: [Server #3350301] Sending 507.38 MB of payload data to client #79 (simulated).
[INFO][21:41:48]: [Client #68] Selected by the server.
[INFO][21:41:48]: [Client #68] Loading its data source...
[INFO][21:41:48]: [Client #68] Dataset size: 2018
[INFO][21:41:48]: [Client #68] Sampler: iid
[INFO][21:41:48]: [Client #79] Selected by the server.
[INFO][21:41:48]: [Client #79] Loading its data source...
[INFO][21:41:48]: [Client #79] Dataset size: 2018
[INFO][21:41:48]: [Client #79] Sampler: iid
[INFO][21:41:49]: [Client #68] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:41:49]: [Client #68] Start to process inbound data.
[INFO][21:41:49]: [Client #79] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:41:49]: [Client #79] Start to process inbound data.
[INFO][21:41:50]: [93m[1m[Client #68] Started training in communication round #11.[0m
[INFO][21:41:50]: [93m[1m[Client #79] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:21,  4.29s/it]  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  4%|â–         | 2/48 [00:05<01:42,  2.23s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.29it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.30it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.30it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:42:35]: [Client #68] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_68_3350395.pth.
{'train_runtime': 39.4314, 'train_samples_per_second': 153.532, 'train_steps_per_second': 1.217, 'train_loss': 3.732046127319336, 'epoch': 3.0}
[INFO][21:42:36]: [Client #79] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_79_3350396.pth.
{'train_runtime': 39.5846, 'train_samples_per_second': 152.938, 'train_steps_per_second': 1.213, 'train_loss': 3.683128039042155, 'epoch': 3.0}
[INFO][21:42:36]: [Client #68] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_68_3350395.pth.
[INFO][21:42:37]: [Client #79] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_79_3350396.pth.
[INFO][21:42:37]: [Client #68] Model trained.
[INFO][21:42:37]: [Client #68] Inbound data has been processed.
[INFO][21:42:37]: [Client #68] Outbound data is ready to be sent after being processed.
[INFO][21:42:37]: [Client #79] Model trained.
[INFO][21:42:37]: [Client #79] Inbound data has been processed.
[INFO][21:42:37]: [Client #79] Outbound data is ready to be sent after being processed.
[INFO][21:42:43]: [Client #68] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:42:43]: [Client #79] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:42:43]: [Server #3350301] Received 507.38 MB of payload data from client #68 (simulated).
[INFO][21:42:44]: [Server #3350301] Received 507.38 MB of payload data from client #79 (simulated).
[INFO][21:42:44]: [Server #3350301] Selecting client #52 for training.
[INFO][21:42:44]: [Server #3350301] Sending the current model to client #52 (simulated).
[INFO][21:42:48]: [Server #3350301] Sending 507.38 MB of payload data to client #52 (simulated).
[INFO][21:42:48]: [Client #52] Selected by the server.
[INFO][21:42:48]: [Client #52] Loading its data source...
[INFO][21:42:48]: [Client #52] Dataset size: 2018
[INFO][21:42:48]: [Client #52] Sampler: iid
[INFO][21:42:49]: [Client #52] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:42:49]: [Client #52] Start to process inbound data.
[INFO][21:42:49]: [93m[1m[Client #52] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:54,  3.72s/it]  4%|â–         | 2/48 [00:04<01:23,  1.81s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.20s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.32it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.51it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.66it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:20,  1.86it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.93it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:08<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:17<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.85it/s]
[INFO][21:43:20]: [Client #52] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_52_3350395.pth.
{'train_runtime': 26.007, 'train_samples_per_second': 232.784, 'train_steps_per_second': 1.846, 'train_loss': 3.723130226135254, 'epoch': 3.0}
[INFO][21:43:21]: [Client #52] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_52_3350395.pth.
[INFO][21:43:22]: [Client #52] Model trained.
[INFO][21:43:22]: [Client #52] Inbound data has been processed.
[INFO][21:43:22]: [Client #52] Outbound data is ready to be sent after being processed.
[INFO][21:43:25]: [Client #52] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:43:26]: [Server #3350301] Received 507.38 MB of payload data from client #52 (simulated).
[INFO][21:43:26]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:43:26]: [Server #3350301] Adding client #11 to the list of clients for aggregation.
[INFO][21:43:26]: [Server #3350301] Adding client #86 to the list of clients for aggregation.
[INFO][21:43:26]: [Server #3350301] Adding client #100 to the list of clients for aggregation.
[INFO][21:43:26]: [Server #3350301] Adding client #56 to the list of clients for aggregation.
[INFO][21:43:26]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:43:26]: [Server #3350301] Updated weights have been received.
[INFO][21:43:27]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:43:27]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:43:27]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.52it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.60it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.89it/s]
[INFO][21:43:37]: [93m[1m[Server #3350301] Global model perplexity: 36.82
[0m
[INFO][21:43:37]: [Server #3350301] All client reports have been processed.
[INFO][21:43:37]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_11.pth.
[INFO][21:43:39]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_11.pth.
[INFO][21:43:39]: [93m[1m
[Server #3350301] Starting round 12/100.[0m
[INFO][21:43:39]: [Server #3350301] Selected clients: [1, 19, 25, 82, 91]
[INFO][21:43:39]: [Server #3350301] Selecting client #82 for training.
[INFO][21:43:39]: [Server #3350301] Sending the current model to client #82 (simulated).
[INFO][21:43:43]: [Server #3350301] Sending 507.38 MB of payload data to client #82 (simulated).
[INFO][21:43:43]: [Server #3350301] Selecting client #1 for training.
[INFO][21:43:43]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:43:46]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:43:46]: [Client #82] Selected by the server.
[INFO][21:43:46]: [Client #82] Loading its data source...
[INFO][21:43:46]: [Client #82] Dataset size: 2018
[INFO][21:43:46]: [Client #82] Sampler: iid
[INFO][21:43:46]: [Client #1] Selected by the server.
[INFO][21:43:46]: [Client #1] Loading its data source...
[INFO][21:43:46]: [Client #1] Dataset size: 2018
[INFO][21:43:46]: [Client #1] Sampler: iid
[INFO][21:43:47]: [Client #82] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:43:47]: [Client #82] Start to process inbound data.
[INFO][21:43:48]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:43:48]: [Client #1] Start to process inbound data.
[INFO][21:43:48]: [93m[1m[Client #82] Started training in communication round #12.[0m
[INFO][21:43:48]: [93m[1m[Client #1] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:38,  2.13s/it]  4%|â–         | 2/48 [00:04<01:40,  2.19s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.49s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:26,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.35it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][21:44:33]: [Client #82] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_82_3350395.pth.
{'train_runtime': 38.9815, 'train_samples_per_second': 155.305, 'train_steps_per_second': 1.231, 'train_loss': 3.7127609252929688, 'epoch': 3.0}
[INFO][21:44:33]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.0726, 'train_samples_per_second': 154.942, 'train_steps_per_second': 1.228, 'train_loss': 3.418429692586263, 'epoch': 3.0}
[INFO][21:44:34]: [Client #82] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_82_3350395.pth.
[INFO][21:44:35]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:44:35]: [Client #82] Model trained.
[INFO][21:44:35]: [Client #82] Inbound data has been processed.
[INFO][21:44:35]: [Client #82] Outbound data is ready to be sent after being processed.
[INFO][21:44:35]: [Client #1] Model trained.
[INFO][21:44:35]: [Client #1] Inbound data has been processed.
[INFO][21:44:35]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:44:41]: [Client #82] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:44:41]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:44:42]: [Server #3350301] Received 507.38 MB of payload data from client #82 (simulated).
[INFO][21:44:43]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:44:43]: [Server #3350301] Selecting client #19 for training.
[INFO][21:44:43]: [Server #3350301] Sending the current model to client #19 (simulated).
[INFO][21:44:46]: [Server #3350301] Sending 507.38 MB of payload data to client #19 (simulated).
[INFO][21:44:46]: [Server #3350301] Selecting client #25 for training.
[INFO][21:44:46]: [Server #3350301] Sending the current model to client #25 (simulated).
[INFO][21:44:50]: [Server #3350301] Sending 507.38 MB of payload data to client #25 (simulated).
[INFO][21:44:50]: [Client #19] Selected by the server.
[INFO][21:44:50]: [Client #25] Selected by the server.
[INFO][21:44:50]: [Client #19] Loading its data source...
[INFO][21:44:50]: [Client #25] Loading its data source...
[INFO][21:44:50]: [Client #19] Dataset size: 2018
[INFO][21:44:50]: [Client #19] Sampler: iid
[INFO][21:44:50]: [Client #25] Dataset size: 2018
[INFO][21:44:50]: [Client #25] Sampler: iid
[INFO][21:44:51]: [Client #25] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:44:51]: [Client #25] Start to process inbound data.
[INFO][21:44:51]: [Client #19] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:44:51]: [Client #19] Start to process inbound data.
[INFO][21:44:52]: [93m[1m[Client #25] Started training in communication round #12.[0m
[INFO][21:44:52]: [93m[1m[Client #19] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:25,  4.38s/it]  2%|â–         | 1/48 [00:04<03:34,  4.56s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  4%|â–         | 2/48 [00:05<01:55,  2.51s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.80s/it]  6%|â–‹         | 3/48 [00:06<01:23,  1.85s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.47s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.47s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.20s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.06s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:39,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.26it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.29it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.29it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.29it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][21:45:38]: [Client #19] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_19_3350395.pth.
{'train_runtime': 40.2722, 'train_samples_per_second': 150.327, 'train_steps_per_second': 1.192, 'train_loss': 3.6803458531697593, 'epoch': 3.0}
[INFO][21:45:38]: [Client #25] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_25_3350396.pth.
{'train_runtime': 40.2859, 'train_samples_per_second': 150.276, 'train_steps_per_second': 1.191, 'train_loss': 3.6748437881469727, 'epoch': 3.0}
[INFO][21:45:39]: [Client #19] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_19_3350395.pth.
[INFO][21:45:39]: [Client #25] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_25_3350396.pth.
[INFO][21:45:40]: [Client #19] Model trained.
[INFO][21:45:40]: [Client #19] Inbound data has been processed.
[INFO][21:45:40]: [Client #19] Outbound data is ready to be sent after being processed.
[INFO][21:45:40]: [Client #25] Model trained.
[INFO][21:45:40]: [Client #25] Inbound data has been processed.
[INFO][21:45:40]: [Client #25] Outbound data is ready to be sent after being processed.
[INFO][21:45:45]: [Client #19] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:45:46]: [Client #25] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:45:46]: [Server #3350301] Received 507.38 MB of payload data from client #19 (simulated).
[INFO][21:45:47]: [Server #3350301] Received 507.38 MB of payload data from client #25 (simulated).
[INFO][21:45:47]: [Server #3350301] Selecting client #91 for training.
[INFO][21:45:47]: [Server #3350301] Sending the current model to client #91 (simulated).
[INFO][21:45:50]: [Server #3350301] Sending 507.38 MB of payload data to client #91 (simulated).
[INFO][21:45:50]: [Client #91] Selected by the server.
[INFO][21:45:50]: [Client #91] Loading its data source...
[INFO][21:45:50]: [Client #91] Dataset size: 2018
[INFO][21:45:50]: [Client #91] Sampler: iid
[INFO][21:45:51]: [Client #91] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:45:51]: [Client #91] Start to process inbound data.
[INFO][21:45:51]: [93m[1m[Client #91] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<02:55,  3.73s/it]  4%|â–         | 2/48 [00:04<01:23,  1.82s/it]  6%|â–‹         | 3/48 [00:04<00:54,  1.21s/it]  8%|â–Š         | 4/48 [00:05<00:40,  1.09it/s] 10%|â–ˆ         | 5/48 [00:05<00:32,  1.31it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:27,  1.50it/s] 15%|â–ˆâ–        | 7/48 [00:06<00:24,  1.65it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:22,  1.77it/s] 19%|â–ˆâ–‰        | 9/48 [00:07<00:21,  1.85it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.92it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.01it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:09<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:10<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:11<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:12<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:13<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:14<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:15<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:16<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:18<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:19<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:20<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:21<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:22<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:23<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:24<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:25<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.20it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.84it/s]
[INFO][21:46:23]: [Client #91] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_91_3350395.pth.
{'train_runtime': 26.0467, 'train_samples_per_second': 232.429, 'train_steps_per_second': 1.843, 'train_loss': 3.6474831899007163, 'epoch': 3.0}
[INFO][21:46:24]: [Client #91] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_91_3350395.pth.
[INFO][21:46:24]: [Client #91] Model trained.
[INFO][21:46:24]: [Client #91] Inbound data has been processed.
[INFO][21:46:24]: [Client #91] Outbound data is ready to be sent after being processed.
[INFO][21:46:28]: [Client #91] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:46:29]: [Server #3350301] Received 507.38 MB of payload data from client #91 (simulated).
[INFO][21:46:29]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:46:29]: [Server #3350301] Adding client #50 to the list of clients for aggregation.
[INFO][21:46:29]: [Server #3350301] Adding client #83 to the list of clients for aggregation.
[INFO][21:46:29]: [Server #3350301] Adding client #91 to the list of clients for aggregation.
[INFO][21:46:29]: [Server #3350301] Adding client #82 to the list of clients for aggregation.
[INFO][21:46:29]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:46:29]: [Server #3350301] Updated weights have been received.
[INFO][21:46:29]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:46:30]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:46:30]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.59it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.72it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.91it/s]
[INFO][21:46:40]: [93m[1m[Server #3350301] Global model perplexity: 34.67
[0m
[INFO][21:46:40]: [Server #3350301] All client reports have been processed.
[INFO][21:46:41]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_12.pth.
[INFO][21:46:43]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_12.pth.
[INFO][21:46:43]: [93m[1m
[Server #3350301] Starting round 13/100.[0m
[INFO][21:46:43]: [Server #3350301] Selected clients: [1, 41, 22, 47, 99]
[INFO][21:46:43]: [Server #3350301] Selecting client #22 for training.
[INFO][21:46:43]: [Server #3350301] Sending the current model to client #22 (simulated).
[INFO][21:46:46]: [Server #3350301] Sending 507.38 MB of payload data to client #22 (simulated).
[INFO][21:46:46]: [Server #3350301] Selecting client #1 for training.
[INFO][21:46:46]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:46:50]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:46:50]: [Client #22] Selected by the server.
[INFO][21:46:50]: [Client #22] Loading its data source...
[INFO][21:46:50]: [Client #22] Dataset size: 2018
[INFO][21:46:50]: [Client #22] Sampler: iid
[INFO][21:46:50]: [Client #1] Selected by the server.
[INFO][21:46:50]: [Client #1] Loading its data source...
[INFO][21:46:50]: [Client #1] Dataset size: 2018
[INFO][21:46:50]: [Client #1] Sampler: iid
[INFO][21:46:51]: [Client #22] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:46:51]: [Client #22] Start to process inbound data.
[INFO][21:46:51]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:46:51]: [Client #1] Start to process inbound data.
[INFO][21:46:52]: [93m[1m[Client #22] Started training in communication round #13.[0m
[INFO][21:46:52]: [93m[1m[Client #1] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:05<03:57,  5.06s/it]  2%|â–         | 1/48 [00:05<03:57,  5.06s/it]  4%|â–         | 2/48 [00:05<01:57,  2.56s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.76s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.33s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.36s/it] 10%|â–ˆ         | 5/48 [00:08<00:47,  1.12s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.00it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][21:47:38]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.9274, 'train_samples_per_second': 151.625, 'train_steps_per_second': 1.202, 'train_loss': 3.3060855865478516, 'epoch': 3.0}
[INFO][21:47:38]: [Client #22] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_22_3350395.pth.
{'train_runtime': 39.9933, 'train_samples_per_second': 151.376, 'train_steps_per_second': 1.2, 'train_loss': 3.65311336517334, 'epoch': 3.0}
[INFO][21:47:39]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:47:39]: [Client #22] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_22_3350395.pth.
[INFO][21:47:39]: [Client #1] Model trained.
[INFO][21:47:39]: [Client #1] Inbound data has been processed.
[INFO][21:47:39]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:47:40]: [Client #22] Model trained.
[INFO][21:47:40]: [Client #22] Inbound data has been processed.
[INFO][21:47:40]: [Client #22] Outbound data is ready to be sent after being processed.
[INFO][21:47:45]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:47:46]: [Client #22] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:47:46]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:47:47]: [Server #3350301] Received 507.38 MB of payload data from client #22 (simulated).
[INFO][21:47:47]: [Server #3350301] Selecting client #99 for training.
[INFO][21:47:47]: [Server #3350301] Sending the current model to client #99 (simulated).
[INFO][21:47:50]: [Server #3350301] Sending 507.38 MB of payload data to client #99 (simulated).
[INFO][21:47:50]: [Server #3350301] Selecting client #41 for training.
[INFO][21:47:50]: [Server #3350301] Sending the current model to client #41 (simulated).
[INFO][21:47:53]: [Server #3350301] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][21:47:53]: [Client #99] Selected by the server.
[INFO][21:47:53]: [Client #99] Loading its data source...
[INFO][21:47:53]: [Client #99] Dataset size: 2018
[INFO][21:47:53]: [Client #99] Sampler: iid
[INFO][21:47:53]: [Client #41] Selected by the server.
[INFO][21:47:53]: [Client #41] Loading its data source...
[INFO][21:47:53]: [Client #41] Dataset size: 2018
[INFO][21:47:53]: [Client #41] Sampler: iid
[INFO][21:47:55]: [Client #99] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:47:55]: [Client #99] Start to process inbound data.
[INFO][21:47:55]: [93m[1m[Client #99] Started training in communication round #13.[0m
[INFO][21:47:55]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:47:55]: [Client #41] Start to process inbound data.
[INFO][21:47:55]: [93m[1m[Client #41] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:45,  4.79s/it]  2%|â–         | 1/48 [00:05<03:58,  5.07s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  4%|â–         | 2/48 [00:05<02:00,  2.61s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.71s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.82s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.39s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.45s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.20s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:45,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.12s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.06s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.01s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:41,  1.03s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.02it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.07it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:34,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:29,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.12it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:16,  1.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.12it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.06it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.08it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:12,  1.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:11,  1.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.11it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
[INFO][21:48:49]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3350396.pth.
{'train_runtime': 47.6861, 'train_samples_per_second': 126.955, 'train_steps_per_second': 1.007, 'train_loss': 3.6300789515177407, 'epoch': 3.0}
[INFO][21:48:49]: [Client #99] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_99_3350395.pth.
{'train_runtime': 47.8985, 'train_samples_per_second': 126.392, 'train_steps_per_second': 1.002, 'train_loss': 3.595301628112793, 'epoch': 3.0}
[INFO][21:48:50]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3350396.pth.
[INFO][21:48:50]: [Client #99] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_99_3350395.pth.
[INFO][21:48:50]: [Client #41] Model trained.
[INFO][21:48:50]: [Client #41] Inbound data has been processed.
[INFO][21:48:50]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][21:48:51]: [Client #99] Model trained.
[INFO][21:48:51]: [Client #99] Inbound data has been processed.
[INFO][21:48:51]: [Client #99] Outbound data is ready to be sent after being processed.
[INFO][21:48:56]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:48:57]: [Client #99] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:48:57]: [Server #3350301] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][21:48:58]: [Server #3350301] Received 507.38 MB of payload data from client #99 (simulated).
[INFO][21:48:58]: [Server #3350301] Selecting client #47 for training.
[INFO][21:48:58]: [Server #3350301] Sending the current model to client #47 (simulated).
[INFO][21:49:01]: [Server #3350301] Sending 507.38 MB of payload data to client #47 (simulated).
[INFO][21:49:01]: [Client #47] Selected by the server.
[INFO][21:49:01]: [Client #47] Loading its data source...
[INFO][21:49:01]: [Client #47] Dataset size: 2018
[INFO][21:49:01]: [Client #47] Sampler: iid
[INFO][21:49:03]: [Client #47] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:49:03]: [Client #47] Start to process inbound data.
[INFO][21:49:03]: [93m[1m[Client #47] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:21,  4.28s/it]  4%|â–         | 2/48 [00:04<01:34,  2.05s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.01s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.41it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.56it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.68it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.78it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.85it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.90it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.93it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.96it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  1.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:13<00:14,  2.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:14<00:13,  2.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:15<00:12,  2.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:16<00:11,  2.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:17<00:10,  2.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:18<00:09,  2.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:19<00:08,  2.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.12it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  1.76it/s]
[INFO][21:49:37]: [Client #47] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_47_3350395.pth.
{'train_runtime': 27.2672, 'train_samples_per_second': 222.025, 'train_steps_per_second': 1.76, 'train_loss': 3.6022888819376626, 'epoch': 3.0}
[INFO][21:49:38]: [Client #47] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_47_3350395.pth.
[INFO][21:49:38]: [Client #47] Model trained.
[INFO][21:49:38]: [Client #47] Inbound data has been processed.
[INFO][21:49:38]: [Client #47] Outbound data is ready to be sent after being processed.
[INFO][21:49:42]: [Client #47] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:49:43]: [Server #3350301] Received 507.38 MB of payload data from client #47 (simulated).
[INFO][21:49:43]: [Server #3350301] Adding client #19 to the list of clients for aggregation.
[INFO][21:49:43]: [Server #3350301] Adding client #52 to the list of clients for aggregation.
[INFO][21:49:43]: [Server #3350301] Adding client #68 to the list of clients for aggregation.
[INFO][21:49:43]: [Server #3350301] Adding client #79 to the list of clients for aggregation.
[INFO][21:49:43]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:49:43]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:49:43]: [Server #3350301] Updated weights have been received.
[INFO][21:49:44]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:49:44]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:49:44]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.70it/s]
[INFO][21:49:56]: [93m[1m[Server #3350301] Global model perplexity: 34.34
[0m
[INFO][21:49:56]: [Server #3350301] All client reports have been processed.
[INFO][21:49:56]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_13.pth.
[INFO][21:49:58]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_13.pth.
[INFO][21:49:58]: [93m[1m
[Server #3350301] Starting round 14/100.[0m
[INFO][21:49:58]: [Server #3350301] Selected clients: [1, 2, 77, 65, 32]
[INFO][21:49:58]: [Server #3350301] Selecting client #32 for training.
[INFO][21:49:58]: [Server #3350301] Sending the current model to client #32 (simulated).
[INFO][21:50:02]: [Server #3350301] Sending 507.38 MB of payload data to client #32 (simulated).
[INFO][21:50:02]: [Server #3350301] Selecting client #65 for training.
[INFO][21:50:02]: [Server #3350301] Sending the current model to client #65 (simulated).
[INFO][21:50:06]: [Server #3350301] Sending 507.38 MB of payload data to client #65 (simulated).
[INFO][21:50:06]: [Client #32] Selected by the server.
[INFO][21:50:06]: [Client #32] Loading its data source...
[INFO][21:50:06]: [Client #32] Dataset size: 2018
[INFO][21:50:06]: [Client #32] Sampler: iid
[INFO][21:50:06]: [Client #65] Selected by the server.
[INFO][21:50:06]: [Client #65] Loading its data source...
[INFO][21:50:06]: [Client #65] Dataset size: 2018
[INFO][21:50:06]: [Client #65] Sampler: iid
[INFO][21:50:07]: [Client #65] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:50:07]: [Client #65] Start to process inbound data.
[INFO][21:50:07]: [Client #32] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:50:07]: [Client #32] Start to process inbound data.
[INFO][21:50:08]: [93m[1m[Client #65] Started training in communication round #14.[0m
[INFO][21:50:08]: [93m[1m[Client #32] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  4%|â–         | 2/48 [00:05<01:49,  2.37s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:16,  1.36it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.36it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.36it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:50:54]: [Client #65] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_65_3350396.pth.
{'train_runtime': 39.5605, 'train_samples_per_second': 153.031, 'train_steps_per_second': 1.213, 'train_loss': 3.5964342753092446, 'epoch': 3.0}
[INFO][21:50:54]: [Client #32] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_32_3350395.pth.
{'train_runtime': 39.4246, 'train_samples_per_second': 153.559, 'train_steps_per_second': 1.218, 'train_loss': 3.6322142283121743, 'epoch': 3.0}
[INFO][21:50:55]: [Client #65] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_65_3350396.pth.
[INFO][21:50:55]: [Client #32] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_32_3350395.pth.
[INFO][21:50:55]: [Client #65] Model trained.
[INFO][21:50:55]: [Client #65] Inbound data has been processed.
[INFO][21:50:55]: [Client #65] Outbound data is ready to be sent after being processed.
[INFO][21:50:56]: [Client #32] Model trained.
[INFO][21:50:56]: [Client #32] Inbound data has been processed.
[INFO][21:50:56]: [Client #32] Outbound data is ready to be sent after being processed.
[INFO][21:51:02]: [Client #65] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:51:02]: [Client #32] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:51:03]: [Server #3350301] Received 507.38 MB of payload data from client #65 (simulated).
[INFO][21:51:04]: [Server #3350301] Received 507.38 MB of payload data from client #32 (simulated).
[INFO][21:51:04]: [Server #3350301] Selecting client #2 for training.
[INFO][21:51:04]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][21:51:07]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][21:51:07]: [Server #3350301] Selecting client #1 for training.
[INFO][21:51:07]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:51:11]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:51:11]: [Client #2] Selected by the server.
[INFO][21:51:11]: [Client #2] Loading its data source...
[INFO][21:51:11]: [Client #2] Dataset size: 2018
[INFO][21:51:11]: [Client #2] Sampler: iid
[INFO][21:51:11]: [Client #1] Selected by the server.
[INFO][21:51:11]: [Client #1] Loading its data source...
[INFO][21:51:11]: [Client #1] Dataset size: 2018
[INFO][21:51:11]: [Client #1] Sampler: iid
[INFO][21:51:12]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:51:12]: [Client #2] Start to process inbound data.
[INFO][21:51:12]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:51:12]: [Client #1] Start to process inbound data.
[INFO][21:51:13]: [93m[1m[Client #2] Started training in communication round #14.[0m
[INFO][21:51:13]: [93m[1m[Client #1] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.27s/it]  2%|â–         | 1/48 [00:04<03:49,  4.88s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:51:59]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2587, 'train_samples_per_second': 154.208, 'train_steps_per_second': 1.223, 'train_loss': 3.2722228368123374, 'epoch': 3.0}
[INFO][21:51:59]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.6249, 'train_samples_per_second': 152.783, 'train_steps_per_second': 1.211, 'train_loss': 3.5314388275146484, 'epoch': 3.0}
[INFO][21:52:00]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][21:52:00]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:52:01]: [Client #2] Model trained.
[INFO][21:52:01]: [Client #2] Inbound data has been processed.
[INFO][21:52:01]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][21:52:01]: [Client #1] Model trained.
[INFO][21:52:01]: [Client #1] Inbound data has been processed.
[INFO][21:52:01]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:52:07]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:52:08]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:52:08]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:52:09]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][21:52:09]: [Server #3350301] Selecting client #77 for training.
[INFO][21:52:09]: [Server #3350301] Sending the current model to client #77 (simulated).
[INFO][21:52:13]: [Server #3350301] Sending 507.38 MB of payload data to client #77 (simulated).
[INFO][21:52:13]: [Client #77] Selected by the server.
[INFO][21:52:13]: [Client #77] Loading its data source...
[INFO][21:52:13]: [Client #77] Dataset size: 2018
[INFO][21:52:13]: [Client #77] Sampler: iid
[INFO][21:52:15]: [Client #77] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:52:15]: [Client #77] Start to process inbound data.
[INFO][21:52:15]: [93m[1m[Client #77] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:22,  4.30s/it]  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][21:52:48]: [Client #77] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_77_3350395.pth.
{'train_runtime': 26.7668, 'train_samples_per_second': 226.175, 'train_steps_per_second': 1.793, 'train_loss': 3.577394485473633, 'epoch': 3.0}
[INFO][21:52:49]: [Client #77] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_77_3350395.pth.
[INFO][21:52:49]: [Client #77] Model trained.
[INFO][21:52:49]: [Client #77] Inbound data has been processed.
[INFO][21:52:49]: [Client #77] Outbound data is ready to be sent after being processed.
[INFO][21:52:53]: [Client #77] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:52:54]: [Server #3350301] Received 507.38 MB of payload data from client #77 (simulated).
[INFO][21:52:54]: [Server #3350301] Adding client #41 to the list of clients for aggregation.
[INFO][21:52:54]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:52:54]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][21:52:54]: [Server #3350301] Adding client #77 to the list of clients for aggregation.
[INFO][21:52:54]: [Server #3350301] Adding client #25 to the list of clients for aggregation.
[INFO][21:52:54]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:52:54]: [Server #3350301] Updated weights have been received.
[INFO][21:52:55]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:52:55]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:52:55]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.90it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][21:53:07]: [93m[1m[Server #3350301] Global model perplexity: 33.39
[0m
[INFO][21:53:07]: [Server #3350301] All client reports have been processed.
[INFO][21:53:07]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_14.pth.
[INFO][21:53:09]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_14.pth.
[INFO][21:53:09]: [93m[1m
[Server #3350301] Starting round 15/100.[0m
[INFO][21:53:09]: [Server #3350301] Selected clients: [1, 49, 48, 93, 81]
[INFO][21:53:09]: [Server #3350301] Selecting client #48 for training.
[INFO][21:53:09]: [Server #3350301] Sending the current model to client #48 (simulated).
[INFO][21:53:13]: [Server #3350301] Sending 507.38 MB of payload data to client #48 (simulated).
[INFO][21:53:13]: [Server #3350301] Selecting client #1 for training.
[INFO][21:53:13]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:53:16]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:53:16]: [Client #48] Selected by the server.
[INFO][21:53:16]: [Client #48] Loading its data source...
[INFO][21:53:16]: [Client #48] Dataset size: 2018
[INFO][21:53:16]: [Client #48] Sampler: iid
[INFO][21:53:16]: [Client #1] Selected by the server.
[INFO][21:53:16]: [Client #1] Loading its data source...
[INFO][21:53:16]: [Client #1] Dataset size: 2018
[INFO][21:53:16]: [Client #1] Sampler: iid
[INFO][21:53:18]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:53:18]: [Client #1] Start to process inbound data.
[INFO][21:53:18]: [Client #48] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:53:18]: [Client #48] Start to process inbound data.
[INFO][21:53:18]: [93m[1m[Client #1] Started training in communication round #15.[0m
[INFO][21:53:18]: [93m[1m[Client #48] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:54:04]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2794, 'train_samples_per_second': 154.126, 'train_steps_per_second': 1.222, 'train_loss': 3.1734415690104165, 'epoch': 3.0}
[INFO][21:54:04]: [Client #48] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_48_3350395.pth.
{'train_runtime': 39.5447, 'train_samples_per_second': 153.092, 'train_steps_per_second': 1.214, 'train_loss': 3.5976845423380532, 'epoch': 3.0}
[INFO][21:54:05]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:54:05]: [Client #48] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_48_3350395.pth.
[INFO][21:54:06]: [Client #1] Model trained.
[INFO][21:54:06]: [Client #1] Inbound data has been processed.
[INFO][21:54:06]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:54:06]: [Client #48] Model trained.
[INFO][21:54:06]: [Client #48] Inbound data has been processed.
[INFO][21:54:06]: [Client #48] Outbound data is ready to be sent after being processed.
[INFO][21:54:13]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:54:13]: [Client #48] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:54:14]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:54:15]: [Server #3350301] Received 507.38 MB of payload data from client #48 (simulated).
[INFO][21:54:15]: [Server #3350301] Selecting client #81 for training.
[INFO][21:54:15]: [Server #3350301] Sending the current model to client #81 (simulated).
[INFO][21:54:18]: [Server #3350301] Sending 507.38 MB of payload data to client #81 (simulated).
[INFO][21:54:18]: [Server #3350301] Selecting client #49 for training.
[INFO][21:54:18]: [Server #3350301] Sending the current model to client #49 (simulated).
[INFO][21:54:22]: [Server #3350301] Sending 507.38 MB of payload data to client #49 (simulated).
[INFO][21:54:22]: [Client #81] Selected by the server.
[INFO][21:54:22]: [Client #49] Selected by the server.
[INFO][21:54:22]: [Client #81] Loading its data source...
[INFO][21:54:22]: [Client #49] Loading its data source...
[INFO][21:54:22]: [Client #81] Dataset size: 2018
[INFO][21:54:22]: [Client #49] Dataset size: 2018
[INFO][21:54:22]: [Client #81] Sampler: iid
[INFO][21:54:22]: [Client #49] Sampler: iid
[INFO][21:54:23]: [Client #81] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:54:23]: [Client #81] Start to process inbound data.
[INFO][21:54:23]: [Client #49] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:54:23]: [Client #49] Start to process inbound data.
[INFO][21:54:24]: [93m[1m[Client #49] Started training in communication round #15.[0m
[INFO][21:54:24]: [93m[1m[Client #81] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:52,  4.95s/it]  2%|â–         | 1/48 [00:04<03:54,  4.98s/it]  4%|â–         | 2/48 [00:05<01:58,  2.59s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.80s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.82s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.40s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.16s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:42,  1.02s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][21:55:11]: [Client #49] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_49_3350396.pth.
{'train_runtime': 40.2922, 'train_samples_per_second': 150.252, 'train_steps_per_second': 1.191, 'train_loss': 3.5390625, 'epoch': 3.0}
[INFO][21:55:11]: [Client #81] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_81_3350395.pth.
{'train_runtime': 40.196, 'train_samples_per_second': 150.612, 'train_steps_per_second': 1.194, 'train_loss': 3.5315170288085938, 'epoch': 3.0}
[INFO][21:55:12]: [Client #49] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_49_3350396.pth.
[INFO][21:55:12]: [Client #81] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_81_3350395.pth.
[INFO][21:55:12]: [Client #49] Model trained.
[INFO][21:55:12]: [Client #49] Inbound data has been processed.
[INFO][21:55:12]: [Client #49] Outbound data is ready to be sent after being processed.
[INFO][21:55:13]: [Client #81] Model trained.
[INFO][21:55:13]: [Client #81] Inbound data has been processed.
[INFO][21:55:13]: [Client #81] Outbound data is ready to be sent after being processed.
[INFO][21:55:18]: [Client #49] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:55:19]: [Client #81] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:55:19]: [Server #3350301] Received 507.38 MB of payload data from client #49 (simulated).
[INFO][21:55:21]: [Server #3350301] Received 507.38 MB of payload data from client #81 (simulated).
[INFO][21:55:21]: [Server #3350301] Selecting client #93 for training.
[INFO][21:55:21]: [Server #3350301] Sending the current model to client #93 (simulated).
[INFO][21:55:24]: [Server #3350301] Sending 507.38 MB of payload data to client #93 (simulated).
[INFO][21:55:24]: [Client #93] Selected by the server.
[INFO][21:55:24]: [Client #93] Loading its data source...
[INFO][21:55:24]: [Client #93] Dataset size: 2018
[INFO][21:55:24]: [Client #93] Sampler: iid
[INFO][21:55:26]: [Client #93] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:55:26]: [Client #93] Start to process inbound data.
[INFO][21:55:26]: [93m[1m[Client #93] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:22,  4.31s/it]  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.00s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:13<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  1.77it/s]
[INFO][21:56:00]: [Client #93] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_93_3350395.pth.
{'train_runtime': 27.1126, 'train_samples_per_second': 223.291, 'train_steps_per_second': 1.77, 'train_loss': 3.5408722559611, 'epoch': 3.0}
[INFO][21:56:01]: [Client #93] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_93_3350395.pth.
[INFO][21:56:01]: [Client #93] Model trained.
[INFO][21:56:01]: [Client #93] Inbound data has been processed.
[INFO][21:56:01]: [Client #93] Outbound data is ready to be sent after being processed.
[INFO][21:56:05]: [Client #93] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:56:07]: [Server #3350301] Received 507.38 MB of payload data from client #93 (simulated).
[INFO][21:56:07]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:56:07]: [Server #3350301] Adding client #48 to the list of clients for aggregation.
[INFO][21:56:07]: [Server #3350301] Adding client #81 to the list of clients for aggregation.
[INFO][21:56:07]: [Server #3350301] Adding client #22 to the list of clients for aggregation.
[INFO][21:56:07]: [Server #3350301] Adding client #47 to the list of clients for aggregation.
[INFO][21:56:07]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:56:07]: [Server #3350301] Updated weights have been received.
[INFO][21:56:07]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:56:08]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:56:08]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.42it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.93it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.69it/s]
[INFO][21:56:19]: [93m[1m[Server #3350301] Global model perplexity: 32.18
[0m
[INFO][21:56:19]: [Server #3350301] All client reports have been processed.
[INFO][21:56:19]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_15.pth.
[INFO][21:56:21]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_15.pth.
[INFO][21:56:21]: [93m[1m
[Server #3350301] Starting round 16/100.[0m
[INFO][21:56:21]: [Server #3350301] Selected clients: [1, 2, 3, 89, 72]
[INFO][21:56:21]: [Server #3350301] Selecting client #2 for training.
[INFO][21:56:21]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][21:56:25]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][21:56:25]: [Server #3350301] Selecting client #1 for training.
[INFO][21:56:25]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:56:29]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:56:29]: [Client #2] Selected by the server.
[INFO][21:56:29]: [Client #2] Loading its data source...
[INFO][21:56:29]: [Client #2] Dataset size: 2018
[INFO][21:56:29]: [Client #2] Sampler: iid
[INFO][21:56:29]: [Client #1] Selected by the server.
[INFO][21:56:29]: [Client #1] Loading its data source...
[INFO][21:56:29]: [Client #1] Dataset size: 2018
[INFO][21:56:29]: [Client #1] Sampler: iid
[INFO][21:56:30]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:56:30]: [Client #1] Start to process inbound data.
[INFO][21:56:30]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:56:30]: [Client #2] Start to process inbound data.
[INFO][21:56:31]: [93m[1m[Client #2] Started training in communication round #16.[0m
[INFO][21:56:31]: [93m[1m[Client #1] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  2%|â–         | 1/48 [00:05<04:01,  5.14s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  4%|â–         | 2/48 [00:05<01:57,  2.54s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.58s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.71s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.25s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.33s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.07s/it] 10%|â–ˆ         | 5/48 [00:08<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.42it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:57:17]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.2813, 'train_samples_per_second': 154.119, 'train_steps_per_second': 1.222, 'train_loss': 3.4057944615681968, 'epoch': 3.0}
[INFO][21:57:17]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.6995, 'train_samples_per_second': 152.496, 'train_steps_per_second': 1.209, 'train_loss': 3.0951865514119468, 'epoch': 3.0}
[INFO][21:57:18]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][21:57:18]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][21:57:19]: [Client #2] Model trained.
[INFO][21:57:19]: [Client #2] Inbound data has been processed.
[INFO][21:57:19]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][21:57:19]: [Client #1] Model trained.
[INFO][21:57:19]: [Client #1] Inbound data has been processed.
[INFO][21:57:19]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][21:57:25]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:57:25]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:57:26]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][21:57:27]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][21:57:27]: [Server #3350301] Selecting client #72 for training.
[INFO][21:57:27]: [Server #3350301] Sending the current model to client #72 (simulated).
[INFO][21:57:31]: [Server #3350301] Sending 507.38 MB of payload data to client #72 (simulated).
[INFO][21:57:31]: [Server #3350301] Selecting client #3 for training.
[INFO][21:57:31]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][21:57:34]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][21:57:34]: [Client #72] Selected by the server.
[INFO][21:57:34]: [Client #72] Loading its data source...
[INFO][21:57:34]: [Client #72] Dataset size: 2018
[INFO][21:57:34]: [Client #3] Selected by the server.
[INFO][21:57:34]: [Client #72] Sampler: iid
[INFO][21:57:34]: [Client #3] Loading its data source...
[INFO][21:57:34]: [Client #3] Dataset size: 2018
[INFO][21:57:34]: [Client #3] Sampler: iid
[INFO][21:57:36]: [Client #72] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:57:36]: [Client #72] Start to process inbound data.
[INFO][21:57:36]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:57:36]: [Client #3] Start to process inbound data.
[INFO][21:57:37]: [93m[1m[Client #3] Started training in communication round #16.[0m
[INFO][21:57:37]: [93m[1m[Client #72] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:31,  4.50s/it]  2%|â–         | 1/48 [00:05<03:59,  5.09s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  4%|â–         | 2/48 [00:05<01:57,  2.55s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.56s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.14s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.00it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:16,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][21:58:23]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.3414, 'train_samples_per_second': 153.884, 'train_steps_per_second': 1.22, 'train_loss': 3.453685442606608, 'epoch': 3.0}
[INFO][21:58:23]: [Client #72] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_72_3350395.pth.
{'train_runtime': 39.7862, 'train_samples_per_second': 152.163, 'train_steps_per_second': 1.206, 'train_loss': 3.5685675938924155, 'epoch': 3.0}
[INFO][21:58:24]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][21:58:24]: [Client #72] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_72_3350395.pth.
[INFO][21:58:25]: [Client #3] Model trained.
[INFO][21:58:25]: [Client #3] Inbound data has been processed.
[INFO][21:58:25]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][21:58:25]: [Client #72] Model trained.
[INFO][21:58:25]: [Client #72] Inbound data has been processed.
[INFO][21:58:25]: [Client #72] Outbound data is ready to be sent after being processed.
[INFO][21:58:32]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:58:32]: [Client #72] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:58:33]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][21:58:34]: [Server #3350301] Received 507.38 MB of payload data from client #72 (simulated).
[INFO][21:58:34]: [Server #3350301] Selecting client #89 for training.
[INFO][21:58:34]: [Server #3350301] Sending the current model to client #89 (simulated).
[INFO][21:58:38]: [Server #3350301] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][21:58:38]: [Client #89] Selected by the server.
[INFO][21:58:38]: [Client #89] Loading its data source...
[INFO][21:58:38]: [Client #89] Dataset size: 2018
[INFO][21:58:38]: [Client #89] Sampler: iid
[INFO][21:58:40]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:58:40]: [Client #89] Start to process inbound data.
[INFO][21:58:40]: [93m[1m[Client #89] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:22,  4.32s/it]  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.00s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.41it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:13<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  1.78it/s]
[INFO][21:59:13]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3350395.pth.
{'train_runtime': 27.0409, 'train_samples_per_second': 223.883, 'train_steps_per_second': 1.775, 'train_loss': 3.491978327433268, 'epoch': 3.0}
[INFO][21:59:14]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3350395.pth.
[INFO][21:59:15]: [Client #89] Model trained.
[INFO][21:59:15]: [Client #89] Inbound data has been processed.
[INFO][21:59:15]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][21:59:19]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][21:59:20]: [Server #3350301] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][21:59:20]: [Server #3350301] Adding client #99 to the list of clients for aggregation.
[INFO][21:59:20]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][21:59:20]: [Server #3350301] Adding client #32 to the list of clients for aggregation.
[INFO][21:59:20]: [Server #3350301] Adding client #65 to the list of clients for aggregation.
[INFO][21:59:20]: [Server #3350301] Adding client #89 to the list of clients for aggregation.
[INFO][21:59:20]: [Server #3350301] Aggregating 5 clients in total.
[INFO][21:59:20]: [Server #3350301] Updated weights have been received.
[INFO][21:59:20]: [Server #3350301] Aggregating model weight deltas.
[INFO][21:59:21]: [Server #3350301] Finished aggregating updated weights.
[INFO][21:59:21]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][21:59:32]: [93m[1m[Server #3350301] Global model perplexity: 32.07
[0m
[INFO][21:59:32]: [Server #3350301] All client reports have been processed.
[INFO][21:59:32]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_16.pth.
[INFO][21:59:35]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_16.pth.
[INFO][21:59:35]: [93m[1m
[Server #3350301] Starting round 17/100.[0m
[INFO][21:59:35]: [Server #3350301] Selected clients: [1, 4, 5, 12, 88]
[INFO][21:59:35]: [Server #3350301] Selecting client #4 for training.
[INFO][21:59:35]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][21:59:39]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][21:59:39]: [Server #3350301] Selecting client #1 for training.
[INFO][21:59:39]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][21:59:42]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][21:59:42]: [Client #4] Selected by the server.
[INFO][21:59:42]: [Client #1] Selected by the server.
[INFO][21:59:42]: [Client #4] Loading its data source...
[INFO][21:59:42]: [Client #1] Loading its data source...
[INFO][21:59:42]: [Client #4] Dataset size: 2018
[INFO][21:59:42]: [Client #4] Sampler: iid
[INFO][21:59:42]: [Client #1] Dataset size: 2018
[INFO][21:59:42]: [Client #1] Sampler: iid
[INFO][21:59:44]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:59:44]: [Client #4] Start to process inbound data.
[INFO][21:59:44]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][21:59:44]: [Client #1] Start to process inbound data.
[INFO][21:59:44]: [93m[1m[Client #4] Started training in communication round #17.[0m
[INFO][21:59:45]: [93m[1m[Client #1] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:28,  4.44s/it]  2%|â–         | 1/48 [00:04<03:53,  4.96s/it]  4%|â–         | 2/48 [00:05<01:42,  2.23s/it]  4%|â–         | 2/48 [00:05<01:56,  2.52s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.71s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:00:30]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.3213, 'train_samples_per_second': 153.962, 'train_steps_per_second': 1.221, 'train_loss': 3.541499137878418, 'epoch': 3.0}
[INFO][22:00:30]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.691, 'train_samples_per_second': 152.528, 'train_steps_per_second': 1.209, 'train_loss': 3.048647880554199, 'epoch': 3.0}
[INFO][22:00:31]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][22:00:32]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:00:32]: [Client #4] Model trained.
[INFO][22:00:32]: [Client #4] Inbound data has been processed.
[INFO][22:00:32]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][22:00:32]: [Client #1] Model trained.
[INFO][22:00:32]: [Client #1] Inbound data has been processed.
[INFO][22:00:32]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:00:39]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:00:39]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:00:40]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][22:00:41]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:00:41]: [Server #3350301] Selecting client #88 for training.
[INFO][22:00:41]: [Server #3350301] Sending the current model to client #88 (simulated).
[INFO][22:00:45]: [Server #3350301] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][22:00:45]: [Server #3350301] Selecting client #5 for training.
[INFO][22:00:45]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:00:48]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:00:48]: [Client #88] Selected by the server.
[INFO][22:00:48]: [Client #88] Loading its data source...
[INFO][22:00:48]: [Client #5] Selected by the server.
[INFO][22:00:48]: [Client #88] Dataset size: 2018
[INFO][22:00:48]: [Client #5] Loading its data source...
[INFO][22:00:48]: [Client #88] Sampler: iid
[INFO][22:00:48]: [Client #5] Dataset size: 2018
[INFO][22:00:48]: [Client #5] Sampler: iid
[INFO][22:00:50]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:00:50]: [Client #5] Start to process inbound data.
[INFO][22:00:50]: [93m[1m[Client #5] Started training in communication round #17.[0m
[INFO][22:00:50]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:00:50]: [Client #88] Start to process inbound data.
[INFO][22:00:51]: [93m[1m[Client #88] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:32,  4.52s/it]  4%|â–         | 2/48 [00:05<01:39,  2.16s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  6%|â–‹         | 3/48 [00:05<01:08,  1.51s/it]  2%|â–         | 1/48 [00:04<03:53,  4.97s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  4%|â–         | 2/48 [00:05<01:54,  2.50s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.07it/s]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.39it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.30it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.36it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.71it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][22:01:36]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.2444, 'train_samples_per_second': 154.264, 'train_steps_per_second': 1.223, 'train_loss': 3.4442831675211587, 'epoch': 3.0}
[INFO][22:01:37]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3350395.pth.
{'train_runtime': 39.4118, 'train_samples_per_second': 153.609, 'train_steps_per_second': 1.218, 'train_loss': 3.545450528462728, 'epoch': 3.0}
[INFO][22:01:37]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][22:01:37]: [Client #5] Model trained.
[INFO][22:01:37]: [Client #5] Inbound data has been processed.
[INFO][22:01:37]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:01:38]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3350395.pth.
[INFO][22:01:38]: [Client #88] Model trained.
[INFO][22:01:38]: [Client #88] Inbound data has been processed.
[INFO][22:01:38]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][22:01:42]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:01:44]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][22:01:44]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:01:45]: [Server #3350301] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][22:01:45]: [Server #3350301] Selecting client #12 for training.
[INFO][22:01:45]: [Server #3350301] Sending the current model to client #12 (simulated).
[INFO][22:01:49]: [Server #3350301] Sending 507.38 MB of payload data to client #12 (simulated).
[INFO][22:01:49]: [Client #12] Selected by the server.
[INFO][22:01:49]: [Client #12] Loading its data source...
[INFO][22:01:49]: [Client #12] Dataset size: 2018
[INFO][22:01:49]: [Client #12] Sampler: iid
[INFO][22:01:50]: [Client #12] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:01:50]: [Client #12] Start to process inbound data.
[INFO][22:01:50]: [93m[1m[Client #12] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:02:23]: [Client #12] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_12_3350395.pth.
{'train_runtime': 26.7897, 'train_samples_per_second': 225.982, 'train_steps_per_second': 1.792, 'train_loss': 3.549872398376465, 'epoch': 3.0}
[INFO][22:02:24]: [Client #12] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_12_3350395.pth.
[INFO][22:02:25]: [Client #12] Model trained.
[INFO][22:02:25]: [Client #12] Inbound data has been processed.
[INFO][22:02:25]: [Client #12] Outbound data is ready to be sent after being processed.
[INFO][22:02:29]: [Client #12] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:02:30]: [Server #3350301] Received 507.38 MB of payload data from client #12 (simulated).
[INFO][22:02:30]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:02:30]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:02:30]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:02:30]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][22:02:30]: [Server #3350301] Adding client #88 to the list of clients for aggregation.
[INFO][22:02:30]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:02:30]: [Server #3350301] Updated weights have been received.
[INFO][22:02:30]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:02:31]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:02:31]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 12.70it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][22:02:42]: [93m[1m[Server #3350301] Global model perplexity: 31.02
[0m
[INFO][22:02:42]: [Server #3350301] All client reports have been processed.
[INFO][22:02:42]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_17.pth.
[INFO][22:02:45]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_17.pth.
[INFO][22:02:45]: [93m[1m
[Server #3350301] Starting round 18/100.[0m
[INFO][22:02:45]: [Server #3350301] Selected clients: [1, 24, 66, 76, 36]
[INFO][22:02:45]: [Server #3350301] Selecting client #66 for training.
[INFO][22:02:45]: [Server #3350301] Sending the current model to client #66 (simulated).
[INFO][22:02:49]: [Server #3350301] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][22:02:49]: [Server #3350301] Selecting client #1 for training.
[INFO][22:02:49]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:02:52]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:02:52]: [Client #66] Selected by the server.
[INFO][22:02:52]: [Client #66] Loading its data source...
[INFO][22:02:52]: [Client #66] Dataset size: 2018
[INFO][22:02:52]: [Client #66] Sampler: iid
[INFO][22:02:52]: [Client #1] Selected by the server.
[INFO][22:02:52]: [Client #1] Loading its data source...
[INFO][22:02:52]: [Client #1] Dataset size: 2018
[INFO][22:02:52]: [Client #1] Sampler: iid
[INFO][22:02:54]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:02:54]: [Client #66] Start to process inbound data.
[INFO][22:02:54]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:02:54]: [Client #1] Start to process inbound data.
[INFO][22:02:55]: [93m[1m[Client #1] Started training in communication round #18.[0m
[INFO][22:02:55]: [93m[1m[Client #66] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:39,  4.68s/it]  2%|â–         | 1/48 [00:04<03:46,  4.82s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.30it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:03:41]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.6618, 'train_samples_per_second': 152.641, 'train_steps_per_second': 1.21, 'train_loss': 2.9709831873575845, 'epoch': 3.0}
[INFO][22:03:41]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3350395.pth.
{'train_runtime': 39.5501, 'train_samples_per_second': 153.072, 'train_steps_per_second': 1.214, 'train_loss': 3.5193653106689453, 'epoch': 3.0}
[INFO][22:03:42]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:03:42]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3350395.pth.
[INFO][22:03:42]: [Client #1] Model trained.
[INFO][22:03:42]: [Client #1] Inbound data has been processed.
[INFO][22:03:42]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:03:43]: [Client #66] Model trained.
[INFO][22:03:43]: [Client #66] Inbound data has been processed.
[INFO][22:03:43]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][22:03:48]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:03:49]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:03:49]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:03:50]: [Server #3350301] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][22:03:50]: [Server #3350301] Selecting client #36 for training.
[INFO][22:03:50]: [Server #3350301] Sending the current model to client #36 (simulated).
[INFO][22:03:54]: [Server #3350301] Sending 507.38 MB of payload data to client #36 (simulated).
[INFO][22:03:54]: [Client #36] Selected by the server.
[INFO][22:03:54]: [Client #36] Loading its data source...
[INFO][22:03:54]: [Client #36] Dataset size: 2018
[INFO][22:03:54]: [Client #36] Sampler: iid
[INFO][22:03:55]: [Client #36] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:03:55]: [Client #36] Start to process inbound data.
[INFO][22:03:56]: [93m[1m[Client #36] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:04:29]: [Client #36] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_36_3350395.pth.
{'train_runtime': 26.7655, 'train_samples_per_second': 226.187, 'train_steps_per_second': 1.793, 'train_loss': 3.5187899271647134, 'epoch': 3.0}
[INFO][22:04:30]: [Client #36] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_36_3350395.pth.
[INFO][22:04:30]: [Client #36] Model trained.
[INFO][22:04:30]: [Client #36] Inbound data has been processed.
[INFO][22:04:30]: [Client #36] Outbound data is ready to be sent after being processed.
[INFO][22:04:34]: [Client #36] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:04:35]: [Server #3350301] Received 507.38 MB of payload data from client #36 (simulated).
[INFO][22:04:35]: [Server #3350301] Selecting client #24 for training.
[INFO][22:04:35]: [Server #3350301] Sending the current model to client #24 (simulated).
[INFO][22:04:39]: [Server #3350301] Sending 507.38 MB of payload data to client #24 (simulated).
[INFO][22:04:39]: [Client #24] Selected by the server.
[INFO][22:04:39]: [Client #24] Loading its data source...
[INFO][22:04:39]: [Client #24] Dataset size: 2018
[INFO][22:04:39]: [Client #24] Sampler: iid
[INFO][22:04:40]: [Client #24] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:04:40]: [Client #24] Start to process inbound data.
[INFO][22:04:41]: [93m[1m[Client #24] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:05:13]: [Client #24] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_24_3350395.pth.
{'train_runtime': 26.8476, 'train_samples_per_second': 225.495, 'train_steps_per_second': 1.788, 'train_loss': 3.51996644337972, 'epoch': 3.0}
[INFO][22:05:14]: [Client #24] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_24_3350395.pth.
[INFO][22:05:15]: [Client #24] Model trained.
[INFO][22:05:15]: [Client #24] Inbound data has been processed.
[INFO][22:05:15]: [Client #24] Outbound data is ready to be sent after being processed.
[INFO][22:05:19]: [Client #24] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:05:20]: [Server #3350301] Received 507.38 MB of payload data from client #24 (simulated).
[INFO][22:05:20]: [Server #3350301] Selecting client #76 for training.
[INFO][22:05:20]: [Server #3350301] Sending the current model to client #76 (simulated).
[INFO][22:05:24]: [Server #3350301] Sending 507.38 MB of payload data to client #76 (simulated).
[INFO][22:05:24]: [Client #76] Selected by the server.
[INFO][22:05:24]: [Client #76] Loading its data source...
[INFO][22:05:24]: [Client #76] Dataset size: 2018
[INFO][22:05:24]: [Client #76] Sampler: iid
[INFO][22:05:25]: [Client #76] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:05:25]: [Client #76] Start to process inbound data.
[INFO][22:05:25]: [93m[1m[Client #76] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.27s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.96it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:05:58]: [Client #76] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_76_3350395.pth.
{'train_runtime': 26.7633, 'train_samples_per_second': 226.205, 'train_steps_per_second': 1.793, 'train_loss': 3.507871945699056, 'epoch': 3.0}
[INFO][22:05:59]: [Client #76] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_76_3350395.pth.
[INFO][22:06:00]: [Client #76] Model trained.
[INFO][22:06:00]: [Client #76] Inbound data has been processed.
[INFO][22:06:00]: [Client #76] Outbound data is ready to be sent after being processed.
[INFO][22:06:04]: [Client #76] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:06:05]: [Server #3350301] Received 507.38 MB of payload data from client #76 (simulated).
[INFO][22:06:05]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:06:05]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][22:06:05]: [Server #3350301] Adding client #66 to the list of clients for aggregation.
[INFO][22:06:05]: [Server #3350301] Adding client #76 to the list of clients for aggregation.
[INFO][22:06:05]: [Server #3350301] Adding client #49 to the list of clients for aggregation.
[INFO][22:06:05]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:06:05]: [Server #3350301] Updated weights have been received.
[INFO][22:06:05]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:06:06]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:06:06]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][22:06:17]: [93m[1m[Server #3350301] Global model perplexity: 30.22
[0m
[INFO][22:06:17]: [Server #3350301] All client reports have been processed.
[INFO][22:06:17]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_18.pth.
[INFO][22:06:19]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_18.pth.
[INFO][22:06:19]: [93m[1m
[Server #3350301] Starting round 19/100.[0m
[INFO][22:06:19]: [Server #3350301] Selected clients: [1, 44, 75, 21, 39]
[INFO][22:06:19]: [Server #3350301] Selecting client #44 for training.
[INFO][22:06:19]: [Server #3350301] Sending the current model to client #44 (simulated).
[INFO][22:06:23]: [Server #3350301] Sending 507.38 MB of payload data to client #44 (simulated).
[INFO][22:06:23]: [Server #3350301] Selecting client #1 for training.
[INFO][22:06:23]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:06:27]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:06:27]: [Client #44] Selected by the server.
[INFO][22:06:27]: [Client #44] Loading its data source...
[INFO][22:06:27]: [Client #44] Dataset size: 2018
[INFO][22:06:27]: [Client #44] Sampler: iid
[INFO][22:06:27]: [Client #1] Selected by the server.
[INFO][22:06:27]: [Client #1] Loading its data source...
[INFO][22:06:27]: [Client #1] Dataset size: 2018
[INFO][22:06:27]: [Client #1] Sampler: iid
[INFO][22:06:28]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:06:28]: [Client #1] Start to process inbound data.
[INFO][22:06:28]: [93m[1m[Client #1] Started training in communication round #19.[0m
[INFO][22:06:28]: [Client #44] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:06:28]: [Client #44] Start to process inbound data.
[INFO][22:06:29]: [93m[1m[Client #44] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:47,  4.84s/it]  2%|â–         | 1/48 [00:04<03:48,  4.85s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.33it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:22,  1.31it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:07:14]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.7485, 'train_samples_per_second': 152.308, 'train_steps_per_second': 1.208, 'train_loss': 2.9144789377848306, 'epoch': 3.0}
[INFO][22:07:15]: [Client #44] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_44_3350395.pth.
{'train_runtime': 39.6537, 'train_samples_per_second': 152.672, 'train_steps_per_second': 1.21, 'train_loss': 3.480991999308268, 'epoch': 3.0}
[INFO][22:07:16]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:07:16]: [Client #44] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_44_3350395.pth.
[INFO][22:07:16]: [Client #1] Model trained.
[INFO][22:07:16]: [Client #1] Inbound data has been processed.
[INFO][22:07:16]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:07:16]: [Client #44] Model trained.
[INFO][22:07:16]: [Client #44] Inbound data has been processed.
[INFO][22:07:16]: [Client #44] Outbound data is ready to be sent after being processed.
[INFO][22:07:23]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:07:23]: [Client #44] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:07:24]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:07:25]: [Server #3350301] Received 507.38 MB of payload data from client #44 (simulated).
[INFO][22:07:25]: [Server #3350301] Selecting client #21 for training.
[INFO][22:07:25]: [Server #3350301] Sending the current model to client #21 (simulated).
[INFO][22:07:28]: [Server #3350301] Sending 507.38 MB of payload data to client #21 (simulated).
[INFO][22:07:28]: [Server #3350301] Selecting client #39 for training.
[INFO][22:07:28]: [Server #3350301] Sending the current model to client #39 (simulated).
[INFO][22:07:32]: [Server #3350301] Sending 507.38 MB of payload data to client #39 (simulated).
[INFO][22:07:32]: [Client #21] Selected by the server.
[INFO][22:07:32]: [Client #21] Loading its data source...
[INFO][22:07:32]: [Client #39] Selected by the server.
[INFO][22:07:32]: [Client #21] Dataset size: 2018
[INFO][22:07:32]: [Client #21] Sampler: iid
[INFO][22:07:32]: [Client #39] Loading its data source...
[INFO][22:07:32]: [Client #39] Dataset size: 2018
[INFO][22:07:32]: [Client #39] Sampler: iid
[INFO][22:07:33]: [Client #39] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:07:33]: [Client #39] Start to process inbound data.
[INFO][22:07:33]: [Client #21] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:07:33]: [Client #21] Start to process inbound data.
[INFO][22:07:34]: [93m[1m[Client #39] Started training in communication round #19.[0m
[INFO][22:07:34]: [93m[1m[Client #21] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.14s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:49,  4.88s/it]  4%|â–         | 2/48 [00:04<01:37,  2.11s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.59s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.84s/it]  8%|â–Š         | 4/48 [00:06<00:59,  1.34s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.45s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.17s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.21s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.05s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:39,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:35,  1.13it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
[INFO][22:08:20]: [Client #21] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_21_3350395.pth.
{'train_runtime': 39.6569, 'train_samples_per_second': 152.66, 'train_steps_per_second': 1.21, 'train_loss': 3.4278691609700522, 'epoch': 3.0}
[INFO][22:08:21]: [Client #39] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_39_3350396.pth.
{'train_runtime': 40.0853, 'train_samples_per_second': 151.028, 'train_steps_per_second': 1.197, 'train_loss': 3.4273417790730796, 'epoch': 3.0}
[INFO][22:08:22]: [Client #21] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_21_3350395.pth.
[INFO][22:08:22]: [Client #39] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_39_3350396.pth.
[INFO][22:08:22]: [Client #21] Model trained.
[INFO][22:08:22]: [Client #21] Inbound data has been processed.
[INFO][22:08:22]: [Client #21] Outbound data is ready to be sent after being processed.
[INFO][22:08:22]: [Client #39] Model trained.
[INFO][22:08:22]: [Client #39] Inbound data has been processed.
[INFO][22:08:22]: [Client #39] Outbound data is ready to be sent after being processed.
[INFO][22:08:29]: [Client #21] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:08:29]: [Client #39] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:08:30]: [Server #3350301] Received 507.38 MB of payload data from client #21 (simulated).
[INFO][22:08:31]: [Server #3350301] Received 507.38 MB of payload data from client #39 (simulated).
[INFO][22:08:31]: [Server #3350301] Selecting client #75 for training.
[INFO][22:08:31]: [Server #3350301] Sending the current model to client #75 (simulated).
[INFO][22:08:34]: [Server #3350301] Sending 507.38 MB of payload data to client #75 (simulated).
[INFO][22:08:34]: [Client #75] Selected by the server.
[INFO][22:08:34]: [Client #75] Loading its data source...
[INFO][22:08:34]: [Client #75] Dataset size: 2018
[INFO][22:08:34]: [Client #75] Sampler: iid
[INFO][22:08:36]: [Client #75] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:08:36]: [Client #75] Start to process inbound data.
[INFO][22:08:36]: [93m[1m[Client #75] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:09:09]: [Client #75] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_75_3350395.pth.
{'train_runtime': 26.7274, 'train_samples_per_second': 226.509, 'train_steps_per_second': 1.796, 'train_loss': 3.3962268829345703, 'epoch': 3.0}
[INFO][22:09:10]: [Client #75] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_75_3350395.pth.
[INFO][22:09:11]: [Client #75] Model trained.
[INFO][22:09:11]: [Client #75] Inbound data has been processed.
[INFO][22:09:11]: [Client #75] Outbound data is ready to be sent after being processed.
[INFO][22:09:15]: [Client #75] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:09:16]: [Server #3350301] Received 507.38 MB of payload data from client #75 (simulated).
[INFO][22:09:16]: [Server #3350301] Adding client #93 to the list of clients for aggregation.
[INFO][22:09:16]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:09:16]: [Server #3350301] Adding client #21 to the list of clients for aggregation.
[INFO][22:09:16]: [Server #3350301] Adding client #72 to the list of clients for aggregation.
[INFO][22:09:16]: [Server #3350301] Adding client #12 to the list of clients for aggregation.
[INFO][22:09:16]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:09:16]: [Server #3350301] Updated weights have been received.
[INFO][22:09:16]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:09:17]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:09:17]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.89it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][22:09:28]: [93m[1m[Server #3350301] Global model perplexity: 30.42
[0m
[INFO][22:09:28]: [Server #3350301] All client reports have been processed.
[INFO][22:09:28]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_19.pth.
[INFO][22:09:30]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_19.pth.
[INFO][22:09:30]: [93m[1m
[Server #3350301] Starting round 20/100.[0m
[INFO][22:09:30]: [Server #3350301] Selected clients: [1, 63, 96, 90, 46]
[INFO][22:09:30]: [Server #3350301] Selecting client #96 for training.
[INFO][22:09:30]: [Server #3350301] Sending the current model to client #96 (simulated).
[INFO][22:09:34]: [Server #3350301] Sending 507.38 MB of payload data to client #96 (simulated).
[INFO][22:09:34]: [Server #3350301] Selecting client #1 for training.
[INFO][22:09:34]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:09:38]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:09:38]: [Client #96] Selected by the server.
[INFO][22:09:38]: [Client #96] Loading its data source...
[INFO][22:09:38]: [Client #96] Dataset size: 2018
[INFO][22:09:38]: [Client #96] Sampler: iid
[INFO][22:09:38]: [Client #1] Selected by the server.
[INFO][22:09:38]: [Client #1] Loading its data source...
[INFO][22:09:38]: [Client #1] Dataset size: 2018
[INFO][22:09:38]: [Client #1] Sampler: iid
[INFO][22:09:40]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:09:40]: [Client #1] Start to process inbound data.
[INFO][22:09:40]: [Client #96] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:09:40]: [Client #96] Start to process inbound data.
[INFO][22:09:40]: [93m[1m[Client #1] Started training in communication round #20.[0m
[INFO][22:09:40]: [93m[1m[Client #96] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.21s/it]  2%|â–         | 1/48 [00:04<03:40,  4.70s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][22:10:26]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 38.9693, 'train_samples_per_second': 155.353, 'train_steps_per_second': 1.232, 'train_loss': 2.8720391591389975, 'epoch': 3.0}
[INFO][22:10:26]: [Client #96] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_96_3350395.pth.
{'train_runtime': 39.3228, 'train_samples_per_second': 153.956, 'train_steps_per_second': 1.221, 'train_loss': 3.491260528564453, 'epoch': 3.0}
[INFO][22:10:27]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:10:27]: [Client #96] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_96_3350395.pth.
[INFO][22:10:27]: [Client #1] Model trained.
[INFO][22:10:27]: [Client #1] Inbound data has been processed.
[INFO][22:10:27]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:10:27]: [Client #96] Model trained.
[INFO][22:10:27]: [Client #96] Inbound data has been processed.
[INFO][22:10:27]: [Client #96] Outbound data is ready to be sent after being processed.
[INFO][22:10:34]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:10:34]: [Client #96] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:10:35]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:10:36]: [Server #3350301] Received 507.38 MB of payload data from client #96 (simulated).
[INFO][22:10:36]: [Server #3350301] Selecting client #90 for training.
[INFO][22:10:36]: [Server #3350301] Sending the current model to client #90 (simulated).
[INFO][22:10:40]: [Server #3350301] Sending 507.38 MB of payload data to client #90 (simulated).
[INFO][22:10:40]: [Server #3350301] Selecting client #63 for training.
[INFO][22:10:40]: [Server #3350301] Sending the current model to client #63 (simulated).
[INFO][22:10:43]: [Server #3350301] Sending 507.38 MB of payload data to client #63 (simulated).
[INFO][22:10:43]: [Client #90] Selected by the server.
[INFO][22:10:43]: [Client #90] Loading its data source...
[INFO][22:10:43]: [Client #90] Dataset size: 2018
[INFO][22:10:43]: [Client #90] Sampler: iid
[INFO][22:10:43]: [Client #63] Selected by the server.
[INFO][22:10:43]: [Client #63] Loading its data source...
[INFO][22:10:43]: [Client #63] Dataset size: 2018
[INFO][22:10:43]: [Client #63] Sampler: iid
[INFO][22:10:45]: [Client #90] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:10:45]: [Client #90] Start to process inbound data.
[INFO][22:10:45]: [Client #63] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:10:45]: [Client #63] Start to process inbound data.
[INFO][22:10:45]: [93m[1m[Client #90] Started training in communication round #20.[0m
[INFO][22:10:45]: [93m[1m[Client #63] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:42,  4.73s/it]  2%|â–         | 1/48 [00:04<03:44,  4.77s/it]  4%|â–         | 2/48 [00:05<01:49,  2.37s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:11:31]: [Client #63] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_63_3350396.pth.
{'train_runtime': 39.6276, 'train_samples_per_second': 152.772, 'train_steps_per_second': 1.211, 'train_loss': 3.3912359873453775, 'epoch': 3.0}
[INFO][22:11:31]: [Client #90] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_90_3350395.pth.
{'train_runtime': 39.5661, 'train_samples_per_second': 153.01, 'train_steps_per_second': 1.213, 'train_loss': 3.4821653366088867, 'epoch': 3.0}
[INFO][22:11:32]: [Client #63] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_63_3350396.pth.
[INFO][22:11:33]: [Client #90] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_90_3350395.pth.
[INFO][22:11:33]: [Client #63] Model trained.
[INFO][22:11:33]: [Client #63] Inbound data has been processed.
[INFO][22:11:33]: [Client #63] Outbound data is ready to be sent after being processed.
[INFO][22:11:33]: [Client #90] Model trained.
[INFO][22:11:33]: [Client #90] Inbound data has been processed.
[INFO][22:11:33]: [Client #90] Outbound data is ready to be sent after being processed.
[INFO][22:11:40]: [Client #63] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:11:40]: [Client #90] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:11:41]: [Server #3350301] Received 507.38 MB of payload data from client #63 (simulated).
[INFO][22:11:42]: [Server #3350301] Received 507.38 MB of payload data from client #90 (simulated).
[INFO][22:11:42]: [Server #3350301] Selecting client #46 for training.
[INFO][22:11:42]: [Server #3350301] Sending the current model to client #46 (simulated).
[INFO][22:11:46]: [Server #3350301] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][22:11:46]: [Client #46] Selected by the server.
[INFO][22:11:46]: [Client #46] Loading its data source...
[INFO][22:11:46]: [Client #46] Dataset size: 2018
[INFO][22:11:46]: [Client #46] Sampler: iid
[INFO][22:11:47]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:11:47]: [Client #46] Start to process inbound data.
[INFO][22:11:47]: [93m[1m[Client #46] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:12:20]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3350395.pth.
{'train_runtime': 26.6959, 'train_samples_per_second': 226.777, 'train_steps_per_second': 1.798, 'train_loss': 3.475038210550944, 'epoch': 3.0}
[INFO][22:12:22]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3350395.pth.
[INFO][22:12:22]: [Client #46] Model trained.
[INFO][22:12:22]: [Client #46] Inbound data has been processed.
[INFO][22:12:22]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][22:12:26]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:12:27]: [Server #3350301] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][22:12:27]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:12:27]: [Server #3350301] Adding client #24 to the list of clients for aggregation.
[INFO][22:12:27]: [Server #3350301] Adding client #36 to the list of clients for aggregation.
[INFO][22:12:27]: [Server #3350301] Adding client #46 to the list of clients for aggregation.
[INFO][22:12:27]: [Server #3350301] Adding client #39 to the list of clients for aggregation.
[INFO][22:12:27]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:12:27]: [Server #3350301] Updated weights have been received.
[INFO][22:12:28]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:12:28]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:12:28]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.64it/s]
[INFO][22:12:39]: [93m[1m[Server #3350301] Global model perplexity: 29.70
[0m
[INFO][22:12:39]: [Server #3350301] All client reports have been processed.
[INFO][22:12:39]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_20.pth.
[INFO][22:12:42]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_20.pth.
[INFO][22:12:42]: [93m[1m
[Server #3350301] Starting round 21/100.[0m
[INFO][22:12:42]: [Server #3350301] Selected clients: [1, 2, 13, 60, 78]
[INFO][22:12:42]: [Server #3350301] Selecting client #2 for training.
[INFO][22:12:42]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:12:46]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:12:46]: [Server #3350301] Selecting client #1 for training.
[INFO][22:12:46]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:12:49]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:12:49]: [Client #2] Selected by the server.
[INFO][22:12:49]: [Client #2] Loading its data source...
[INFO][22:12:49]: [Client #2] Dataset size: 2018
[INFO][22:12:49]: [Client #2] Sampler: iid
[INFO][22:12:49]: [Client #1] Selected by the server.
[INFO][22:12:49]: [Client #1] Loading its data source...
[INFO][22:12:49]: [Client #1] Dataset size: 2018
[INFO][22:12:49]: [Client #1] Sampler: iid
[INFO][22:12:51]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:12:51]: [Client #1] Start to process inbound data.
[INFO][22:12:51]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:12:51]: [Client #2] Start to process inbound data.
[INFO][22:12:52]: [93m[1m[Client #1] Started training in communication round #21.[0m
[INFO][22:12:52]: [93m[1m[Client #2] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.13s/it]  2%|â–         | 1/48 [00:04<03:47,  4.85s/it]  4%|â–         | 2/48 [00:04<01:37,  2.12s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.49s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][22:13:37]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 38.9838, 'train_samples_per_second': 155.295, 'train_steps_per_second': 1.231, 'train_loss': 2.819805463155111, 'epoch': 3.0}
[INFO][22:13:37]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.4778, 'train_samples_per_second': 153.352, 'train_steps_per_second': 1.216, 'train_loss': 3.2658262252807617, 'epoch': 3.0}
[INFO][22:13:38]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:13:38]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:13:39]: [Client #1] Model trained.
[INFO][22:13:39]: [Client #1] Inbound data has been processed.
[INFO][22:13:39]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:13:39]: [Client #2] Model trained.
[INFO][22:13:39]: [Client #2] Inbound data has been processed.
[INFO][22:13:39]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:13:45]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:13:45]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:13:46]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:13:47]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:13:47]: [Server #3350301] Selecting client #60 for training.
[INFO][22:13:47]: [Server #3350301] Sending the current model to client #60 (simulated).
[INFO][22:13:51]: [Server #3350301] Sending 507.38 MB of payload data to client #60 (simulated).
[INFO][22:13:51]: [Server #3350301] Selecting client #13 for training.
[INFO][22:13:51]: [Server #3350301] Sending the current model to client #13 (simulated).
[INFO][22:13:54]: [Server #3350301] Sending 507.38 MB of payload data to client #13 (simulated).
[INFO][22:13:54]: [Client #60] Selected by the server.
[INFO][22:13:54]: [Client #60] Loading its data source...
[INFO][22:13:54]: [Client #60] Dataset size: 2018
[INFO][22:13:54]: [Client #60] Sampler: iid
[INFO][22:13:54]: [Client #13] Selected by the server.
[INFO][22:13:54]: [Client #13] Loading its data source...
[INFO][22:13:54]: [Client #13] Dataset size: 2018
[INFO][22:13:54]: [Client #13] Sampler: iid
[INFO][22:13:56]: [Client #60] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:13:56]: [Client #60] Start to process inbound data.
[INFO][22:13:56]: [Client #13] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:13:56]: [Client #13] Start to process inbound data.
[INFO][22:13:57]: [93m[1m[Client #60] Started training in communication round #21.[0m
[INFO][22:13:57]: [93m[1m[Client #13] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  2%|â–         | 1/48 [00:04<03:50,  4.89s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:57,  1.30s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:14:43]: [Client #60] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_60_3350395.pth.
{'train_runtime': 39.7751, 'train_samples_per_second': 152.206, 'train_steps_per_second': 1.207, 'train_loss': 3.4259109497070312, 'epoch': 3.0}
[INFO][22:14:43]: [Client #13] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3350396.pth.
{'train_runtime': 39.6426, 'train_samples_per_second': 152.714, 'train_steps_per_second': 1.211, 'train_loss': 3.389552434285482, 'epoch': 3.0}
[INFO][22:14:44]: [Client #60] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_60_3350395.pth.
[INFO][22:14:44]: [Client #13] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3350396.pth.
[INFO][22:14:44]: [Client #60] Model trained.
[INFO][22:14:44]: [Client #60] Inbound data has been processed.
[INFO][22:14:44]: [Client #60] Outbound data is ready to be sent after being processed.
[INFO][22:14:45]: [Client #13] Model trained.
[INFO][22:14:45]: [Client #13] Inbound data has been processed.
[INFO][22:14:45]: [Client #13] Outbound data is ready to be sent after being processed.
[INFO][22:14:51]: [Client #60] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:14:51]: [Client #13] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:14:52]: [Server #3350301] Received 507.38 MB of payload data from client #60 (simulated).
[INFO][22:14:53]: [Server #3350301] Received 507.38 MB of payload data from client #13 (simulated).
[INFO][22:14:53]: [Server #3350301] Selecting client #78 for training.
[INFO][22:14:53]: [Server #3350301] Sending the current model to client #78 (simulated).
[INFO][22:14:57]: [Server #3350301] Sending 507.38 MB of payload data to client #78 (simulated).
[INFO][22:14:57]: [Client #78] Selected by the server.
[INFO][22:14:57]: [Client #78] Loading its data source...
[INFO][22:14:57]: [Client #78] Dataset size: 2018
[INFO][22:14:57]: [Client #78] Sampler: iid
[INFO][22:14:58]: [Client #78] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:14:58]: [Client #78] Start to process inbound data.
[INFO][22:14:58]: [93m[1m[Client #78] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.26s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:15:31]: [Client #78] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3350395.pth.
{'train_runtime': 26.8843, 'train_samples_per_second': 225.187, 'train_steps_per_second': 1.785, 'train_loss': 3.436598777770996, 'epoch': 3.0}
[INFO][22:15:33]: [Client #78] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3350395.pth.
[INFO][22:15:33]: [Client #78] Model trained.
[INFO][22:15:33]: [Client #78] Inbound data has been processed.
[INFO][22:15:33]: [Client #78] Outbound data is ready to be sent after being processed.
[INFO][22:15:37]: [Client #78] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:15:38]: [Server #3350301] Received 507.38 MB of payload data from client #78 (simulated).
[INFO][22:15:38]: [Server #3350301] Adding client #44 to the list of clients for aggregation.
[INFO][22:15:38]: [Server #3350301] Adding client #75 to the list of clients for aggregation.
[INFO][22:15:38]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:15:38]: [Server #3350301] Adding client #13 to the list of clients for aggregation.
[INFO][22:15:38]: [Server #3350301] Adding client #78 to the list of clients for aggregation.
[INFO][22:15:38]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:15:38]: [Server #3350301] Updated weights have been received.
[INFO][22:15:39]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:15:40]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:15:40]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.65it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 12.63it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][22:15:51]: [93m[1m[Server #3350301] Global model perplexity: 29.22
[0m
[INFO][22:15:51]: [Server #3350301] All client reports have been processed.
[INFO][22:15:51]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_21.pth.
[INFO][22:15:53]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_21.pth.
[INFO][22:15:53]: [93m[1m
[Server #3350301] Starting round 22/100.[0m
[INFO][22:15:53]: [Server #3350301] Selected clients: [1, 3, 4, 17, 57]
[INFO][22:15:53]: [Server #3350301] Selecting client #4 for training.
[INFO][22:15:53]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][22:15:57]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][22:15:57]: [Server #3350301] Selecting client #1 for training.
[INFO][22:15:57]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:16:01]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:16:01]: [Client #4] Selected by the server.
[INFO][22:16:01]: [Client #4] Loading its data source...
[INFO][22:16:01]: [Client #4] Dataset size: 2018
[INFO][22:16:01]: [Client #4] Sampler: iid
[INFO][22:16:01]: [Client #1] Selected by the server.
[INFO][22:16:01]: [Client #1] Loading its data source...
[INFO][22:16:01]: [Client #1] Dataset size: 2018
[INFO][22:16:01]: [Client #1] Sampler: iid
[INFO][22:16:02]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:16:02]: [Client #4] Start to process inbound data.
[INFO][22:16:02]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:16:02]: [Client #1] Start to process inbound data.
[INFO][22:16:03]: [93m[1m[Client #4] Started training in communication round #22.[0m
[INFO][22:16:03]: [93m[1m[Client #1] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  2%|â–         | 1/48 [00:04<03:46,  4.81s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][22:16:48]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.0227, 'train_samples_per_second': 155.14, 'train_steps_per_second': 1.23, 'train_loss': 2.7528273264567056, 'epoch': 3.0}
[INFO][22:16:48]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.457, 'train_samples_per_second': 153.433, 'train_steps_per_second': 1.217, 'train_loss': 3.363966623942057, 'epoch': 3.0}
[INFO][22:16:49]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:16:50]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][22:16:50]: [Client #1] Model trained.
[INFO][22:16:50]: [Client #1] Inbound data has been processed.
[INFO][22:16:50]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:16:50]: [Client #4] Model trained.
[INFO][22:16:50]: [Client #4] Inbound data has been processed.
[INFO][22:16:50]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][22:16:57]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:16:57]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:16:58]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:16:59]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][22:16:59]: [Server #3350301] Selecting client #17 for training.
[INFO][22:16:59]: [Server #3350301] Sending the current model to client #17 (simulated).
[INFO][22:17:02]: [Server #3350301] Sending 507.38 MB of payload data to client #17 (simulated).
[INFO][22:17:02]: [Server #3350301] Selecting client #3 for training.
[INFO][22:17:02]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:17:06]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:17:06]: [Client #17] Selected by the server.
[INFO][22:17:06]: [Client #17] Loading its data source...
[INFO][22:17:06]: [Client #17] Dataset size: 2018
[INFO][22:17:06]: [Client #17] Sampler: iid
[INFO][22:17:06]: [Client #3] Selected by the server.
[INFO][22:17:06]: [Client #3] Loading its data source...
[INFO][22:17:06]: [Client #3] Dataset size: 2018
[INFO][22:17:06]: [Client #3] Sampler: iid
[INFO][22:17:07]: [Client #17] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:17:07]: [Client #17] Start to process inbound data.
[INFO][22:17:07]: [93m[1m[Client #17] Started training in communication round #22.[0m
[INFO][22:17:07]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:17:07]: [Client #3] Start to process inbound data.
[INFO][22:17:08]: [93m[1m[Client #3] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:39,  4.67s/it]  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  4%|â–         | 2/48 [00:05<01:53,  2.48s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.78s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.23s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.23s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.00it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:38,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:37,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:30,  1.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.05it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.06it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.06it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:21,  1.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:15,  1.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.01it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.06it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.03it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
[INFO][22:18:02]: [Client #17] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3350395.pth.
{'train_runtime': 48.4036, 'train_samples_per_second': 125.073, 'train_steps_per_second': 0.992, 'train_loss': 3.3624340693155923, 'epoch': 3.0}
[INFO][22:18:02]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 48.2417, 'train_samples_per_second': 125.493, 'train_steps_per_second': 0.995, 'train_loss': 3.276399612426758, 'epoch': 3.0}
[INFO][22:18:03]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][22:18:04]: [Client #17] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3350395.pth.
[INFO][22:18:04]: [Client #3] Model trained.
[INFO][22:18:04]: [Client #3] Inbound data has been processed.
[INFO][22:18:04]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][22:18:04]: [Client #17] Model trained.
[INFO][22:18:04]: [Client #17] Inbound data has been processed.
[INFO][22:18:04]: [Client #17] Outbound data is ready to be sent after being processed.
[INFO][22:18:11]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:18:11]: [Client #17] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:18:12]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][22:18:13]: [Server #3350301] Received 507.38 MB of payload data from client #17 (simulated).
[INFO][22:18:13]: [Server #3350301] Selecting client #57 for training.
[INFO][22:18:13]: [Server #3350301] Sending the current model to client #57 (simulated).
[INFO][22:18:16]: [Server #3350301] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][22:18:16]: [Client #57] Selected by the server.
[INFO][22:18:16]: [Client #57] Loading its data source...
[INFO][22:18:16]: [Client #57] Dataset size: 2018
[INFO][22:18:16]: [Client #57] Sampler: iid
[INFO][22:18:18]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:18:18]: [Client #57] Start to process inbound data.
[INFO][22:18:18]: [93m[1m[Client #57] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.21s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:18:51]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3350395.pth.
{'train_runtime': 26.825, 'train_samples_per_second': 225.685, 'train_steps_per_second': 1.789, 'train_loss': 3.348632494608561, 'epoch': 3.0}
[INFO][22:18:52]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3350395.pth.
[INFO][22:18:52]: [Client #57] Model trained.
[INFO][22:18:52]: [Client #57] Inbound data has been processed.
[INFO][22:18:52]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][22:18:56]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:18:57]: [Server #3350301] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][22:18:57]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:18:57]: [Server #3350301] Adding client #60 to the list of clients for aggregation.
[INFO][22:18:57]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:18:57]: [Server #3350301] Adding client #17 to the list of clients for aggregation.
[INFO][22:18:57]: [Server #3350301] Adding client #57 to the list of clients for aggregation.
[INFO][22:18:57]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:18:57]: [Server #3350301] Updated weights have been received.
[INFO][22:18:58]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:18:58]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:18:58]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.66it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.64it/s]
[INFO][22:19:09]: [93m[1m[Server #3350301] Global model perplexity: 29.09
[0m
[INFO][22:19:09]: [Server #3350301] All client reports have been processed.
[INFO][22:19:09]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_22.pth.
[INFO][22:19:12]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_22.pth.
[INFO][22:19:12]: [93m[1m
[Server #3350301] Starting round 23/100.[0m
[INFO][22:19:12]: [Server #3350301] Selected clients: [1, 15, 40, 31, 29]
[INFO][22:19:12]: [Server #3350301] Selecting client #40 for training.
[INFO][22:19:12]: [Server #3350301] Sending the current model to client #40 (simulated).
[INFO][22:19:16]: [Server #3350301] Sending 507.38 MB of payload data to client #40 (simulated).
[INFO][22:19:16]: [Server #3350301] Selecting client #1 for training.
[INFO][22:19:16]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:19:19]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:19:19]: [Client #40] Selected by the server.
[INFO][22:19:19]: [Client #40] Loading its data source...
[INFO][22:19:19]: [Client #40] Dataset size: 2018
[INFO][22:19:19]: [Client #40] Sampler: iid
[INFO][22:19:19]: [Client #1] Selected by the server.
[INFO][22:19:19]: [Client #1] Loading its data source...
[INFO][22:19:19]: [Client #1] Dataset size: 2018
[INFO][22:19:19]: [Client #1] Sampler: iid
[INFO][22:19:21]: [Client #40] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:19:21]: [Client #40] Start to process inbound data.
[INFO][22:19:21]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:19:21]: [Client #1] Start to process inbound data.
[INFO][22:19:21]: [93m[1m[Client #1] Started training in communication round #23.[0m
[INFO][22:19:21]: [93m[1m[Client #40] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:33,  4.54s/it]  2%|â–         | 1/48 [00:05<03:59,  5.10s/it]  4%|â–         | 2/48 [00:05<01:45,  2.30s/it]  4%|â–         | 2/48 [00:05<01:57,  2.56s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.58s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:08<00:49,  1.15s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][22:20:07]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4391, 'train_samples_per_second': 153.503, 'train_steps_per_second': 1.217, 'train_loss': 2.6955998738606772, 'epoch': 3.0}
[INFO][22:20:08]: [Client #40] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_40_3350395.pth.
{'train_runtime': 39.8764, 'train_samples_per_second': 151.819, 'train_steps_per_second': 1.204, 'train_loss': 3.414525349934896, 'epoch': 3.0}
[INFO][22:20:08]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:20:09]: [Client #40] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_40_3350395.pth.
[INFO][22:20:09]: [Client #1] Model trained.
[INFO][22:20:09]: [Client #1] Inbound data has been processed.
[INFO][22:20:09]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:20:10]: [Client #40] Model trained.
[INFO][22:20:10]: [Client #40] Inbound data has been processed.
[INFO][22:20:10]: [Client #40] Outbound data is ready to be sent after being processed.
[INFO][22:20:15]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:20:16]: [Client #40] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:20:16]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:20:17]: [Server #3350301] Received 507.38 MB of payload data from client #40 (simulated).
[INFO][22:20:17]: [Server #3350301] Selecting client #31 for training.
[INFO][22:20:17]: [Server #3350301] Sending the current model to client #31 (simulated).
[INFO][22:20:21]: [Server #3350301] Sending 507.38 MB of payload data to client #31 (simulated).
[INFO][22:20:21]: [Server #3350301] Selecting client #29 for training.
[INFO][22:20:21]: [Server #3350301] Sending the current model to client #29 (simulated).
[INFO][22:20:24]: [Server #3350301] Sending 507.38 MB of payload data to client #29 (simulated).
[INFO][22:20:24]: [Client #31] Selected by the server.
[INFO][22:20:24]: [Client #31] Loading its data source...
[INFO][22:20:24]: [Client #29] Selected by the server.
[INFO][22:20:24]: [Client #31] Dataset size: 2018
[INFO][22:20:24]: [Client #31] Sampler: iid
[INFO][22:20:24]: [Client #29] Loading its data source...
[INFO][22:20:24]: [Client #29] Dataset size: 2018
[INFO][22:20:24]: [Client #29] Sampler: iid
[INFO][22:20:26]: [Client #29] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:20:26]: [Client #29] Start to process inbound data.
[INFO][22:20:26]: [Client #31] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:20:26]: [Client #31] Start to process inbound data.
[INFO][22:20:27]: [93m[1m[Client #29] Started training in communication round #23.[0m
[INFO][22:20:27]: [93m[1m[Client #31] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.11s/it]  2%|â–         | 1/48 [00:04<03:46,  4.82s/it]  4%|â–         | 2/48 [00:04<01:37,  2.11s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:21:13]: [Client #31] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_31_3350395.pth.
{'train_runtime': 39.2129, 'train_samples_per_second': 154.388, 'train_steps_per_second': 1.224, 'train_loss': 3.3419933319091797, 'epoch': 3.0}
[INFO][22:21:13]: [Client #29] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_29_3350396.pth.
{'train_runtime': 39.6692, 'train_samples_per_second': 152.612, 'train_steps_per_second': 1.21, 'train_loss': 3.334935188293457, 'epoch': 3.0}
[INFO][22:21:14]: [Client #31] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_31_3350395.pth.
[INFO][22:21:14]: [Client #29] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_29_3350396.pth.
[INFO][22:21:15]: [Client #31] Model trained.
[INFO][22:21:15]: [Client #31] Inbound data has been processed.
[INFO][22:21:15]: [Client #31] Outbound data is ready to be sent after being processed.
[INFO][22:21:15]: [Client #29] Model trained.
[INFO][22:21:15]: [Client #29] Inbound data has been processed.
[INFO][22:21:15]: [Client #29] Outbound data is ready to be sent after being processed.
[INFO][22:21:22]: [Client #31] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:21:22]: [Client #29] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:21:22]: [Server #3350301] Received 507.38 MB of payload data from client #31 (simulated).
[INFO][22:21:24]: [Server #3350301] Received 507.38 MB of payload data from client #29 (simulated).
[INFO][22:21:24]: [Server #3350301] Selecting client #15 for training.
[INFO][22:21:24]: [Server #3350301] Sending the current model to client #15 (simulated).
[INFO][22:21:27]: [Server #3350301] Sending 507.38 MB of payload data to client #15 (simulated).
[INFO][22:21:27]: [Client #15] Selected by the server.
[INFO][22:21:27]: [Client #15] Loading its data source...
[INFO][22:21:27]: [Client #15] Dataset size: 2018
[INFO][22:21:27]: [Client #15] Sampler: iid
[INFO][22:21:29]: [Client #15] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:21:29]: [Client #15] Start to process inbound data.
[INFO][22:21:29]: [93m[1m[Client #15] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.99it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:22:02]: [Client #15] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_15_3350395.pth.
{'train_runtime': 26.6883, 'train_samples_per_second': 226.841, 'train_steps_per_second': 1.799, 'train_loss': 3.323462804158529, 'epoch': 3.0}
[INFO][22:22:03]: [Client #15] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_15_3350395.pth.
[INFO][22:22:03]: [Client #15] Model trained.
[INFO][22:22:03]: [Client #15] Inbound data has been processed.
[INFO][22:22:03]: [Client #15] Outbound data is ready to be sent after being processed.
[INFO][22:22:07]: [Client #15] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:22:08]: [Server #3350301] Received 507.38 MB of payload data from client #15 (simulated).
[INFO][22:22:08]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:22:08]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:22:08]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][22:22:08]: [Server #3350301] Adding client #63 to the list of clients for aggregation.
[INFO][22:22:08]: [Server #3350301] Adding client #90 to the list of clients for aggregation.
[INFO][22:22:08]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:22:08]: [Server #3350301] Updated weights have been received.
[INFO][22:22:09]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:22:10]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:22:10]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.73it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][22:22:20]: [93m[1m[Server #3350301] Global model perplexity: 29.28
[0m
[INFO][22:22:20]: [Server #3350301] All client reports have been processed.
[INFO][22:22:21]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_23.pth.
[INFO][22:22:23]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_23.pth.
[INFO][22:22:23]: [93m[1m
[Server #3350301] Starting round 24/100.[0m
[INFO][22:22:23]: [Server #3350301] Selected clients: [1, 62, 2, 87, 85]
[INFO][22:22:23]: [Server #3350301] Selecting client #2 for training.
[INFO][22:22:23]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:22:27]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:22:27]: [Server #3350301] Selecting client #1 for training.
[INFO][22:22:27]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:22:30]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:22:30]: [Client #2] Selected by the server.
[INFO][22:22:30]: [Client #2] Loading its data source...
[INFO][22:22:30]: [Client #2] Dataset size: 2018
[INFO][22:22:30]: [Client #2] Sampler: iid
[INFO][22:22:30]: [Client #1] Selected by the server.
[INFO][22:22:30]: [Client #1] Loading its data source...
[INFO][22:22:30]: [Client #1] Dataset size: 2018
[INFO][22:22:30]: [Client #1] Sampler: iid
[INFO][22:22:32]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:22:32]: [Client #2] Start to process inbound data.
[INFO][22:22:32]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:22:32]: [Client #1] Start to process inbound data.
[INFO][22:22:32]: [93m[1m[Client #1] Started training in communication round #24.[0m
[INFO][22:22:32]: [93m[1m[Client #2] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:52,  4.95s/it]  2%|â–         | 1/48 [00:04<03:52,  4.95s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  4%|â–         | 2/48 [00:05<02:00,  2.61s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.83s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.84s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.43s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.44s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.21s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:44,  1.05s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:39,  1.05it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.13it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][22:23:19]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 40.2473, 'train_samples_per_second': 150.42, 'train_steps_per_second': 1.193, 'train_loss': 3.193828582763672, 'epoch': 3.0}
[INFO][22:23:19]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 40.1605, 'train_samples_per_second': 150.745, 'train_steps_per_second': 1.195, 'train_loss': 2.6717920303344727, 'epoch': 3.0}
[INFO][22:23:20]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:23:20]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:23:21]: [Client #2] Model trained.
[INFO][22:23:21]: [Client #2] Inbound data has been processed.
[INFO][22:23:21]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:23:21]: [Client #1] Model trained.
[INFO][22:23:21]: [Client #1] Inbound data has been processed.
[INFO][22:23:21]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:23:27]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:23:28]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:23:28]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:23:29]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:23:29]: [Server #3350301] Selecting client #62 for training.
[INFO][22:23:29]: [Server #3350301] Sending the current model to client #62 (simulated).
[INFO][22:23:33]: [Server #3350301] Sending 507.38 MB of payload data to client #62 (simulated).
[INFO][22:23:33]: [Server #3350301] Selecting client #85 for training.
[INFO][22:23:33]: [Server #3350301] Sending the current model to client #85 (simulated).
[INFO][22:23:36]: [Server #3350301] Sending 507.38 MB of payload data to client #85 (simulated).
[INFO][22:23:37]: [Client #62] Selected by the server.
[INFO][22:23:37]: [Client #62] Loading its data source...
[INFO][22:23:37]: [Client #85] Selected by the server.
[INFO][22:23:37]: [Client #85] Loading its data source...
[INFO][22:23:37]: [Client #62] Dataset size: 2018
[INFO][22:23:37]: [Client #62] Sampler: iid
[INFO][22:23:37]: [Client #85] Dataset size: 2018
[INFO][22:23:37]: [Client #85] Sampler: iid
[INFO][22:23:38]: [Client #85] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:23:38]: [Client #85] Start to process inbound data.
[INFO][22:23:38]: [Client #62] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:23:38]: [Client #62] Start to process inbound data.
[INFO][22:23:39]: [93m[1m[Client #85] Started training in communication round #24.[0m
[INFO][22:23:39]: [93m[1m[Client #62] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  2%|â–         | 1/48 [00:04<03:42,  4.74s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][22:24:24]: [Client #85] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3350396.pth.
{'train_runtime': 39.0768, 'train_samples_per_second': 154.926, 'train_steps_per_second': 1.228, 'train_loss': 3.321272850036621, 'epoch': 3.0}
[INFO][22:24:24]: [Client #62] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3350395.pth.
{'train_runtime': 39.4396, 'train_samples_per_second': 153.501, 'train_steps_per_second': 1.217, 'train_loss': 3.389495849609375, 'epoch': 3.0}
[INFO][22:24:25]: [Client #85] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3350396.pth.
[INFO][22:24:25]: [Client #62] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3350395.pth.
[INFO][22:24:25]: [Client #85] Model trained.
[INFO][22:24:25]: [Client #85] Inbound data has been processed.
[INFO][22:24:25]: [Client #85] Outbound data is ready to be sent after being processed.
[INFO][22:24:26]: [Client #62] Model trained.
[INFO][22:24:26]: [Client #62] Inbound data has been processed.
[INFO][22:24:26]: [Client #62] Outbound data is ready to be sent after being processed.
[INFO][22:24:32]: [Client #85] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:24:32]: [Client #62] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:24:33]: [Server #3350301] Received 507.38 MB of payload data from client #85 (simulated).
[INFO][22:24:35]: [Server #3350301] Received 507.38 MB of payload data from client #62 (simulated).
[INFO][22:24:35]: [Server #3350301] Selecting client #87 for training.
[INFO][22:24:35]: [Server #3350301] Sending the current model to client #87 (simulated).
[INFO][22:24:38]: [Server #3350301] Sending 507.38 MB of payload data to client #87 (simulated).
[INFO][22:24:38]: [Client #87] Selected by the server.
[INFO][22:24:38]: [Client #87] Loading its data source...
[INFO][22:24:38]: [Client #87] Dataset size: 2018
[INFO][22:24:38]: [Client #87] Sampler: iid
[INFO][22:24:40]: [Client #87] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:24:40]: [Client #87] Start to process inbound data.
[INFO][22:24:40]: [93m[1m[Client #87] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.17s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:25:13]: [Client #87] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_87_3350395.pth.
{'train_runtime': 26.6838, 'train_samples_per_second': 226.879, 'train_steps_per_second': 1.799, 'train_loss': 3.326853116353353, 'epoch': 3.0}
[INFO][22:25:14]: [Client #87] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_87_3350395.pth.
[INFO][22:25:15]: [Client #87] Model trained.
[INFO][22:25:15]: [Client #87] Inbound data has been processed.
[INFO][22:25:15]: [Client #87] Outbound data is ready to be sent after being processed.
[INFO][22:25:18]: [Client #87] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:25:20]: [Server #3350301] Received 507.38 MB of payload data from client #87 (simulated).
[INFO][22:25:20]: [Server #3350301] Adding client #96 to the list of clients for aggregation.
[INFO][22:25:20]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:25:20]: [Server #3350301] Adding client #62 to the list of clients for aggregation.
[INFO][22:25:20]: [Server #3350301] Adding client #85 to the list of clients for aggregation.
[INFO][22:25:20]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:25:20]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:25:20]: [Server #3350301] Updated weights have been received.
[INFO][22:25:20]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:25:21]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:25:21]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][22:25:31]: [93m[1m[Server #3350301] Global model perplexity: 28.65
[0m
[INFO][22:25:31]: [Server #3350301] All client reports have been processed.
[INFO][22:25:31]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_24.pth.
[INFO][22:25:34]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_24.pth.
[INFO][22:25:34]: [93m[1m
[Server #3350301] Starting round 25/100.[0m
[INFO][22:25:34]: [Server #3350301] Selected clients: [1, 2, 3, 26, 54]
[INFO][22:25:34]: [Server #3350301] Selecting client #2 for training.
[INFO][22:25:34]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:25:38]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:25:38]: [Server #3350301] Selecting client #1 for training.
[INFO][22:25:38]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:25:41]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:25:41]: [Client #2] Selected by the server.
[INFO][22:25:41]: [Client #2] Loading its data source...
[INFO][22:25:41]: [Client #2] Dataset size: 2018
[INFO][22:25:41]: [Client #2] Sampler: iid
[INFO][22:25:41]: [Client #1] Selected by the server.
[INFO][22:25:41]: [Client #1] Loading its data source...
[INFO][22:25:41]: [Client #1] Dataset size: 2018
[INFO][22:25:41]: [Client #1] Sampler: iid
[INFO][22:25:43]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:25:43]: [Client #2] Start to process inbound data.
[INFO][22:25:43]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:25:43]: [Client #1] Start to process inbound data.
[INFO][22:25:44]: [93m[1m[Client #1] Started training in communication round #25.[0m
[INFO][22:25:44]: [93m[1m[Client #2] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.40s/it]  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.58s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][22:26:29]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.0723, 'train_samples_per_second': 154.944, 'train_steps_per_second': 1.228, 'train_loss': 3.1055335998535156, 'epoch': 3.0}
[INFO][22:26:29]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4016, 'train_samples_per_second': 153.649, 'train_steps_per_second': 1.218, 'train_loss': 2.6123600006103516, 'epoch': 3.0}
[INFO][22:26:30]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:26:30]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:26:30]: [Client #2] Model trained.
[INFO][22:26:30]: [Client #2] Inbound data has been processed.
[INFO][22:26:30]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:26:31]: [Client #1] Model trained.
[INFO][22:26:31]: [Client #1] Inbound data has been processed.
[INFO][22:26:31]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:26:37]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:26:37]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:26:38]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:26:39]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:26:39]: [Server #3350301] Selecting client #54 for training.
[INFO][22:26:39]: [Server #3350301] Sending the current model to client #54 (simulated).
[INFO][22:26:43]: [Server #3350301] Sending 507.38 MB of payload data to client #54 (simulated).
[INFO][22:26:43]: [Server #3350301] Selecting client #3 for training.
[INFO][22:26:43]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:26:46]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:26:46]: [Client #54] Selected by the server.
[INFO][22:26:46]: [Client #54] Loading its data source...
[INFO][22:26:46]: [Client #54] Dataset size: 2018
[INFO][22:26:46]: [Client #3] Selected by the server.
[INFO][22:26:46]: [Client #54] Sampler: iid
[INFO][22:26:46]: [Client #3] Loading its data source...
[INFO][22:26:46]: [Client #3] Dataset size: 2018
[INFO][22:26:46]: [Client #3] Sampler: iid
[INFO][22:26:48]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:26:48]: [Client #3] Start to process inbound data.
[INFO][22:26:48]: [93m[1m[Client #3] Started training in communication round #25.[0m
[INFO][22:26:48]: [Client #54] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:26:48]: [Client #54] Start to process inbound data.
[INFO][22:26:48]: [93m[1m[Client #54] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  2%|â–         | 1/48 [00:04<03:48,  4.87s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  4%|â–         | 2/48 [00:05<01:54,  2.48s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.71s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.33s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][22:27:34]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.8782, 'train_samples_per_second': 151.812, 'train_steps_per_second': 1.204, 'train_loss': 3.179560343424479, 'epoch': 3.0}
[INFO][22:27:34]: [Client #54] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3350395.pth.
{'train_runtime': 39.7215, 'train_samples_per_second': 152.411, 'train_steps_per_second': 1.208, 'train_loss': 3.3681503931681314, 'epoch': 3.0}
[INFO][22:27:35]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][22:27:35]: [Client #54] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3350395.pth.
[INFO][22:27:35]: [Client #3] Model trained.
[INFO][22:27:35]: [Client #3] Inbound data has been processed.
[INFO][22:27:35]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][22:27:36]: [Client #54] Model trained.
[INFO][22:27:36]: [Client #54] Inbound data has been processed.
[INFO][22:27:36]: [Client #54] Outbound data is ready to be sent after being processed.
[INFO][22:27:42]: [Client #54] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:27:42]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:27:43]: [Server #3350301] Received 507.38 MB of payload data from client #54 (simulated).
[INFO][22:27:44]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][22:27:44]: [Server #3350301] Selecting client #26 for training.
[INFO][22:27:44]: [Server #3350301] Sending the current model to client #26 (simulated).
[INFO][22:27:48]: [Server #3350301] Sending 507.38 MB of payload data to client #26 (simulated).
[INFO][22:27:48]: [Client #26] Selected by the server.
[INFO][22:27:48]: [Client #26] Loading its data source...
[INFO][22:27:48]: [Client #26] Dataset size: 2018
[INFO][22:27:48]: [Client #26] Sampler: iid
[INFO][22:27:49]: [Client #26] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:27:49]: [Client #26] Start to process inbound data.
[INFO][22:27:49]: [93m[1m[Client #26] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.78it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.85it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.90it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.93it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.96it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.97it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  1.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][22:28:22]: [Client #26] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_26_3350395.pth.
{'train_runtime': 26.9255, 'train_samples_per_second': 224.843, 'train_steps_per_second': 1.783, 'train_loss': 3.372826894124349, 'epoch': 3.0}
[INFO][22:28:23]: [Client #26] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_26_3350395.pth.
[INFO][22:28:24]: [Client #26] Model trained.
[INFO][22:28:24]: [Client #26] Inbound data has been processed.
[INFO][22:28:24]: [Client #26] Outbound data is ready to be sent after being processed.
[INFO][22:28:28]: [Client #26] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:28:29]: [Server #3350301] Received 507.38 MB of payload data from client #26 (simulated).
[INFO][22:28:29]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:28:29]: [Server #3350301] Adding client #54 to the list of clients for aggregation.
[INFO][22:28:29]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:28:29]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:28:29]: [Server #3350301] Adding client #15 to the list of clients for aggregation.
[INFO][22:28:29]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:28:29]: [Server #3350301] Updated weights have been received.
[INFO][22:28:29]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:28:30]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:28:30]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.24it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][22:28:41]: [93m[1m[Server #3350301] Global model perplexity: 28.38
[0m
[INFO][22:28:41]: [Server #3350301] All client reports have been processed.
[INFO][22:28:41]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_25.pth.
[INFO][22:28:43]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_25.pth.
[INFO][22:28:43]: [93m[1m
[Server #3350301] Starting round 26/100.[0m
[INFO][22:28:43]: [Server #3350301] Selected clients: [1, 2, 55, 35, 10]
[INFO][22:28:43]: [Server #3350301] Selecting client #2 for training.
[INFO][22:28:43]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:28:47]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:28:47]: [Server #3350301] Selecting client #1 for training.
[INFO][22:28:47]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:28:50]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:28:50]: [Client #2] Selected by the server.
[INFO][22:28:50]: [Client #2] Loading its data source...
[INFO][22:28:50]: [Client #2] Dataset size: 2018
[INFO][22:28:50]: [Client #2] Sampler: iid
[INFO][22:28:50]: [Client #1] Selected by the server.
[INFO][22:28:50]: [Client #1] Loading its data source...
[INFO][22:28:50]: [Client #1] Dataset size: 2018
[INFO][22:28:50]: [Client #1] Sampler: iid
[INFO][22:28:52]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:28:52]: [Client #2] Start to process inbound data.
[INFO][22:28:52]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:28:52]: [Client #1] Start to process inbound data.
[INFO][22:28:53]: [93m[1m[Client #1] Started training in communication round #26.[0m
[INFO][22:28:53]: [93m[1m[Client #2] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  2%|â–         | 1/48 [00:04<03:51,  4.93s/it]  4%|â–         | 2/48 [00:05<01:57,  2.54s/it]  4%|â–         | 2/48 [00:05<01:58,  2.57s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.77s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.39s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.12s/it] 10%|â–ˆ         | 5/48 [00:08<00:49,  1.15s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.01s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
[INFO][22:29:39]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 40.0939, 'train_samples_per_second': 150.996, 'train_steps_per_second': 1.197, 'train_loss': 2.5771700541178384, 'epoch': 3.0}
[INFO][22:29:39]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.9688, 'train_samples_per_second': 151.468, 'train_steps_per_second': 1.201, 'train_loss': 3.0264533360799155, 'epoch': 3.0}
[INFO][22:29:40]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:29:41]: [Client #1] Model trained.
[INFO][22:29:41]: [Client #1] Inbound data has been processed.
[INFO][22:29:41]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:29:41]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:29:41]: [Client #2] Model trained.
[INFO][22:29:41]: [Client #2] Inbound data has been processed.
[INFO][22:29:41]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:29:47]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:29:47]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:29:48]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:29:49]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:29:49]: [Server #3350301] Selecting client #10 for training.
[INFO][22:29:49]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][22:29:53]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][22:29:53]: [Server #3350301] Selecting client #35 for training.
[INFO][22:29:53]: [Server #3350301] Sending the current model to client #35 (simulated).
[INFO][22:29:56]: [Server #3350301] Sending 507.38 MB of payload data to client #35 (simulated).
[INFO][22:29:56]: [Client #10] Selected by the server.
[INFO][22:29:56]: [Client #10] Loading its data source...
[INFO][22:29:56]: [Client #10] Dataset size: 2018
[INFO][22:29:56]: [Client #10] Sampler: iid
[INFO][22:29:56]: [Client #35] Selected by the server.
[INFO][22:29:56]: [Client #35] Loading its data source...
[INFO][22:29:56]: [Client #35] Dataset size: 2018
[INFO][22:29:56]: [Client #35] Sampler: iid
[INFO][22:29:58]: [Client #35] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:29:58]: [Client #35] Start to process inbound data.
[INFO][22:29:58]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:29:58]: [Client #10] Start to process inbound data.
[INFO][22:29:59]: [93m[1m[Client #10] Started training in communication round #26.[0m
[INFO][22:29:59]: [93m[1m[Client #35] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.21s/it]  2%|â–         | 1/48 [00:04<03:47,  4.84s/it]  4%|â–         | 2/48 [00:04<01:38,  2.13s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:30:44]: [Client #35] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_35_3350396.pth.
{'train_runtime': 39.1924, 'train_samples_per_second': 154.469, 'train_steps_per_second': 1.225, 'train_loss': 3.2705376942952475, 'epoch': 3.0}
[INFO][22:30:44]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.5621, 'train_samples_per_second': 153.025, 'train_steps_per_second': 1.213, 'train_loss': 3.3540541330973306, 'epoch': 3.0}
[INFO][22:30:45]: [Client #35] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_35_3350396.pth.
[INFO][22:30:46]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][22:30:46]: [Client #35] Model trained.
[INFO][22:30:46]: [Client #35] Inbound data has been processed.
[INFO][22:30:46]: [Client #35] Outbound data is ready to be sent after being processed.
[INFO][22:30:46]: [Client #10] Model trained.
[INFO][22:30:46]: [Client #10] Inbound data has been processed.
[INFO][22:30:46]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][22:30:52]: [Client #35] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:30:53]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:30:53]: [Server #3350301] Received 507.38 MB of payload data from client #35 (simulated).
[INFO][22:30:54]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][22:30:54]: [Server #3350301] Selecting client #55 for training.
[INFO][22:30:54]: [Server #3350301] Sending the current model to client #55 (simulated).
[INFO][22:30:58]: [Server #3350301] Sending 507.38 MB of payload data to client #55 (simulated).
[INFO][22:30:58]: [Client #55] Selected by the server.
[INFO][22:30:58]: [Client #55] Loading its data source...
[INFO][22:30:58]: [Client #55] Dataset size: 2018
[INFO][22:30:58]: [Client #55] Sampler: iid
[INFO][22:30:59]: [Client #55] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:30:59]: [Client #55] Start to process inbound data.
[INFO][22:30:59]: [93m[1m[Client #55] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:31:32]: [Client #55] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_55_3350395.pth.
{'train_runtime': 26.694, 'train_samples_per_second': 226.793, 'train_steps_per_second': 1.798, 'train_loss': 3.271254539489746, 'epoch': 3.0}
[INFO][22:31:33]: [Client #55] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_55_3350395.pth.
[INFO][22:31:34]: [Client #55] Model trained.
[INFO][22:31:34]: [Client #55] Inbound data has been processed.
[INFO][22:31:34]: [Client #55] Outbound data is ready to be sent after being processed.
[INFO][22:31:37]: [Client #55] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:31:38]: [Server #3350301] Received 507.38 MB of payload data from client #55 (simulated).
[INFO][22:31:38]: [Server #3350301] Adding client #29 to the list of clients for aggregation.
[INFO][22:31:38]: [Server #3350301] Adding client #31 to the list of clients for aggregation.
[INFO][22:31:38]: [Server #3350301] Adding client #40 to the list of clients for aggregation.
[INFO][22:31:38]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:31:38]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][22:31:38]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:31:38]: [Server #3350301] Updated weights have been received.
[INFO][22:31:39]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:31:40]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:31:40]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.72it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.53it/s]
[INFO][22:31:50]: [93m[1m[Server #3350301] Global model perplexity: 28.76
[0m
[INFO][22:31:50]: [Server #3350301] All client reports have been processed.
[INFO][22:31:50]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_26.pth.
[INFO][22:31:53]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_26.pth.
[INFO][22:31:53]: [93m[1m
[Server #3350301] Starting round 27/100.[0m
[INFO][22:31:53]: [Server #3350301] Selected clients: [1, 3, 4, 5, 23]
[INFO][22:31:53]: [Server #3350301] Selecting client #4 for training.
[INFO][22:31:53]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][22:31:57]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][22:31:57]: [Server #3350301] Selecting client #1 for training.
[INFO][22:31:57]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:32:00]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:32:00]: [Client #4] Selected by the server.
[INFO][22:32:00]: [Client #4] Loading its data source...
[INFO][22:32:00]: [Client #4] Dataset size: 2018
[INFO][22:32:00]: [Client #4] Sampler: iid
[INFO][22:32:00]: [Client #1] Selected by the server.
[INFO][22:32:00]: [Client #1] Loading its data source...
[INFO][22:32:00]: [Client #1] Dataset size: 2018
[INFO][22:32:00]: [Client #1] Sampler: iid
[INFO][22:32:02]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:32:02]: [Client #1] Start to process inbound data.
[INFO][22:32:02]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:32:02]: [Client #4] Start to process inbound data.
[INFO][22:32:02]: [93m[1m[Client #1] Started training in communication round #27.[0m
[INFO][22:32:02]: [93m[1m[Client #4] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:29,  4.45s/it]  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  4%|â–         | 2/48 [00:05<01:45,  2.30s/it]  4%|â–         | 2/48 [00:05<01:46,  2.31s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:58,  1.33s/it]  8%|â–Š         | 4/48 [00:06<00:57,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.15s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.18s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.06s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.07s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.01s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:40,  1.00it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.05it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:36,  1.07it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:36,  1.08it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:34,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:34,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:33,  1.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:33,  1.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.12it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.12it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:31,  1.12it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:31,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.12it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:31,  1.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:27,  1.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:28,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:24,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:22,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:21,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:20,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:19,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:19,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:18,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:18,  1.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:17,  1.13it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:16,  1.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:16,  1.13it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.12it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:16,  1.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.11it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:31<00:13,  1.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.04it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.02it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:11,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:10,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:10,  1.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:09,  1.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:09,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.10it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.02it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.02it/s]
[INFO][22:32:56]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 46.9712, 'train_samples_per_second': 128.887, 'train_steps_per_second': 1.022, 'train_loss': 3.2563212712605796, 'epoch': 3.0}
[INFO][22:32:56]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.1888, 'train_samples_per_second': 128.293, 'train_steps_per_second': 1.017, 'train_loss': 2.543674945831299, 'epoch': 3.0}
[INFO][22:32:57]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][22:32:57]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:32:57]: [Client #4] Model trained.
[INFO][22:32:57]: [Client #4] Inbound data has been processed.
[INFO][22:32:57]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][22:32:57]: [Client #1] Model trained.
[INFO][22:32:57]: [Client #1] Inbound data has been processed.
[INFO][22:32:57]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:33:04]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:33:04]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:33:05]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:33:06]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][22:33:06]: [Server #3350301] Selecting client #3 for training.
[INFO][22:33:06]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:33:10]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:33:10]: [Server #3350301] Selecting client #5 for training.
[INFO][22:33:10]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:33:13]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:33:13]: [Client #3] Selected by the server.
[INFO][22:33:13]: [Client #3] Loading its data source...
[INFO][22:33:13]: [Client #3] Dataset size: 2018
[INFO][22:33:13]: [Client #3] Sampler: iid
[INFO][22:33:13]: [Client #5] Selected by the server.
[INFO][22:33:13]: [Client #5] Loading its data source...
[INFO][22:33:13]: [Client #5] Dataset size: 2018
[INFO][22:33:13]: [Client #5] Sampler: iid
[INFO][22:33:15]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:33:15]: [Client #3] Start to process inbound data.
[INFO][22:33:15]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:33:15]: [Client #5] Start to process inbound data.
[INFO][22:33:16]: [93m[1m[Client #3] Started training in communication round #27.[0m
[INFO][22:33:16]: [93m[1m[Client #5] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.15s/it]  4%|â–         | 2/48 [00:04<01:37,  2.11s/it]  2%|â–         | 1/48 [00:04<03:50,  4.91s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.58s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  8%|â–Š         | 4/48 [00:06<00:57,  1.30s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.12s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.18s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.11it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.03s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.16it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.58it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
[INFO][22:34:01]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.3802, 'train_samples_per_second': 153.732, 'train_steps_per_second': 1.219, 'train_loss': 3.1967455546061196, 'epoch': 3.0}
[INFO][22:34:02]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 40.026, 'train_samples_per_second': 151.252, 'train_steps_per_second': 1.199, 'train_loss': 3.1228930155436196, 'epoch': 3.0}
[INFO][22:34:02]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][22:34:03]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][22:34:03]: [Client #5] Model trained.
[INFO][22:34:03]: [Client #5] Inbound data has been processed.
[INFO][22:34:03]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:34:03]: [Client #3] Model trained.
[INFO][22:34:03]: [Client #3] Inbound data has been processed.
[INFO][22:34:03]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][22:34:09]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:34:10]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:34:10]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][22:34:11]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][22:34:11]: [Server #3350301] Selecting client #23 for training.
[INFO][22:34:11]: [Server #3350301] Sending the current model to client #23 (simulated).
[INFO][22:34:15]: [Server #3350301] Sending 507.38 MB of payload data to client #23 (simulated).
[INFO][22:34:15]: [Client #23] Selected by the server.
[INFO][22:34:15]: [Client #23] Loading its data source...
[INFO][22:34:15]: [Client #23] Dataset size: 2018
[INFO][22:34:15]: [Client #23] Sampler: iid
[INFO][22:34:16]: [Client #23] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:34:16]: [Client #23] Start to process inbound data.
[INFO][22:34:16]: [93m[1m[Client #23] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:34:49]: [Client #23] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3350395.pth.
{'train_runtime': 26.7174, 'train_samples_per_second': 226.594, 'train_steps_per_second': 1.797, 'train_loss': 3.259740193684896, 'epoch': 3.0}
[INFO][22:34:50]: [Client #23] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3350395.pth.
[INFO][22:34:51]: [Client #23] Model trained.
[INFO][22:34:51]: [Client #23] Inbound data has been processed.
[INFO][22:34:51]: [Client #23] Outbound data is ready to be sent after being processed.
[INFO][22:34:55]: [Client #23] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:34:56]: [Server #3350301] Received 507.38 MB of payload data from client #23 (simulated).
[INFO][22:34:56]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:34:56]: [Server #3350301] Adding client #55 to the list of clients for aggregation.
[INFO][22:34:56]: [Server #3350301] Adding client #87 to the list of clients for aggregation.
[INFO][22:34:56]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:34:56]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][22:34:56]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:34:56]: [Server #3350301] Updated weights have been received.
[INFO][22:34:56]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:34:57]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:34:57]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][22:35:08]: [93m[1m[Server #3350301] Global model perplexity: 28.69
[0m
[INFO][22:35:08]: [Server #3350301] All client reports have been processed.
[INFO][22:35:08]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_27.pth.
[INFO][22:35:10]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_27.pth.
[INFO][22:35:10]: [93m[1m
[Server #3350301] Starting round 28/100.[0m
[INFO][22:35:10]: [Server #3350301] Selected clients: [1, 2, 5, 6, 7]
[INFO][22:35:10]: [Server #3350301] Selecting client #2 for training.
[INFO][22:35:10]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:35:14]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:35:14]: [Server #3350301] Selecting client #1 for training.
[INFO][22:35:14]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:35:18]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:35:18]: [Client #2] Selected by the server.
[INFO][22:35:18]: [Client #2] Loading its data source...
[INFO][22:35:18]: [Client #2] Dataset size: 2018
[INFO][22:35:18]: [Client #2] Sampler: iid
[INFO][22:35:18]: [Client #1] Selected by the server.
[INFO][22:35:18]: [Client #1] Loading its data source...
[INFO][22:35:18]: [Client #1] Dataset size: 2018
[INFO][22:35:18]: [Client #1] Sampler: iid
[INFO][22:35:19]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:35:19]: [Client #2] Start to process inbound data.
[INFO][22:35:19]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:35:19]: [Client #1] Start to process inbound data.
[INFO][22:35:20]: [93m[1m[Client #2] Started training in communication round #28.[0m
[INFO][22:35:20]: [93m[1m[Client #1] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.69s/it]  2%|â–         | 1/48 [00:04<03:43,  4.75s/it]  4%|â–         | 2/48 [00:05<01:49,  2.37s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:36:06]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.5568, 'train_samples_per_second': 153.046, 'train_steps_per_second': 1.213, 'train_loss': 2.5151305198669434, 'epoch': 3.0}
[INFO][22:36:06]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.5457, 'train_samples_per_second': 153.089, 'train_steps_per_second': 1.214, 'train_loss': 2.9897902806599936, 'epoch': 3.0}
[INFO][22:36:07]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:36:07]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:36:08]: [Client #1] Model trained.
[INFO][22:36:08]: [Client #1] Inbound data has been processed.
[INFO][22:36:08]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:36:08]: [Client #2] Model trained.
[INFO][22:36:08]: [Client #2] Inbound data has been processed.
[INFO][22:36:08]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:36:14]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:36:15]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:36:15]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:36:16]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:36:16]: [Server #3350301] Selecting client #6 for training.
[INFO][22:36:16]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][22:36:20]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][22:36:20]: [Server #3350301] Selecting client #5 for training.
[INFO][22:36:20]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:36:23]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:36:23]: [Client #6] Selected by the server.
[INFO][22:36:23]: [Client #5] Selected by the server.
[INFO][22:36:23]: [Client #6] Loading its data source...
[INFO][22:36:23]: [Client #5] Loading its data source...
[INFO][22:36:23]: [Client #6] Dataset size: 2018
[INFO][22:36:23]: [Client #5] Dataset size: 2018
[INFO][22:36:23]: [Client #6] Sampler: iid
[INFO][22:36:23]: [Client #5] Sampler: iid
[INFO][22:36:24]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:36:24]: [Client #6] Start to process inbound data.
[INFO][22:36:25]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:36:25]: [Client #5] Start to process inbound data.
[INFO][22:36:25]: [93m[1m[Client #6] Started training in communication round #28.[0m
[INFO][22:36:25]: [93m[1m[Client #5] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  2%|â–         | 1/48 [00:04<03:43,  4.75s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:37:11]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.6404, 'train_samples_per_second': 152.723, 'train_steps_per_second': 1.211, 'train_loss': 3.089112917582194, 'epoch': 3.0}
[INFO][22:37:11]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.0854, 'train_samples_per_second': 154.892, 'train_steps_per_second': 1.228, 'train_loss': 3.328419049580892, 'epoch': 3.0}
[INFO][22:37:12]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][22:37:12]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][22:37:12]: [Client #5] Model trained.
[INFO][22:37:12]: [Client #5] Inbound data has been processed.
[INFO][22:37:12]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:37:13]: [Client #6] Model trained.
[INFO][22:37:13]: [Client #6] Inbound data has been processed.
[INFO][22:37:13]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][22:37:19]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:37:19]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:37:20]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][22:37:21]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][22:37:21]: [Server #3350301] Selecting client #7 for training.
[INFO][22:37:21]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][22:37:25]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][22:37:25]: [Client #7] Selected by the server.
[INFO][22:37:25]: [Client #7] Loading its data source...
[INFO][22:37:25]: [Client #7] Dataset size: 2018
[INFO][22:37:25]: [Client #7] Sampler: iid
[INFO][22:37:26]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:37:26]: [Client #7] Start to process inbound data.
[INFO][22:37:26]: [93m[1m[Client #7] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:37:59]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350395.pth.
{'train_runtime': 26.8821, 'train_samples_per_second': 225.206, 'train_steps_per_second': 1.786, 'train_loss': 3.2229741414388022, 'epoch': 3.0}
[INFO][22:38:00]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350395.pth.
[INFO][22:38:01]: [Client #7] Model trained.
[INFO][22:38:01]: [Client #7] Inbound data has been processed.
[INFO][22:38:01]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][22:38:04]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:38:06]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][22:38:06]: [Server #3350301] Adding client #23 to the list of clients for aggregation.
[INFO][22:38:06]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:38:06]: [Server #3350301] Adding client #35 to the list of clients for aggregation.
[INFO][22:38:06]: [Server #3350301] Adding client #26 to the list of clients for aggregation.
[INFO][22:38:06]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:38:06]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:38:06]: [Server #3350301] Updated weights have been received.
[INFO][22:38:06]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:38:07]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:38:07]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]
[INFO][22:38:18]: [93m[1m[Server #3350301] Global model perplexity: 28.77
[0m
[INFO][22:38:18]: [Server #3350301] All client reports have been processed.
[INFO][22:38:18]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_28.pth.
[INFO][22:38:20]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_28.pth.
[INFO][22:38:20]: [93m[1m
[Server #3350301] Starting round 29/100.[0m
[INFO][22:38:20]: [Server #3350301] Selected clients: [1, 3, 8, 9, 10]
[INFO][22:38:20]: [Server #3350301] Selecting client #8 for training.
[INFO][22:38:20]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][22:38:24]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][22:38:24]: [Server #3350301] Selecting client #1 for training.
[INFO][22:38:24]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:38:27]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:38:27]: [Client #8] Selected by the server.
[INFO][22:38:27]: [Client #8] Loading its data source...
[INFO][22:38:27]: [Client #8] Dataset size: 2018
[INFO][22:38:27]: [Client #1] Selected by the server.
[INFO][22:38:27]: [Client #8] Sampler: iid
[INFO][22:38:27]: [Client #1] Loading its data source...
[INFO][22:38:27]: [Client #1] Dataset size: 2018
[INFO][22:38:27]: [Client #1] Sampler: iid
[INFO][22:38:29]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:38:29]: [Client #8] Start to process inbound data.
[INFO][22:38:29]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:38:29]: [Client #1] Start to process inbound data.
[INFO][22:38:30]: [93m[1m[Client #8] Started training in communication round #29.[0m
[INFO][22:38:30]: [93m[1m[Client #1] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  2%|â–         | 1/48 [00:04<03:13,  4.11s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  4%|â–         | 2/48 [00:04<01:38,  2.13s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.49s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.29it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.30it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
[INFO][22:39:15]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 38.9691, 'train_samples_per_second': 155.354, 'train_steps_per_second': 1.232, 'train_loss': 3.3194220860799155, 'epoch': 3.0}
[INFO][22:39:15]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2661, 'train_samples_per_second': 154.179, 'train_steps_per_second': 1.222, 'train_loss': 2.494206269582113, 'epoch': 3.0}
[INFO][22:39:16]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][22:39:16]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:39:16]: [Client #8] Model trained.
[INFO][22:39:16]: [Client #8] Inbound data has been processed.
[INFO][22:39:16]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][22:39:17]: [Client #1] Model trained.
[INFO][22:39:17]: [Client #1] Inbound data has been processed.
[INFO][22:39:17]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:39:23]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:39:23]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:39:24]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][22:39:25]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:39:25]: [Server #3350301] Selecting client #10 for training.
[INFO][22:39:25]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][22:39:28]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][22:39:28]: [Server #3350301] Selecting client #3 for training.
[INFO][22:39:28]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:39:32]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:39:32]: [Client #10] Selected by the server.
[INFO][22:39:32]: [Client #10] Loading its data source...
[INFO][22:39:32]: [Client #3] Selected by the server.
[INFO][22:39:32]: [Client #10] Dataset size: 2018
[INFO][22:39:32]: [Client #3] Loading its data source...
[INFO][22:39:32]: [Client #10] Sampler: iid
[INFO][22:39:32]: [Client #3] Dataset size: 2018
[INFO][22:39:32]: [Client #3] Sampler: iid
[INFO][22:39:34]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:39:34]: [Client #10] Start to process inbound data.
[INFO][22:39:34]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:39:34]: [Client #3] Start to process inbound data.
[INFO][22:39:34]: [93m[1m[Client #3] Started training in communication round #29.[0m
[INFO][22:39:34]: [93m[1m[Client #10] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  2%|â–         | 1/48 [00:05<03:58,  5.08s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  4%|â–         | 2/48 [00:06<02:03,  2.68s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it]  6%|â–‹         | 3/48 [00:06<01:23,  1.85s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.45s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.25s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.14s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.05s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:39,  1.00it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.03it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.04it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:21,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:13,  1.15it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:12,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.10it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.10it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.06it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.00s/it]
[INFO][22:40:29]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 47.8914, 'train_samples_per_second': 126.411, 'train_steps_per_second': 1.002, 'train_loss': 3.2881603240966797, 'epoch': 3.0}
[INFO][22:40:29]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 48.13, 'train_samples_per_second': 125.784, 'train_steps_per_second': 0.997, 'train_loss': 3.017758051554362, 'epoch': 3.0}
[INFO][22:40:30]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][22:40:30]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][22:40:30]: [Client #3] Model trained.
[INFO][22:40:30]: [Client #3] Inbound data has been processed.
[INFO][22:40:30]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][22:40:30]: [Client #10] Model trained.
[INFO][22:40:30]: [Client #10] Inbound data has been processed.
[INFO][22:40:30]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][22:40:36]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:40:37]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:40:37]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][22:40:38]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][22:40:38]: [Server #3350301] Selecting client #9 for training.
[INFO][22:40:38]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][22:40:42]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][22:40:42]: [Client #9] Selected by the server.
[INFO][22:40:42]: [Client #9] Loading its data source...
[INFO][22:40:42]: [Client #9] Dataset size: 2018
[INFO][22:40:42]: [Client #9] Sampler: iid
[INFO][22:40:43]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:40:43]: [Client #9] Start to process inbound data.
[INFO][22:40:43]: [93m[1m[Client #9] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:41:16]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7758, 'train_samples_per_second': 226.099, 'train_steps_per_second': 1.793, 'train_loss': 3.2216208775838218, 'epoch': 3.0}
[INFO][22:41:17]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][22:41:18]: [Client #9] Model trained.
[INFO][22:41:18]: [Client #9] Inbound data has been processed.
[INFO][22:41:18]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][22:41:21]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:41:22]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][22:41:22]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][22:41:22]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][22:41:22]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:41:22]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][22:41:22]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:41:22]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:41:22]: [Server #3350301] Updated weights have been received.
[INFO][22:41:23]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:41:23]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:41:23]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.86it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.57it/s]
[INFO][22:41:34]: [93m[1m[Server #3350301] Global model perplexity: 28.61
[0m
[INFO][22:41:34]: [Server #3350301] All client reports have been processed.
[INFO][22:41:34]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_29.pth.
[INFO][22:41:37]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_29.pth.
[INFO][22:41:37]: [93m[1m
[Server #3350301] Starting round 30/100.[0m
[INFO][22:41:37]: [Server #3350301] Selected clients: [1, 2, 4, 5, 7]
[INFO][22:41:37]: [Server #3350301] Selecting client #2 for training.
[INFO][22:41:37]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:41:41]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:41:41]: [Server #3350301] Selecting client #1 for training.
[INFO][22:41:41]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:41:44]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:41:44]: [Client #2] Selected by the server.
[INFO][22:41:44]: [Client #2] Loading its data source...
[INFO][22:41:44]: [Client #2] Dataset size: 2018
[INFO][22:41:44]: [Client #2] Sampler: iid
[INFO][22:41:44]: [Client #1] Selected by the server.
[INFO][22:41:44]: [Client #1] Loading its data source...
[INFO][22:41:44]: [Client #1] Dataset size: 2018
[INFO][22:41:44]: [Client #1] Sampler: iid
[INFO][22:41:46]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:41:46]: [Client #1] Start to process inbound data.
[INFO][22:41:46]: [93m[1m[Client #1] Started training in communication round #30.[0m
[INFO][22:41:46]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:41:46]: [Client #2] Start to process inbound data.
[INFO][22:41:46]: [93m[1m[Client #2] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.06s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  2%|â–         | 1/48 [00:04<03:40,  4.69s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][22:42:31]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.0937, 'train_samples_per_second': 154.859, 'train_steps_per_second': 1.228, 'train_loss': 2.4721875190734863, 'epoch': 3.0}
[INFO][22:42:31]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.2658, 'train_samples_per_second': 154.18, 'train_steps_per_second': 1.222, 'train_loss': 2.9431753158569336, 'epoch': 3.0}
[INFO][22:42:32]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:42:32]: [Client #1] Model trained.
[INFO][22:42:32]: [Client #1] Inbound data has been processed.
[INFO][22:42:32]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:42:33]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:42:33]: [Client #2] Model trained.
[INFO][22:42:33]: [Client #2] Inbound data has been processed.
[INFO][22:42:33]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:42:38]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:42:39]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:42:39]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:42:40]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:42:40]: [Server #3350301] Selecting client #4 for training.
[INFO][22:42:40]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][22:42:44]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][22:42:44]: [Server #3350301] Selecting client #5 for training.
[INFO][22:42:44]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:42:47]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:42:47]: [Client #5] Selected by the server.
[INFO][22:42:47]: [Client #5] Loading its data source...
[INFO][22:42:47]: [Client #4] Selected by the server.
[INFO][22:42:47]: [Client #5] Dataset size: 2018
[INFO][22:42:47]: [Client #5] Sampler: iid
[INFO][22:42:47]: [Client #4] Loading its data source...
[INFO][22:42:47]: [Client #4] Dataset size: 2018
[INFO][22:42:47]: [Client #4] Sampler: iid
[INFO][22:42:49]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:42:49]: [Client #4] Start to process inbound data.
[INFO][22:42:49]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:42:49]: [Client #5] Start to process inbound data.
[INFO][22:42:50]: [93m[1m[Client #4] Started training in communication round #30.[0m
[INFO][22:42:50]: [93m[1m[Client #5] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:05<01:44,  2.26s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.59s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.25s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][22:43:35]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.0239, 'train_samples_per_second': 155.136, 'train_steps_per_second': 1.23, 'train_loss': 3.16915225982666, 'epoch': 3.0}
[INFO][22:43:35]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.3267, 'train_samples_per_second': 153.941, 'train_steps_per_second': 1.221, 'train_loss': 3.016831715901693, 'epoch': 3.0}
[INFO][22:43:36]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][22:43:37]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][22:43:37]: [Client #4] Model trained.
[INFO][22:43:37]: [Client #4] Inbound data has been processed.
[INFO][22:43:37]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][22:43:37]: [Client #5] Model trained.
[INFO][22:43:37]: [Client #5] Inbound data has been processed.
[INFO][22:43:37]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:43:44]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:43:44]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:43:45]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][22:43:46]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][22:43:46]: [Server #3350301] Selecting client #7 for training.
[INFO][22:43:46]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][22:43:49]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][22:43:49]: [Client #7] Selected by the server.
[INFO][22:43:49]: [Client #7] Loading its data source...
[INFO][22:43:49]: [Client #7] Dataset size: 2018
[INFO][22:43:49]: [Client #7] Sampler: iid
[INFO][22:43:51]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:43:51]: [Client #7] Start to process inbound data.
[INFO][22:43:51]: [93m[1m[Client #7] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:44:24]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350395.pth.
{'train_runtime': 26.7011, 'train_samples_per_second': 226.732, 'train_steps_per_second': 1.798, 'train_loss': 3.1251465479532876, 'epoch': 3.0}
[INFO][22:44:25]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350395.pth.
[INFO][22:44:25]: [Client #7] Model trained.
[INFO][22:44:25]: [Client #7] Inbound data has been processed.
[INFO][22:44:25]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][22:44:29]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:44:30]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][22:44:30]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][22:44:30]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][22:44:30]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:44:30]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][22:44:30]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][22:44:30]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:44:30]: [Server #3350301] Updated weights have been received.
[INFO][22:44:30]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:44:31]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:44:31]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.16it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.50it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.79it/s]
[INFO][22:44:42]: [93m[1m[Server #3350301] Global model perplexity: 26.22
[0m
[INFO][22:44:42]: [Server #3350301] All client reports have been processed.
[INFO][22:44:42]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_30.pth.
[INFO][22:44:44]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_30.pth.
[INFO][22:44:44]: [93m[1m
[Server #3350301] Starting round 31/100.[0m
[INFO][22:44:44]: [Server #3350301] Selected clients: [3, 6, 8, 9, 10]
[INFO][22:44:44]: [Server #3350301] Selecting client #6 for training.
[INFO][22:44:44]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][22:44:48]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][22:44:48]: [Server #3350301] Selecting client #3 for training.
[INFO][22:44:48]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:44:52]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:44:52]: [Client #6] Selected by the server.
[INFO][22:44:52]: [Client #6] Loading its data source...
[INFO][22:44:52]: [Client #6] Dataset size: 2018
[INFO][22:44:52]: [Client #6] Sampler: iid
[INFO][22:44:52]: [Client #3] Selected by the server.
[INFO][22:44:52]: [Client #3] Loading its data source...
[INFO][22:44:52]: [Client #3] Dataset size: 2018
[INFO][22:44:52]: [Client #3] Sampler: iid
[INFO][22:44:53]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:44:53]: [Client #6] Start to process inbound data.
[INFO][22:44:53]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:44:53]: [Client #3] Start to process inbound data.
[INFO][22:44:54]: [93m[1m[Client #3] Started training in communication round #31.[0m
[INFO][22:44:54]: [93m[1m[Client #6] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:44,  4.77s/it]  2%|â–         | 1/48 [00:04<03:48,  4.87s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  4%|â–         | 2/48 [00:05<01:54,  2.49s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.00it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.33it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][22:45:40]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.8817, 'train_samples_per_second': 151.799, 'train_steps_per_second': 1.204, 'train_loss': 2.9615914026896157, 'epoch': 3.0}
[INFO][22:45:40]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.7258, 'train_samples_per_second': 152.395, 'train_steps_per_second': 1.208, 'train_loss': 3.2291386922200522, 'epoch': 3.0}
[INFO][22:45:41]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][22:45:41]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][22:45:41]: [Client #3] Model trained.
[INFO][22:45:41]: [Client #3] Inbound data has been processed.
[INFO][22:45:41]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][22:45:42]: [Client #6] Model trained.
[INFO][22:45:42]: [Client #6] Inbound data has been processed.
[INFO][22:45:42]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][22:45:48]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:45:48]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:45:49]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][22:45:50]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][22:45:50]: [Server #3350301] Selecting client #8 for training.
[INFO][22:45:50]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][22:45:54]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][22:45:54]: [Server #3350301] Selecting client #9 for training.
[INFO][22:45:54]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][22:45:57]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][22:45:57]: [Client #8] Selected by the server.
[INFO][22:45:57]: [Client #9] Selected by the server.
[INFO][22:45:57]: [Client #8] Loading its data source...
[INFO][22:45:57]: [Client #9] Loading its data source...
[INFO][22:45:57]: [Client #8] Dataset size: 2018
[INFO][22:45:57]: [Client #8] Sampler: iid
[INFO][22:45:57]: [Client #9] Dataset size: 2018
[INFO][22:45:57]: [Client #9] Sampler: iid
[INFO][22:45:59]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:45:59]: [Client #9] Start to process inbound data.
[INFO][22:45:59]: [93m[1m[Client #9] Started training in communication round #31.[0m
[INFO][22:45:59]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:45:59]: [Client #8] Start to process inbound data.
[INFO][22:45:59]: [93m[1m[Client #8] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:11,  4.07s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  2%|â–         | 1/48 [00:04<03:37,  4.62s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  4%|â–         | 2/48 [00:05<01:53,  2.48s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.25s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.12s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.41s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.04s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:40,  1.01it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.04s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:36,  1.07it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:34,  1.10it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:33,  1.11it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:30,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.03it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:28,  1.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:25,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:24,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:23,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:22,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:21,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:20,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:19,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:17,  1.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:31<00:14,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.03it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:32<00:13,  1.11it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:11,  1.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:12,  1.17it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:10,  1.23it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:11,  1.20it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:09,  1.27it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:10,  1.23it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:35<00:08,  1.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:09,  1.24it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:36<00:07,  1.30it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:08,  1.28it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:37<00:06,  1.30it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:07,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:38<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:38<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:06,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:39<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:39<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:40<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:40<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:41<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:41<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:41<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:42<00:03,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:42<00:01,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:42<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:43<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:43<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:43<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:43<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:43<00:00,  1.09it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:44<00:00,  1.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.67it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.08it/s]
[INFO][22:46:49]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350396.pth.
{'train_runtime': 43.9705, 'train_samples_per_second': 137.683, 'train_steps_per_second': 1.092, 'train_loss': 3.12141482035319, 'epoch': 3.0}
[INFO][22:46:50]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 44.4338, 'train_samples_per_second': 136.248, 'train_steps_per_second': 1.08, 'train_loss': 3.2212937672932944, 'epoch': 3.0}
[INFO][22:46:50]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350396.pth.
[INFO][22:46:50]: [Client #9] Model trained.
[INFO][22:46:50]: [Client #9] Inbound data has been processed.
[INFO][22:46:50]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][22:46:51]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][22:46:51]: [Client #8] Model trained.
[INFO][22:46:51]: [Client #8] Inbound data has been processed.
[INFO][22:46:51]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][22:46:56]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:46:57]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][22:46:57]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:46:58]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][22:46:58]: [Server #3350301] Selecting client #10 for training.
[INFO][22:46:58]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][22:47:02]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][22:47:02]: [Client #10] Selected by the server.
[INFO][22:47:02]: [Client #10] Loading its data source...
[INFO][22:47:02]: [Client #10] Dataset size: 2018
[INFO][22:47:02]: [Client #10] Sampler: iid
[INFO][22:47:03]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:47:03]: [Client #10] Start to process inbound data.
[INFO][22:47:03]: [93m[1m[Client #10] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:47:36]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.6919, 'train_samples_per_second': 226.81, 'train_steps_per_second': 1.798, 'train_loss': 3.1842692693074546, 'epoch': 3.0}
[INFO][22:47:37]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][22:47:38]: [Client #10] Model trained.
[INFO][22:47:38]: [Client #10] Inbound data has been processed.
[INFO][22:47:38]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][22:47:42]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:47:43]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][22:47:43]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:47:43]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][22:47:43]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:47:43]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][22:47:43]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][22:47:43]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:47:43]: [Server #3350301] Updated weights have been received.
[INFO][22:47:43]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:47:44]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:47:44]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.74it/s]
[INFO][22:47:55]: [93m[1m[Server #3350301] Global model perplexity: 27.86
[0m
[INFO][22:47:55]: [Server #3350301] All client reports have been processed.
[INFO][22:47:55]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_31.pth.
[INFO][22:47:57]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_31.pth.
[INFO][22:47:57]: [93m[1m
[Server #3350301] Starting round 32/100.[0m
[INFO][22:47:57]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][22:47:57]: [Server #3350301] Selecting client #2 for training.
[INFO][22:47:57]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:48:01]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:48:01]: [Server #3350301] Selecting client #1 for training.
[INFO][22:48:01]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:48:04]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:48:04]: [Client #1] Selected by the server.
[INFO][22:48:04]: [Client #1] Loading its data source...
[INFO][22:48:04]: [Client #1] Dataset size: 2018
[INFO][22:48:04]: [Client #1] Sampler: iid
[INFO][22:48:04]: [Client #2] Selected by the server.
[INFO][22:48:04]: [Client #2] Loading its data source...
[INFO][22:48:04]: [Client #2] Dataset size: 2018
[INFO][22:48:04]: [Client #2] Sampler: iid
[INFO][22:48:06]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:48:06]: [Client #1] Start to process inbound data.
[INFO][22:48:06]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:48:06]: [Client #2] Start to process inbound data.
[INFO][22:48:06]: [93m[1m[Client #1] Started training in communication round #32.[0m
[INFO][22:48:07]: [93m[1m[Client #2] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  2%|â–         | 1/48 [00:04<03:38,  4.65s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  4%|â–         | 2/48 [00:05<01:55,  2.51s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.69s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.78s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.39s/it]  8%|â–Š         | 4/48 [00:07<01:05,  1.50s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.26s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:46,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.14s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.03s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.07s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.02s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:41,  1.03s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:32,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:32,  1.10it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.11it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.13it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:28,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:28,  1.05it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:27,  1.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:27,  1.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.12it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.12it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.12it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
[INFO][22:49:00]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.6879, 'train_samples_per_second': 126.95, 'train_steps_per_second': 1.007, 'train_loss': 2.4207682609558105, 'epoch': 3.0}
[INFO][22:49:00]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 47.4624, 'train_samples_per_second': 127.554, 'train_steps_per_second': 1.011, 'train_loss': 2.898505210876465, 'epoch': 3.0}
[INFO][22:49:01]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:49:02]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:49:02]: [Client #1] Model trained.
[INFO][22:49:02]: [Client #1] Inbound data has been processed.
[INFO][22:49:02]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:49:02]: [Client #2] Model trained.
[INFO][22:49:02]: [Client #2] Inbound data has been processed.
[INFO][22:49:02]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:49:08]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:49:08]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:49:09]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:49:10]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:49:10]: [Server #3350301] Selecting client #5 for training.
[INFO][22:49:10]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:49:14]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:49:14]: [Server #3350301] Selecting client #7 for training.
[INFO][22:49:14]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][22:49:17]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][22:49:17]: [Client #5] Selected by the server.
[INFO][22:49:17]: [Client #5] Loading its data source...
[INFO][22:49:17]: [Client #5] Dataset size: 2018
[INFO][22:49:17]: [Client #5] Sampler: iid
[INFO][22:49:17]: [Client #7] Selected by the server.
[INFO][22:49:17]: [Client #7] Loading its data source...
[INFO][22:49:17]: [Client #7] Dataset size: 2018
[INFO][22:49:17]: [Client #7] Sampler: iid
[INFO][22:49:19]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:49:19]: [Client #7] Start to process inbound data.
[INFO][22:49:19]: [93m[1m[Client #7] Started training in communication round #32.[0m
[INFO][22:49:19]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:49:19]: [Client #5] Start to process inbound data.
[INFO][22:49:19]: [93m[1m[Client #5] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]  2%|â–         | 1/48 [00:04<03:47,  4.84s/it]  4%|â–         | 2/48 [00:04<01:38,  2.13s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.27it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:50:04]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.12, 'train_samples_per_second': 154.755, 'train_steps_per_second': 1.227, 'train_loss': 2.9361937840779624, 'epoch': 3.0}
[INFO][22:50:05]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.548, 'train_samples_per_second': 153.08, 'train_steps_per_second': 1.214, 'train_loss': 3.0450000762939453, 'epoch': 3.0}
[INFO][22:50:05]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][22:50:06]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][22:50:06]: [Client #5] Model trained.
[INFO][22:50:06]: [Client #5] Inbound data has been processed.
[INFO][22:50:06]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:50:06]: [Client #7] Model trained.
[INFO][22:50:06]: [Client #7] Inbound data has been processed.
[INFO][22:50:06]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][22:50:12]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:50:13]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:50:13]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][22:50:14]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][22:50:14]: [Server #3350301] Selecting client #9 for training.
[INFO][22:50:14]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][22:50:18]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][22:50:18]: [Client #9] Selected by the server.
[INFO][22:50:18]: [Client #9] Loading its data source...
[INFO][22:50:18]: [Client #9] Dataset size: 2018
[INFO][22:50:18]: [Client #9] Sampler: iid
[INFO][22:50:19]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:50:19]: [Client #9] Start to process inbound data.
[INFO][22:50:19]: [93m[1m[Client #9] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.21s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][22:50:52]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.774, 'train_samples_per_second': 226.115, 'train_steps_per_second': 1.793, 'train_loss': 3.072333653767904, 'epoch': 3.0}
[INFO][22:50:53]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][22:50:54]: [Client #9] Model trained.
[INFO][22:50:54]: [Client #9] Inbound data has been processed.
[INFO][22:50:54]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][22:50:58]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:50:59]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][22:50:59]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][22:50:59]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:50:59]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][22:50:59]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][22:50:59]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:50:59]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:50:59]: [Server #3350301] Updated weights have been received.
[INFO][22:50:59]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:51:00]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:51:00]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.13it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.59it/s]
[INFO][22:51:11]: [93m[1m[Server #3350301] Global model perplexity: 28.13
[0m
[INFO][22:51:11]: [Server #3350301] All client reports have been processed.
[INFO][22:51:11]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_32.pth.
[INFO][22:51:13]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_32.pth.
[INFO][22:51:13]: [93m[1m
[Server #3350301] Starting round 33/100.[0m
[INFO][22:51:13]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][22:51:13]: [Server #3350301] Selecting client #4 for training.
[INFO][22:51:13]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][22:51:17]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][22:51:17]: [Server #3350301] Selecting client #1 for training.
[INFO][22:51:17]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:51:20]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:51:20]: [Client #4] Selected by the server.
[INFO][22:51:20]: [Client #4] Loading its data source...
[INFO][22:51:20]: [Client #4] Dataset size: 2018
[INFO][22:51:20]: [Client #4] Sampler: iid
[INFO][22:51:20]: [Client #1] Selected by the server.
[INFO][22:51:20]: [Client #1] Loading its data source...
[INFO][22:51:20]: [Client #1] Dataset size: 2018
[INFO][22:51:20]: [Client #1] Sampler: iid
[INFO][22:51:22]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:51:22]: [Client #1] Start to process inbound data.
[INFO][22:51:22]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:51:22]: [Client #4] Start to process inbound data.
[INFO][22:51:23]: [93m[1m[Client #1] Started training in communication round #33.[0m
[INFO][22:51:23]: [93m[1m[Client #4] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:48,  4.87s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  4%|â–         | 2/48 [00:05<02:01,  2.64s/it]  8%|â–Š         | 4/48 [00:06<01:00,  1.37s/it]  6%|â–‹         | 3/48 [00:07<01:26,  1.93s/it] 10%|â–ˆ         | 5/48 [00:07<00:54,  1.26s/it]  8%|â–Š         | 4/48 [00:08<01:08,  1.56s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:49,  1.17s/it] 10%|â–ˆ         | 5/48 [00:08<00:56,  1.32s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:44,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.16s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:41,  1.05s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.08s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:38,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:37,  1.02it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:34,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:33,  1.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:34,  1.01s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:30,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:31,  1.05it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.13it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:19<00:29,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:21,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:20,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:30<00:18,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:31<00:17,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:17,  1.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.07it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.06it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:44<00:04,  1.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:45<00:03,  1.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:47<00:01,  1.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.00s/it]
[INFO][22:52:16]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.7997, 'train_samples_per_second': 126.653, 'train_steps_per_second': 1.004, 'train_loss': 2.404906749725342, 'epoch': 3.0}
[INFO][22:52:17]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 48.0703, 'train_samples_per_second': 125.941, 'train_steps_per_second': 0.999, 'train_loss': 3.0991061528523765, 'epoch': 3.0}
[INFO][22:52:17]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:52:18]: [Client #1] Model trained.
[INFO][22:52:18]: [Client #1] Inbound data has been processed.
[INFO][22:52:18]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:52:18]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][22:52:19]: [Client #4] Model trained.
[INFO][22:52:19]: [Client #4] Inbound data has been processed.
[INFO][22:52:19]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][22:52:24]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:52:24]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:52:25]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:52:26]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][22:52:26]: [Server #3350301] Selecting client #8 for training.
[INFO][22:52:26]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][22:52:29]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][22:52:29]: [Server #3350301] Selecting client #3 for training.
[INFO][22:52:29]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:52:33]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:52:33]: [Client #8] Selected by the server.
[INFO][22:52:33]: [Client #8] Loading its data source...
[INFO][22:52:33]: [Client #8] Dataset size: 2018
[INFO][22:52:33]: [Client #8] Sampler: iid
[INFO][22:52:33]: [Client #3] Selected by the server.
[INFO][22:52:33]: [Client #3] Loading its data source...
[INFO][22:52:33]: [Client #3] Dataset size: 2018
[INFO][22:52:33]: [Client #3] Sampler: iid
[INFO][22:52:34]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:52:34]: [Client #3] Start to process inbound data.
[INFO][22:52:34]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:52:34]: [Client #8] Start to process inbound data.
[INFO][22:52:35]: [93m[1m[Client #8] Started training in communication round #33.[0m
[INFO][22:52:35]: [93m[1m[Client #3] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  2%|â–         | 1/48 [00:04<03:48,  4.87s/it]  4%|â–         | 2/48 [00:04<01:39,  2.15s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:22,  1.31it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:53:20]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.2941, 'train_samples_per_second': 154.069, 'train_steps_per_second': 1.222, 'train_loss': 2.911611239115397, 'epoch': 3.0}
[INFO][22:53:21]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.7167, 'train_samples_per_second': 152.429, 'train_steps_per_second': 1.209, 'train_loss': 3.1682987213134766, 'epoch': 3.0}
[INFO][22:53:22]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][22:53:22]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][22:53:22]: [Client #3] Model trained.
[INFO][22:53:22]: [Client #3] Inbound data has been processed.
[INFO][22:53:22]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][22:53:22]: [Client #8] Model trained.
[INFO][22:53:22]: [Client #8] Inbound data has been processed.
[INFO][22:53:22]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][22:53:28]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:53:29]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:53:29]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][22:53:30]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][22:53:30]: [Server #3350301] Selecting client #10 for training.
[INFO][22:53:30]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][22:53:34]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][22:53:34]: [Client #10] Selected by the server.
[INFO][22:53:34]: [Client #10] Loading its data source...
[INFO][22:53:34]: [Client #10] Dataset size: 2018
[INFO][22:53:34]: [Client #10] Sampler: iid
[INFO][22:53:35]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:53:35]: [Client #10] Start to process inbound data.
[INFO][22:53:35]: [93m[1m[Client #10] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][22:54:08]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.7391, 'train_samples_per_second': 226.41, 'train_steps_per_second': 1.795, 'train_loss': 3.125694910685221, 'epoch': 3.0}
[INFO][22:54:09]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][22:54:10]: [Client #10] Model trained.
[INFO][22:54:10]: [Client #10] Inbound data has been processed.
[INFO][22:54:10]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][22:54:14]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:54:15]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][22:54:15]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][22:54:15]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][22:54:15]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][22:54:15]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][22:54:15]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][22:54:15]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:54:15]: [Server #3350301] Updated weights have been received.
[INFO][22:54:15]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:54:16]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:54:16]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.17it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.63it/s]
[INFO][22:54:27]: [93m[1m[Server #3350301] Global model perplexity: 26.35
[0m
[INFO][22:54:27]: [Server #3350301] All client reports have been processed.
[INFO][22:54:27]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_33.pth.
[INFO][22:54:29]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_33.pth.
[INFO][22:54:29]: [93m[1m
[Server #3350301] Starting round 34/100.[0m
[INFO][22:54:29]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][22:54:29]: [Server #3350301] Selecting client #2 for training.
[INFO][22:54:29]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][22:54:33]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][22:54:33]: [Server #3350301] Selecting client #5 for training.
[INFO][22:54:33]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:54:37]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:54:37]: [Client #2] Selected by the server.
[INFO][22:54:37]: [Client #2] Loading its data source...
[INFO][22:54:37]: [Client #2] Dataset size: 2018
[INFO][22:54:37]: [Client #5] Selected by the server.
[INFO][22:54:37]: [Client #2] Sampler: iid
[INFO][22:54:37]: [Client #5] Loading its data source...
[INFO][22:54:37]: [Client #5] Dataset size: 2018
[INFO][22:54:37]: [Client #5] Sampler: iid
[INFO][22:54:38]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:54:38]: [Client #5] Start to process inbound data.
[INFO][22:54:38]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:54:38]: [Client #2] Start to process inbound data.
[INFO][22:54:39]: [93m[1m[Client #5] Started training in communication round #34.[0m
[INFO][22:54:39]: [93m[1m[Client #2] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.06s/it]  2%|â–         | 1/48 [00:04<03:40,  4.69s/it]  4%|â–         | 2/48 [00:05<01:44,  2.26s/it]  4%|â–         | 2/48 [00:05<01:58,  2.59s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it]  6%|â–‹         | 3/48 [00:06<01:26,  1.91s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.39s/it]  8%|â–Š         | 4/48 [00:07<01:07,  1.53s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.20s/it] 10%|â–ˆ         | 5/48 [00:08<00:55,  1.29s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.16s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.03s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.07s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.01s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.10it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:30,  1.02it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:30,  1.01s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:29,  1.01it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:29,  1.03s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:29,  1.02s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:29,  1.05s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:29,  1.04s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:28,  1.06s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:24<00:28,  1.06s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:26,  1.04s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:25<00:26,  1.04s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:25,  1.03s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:26<00:25,  1.03s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:24,  1.01s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:27<00:24,  1.01s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:22,  1.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:28<00:23,  1.00s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:21,  1.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:21,  1.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:20,  1.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:30<00:18,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:31<00:17,  1.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:16,  1.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:33<00:16,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:34<00:14,  1.12it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:35<00:13,  1.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:36<00:12,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:37<00:12,  1.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:38<00:11,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:39<00:10,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:40<00:09,  1.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:41<00:08,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:42<00:07,  1.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:44<00:04,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:45<00:03,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:46<00:02,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:47<00:01,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:48<00:00,  1.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:49<00:00,  1.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:49<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:49<00:00,  1.02s/it]
[INFO][22:55:34]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 48.5519, 'train_samples_per_second': 124.691, 'train_steps_per_second': 0.989, 'train_loss': 2.8612616856892905, 'epoch': 3.0}
[INFO][22:55:34]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 49.1866, 'train_samples_per_second': 123.082, 'train_steps_per_second': 0.976, 'train_loss': 2.8859243392944336, 'epoch': 3.0}
[INFO][22:55:35]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][22:55:35]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][22:55:36]: [Client #5] Model trained.
[INFO][22:55:36]: [Client #5] Inbound data has been processed.
[INFO][22:55:36]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:55:36]: [Client #2] Model trained.
[INFO][22:55:36]: [Client #2] Inbound data has been processed.
[INFO][22:55:36]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][22:55:42]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:55:43]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:55:43]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][22:55:44]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][22:55:44]: [Server #3350301] Selecting client #6 for training.
[INFO][22:55:44]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][22:55:48]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][22:55:48]: [Server #3350301] Selecting client #7 for training.
[INFO][22:55:48]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][22:55:51]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][22:55:51]: [Client #6] Selected by the server.
[INFO][22:55:51]: [Client #6] Loading its data source...
[INFO][22:55:51]: [Client #6] Dataset size: 2018
[INFO][22:55:51]: [Client #6] Sampler: iid
[INFO][22:55:51]: [Client #7] Selected by the server.
[INFO][22:55:51]: [Client #7] Loading its data source...
[INFO][22:55:51]: [Client #7] Dataset size: 2018
[INFO][22:55:51]: [Client #7] Sampler: iid
[INFO][22:55:53]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:55:53]: [Client #6] Start to process inbound data.
[INFO][22:55:53]: [93m[1m[Client #6] Started training in communication round #34.[0m
[INFO][22:55:53]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:55:53]: [Client #7] Start to process inbound data.
[INFO][22:55:54]: [93m[1m[Client #7] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:31,  4.51s/it]  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.23s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.18s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:46,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.09s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.03s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.03s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.00s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:38,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:32,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:27,  1.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.04it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:29,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.04it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:28,  1.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:27,  1.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:27,  1.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.11it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.11it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.11it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.10it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.11it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.09it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.02it/s]
[INFO][22:56:47]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 47.5356, 'train_samples_per_second': 127.357, 'train_steps_per_second': 1.01, 'train_loss': 3.186328570048014, 'epoch': 3.0}
[INFO][22:56:47]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 47.2092, 'train_samples_per_second': 128.238, 'train_steps_per_second': 1.017, 'train_loss': 2.9871886571248374, 'epoch': 3.0}
[INFO][22:56:48]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][22:56:48]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][22:56:48]: [Client #7] Model trained.
[INFO][22:56:48]: [Client #7] Inbound data has been processed.
[INFO][22:56:48]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][22:56:49]: [Client #6] Model trained.
[INFO][22:56:49]: [Client #6] Inbound data has been processed.
[INFO][22:56:49]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][22:56:55]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:56:55]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:56:56]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][22:56:57]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][22:56:57]: [Server #3350301] Selecting client #9 for training.
[INFO][22:56:57]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][22:57:01]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][22:57:01]: [Client #9] Selected by the server.
[INFO][22:57:01]: [Client #9] Loading its data source...
[INFO][22:57:01]: [Client #9] Dataset size: 2018
[INFO][22:57:01]: [Client #9] Sampler: iid
[INFO][22:57:02]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:57:02]: [Client #9] Start to process inbound data.
[INFO][22:57:02]: [93m[1m[Client #9] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.13it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][22:57:35]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.9933, 'train_samples_per_second': 224.278, 'train_steps_per_second': 1.778, 'train_loss': 2.9929895401000977, 'epoch': 3.0}
[INFO][22:57:36]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][22:57:37]: [Client #9] Model trained.
[INFO][22:57:37]: [Client #9] Inbound data has been processed.
[INFO][22:57:37]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][22:57:41]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:57:42]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][22:57:42]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][22:57:42]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][22:57:42]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][22:57:42]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][22:57:42]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][22:57:42]: [Server #3350301] Aggregating 5 clients in total.
[INFO][22:57:42]: [Server #3350301] Updated weights have been received.
[INFO][22:57:42]: [Server #3350301] Aggregating model weight deltas.
[INFO][22:57:43]: [Server #3350301] Finished aggregating updated weights.
[INFO][22:57:43]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.86it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.14it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.50it/s]
[INFO][22:57:53]: [93m[1m[Server #3350301] Global model perplexity: 27.56
[0m
[INFO][22:57:53]: [Server #3350301] All client reports have been processed.
[INFO][22:57:54]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_34.pth.
[INFO][22:57:56]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_34.pth.
[INFO][22:57:56]: [93m[1m
[Server #3350301] Starting round 35/100.[0m
[INFO][22:57:56]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][22:57:56]: [Server #3350301] Selecting client #10 for training.
[INFO][22:57:56]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][22:58:00]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][22:58:00]: [Server #3350301] Selecting client #1 for training.
[INFO][22:58:00]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][22:58:04]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][22:58:04]: [Client #10] Selected by the server.
[INFO][22:58:04]: [Client #10] Loading its data source...
[INFO][22:58:04]: [Client #10] Dataset size: 2018
[INFO][22:58:04]: [Client #10] Sampler: iid
[INFO][22:58:04]: [Client #1] Selected by the server.
[INFO][22:58:04]: [Client #1] Loading its data source...
[INFO][22:58:04]: [Client #1] Dataset size: 2018
[INFO][22:58:04]: [Client #1] Sampler: iid
[INFO][22:58:05]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:58:05]: [Client #10] Start to process inbound data.
[INFO][22:58:05]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:58:05]: [Client #1] Start to process inbound data.
[INFO][22:58:06]: [93m[1m[Client #1] Started training in communication round #35.[0m
[INFO][22:58:06]: [93m[1m[Client #10] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.70s/it]  2%|â–         | 1/48 [00:04<03:45,  4.79s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.27s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:58:52]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.5219, 'train_samples_per_second': 153.181, 'train_steps_per_second': 1.215, 'train_loss': 3.090460459391276, 'epoch': 3.0}
[INFO][22:58:52]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4486, 'train_samples_per_second': 153.466, 'train_steps_per_second': 1.217, 'train_loss': 2.395907402038574, 'epoch': 3.0}
[INFO][22:58:53]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][22:58:53]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][22:58:53]: [Client #10] Model trained.
[INFO][22:58:53]: [Client #10] Inbound data has been processed.
[INFO][22:58:53]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][22:58:53]: [Client #1] Model trained.
[INFO][22:58:53]: [Client #1] Inbound data has been processed.
[INFO][22:58:53]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][22:59:00]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:59:00]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][22:59:01]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][22:59:02]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][22:59:02]: [Server #3350301] Selecting client #3 for training.
[INFO][22:59:02]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][22:59:06]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][22:59:06]: [Server #3350301] Selecting client #5 for training.
[INFO][22:59:06]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][22:59:09]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][22:59:09]: [Client #3] Selected by the server.
[INFO][22:59:09]: [Client #3] Loading its data source...
[INFO][22:59:09]: [Client #3] Dataset size: 2018
[INFO][22:59:09]: [Client #3] Sampler: iid
[INFO][22:59:09]: [Client #5] Selected by the server.
[INFO][22:59:09]: [Client #5] Loading its data source...
[INFO][22:59:09]: [Client #5] Dataset size: 2018
[INFO][22:59:09]: [Client #5] Sampler: iid
[INFO][22:59:11]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:59:11]: [Client #5] Start to process inbound data.
[INFO][22:59:11]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][22:59:11]: [Client #3] Start to process inbound data.
[INFO][22:59:11]: [93m[1m[Client #5] Started training in communication round #35.[0m
[INFO][22:59:11]: [93m[1m[Client #3] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:23,  4.33s/it]  2%|â–         | 1/48 [00:04<03:48,  4.86s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.30it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:16,  1.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][22:59:57]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.3341, 'train_samples_per_second': 153.912, 'train_steps_per_second': 1.22, 'train_loss': 2.8470897674560547, 'epoch': 3.0}
[INFO][22:59:57]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.711, 'train_samples_per_second': 152.452, 'train_steps_per_second': 1.209, 'train_loss': 2.854252497355143, 'epoch': 3.0}
[INFO][22:59:58]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][22:59:58]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][22:59:59]: [Client #5] Model trained.
[INFO][22:59:59]: [Client #5] Inbound data has been processed.
[INFO][22:59:59]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][22:59:59]: [Client #3] Model trained.
[INFO][22:59:59]: [Client #3] Inbound data has been processed.
[INFO][22:59:59]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:00:05]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:00:06]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:00:06]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:00:07]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:00:07]: [Server #3350301] Selecting client #9 for training.
[INFO][23:00:07]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:00:11]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:00:11]: [Client #9] Selected by the server.
[INFO][23:00:11]: [Client #9] Loading its data source...
[INFO][23:00:11]: [Client #9] Dataset size: 2018
[INFO][23:00:11]: [Client #9] Sampler: iid
[INFO][23:00:12]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:00:12]: [Client #9] Start to process inbound data.
[INFO][23:00:12]: [93m[1m[Client #9] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:00:45]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.766, 'train_samples_per_second': 226.183, 'train_steps_per_second': 1.793, 'train_loss': 2.9466072718302407, 'epoch': 3.0}
[INFO][23:00:46]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:00:46]: [Client #9] Model trained.
[INFO][23:00:46]: [Client #9] Inbound data has been processed.
[INFO][23:00:46]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:00:50]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:00:51]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:00:51]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:00:51]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:00:51]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:00:51]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:00:51]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:00:51]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:00:51]: [Server #3350301] Updated weights have been received.
[INFO][23:00:52]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:00:53]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:00:53]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.36it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.59it/s]
[INFO][23:01:03]: [93m[1m[Server #3350301] Global model perplexity: 28.41
[0m
[INFO][23:01:03]: [Server #3350301] All client reports have been processed.
[INFO][23:01:04]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_35.pth.
[INFO][23:01:06]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_35.pth.
[INFO][23:01:06]: [93m[1m
[Server #3350301] Starting round 36/100.[0m
[INFO][23:01:06]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][23:01:06]: [Server #3350301] Selecting client #2 for training.
[INFO][23:01:06]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:01:10]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:01:10]: [Server #3350301] Selecting client #1 for training.
[INFO][23:01:10]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:01:13]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:01:13]: [Client #2] Selected by the server.
[INFO][23:01:13]: [Client #2] Loading its data source...
[INFO][23:01:13]: [Client #2] Dataset size: 2018
[INFO][23:01:13]: [Client #2] Sampler: iid
[INFO][23:01:13]: [Client #1] Selected by the server.
[INFO][23:01:13]: [Client #1] Loading its data source...
[INFO][23:01:13]: [Client #1] Dataset size: 2018
[INFO][23:01:13]: [Client #1] Sampler: iid
[INFO][23:01:15]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:01:15]: [Client #2] Start to process inbound data.
[INFO][23:01:15]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:01:15]: [Client #1] Start to process inbound data.
[INFO][23:01:16]: [93m[1m[Client #2] Started training in communication round #36.[0m
[INFO][23:01:16]: [93m[1m[Client #1] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.03s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.08s/it]  2%|â–         | 1/48 [00:04<03:46,  4.83s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  4%|â–         | 2/48 [00:05<01:58,  2.57s/it]  8%|â–Š         | 4/48 [00:06<00:58,  1.33s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.18s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.44s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:46,  1.10s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.26s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.14s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:39,  1.00it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.08it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:33,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:34,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:31,  1.11it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:32,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.12it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.13it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:28,  1.12it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:26,  1.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:24,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:23,  1.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:23,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:21,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.12it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:19,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:19,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:18,  1.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:32<00:13,  1.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:13,  1.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:12,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:12,  1.15it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:11,  1.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.15it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:10,  1.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.14it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:09,  1.13it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.15it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:08,  1.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:44<00:01,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:45<00:00,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:02,  1.00s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.06it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.02it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.02it/s]
[INFO][23:02:08]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 46.8615, 'train_samples_per_second': 129.189, 'train_steps_per_second': 1.024, 'train_loss': 2.378317674001058, 'epoch': 3.0}
[INFO][23:02:09]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 47.143, 'train_samples_per_second': 128.418, 'train_steps_per_second': 1.018, 'train_loss': 2.8310937881469727, 'epoch': 3.0}
[INFO][23:02:09]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:02:10]: [Client #1] Model trained.
[INFO][23:02:10]: [Client #1] Inbound data has been processed.
[INFO][23:02:10]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:02:10]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:02:11]: [Client #2] Model trained.
[INFO][23:02:11]: [Client #2] Inbound data has been processed.
[INFO][23:02:11]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:02:16]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:02:17]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:02:17]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:02:18]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:02:18]: [Server #3350301] Selecting client #4 for training.
[INFO][23:02:18]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][23:02:22]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][23:02:22]: [Server #3350301] Selecting client #7 for training.
[INFO][23:02:22]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:02:26]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:02:26]: [Client #4] Selected by the server.
[INFO][23:02:26]: [Client #4] Loading its data source...
[INFO][23:02:26]: [Client #7] Selected by the server.
[INFO][23:02:26]: [Client #4] Dataset size: 2018
[INFO][23:02:26]: [Client #7] Loading its data source...
[INFO][23:02:26]: [Client #4] Sampler: iid
[INFO][23:02:26]: [Client #7] Dataset size: 2018
[INFO][23:02:26]: [Client #7] Sampler: iid
[INFO][23:02:27]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:02:27]: [Client #7] Start to process inbound data.
[INFO][23:02:27]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:02:27]: [Client #4] Start to process inbound data.
[INFO][23:02:28]: [93m[1m[Client #7] Started training in communication round #36.[0m
[INFO][23:02:28]: [93m[1m[Client #4] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.04s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.08s/it]  2%|â–         | 1/48 [00:04<03:46,  4.83s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  4%|â–         | 2/48 [00:05<01:58,  2.57s/it]  8%|â–Š         | 4/48 [00:06<00:58,  1.33s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.82s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.18s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.45s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.09s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.02s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.12s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:39,  1.00it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:33,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.05it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:32,  1.04it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:31,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:33,  1.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.06it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.14it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:30,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:30,  1.02it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:28,  1.03it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:30,  1.01s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:28,  1.01s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:28,  1.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:27,  1.01s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:27,  1.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:25,  1.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:26,  1.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:24,  1.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:25,  1.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:23,  1.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:23,  1.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:22,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:20,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:30<00:18,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:31<00:17,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:17,  1.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:33<00:15,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.15it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.08it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.07it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.04it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:44<00:04,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:45<00:03,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:46<00:02,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:47<00:01,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.06it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.00s/it]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
[INFO][23:03:22]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 48.0999, 'train_samples_per_second': 125.863, 'train_steps_per_second': 0.998, 'train_loss': 2.953677495320638, 'epoch': 3.0}
[INFO][23:03:22]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 48.3692, 'train_samples_per_second': 125.162, 'train_steps_per_second': 0.992, 'train_loss': 3.0508546829223633, 'epoch': 3.0}
[INFO][23:03:23]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:03:23]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][23:03:23]: [Client #7] Model trained.
[INFO][23:03:23]: [Client #7] Inbound data has been processed.
[INFO][23:03:23]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:03:24]: [Client #4] Model trained.
[INFO][23:03:24]: [Client #4] Inbound data has been processed.
[INFO][23:03:24]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][23:03:30]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:03:30]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:03:31]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:03:32]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][23:03:32]: [Server #3350301] Selecting client #8 for training.
[INFO][23:03:32]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][23:03:36]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][23:03:36]: [Client #8] Selected by the server.
[INFO][23:03:36]: [Client #8] Loading its data source...
[INFO][23:03:36]: [Client #8] Dataset size: 2018
[INFO][23:03:36]: [Client #8] Sampler: iid
[INFO][23:03:37]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:03:37]: [Client #8] Start to process inbound data.
[INFO][23:03:37]: [93m[1m[Client #8] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][23:04:10]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.7149, 'train_samples_per_second': 226.616, 'train_steps_per_second': 1.797, 'train_loss': 3.121912956237793, 'epoch': 3.0}
[INFO][23:04:11]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][23:04:12]: [Client #8] Model trained.
[INFO][23:04:12]: [Client #8] Inbound data has been processed.
[INFO][23:04:12]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][23:04:15]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:04:17]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][23:04:17]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:04:17]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:04:17]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:04:17]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:04:17]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][23:04:17]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:04:17]: [Server #3350301] Updated weights have been received.
[INFO][23:04:17]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:04:18]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:04:18]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.59it/s]
[INFO][23:04:28]: [93m[1m[Server #3350301] Global model perplexity: 26.15
[0m
[INFO][23:04:28]: [Server #3350301] All client reports have been processed.
[INFO][23:04:29]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_36.pth.
[INFO][23:04:31]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_36.pth.
[INFO][23:04:31]: [93m[1m
[Server #3350301] Starting round 37/100.[0m
[INFO][23:04:31]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][23:04:31]: [Server #3350301] Selecting client #6 for training.
[INFO][23:04:31]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][23:04:35]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][23:04:35]: [Server #3350301] Selecting client #3 for training.
[INFO][23:04:35]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:04:39]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:04:39]: [Client #6] Selected by the server.
[INFO][23:04:39]: [Client #6] Loading its data source...
[INFO][23:04:39]: [Client #6] Dataset size: 2018
[INFO][23:04:39]: [Client #6] Sampler: iid
[INFO][23:04:39]: [Client #3] Selected by the server.
[INFO][23:04:39]: [Client #3] Loading its data source...
[INFO][23:04:39]: [Client #3] Dataset size: 2018
[INFO][23:04:39]: [Client #3] Sampler: iid
[INFO][23:04:40]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:04:40]: [Client #6] Start to process inbound data.
[INFO][23:04:40]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:04:40]: [Client #3] Start to process inbound data.
[INFO][23:04:40]: [93m[1m[Client #6] Started training in communication round #37.[0m
[INFO][23:04:41]: [93m[1m[Client #3] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.12s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  2%|â–         | 1/48 [00:04<03:36,  4.60s/it]  6%|â–‹         | 3/48 [00:05<01:05,  1.47s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  8%|â–Š         | 4/48 [00:06<00:51,  1.18s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.27s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.08it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.16it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.22it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:31,  1.26it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.29it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.31it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:20<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:23<00:14,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:07,  1.28it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.29it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:05:25]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 38.9719, 'train_samples_per_second': 155.343, 'train_steps_per_second': 1.232, 'train_loss': 2.8119309743245444, 'epoch': 3.0}
[INFO][23:05:26]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.2995, 'train_samples_per_second': 154.048, 'train_steps_per_second': 1.221, 'train_loss': 3.1303059260050454, 'epoch': 3.0}
[INFO][23:05:26]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][23:05:27]: [Client #3] Model trained.
[INFO][23:05:27]: [Client #3] Inbound data has been processed.
[INFO][23:05:27]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:05:27]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][23:05:28]: [Client #6] Model trained.
[INFO][23:05:28]: [Client #6] Inbound data has been processed.
[INFO][23:05:28]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][23:05:33]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:05:34]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:05:34]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:05:35]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][23:05:35]: [Server #3350301] Selecting client #10 for training.
[INFO][23:05:35]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:05:39]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:05:39]: [Server #3350301] Selecting client #5 for training.
[INFO][23:05:39]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:05:43]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:05:43]: [Client #10] Selected by the server.
[INFO][23:05:43]: [Client #10] Loading its data source...
[INFO][23:05:43]: [Client #10] Dataset size: 2018
[INFO][23:05:43]: [Client #10] Sampler: iid
[INFO][23:05:43]: [Client #5] Selected by the server.
[INFO][23:05:43]: [Client #5] Loading its data source...
[INFO][23:05:43]: [Client #5] Dataset size: 2018
[INFO][23:05:43]: [Client #5] Sampler: iid
[INFO][23:05:44]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:05:44]: [Client #5] Start to process inbound data.
[INFO][23:05:44]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:05:44]: [Client #10] Start to process inbound data.
[INFO][23:05:44]: [93m[1m[Client #5] Started training in communication round #37.[0m
[INFO][23:05:44]: [93m[1m[Client #10] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  2%|â–         | 1/48 [00:04<03:47,  4.85s/it]  4%|â–         | 2/48 [00:04<01:37,  2.13s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:22,  1.32it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:06:30]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.1971, 'train_samples_per_second': 154.45, 'train_steps_per_second': 1.225, 'train_loss': 3.0352306365966797, 'epoch': 3.0}
[INFO][23:06:30]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.6144, 'train_samples_per_second': 152.823, 'train_steps_per_second': 1.212, 'train_loss': 2.7920939127604165, 'epoch': 3.0}
[INFO][23:06:31]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:06:31]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:06:31]: [Client #10] Model trained.
[INFO][23:06:31]: [Client #10] Inbound data has been processed.
[INFO][23:06:31]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:06:32]: [Client #5] Model trained.
[INFO][23:06:32]: [Client #5] Inbound data has been processed.
[INFO][23:06:32]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:06:38]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:06:38]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:06:39]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:06:40]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:06:40]: [Server #3350301] Selecting client #9 for training.
[INFO][23:06:40]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:06:43]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:06:43]: [Client #9] Selected by the server.
[INFO][23:06:43]: [Client #9] Loading its data source...
[INFO][23:06:43]: [Client #9] Dataset size: 2018
[INFO][23:06:43]: [Client #9] Sampler: iid
[INFO][23:06:45]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:06:45]: [Client #9] Start to process inbound data.
[INFO][23:06:45]: [93m[1m[Client #9] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:07:18]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7782, 'train_samples_per_second': 226.08, 'train_steps_per_second': 1.793, 'train_loss': 2.881591796875, 'epoch': 3.0}
[INFO][23:07:19]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:07:19]: [Client #9] Model trained.
[INFO][23:07:19]: [Client #9] Inbound data has been processed.
[INFO][23:07:19]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:07:23]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:07:25]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:07:25]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:07:25]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:07:25]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:07:25]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:07:25]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:07:25]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:07:25]: [Server #3350301] Updated weights have been received.
[INFO][23:07:25]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:07:26]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:07:26]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][23:07:36]: [93m[1m[Server #3350301] Global model perplexity: 28.10
[0m
[INFO][23:07:36]: [Server #3350301] All client reports have been processed.
[INFO][23:07:36]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_37.pth.
[INFO][23:07:39]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_37.pth.
[INFO][23:07:39]: [93m[1m
[Server #3350301] Starting round 38/100.[0m
[INFO][23:07:39]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][23:07:39]: [Server #3350301] Selecting client #2 for training.
[INFO][23:07:39]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:07:43]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:07:43]: [Server #3350301] Selecting client #1 for training.
[INFO][23:07:43]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:07:47]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:07:47]: [Client #2] Selected by the server.
[INFO][23:07:47]: [Client #2] Loading its data source...
[INFO][23:07:47]: [Client #2] Dataset size: 2018
[INFO][23:07:47]: [Client #2] Sampler: iid
[INFO][23:07:47]: [Client #1] Selected by the server.
[INFO][23:07:47]: [Client #1] Loading its data source...
[INFO][23:07:47]: [Client #1] Dataset size: 2018
[INFO][23:07:47]: [Client #1] Sampler: iid
[INFO][23:07:48]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:07:48]: [Client #2] Start to process inbound data.
[INFO][23:07:48]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:07:48]: [Client #1] Start to process inbound data.
[INFO][23:07:48]: [93m[1m[Client #2] Started training in communication round #38.[0m
[INFO][23:07:49]: [93m[1m[Client #1] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  2%|â–         | 1/48 [00:04<03:52,  4.95s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  4%|â–         | 2/48 [00:05<01:54,  2.49s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.69s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:08:34]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.7212, 'train_samples_per_second': 152.412, 'train_steps_per_second': 1.208, 'train_loss': 2.8177849451700845, 'epoch': 3.0}
[INFO][23:08:35]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.6655, 'train_samples_per_second': 152.626, 'train_steps_per_second': 1.21, 'train_loss': 2.3930174509684243, 'epoch': 3.0}
[INFO][23:08:36]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:08:36]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:08:36]: [Client #2] Model trained.
[INFO][23:08:36]: [Client #2] Inbound data has been processed.
[INFO][23:08:36]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:08:37]: [Client #1] Model trained.
[INFO][23:08:37]: [Client #1] Inbound data has been processed.
[INFO][23:08:37]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:08:42]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:08:43]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:08:43]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:08:44]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:08:44]: [Server #3350301] Selecting client #5 for training.
[INFO][23:08:44]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:08:47]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:08:47]: [Server #3350301] Selecting client #7 for training.
[INFO][23:08:47]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:08:51]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:08:51]: [Client #5] Selected by the server.
[INFO][23:08:51]: [Client #5] Loading its data source...
[INFO][23:08:51]: [Client #7] Selected by the server.
[INFO][23:08:51]: [Client #5] Dataset size: 2018
[INFO][23:08:51]: [Client #7] Loading its data source...
[INFO][23:08:51]: [Client #5] Sampler: iid
[INFO][23:08:51]: [Client #7] Dataset size: 2018
[INFO][23:08:51]: [Client #7] Sampler: iid
[INFO][23:08:52]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:08:52]: [Client #7] Start to process inbound data.
[INFO][23:08:52]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:08:52]: [Client #5] Start to process inbound data.
[INFO][23:08:53]: [93m[1m[Client #5] Started training in communication round #38.[0m
[INFO][23:08:53]: [93m[1m[Client #7] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:40,  2.19s/it]  2%|â–         | 1/48 [00:04<03:53,  4.97s/it]  6%|â–‹         | 3/48 [00:05<01:12,  1.61s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  8%|â–Š         | 4/48 [00:06<00:58,  1.33s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.83s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.14s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.43s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.12it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.18it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.30it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:16,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.55it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][23:09:39]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.6713, 'train_samples_per_second': 152.604, 'train_steps_per_second': 1.21, 'train_loss': 2.753298759460449, 'epoch': 3.0}
[INFO][23:09:40]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 40.2665, 'train_samples_per_second': 150.348, 'train_steps_per_second': 1.192, 'train_loss': 2.890777587890625, 'epoch': 3.0}
[INFO][23:09:40]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][23:09:41]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:09:41]: [Client #5] Model trained.
[INFO][23:09:41]: [Client #5] Inbound data has been processed.
[INFO][23:09:41]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:09:41]: [Client #7] Model trained.
[INFO][23:09:41]: [Client #7] Inbound data has been processed.
[INFO][23:09:41]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:09:47]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:09:47]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:09:48]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:09:49]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:09:49]: [Server #3350301] Selecting client #9 for training.
[INFO][23:09:49]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:09:53]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:09:53]: [Client #9] Selected by the server.
[INFO][23:09:53]: [Client #9] Loading its data source...
[INFO][23:09:53]: [Client #9] Dataset size: 2018
[INFO][23:09:53]: [Client #9] Sampler: iid
[INFO][23:09:54]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:09:54]: [Client #9] Start to process inbound data.
[INFO][23:09:54]: [93m[1m[Client #9] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.21s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:10:27]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8456, 'train_samples_per_second': 225.512, 'train_steps_per_second': 1.788, 'train_loss': 2.840704917907715, 'epoch': 3.0}
[INFO][23:10:29]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:10:29]: [Client #9] Model trained.
[INFO][23:10:29]: [Client #9] Inbound data has been processed.
[INFO][23:10:29]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:10:33]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:10:34]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:10:34]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:10:34]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:10:34]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:10:34]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:10:34]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:10:34]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:10:34]: [Server #3350301] Updated weights have been received.
[INFO][23:10:35]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:10:35]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:10:35]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.61it/s]
[INFO][23:10:46]: [93m[1m[Server #3350301] Global model perplexity: 28.56
[0m
[INFO][23:10:46]: [Server #3350301] All client reports have been processed.
[INFO][23:10:46]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_38.pth.
[INFO][23:10:49]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_38.pth.
[INFO][23:10:49]: [93m[1m
[Server #3350301] Starting round 39/100.[0m
[INFO][23:10:49]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][23:10:49]: [Server #3350301] Selecting client #4 for training.
[INFO][23:10:49]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][23:10:53]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][23:10:53]: [Server #3350301] Selecting client #1 for training.
[INFO][23:10:53]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:10:56]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:10:56]: [Client #4] Selected by the server.
[INFO][23:10:56]: [Client #4] Loading its data source...
[INFO][23:10:56]: [Client #4] Dataset size: 2018
[INFO][23:10:56]: [Client #4] Sampler: iid
[INFO][23:10:56]: [Client #1] Selected by the server.
[INFO][23:10:56]: [Client #1] Loading its data source...
[INFO][23:10:56]: [Client #1] Dataset size: 2018
[INFO][23:10:56]: [Client #1] Sampler: iid
[INFO][23:10:58]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:10:58]: [Client #4] Start to process inbound data.
[INFO][23:10:58]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:10:58]: [Client #1] Start to process inbound data.
[INFO][23:10:58]: [93m[1m[Client #4] Started training in communication round #39.[0m
[INFO][23:10:58]: [93m[1m[Client #1] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  2%|â–         | 1/48 [00:04<03:14,  4.15s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.56s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
[INFO][23:11:43]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 38.8093, 'train_samples_per_second': 155.994, 'train_steps_per_second': 1.237, 'train_loss': 3.006811777750651, 'epoch': 3.0}
[INFO][23:11:44]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.1133, 'train_samples_per_second': 154.781, 'train_steps_per_second': 1.227, 'train_loss': 2.3454588254292807, 'epoch': 3.0}
[INFO][23:11:45]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][23:11:45]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:11:45]: [Client #4] Model trained.
[INFO][23:11:45]: [Client #4] Inbound data has been processed.
[INFO][23:11:45]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][23:11:45]: [Client #1] Model trained.
[INFO][23:11:45]: [Client #1] Inbound data has been processed.
[INFO][23:11:45]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:11:52]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:11:52]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:11:53]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][23:11:54]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:11:54]: [Server #3350301] Selecting client #8 for training.
[INFO][23:11:54]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][23:11:58]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][23:11:58]: [Server #3350301] Selecting client #3 for training.
[INFO][23:11:58]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:12:01]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:12:01]: [Client #8] Selected by the server.
[INFO][23:12:01]: [Client #8] Loading its data source...
[INFO][23:12:01]: [Client #8] Dataset size: 2018
[INFO][23:12:01]: [Client #8] Sampler: iid
[INFO][23:12:01]: [Client #3] Selected by the server.
[INFO][23:12:01]: [Client #3] Loading its data source...
[INFO][23:12:01]: [Client #3] Dataset size: 2018
[INFO][23:12:01]: [Client #3] Sampler: iid
[INFO][23:12:02]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:12:02]: [Client #8] Start to process inbound data.
[INFO][23:12:02]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:12:02]: [Client #3] Start to process inbound data.
[INFO][23:12:03]: [93m[1m[Client #8] Started training in communication round #39.[0m
[INFO][23:12:03]: [93m[1m[Client #3] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.13s/it]  2%|â–         | 1/48 [00:04<03:43,  4.75s/it]  4%|â–         | 2/48 [00:04<01:36,  2.10s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:12:49]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.3391, 'train_samples_per_second': 153.893, 'train_steps_per_second': 1.22, 'train_loss': 3.0723851521809897, 'epoch': 3.0}
[INFO][23:12:50]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.696, 'train_samples_per_second': 152.509, 'train_steps_per_second': 1.209, 'train_loss': 2.77775510152181, 'epoch': 3.0}
[INFO][23:12:50]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][23:12:50]: [Client #8] Model trained.
[INFO][23:12:50]: [Client #8] Inbound data has been processed.
[INFO][23:12:50]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][23:12:51]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][23:12:51]: [Client #3] Model trained.
[INFO][23:12:51]: [Client #3] Inbound data has been processed.
[INFO][23:12:51]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:12:56]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:12:57]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:12:57]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][23:12:58]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:12:58]: [Server #3350301] Selecting client #10 for training.
[INFO][23:12:58]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:13:02]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:13:02]: [Client #10] Selected by the server.
[INFO][23:13:02]: [Client #10] Loading its data source...
[INFO][23:13:02]: [Client #10] Dataset size: 2018
[INFO][23:13:02]: [Client #10] Sampler: iid
[INFO][23:13:04]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:13:04]: [Client #10] Start to process inbound data.
[INFO][23:13:04]: [93m[1m[Client #10] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][23:13:36]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.7381, 'train_samples_per_second': 226.419, 'train_steps_per_second': 1.795, 'train_loss': 2.9945411682128906, 'epoch': 3.0}
[INFO][23:13:37]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:13:38]: [Client #10] Model trained.
[INFO][23:13:38]: [Client #10] Inbound data has been processed.
[INFO][23:13:38]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:13:42]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:13:43]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:13:43]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:13:43]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:13:43]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:13:43]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:13:43]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][23:13:43]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:13:43]: [Server #3350301] Updated weights have been received.
[INFO][23:13:43]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:13:44]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:13:44]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.76it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.37it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][23:13:55]: [93m[1m[Server #3350301] Global model perplexity: 26.82
[0m
[INFO][23:13:55]: [Server #3350301] All client reports have been processed.
[INFO][23:13:55]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_39.pth.
[INFO][23:13:58]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_39.pth.
[INFO][23:13:58]: [93m[1m
[Server #3350301] Starting round 40/100.[0m
[INFO][23:13:58]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][23:13:58]: [Server #3350301] Selecting client #2 for training.
[INFO][23:13:58]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:14:01]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:14:01]: [Server #3350301] Selecting client #5 for training.
[INFO][23:14:01]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:14:05]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:14:05]: [Client #2] Selected by the server.
[INFO][23:14:05]: [Client #2] Loading its data source...
[INFO][23:14:05]: [Client #2] Dataset size: 2018
[INFO][23:14:05]: [Client #2] Sampler: iid
[INFO][23:14:05]: [Client #5] Selected by the server.
[INFO][23:14:05]: [Client #5] Loading its data source...
[INFO][23:14:05]: [Client #5] Dataset size: 2018
[INFO][23:14:05]: [Client #5] Sampler: iid
[INFO][23:14:06]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:14:06]: [Client #2] Start to process inbound data.
[INFO][23:14:07]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:14:07]: [Client #5] Start to process inbound data.
[INFO][23:14:07]: [93m[1m[Client #5] Started training in communication round #40.[0m
[INFO][23:14:07]: [93m[1m[Client #2] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.13s/it]  2%|â–         | 1/48 [00:04<03:53,  4.98s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.82s/it]  8%|â–Š         | 4/48 [00:06<00:59,  1.36s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.47s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.20s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:46,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.14s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.06s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.08s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.02s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:42,  1.05s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:39,  1.02s/it] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:37,  1.02it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.03it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:30,  1.01s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:29,  1.02it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:29,  1.03s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:29,  1.02s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:29,  1.05s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:29,  1.04s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:28,  1.06s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:24<00:28,  1.05s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:27,  1.05s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:26,  1.02s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:24,  1.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:23,  1.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:21,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:20,  1.15it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:19,  1.16it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:19,  1.20it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:18,  1.21it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:17,  1.24it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:16,  1.25it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:16,  1.27it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:16,  1.24it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:15,  1.28it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:15,  1.26it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:14,  1.28it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:13,  1.29it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:13,  1.29it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:12,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:13,  1.31it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:31<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:11,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:32<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:34<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:35<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:36<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:36<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:37<00:06,  1.30it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:37<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:38<00:06,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:38<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:38<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:39<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:39<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:39<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:40<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:40<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:41<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:41<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:41<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:42<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:42<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:42<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:43<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:43<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:43<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:43<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:43<00:00,  1.09it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.08it/s]
[INFO][23:14:57]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 43.9377, 'train_samples_per_second': 137.786, 'train_steps_per_second': 1.092, 'train_loss': 2.7863022486368814, 'epoch': 3.0}
[INFO][23:14:58]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 44.3103, 'train_samples_per_second': 136.627, 'train_steps_per_second': 1.083, 'train_loss': 2.702425956726074, 'epoch': 3.0}
[INFO][23:14:58]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:14:59]: [Client #2] Model trained.
[INFO][23:14:59]: [Client #2] Inbound data has been processed.
[INFO][23:14:59]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:14:59]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:14:59]: [Client #5] Model trained.
[INFO][23:14:59]: [Client #5] Inbound data has been processed.
[INFO][23:14:59]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:15:05]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:15:05]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:15:06]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:15:07]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:15:07]: [Server #3350301] Selecting client #6 for training.
[INFO][23:15:07]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][23:15:10]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][23:15:10]: [Server #3350301] Selecting client #7 for training.
[INFO][23:15:10]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:15:14]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:15:14]: [Client #6] Selected by the server.
[INFO][23:15:14]: [Client #7] Selected by the server.
[INFO][23:15:14]: [Client #6] Loading its data source...
[INFO][23:15:14]: [Client #7] Loading its data source...
[INFO][23:15:14]: [Client #7] Dataset size: 2018
[INFO][23:15:14]: [Client #6] Dataset size: 2018
[INFO][23:15:14]: [Client #7] Sampler: iid
[INFO][23:15:14]: [Client #6] Sampler: iid
[INFO][23:15:15]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:15:15]: [Client #7] Start to process inbound data.
[INFO][23:15:15]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:15:15]: [Client #6] Start to process inbound data.
[INFO][23:15:16]: [93m[1m[Client #7] Started training in communication round #40.[0m
[INFO][23:15:16]: [93m[1m[Client #6] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  2%|â–         | 1/48 [00:04<03:50,  4.91s/it]  4%|â–         | 2/48 [00:05<01:43,  2.24s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.57s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:16:02]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.3202, 'train_samples_per_second': 153.967, 'train_steps_per_second': 1.221, 'train_loss': 2.841122627258301, 'epoch': 3.0}
[INFO][23:16:02]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.6777, 'train_samples_per_second': 152.58, 'train_steps_per_second': 1.21, 'train_loss': 3.0888595581054688, 'epoch': 3.0}
[INFO][23:16:03]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:16:03]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][23:16:03]: [Client #7] Model trained.
[INFO][23:16:03]: [Client #7] Inbound data has been processed.
[INFO][23:16:03]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:16:04]: [Client #6] Model trained.
[INFO][23:16:04]: [Client #6] Inbound data has been processed.
[INFO][23:16:04]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][23:16:10]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:16:11]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:16:11]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:16:12]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][23:16:12]: [Server #3350301] Selecting client #9 for training.
[INFO][23:16:12]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:16:16]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:16:16]: [Client #9] Selected by the server.
[INFO][23:16:16]: [Client #9] Loading its data source...
[INFO][23:16:16]: [Client #9] Dataset size: 2018
[INFO][23:16:16]: [Client #9] Sampler: iid
[INFO][23:16:18]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:16:18]: [Client #9] Start to process inbound data.
[INFO][23:16:18]: [93m[1m[Client #9] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][23:16:51]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.6792, 'train_samples_per_second': 226.918, 'train_steps_per_second': 1.799, 'train_loss': 2.7864020665486655, 'epoch': 3.0}
[INFO][23:16:52]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:16:52]: [Client #9] Model trained.
[INFO][23:16:52]: [Client #9] Inbound data has been processed.
[INFO][23:16:52]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:16:56]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:16:57]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:16:57]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:16:57]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:16:57]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:16:57]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:16:57]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:16:57]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:16:57]: [Server #3350301] Updated weights have been received.
[INFO][23:16:58]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:16:58]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:16:58]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 12.76it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][23:17:10]: [93m[1m[Server #3350301] Global model perplexity: 28.78
[0m
[INFO][23:17:10]: [Server #3350301] All client reports have been processed.
[INFO][23:17:10]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_40.pth.
[INFO][23:17:12]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_40.pth.
[INFO][23:17:12]: [93m[1m
[Server #3350301] Starting round 41/100.[0m
[INFO][23:17:12]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][23:17:12]: [Server #3350301] Selecting client #10 for training.
[INFO][23:17:12]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:17:16]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:17:16]: [Server #3350301] Selecting client #1 for training.
[INFO][23:17:16]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:17:20]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:17:20]: [Client #10] Selected by the server.
[INFO][23:17:20]: [Client #10] Loading its data source...
[INFO][23:17:20]: [Client #1] Selected by the server.
[INFO][23:17:20]: [Client #10] Dataset size: 2018
[INFO][23:17:20]: [Client #1] Loading its data source...
[INFO][23:17:20]: [Client #10] Sampler: iid
[INFO][23:17:20]: [Client #1] Dataset size: 2018
[INFO][23:17:20]: [Client #1] Sampler: iid
[INFO][23:17:21]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:17:21]: [Client #1] Start to process inbound data.
[INFO][23:17:21]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:17:21]: [Client #10] Start to process inbound data.
[INFO][23:17:22]: [93m[1m[Client #1] Started training in communication round #41.[0m
[INFO][23:17:22]: [93m[1m[Client #10] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.14s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  4%|â–         | 2/48 [00:04<01:36,  2.11s/it]  4%|â–         | 2/48 [00:05<01:57,  2.56s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.60s/it]  8%|â–Š         | 4/48 [00:06<00:59,  1.34s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.84s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.17s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.46s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.02s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:44,  1.06s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:39,  1.05it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.13it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][23:18:08]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.4445, 'train_samples_per_second': 153.481, 'train_steps_per_second': 1.217, 'train_loss': 2.9621766408284507, 'epoch': 3.0}
[INFO][23:18:08]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.9988, 'train_samples_per_second': 151.355, 'train_steps_per_second': 1.2, 'train_loss': 2.359062353769938, 'epoch': 3.0}
[INFO][23:18:09]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:18:09]: [Client #10] Model trained.
[INFO][23:18:09]: [Client #10] Inbound data has been processed.
[INFO][23:18:09]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:18:09]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:18:10]: [Client #1] Model trained.
[INFO][23:18:10]: [Client #1] Inbound data has been processed.
[INFO][23:18:10]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:18:15]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:18:16]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:18:16]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:18:17]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:18:17]: [Server #3350301] Selecting client #3 for training.
[INFO][23:18:17]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:18:21]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:18:21]: [Server #3350301] Selecting client #5 for training.
[INFO][23:18:21]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:18:25]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:18:25]: [Client #5] Selected by the server.
[INFO][23:18:25]: [Client #5] Loading its data source...
[INFO][23:18:25]: [Client #5] Dataset size: 2018
[INFO][23:18:25]: [Client #5] Sampler: iid
[INFO][23:18:25]: [Client #3] Selected by the server.
[INFO][23:18:25]: [Client #3] Loading its data source...
[INFO][23:18:25]: [Client #3] Dataset size: 2018
[INFO][23:18:25]: [Client #3] Sampler: iid
[INFO][23:18:26]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:18:26]: [Client #3] Start to process inbound data.
[INFO][23:18:26]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:18:26]: [Client #5] Start to process inbound data.
[INFO][23:18:27]: [93m[1m[Client #3] Started training in communication round #41.[0m
[INFO][23:18:27]: [93m[1m[Client #5] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:37,  4.62s/it]  2%|â–         | 1/48 [00:05<04:02,  5.15s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  4%|â–         | 2/48 [00:05<01:58,  2.59s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.00it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][23:19:13]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.5008, 'train_samples_per_second': 153.263, 'train_steps_per_second': 1.215, 'train_loss': 2.672409693400065, 'epoch': 3.0}
[INFO][23:19:13]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.8663, 'train_samples_per_second': 151.858, 'train_steps_per_second': 1.204, 'train_loss': 2.7326151529947915, 'epoch': 3.0}
[INFO][23:19:14]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:19:14]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][23:19:14]: [Client #5] Model trained.
[INFO][23:19:14]: [Client #5] Inbound data has been processed.
[INFO][23:19:14]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:19:15]: [Client #3] Model trained.
[INFO][23:19:15]: [Client #3] Inbound data has been processed.
[INFO][23:19:15]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:19:21]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:19:21]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:19:22]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:19:23]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:19:23]: [Server #3350301] Selecting client #9 for training.
[INFO][23:19:23]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:19:26]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:19:26]: [Client #9] Selected by the server.
[INFO][23:19:26]: [Client #9] Loading its data source...
[INFO][23:19:26]: [Client #9] Dataset size: 2018
[INFO][23:19:26]: [Client #9] Sampler: iid
[INFO][23:19:28]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:19:28]: [Client #9] Start to process inbound data.
[INFO][23:19:28]: [93m[1m[Client #9] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.96it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][23:20:01]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7096, 'train_samples_per_second': 226.66, 'train_steps_per_second': 1.797, 'train_loss': 2.746291478474935, 'epoch': 3.0}
[INFO][23:20:02]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:20:03]: [Client #9] Model trained.
[INFO][23:20:03]: [Client #9] Inbound data has been processed.
[INFO][23:20:03]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:20:07]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:20:08]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:20:08]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:20:08]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:20:08]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:20:08]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:20:08]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:20:08]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:20:08]: [Server #3350301] Updated weights have been received.
[INFO][23:20:08]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:20:09]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:20:09]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.81it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.56it/s]
[INFO][23:20:20]: [93m[1m[Server #3350301] Global model perplexity: 29.83
[0m
[INFO][23:20:20]: [Server #3350301] All client reports have been processed.
[INFO][23:20:20]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_41.pth.
[INFO][23:20:22]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_41.pth.
[INFO][23:20:22]: [93m[1m
[Server #3350301] Starting round 42/100.[0m
[INFO][23:20:22]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][23:20:22]: [Server #3350301] Selecting client #2 for training.
[INFO][23:20:22]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:20:26]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:20:26]: [Server #3350301] Selecting client #1 for training.
[INFO][23:20:26]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:20:30]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:20:30]: [Client #2] Selected by the server.
[INFO][23:20:30]: [Client #2] Loading its data source...
[INFO][23:20:30]: [Client #2] Dataset size: 2018
[INFO][23:20:30]: [Client #2] Sampler: iid
[INFO][23:20:30]: [Client #1] Selected by the server.
[INFO][23:20:30]: [Client #1] Loading its data source...
[INFO][23:20:30]: [Client #1] Dataset size: 2018
[INFO][23:20:30]: [Client #1] Sampler: iid
[INFO][23:20:31]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:20:31]: [Client #2] Start to process inbound data.
[INFO][23:20:31]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:20:31]: [Client #1] Start to process inbound data.
[INFO][23:20:32]: [93m[1m[Client #1] Started training in communication round #42.[0m
[INFO][23:20:32]: [93m[1m[Client #2] Started training in communication round #42.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  2%|â–         | 1/48 [00:04<03:37,  4.62s/it]  4%|â–         | 2/48 [00:05<01:44,  2.26s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.58s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.69s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:21:17]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.6489, 'train_samples_per_second': 152.69, 'train_steps_per_second': 1.211, 'train_loss': 2.2915776570638022, 'epoch': 3.0}
[INFO][23:21:18]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.1816, 'train_samples_per_second': 154.511, 'train_steps_per_second': 1.225, 'train_loss': 2.753085454305013, 'epoch': 3.0}
[INFO][23:21:18]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:21:19]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:21:19]: [Client #1] Model trained.
[INFO][23:21:19]: [Client #1] Inbound data has been processed.
[INFO][23:21:19]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:21:19]: [Client #2] Model trained.
[INFO][23:21:19]: [Client #2] Inbound data has been processed.
[INFO][23:21:19]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:21:25]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:21:26]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:21:26]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:21:27]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:21:27]: [Server #3350301] Selecting client #4 for training.
[INFO][23:21:27]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][23:21:31]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][23:21:31]: [Server #3350301] Selecting client #7 for training.
[INFO][23:21:31]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:21:34]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:21:34]: [Client #4] Selected by the server.
[INFO][23:21:34]: [Client #4] Loading its data source...
[INFO][23:21:34]: [Client #7] Selected by the server.
[INFO][23:21:34]: [Client #4] Dataset size: 2018
[INFO][23:21:34]: [Client #7] Loading its data source...
[INFO][23:21:34]: [Client #4] Sampler: iid
[INFO][23:21:34]: [Client #7] Dataset size: 2018
[INFO][23:21:34]: [Client #7] Sampler: iid
[INFO][23:21:36]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:21:36]: [Client #7] Start to process inbound data.
[INFO][23:21:36]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:21:36]: [Client #4] Start to process inbound data.
[INFO][23:21:36]: [93m[1m[Client #7] Started training in communication round #42.[0m
[INFO][23:21:37]: [93m[1m[Client #4] Started training in communication round #42.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  2%|â–         | 1/48 [00:04<03:47,  4.84s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:22:22]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.0872, 'train_samples_per_second': 154.885, 'train_steps_per_second': 1.228, 'train_loss': 2.8032248814900718, 'epoch': 3.0}
[INFO][23:22:22]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.4537, 'train_samples_per_second': 153.446, 'train_steps_per_second': 1.217, 'train_loss': 2.971968650817871, 'epoch': 3.0}
[INFO][23:22:23]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][23:22:23]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:22:24]: [Client #4] Model trained.
[INFO][23:22:24]: [Client #4] Inbound data has been processed.
[INFO][23:22:24]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][23:22:24]: [Client #7] Model trained.
[INFO][23:22:24]: [Client #7] Inbound data has been processed.
[INFO][23:22:24]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:22:31]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:22:31]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:22:32]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][23:22:33]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:22:33]: [Server #3350301] Selecting client #8 for training.
[INFO][23:22:33]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][23:22:36]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][23:22:36]: [Client #8] Selected by the server.
[INFO][23:22:36]: [Client #8] Loading its data source...
[INFO][23:22:36]: [Client #8] Dataset size: 2018
[INFO][23:22:36]: [Client #8] Sampler: iid
[INFO][23:22:38]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:22:38]: [Client #8] Start to process inbound data.
[INFO][23:22:38]: [93m[1m[Client #8] Started training in communication round #42.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:23:11]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.8137, 'train_samples_per_second': 225.78, 'train_steps_per_second': 1.79, 'train_loss': 3.0324484507242837, 'epoch': 3.0}
[INFO][23:23:12]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][23:23:12]: [Client #8] Model trained.
[INFO][23:23:12]: [Client #8] Inbound data has been processed.
[INFO][23:23:12]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][23:23:16]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:23:17]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][23:23:17]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:23:17]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:23:17]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:23:17]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:23:17]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][23:23:17]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:23:17]: [Server #3350301] Updated weights have been received.
[INFO][23:23:18]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:23:18]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:23:18]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.80it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 12.75it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.64it/s]
[INFO][23:23:29]: [93m[1m[Server #3350301] Global model perplexity: 27.25
[0m
[INFO][23:23:29]: [Server #3350301] All client reports have been processed.
[INFO][23:23:29]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_42.pth.
[INFO][23:23:32]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_42.pth.
[INFO][23:23:32]: [93m[1m
[Server #3350301] Starting round 43/100.[0m
[INFO][23:23:32]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][23:23:32]: [Server #3350301] Selecting client #6 for training.
[INFO][23:23:32]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][23:23:36]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][23:23:36]: [Server #3350301] Selecting client #3 for training.
[INFO][23:23:36]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:23:39]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:23:39]: [Client #6] Selected by the server.
[INFO][23:23:39]: [Client #6] Loading its data source...
[INFO][23:23:39]: [Client #6] Dataset size: 2018
[INFO][23:23:39]: [Client #6] Sampler: iid
[INFO][23:23:39]: [Client #3] Selected by the server.
[INFO][23:23:39]: [Client #3] Loading its data source...
[INFO][23:23:39]: [Client #3] Dataset size: 2018
[INFO][23:23:39]: [Client #3] Sampler: iid
[INFO][23:23:41]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:23:41]: [Client #3] Start to process inbound data.
[INFO][23:23:41]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:23:41]: [Client #6] Start to process inbound data.
[INFO][23:23:42]: [93m[1m[Client #6] Started training in communication round #43.[0m
[INFO][23:23:42]: [93m[1m[Client #3] Started training in communication round #43.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:08,  4.01s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:34,  2.05s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  4%|â–         | 2/48 [00:05<02:00,  2.61s/it]  8%|â–Š         | 4/48 [00:06<00:59,  1.34s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.79s/it] 10%|â–ˆ         | 5/48 [00:07<00:50,  1.18s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.43s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.08s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.01s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.15s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:41,  1.03s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.08s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:38,  1.02it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:41,  1.04s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.00s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:33,  1.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:34,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.06it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:26,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:23,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:21,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:19,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:18,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:17,  1.13it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:16,  1.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:17,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:15,  1.14it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.12it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.02it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.03it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:12,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.16it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:10,  1.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:10,  1.22it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:09,  1.17it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:09,  1.25it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:08,  1.22it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:08,  1.28it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:07,  1.25it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:07,  1.29it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:38<00:06,  1.27it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:39<00:05,  1.29it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:06,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:40<00:04,  1.28it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:05,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:41<00:03,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:40<00:04,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:41<00:03,  1.29it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:41<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:42<00:02,  1.29it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:42<00:03,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:43<00:01,  1.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:43<00:02,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:44<00:00,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:43<00:01,  1.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.07it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:44<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:45<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:45<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:45<00:00,  1.07it/s]
[INFO][23:24:33]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 44.8255, 'train_samples_per_second': 135.057, 'train_steps_per_second': 1.071, 'train_loss': 2.7009874979654946, 'epoch': 3.0}
[INFO][23:24:33]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 45.0214, 'train_samples_per_second': 134.469, 'train_steps_per_second': 1.066, 'train_loss': 3.0487025578816733, 'epoch': 3.0}
[INFO][23:24:34]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][23:24:34]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][23:24:34]: [Client #3] Model trained.
[INFO][23:24:34]: [Client #3] Inbound data has been processed.
[INFO][23:24:34]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:24:35]: [Client #6] Model trained.
[INFO][23:24:35]: [Client #6] Inbound data has been processed.
[INFO][23:24:35]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][23:24:40]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:24:41]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:24:41]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:24:42]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][23:24:42]: [Server #3350301] Selecting client #10 for training.
[INFO][23:24:42]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:24:46]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:24:46]: [Server #3350301] Selecting client #5 for training.
[INFO][23:24:46]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:24:50]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:24:50]: [Client #10] Selected by the server.
[INFO][23:24:50]: [Client #10] Loading its data source...
[INFO][23:24:50]: [Client #10] Dataset size: 2018
[INFO][23:24:50]: [Client #5] Selected by the server.
[INFO][23:24:50]: [Client #10] Sampler: iid
[INFO][23:24:50]: [Client #5] Loading its data source...
[INFO][23:24:50]: [Client #5] Dataset size: 2018
[INFO][23:24:50]: [Client #5] Sampler: iid
[INFO][23:24:51]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:24:51]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:24:51]: [Client #5] Start to process inbound data.
[INFO][23:24:51]: [Client #10] Start to process inbound data.
[INFO][23:24:52]: [93m[1m[Client #10] Started training in communication round #43.[0m
[INFO][23:24:52]: [93m[1m[Client #5] Started training in communication round #43.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:21,  4.28s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.20it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.34it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:25:37]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.2212, 'train_samples_per_second': 154.355, 'train_steps_per_second': 1.224, 'train_loss': 2.6306111017862954, 'epoch': 3.0}
[INFO][23:25:38]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.6049, 'train_samples_per_second': 152.86, 'train_steps_per_second': 1.212, 'train_loss': 2.917184511820475, 'epoch': 3.0}
[INFO][23:25:39]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:25:39]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:25:40]: [Client #5] Model trained.
[INFO][23:25:40]: [Client #5] Inbound data has been processed.
[INFO][23:25:40]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:25:40]: [Client #10] Model trained.
[INFO][23:25:40]: [Client #10] Inbound data has been processed.
[INFO][23:25:40]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:25:46]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:25:46]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:25:47]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:25:48]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:25:48]: [Server #3350301] Selecting client #9 for training.
[INFO][23:25:48]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:25:52]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:25:52]: [Client #9] Selected by the server.
[INFO][23:25:52]: [Client #9] Loading its data source...
[INFO][23:25:52]: [Client #9] Dataset size: 2018
[INFO][23:25:52]: [Client #9] Sampler: iid
[INFO][23:25:53]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:25:53]: [Client #9] Start to process inbound data.
[INFO][23:25:53]: [93m[1m[Client #9] Started training in communication round #43.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.85it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.90it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.94it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.96it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:26:26]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8499, 'train_samples_per_second': 225.475, 'train_steps_per_second': 1.788, 'train_loss': 2.7062209447224936, 'epoch': 3.0}
[INFO][23:26:27]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:26:28]: [Client #9] Model trained.
[INFO][23:26:28]: [Client #9] Inbound data has been processed.
[INFO][23:26:28]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:26:32]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:26:33]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:26:33]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:26:33]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:26:33]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:26:33]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:26:33]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:26:33]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:26:33]: [Server #3350301] Updated weights have been received.
[INFO][23:26:33]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:26:34]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:26:34]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.68it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 12.65it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.63it/s]
[INFO][23:26:45]: [93m[1m[Server #3350301] Global model perplexity: 30.48
[0m
[INFO][23:26:45]: [Server #3350301] All client reports have been processed.
[INFO][23:26:45]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_43.pth.
[INFO][23:26:48]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_43.pth.
[INFO][23:26:48]: [93m[1m
[Server #3350301] Starting round 44/100.[0m
[INFO][23:26:48]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][23:26:48]: [Server #3350301] Selecting client #2 for training.
[INFO][23:26:48]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:26:51]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:26:51]: [Server #3350301] Selecting client #1 for training.
[INFO][23:26:51]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:26:55]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:26:55]: [Client #2] Selected by the server.
[INFO][23:26:55]: [Client #2] Loading its data source...
[INFO][23:26:55]: [Client #2] Dataset size: 2018
[INFO][23:26:55]: [Client #2] Sampler: iid
[INFO][23:26:55]: [Client #1] Selected by the server.
[INFO][23:26:55]: [Client #1] Loading its data source...
[INFO][23:26:55]: [Client #1] Dataset size: 2018
[INFO][23:26:55]: [Client #1] Sampler: iid
[INFO][23:26:56]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:26:56]: [Client #2] Start to process inbound data.
[INFO][23:26:56]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:26:56]: [Client #1] Start to process inbound data.
[INFO][23:26:57]: [93m[1m[Client #1] Started training in communication round #44.[0m
[INFO][23:26:57]: [93m[1m[Client #2] Started training in communication round #44.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:46,  4.81s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  8%|â–Š         | 4/48 [00:06<00:58,  1.32s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.84s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.19s/it]  8%|â–Š         | 4/48 [00:07<01:05,  1.49s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:47,  1.13s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.28s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.13s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.08s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:39,  1.00s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:41,  1.04s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.01s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:34,  1.05it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.04it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:33,  1.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:31,  1.05it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:33,  1.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:30,  1.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:31,  1.04it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.12it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:25,  1.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:23,  1.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:25,  1.20it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:22,  1.24it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:23,  1.24it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:21,  1.27it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:22,  1.24it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:20,  1.28it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:21,  1.26it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:19,  1.29it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:20,  1.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:18,  1.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:19,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:16,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:15,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:13,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:13,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.36it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:30<00:12,  1.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:31<00:10,  1.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:33<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:36<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:39<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:41<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.14it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.68it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.13it/s]
[INFO][23:27:45]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 41.9246, 'train_samples_per_second': 144.402, 'train_steps_per_second': 1.145, 'train_loss': 2.303393840789795, 'epoch': 3.0}
[INFO][23:27:46]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 42.3779, 'train_samples_per_second': 142.857, 'train_steps_per_second': 1.133, 'train_loss': 2.742446263631185, 'epoch': 3.0}
[INFO][23:27:46]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:27:47]: [Client #1] Model trained.
[INFO][23:27:47]: [Client #1] Inbound data has been processed.
[INFO][23:27:47]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:27:47]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:27:48]: [Client #2] Model trained.
[INFO][23:27:48]: [Client #2] Inbound data has been processed.
[INFO][23:27:48]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:27:52]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:27:53]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:27:54]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:27:55]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:27:55]: [Server #3350301] Selecting client #5 for training.
[INFO][23:27:55]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:27:58]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:27:58]: [Server #3350301] Selecting client #7 for training.
[INFO][23:27:58]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:28:02]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:28:02]: [Client #5] Selected by the server.
[INFO][23:28:02]: [Client #5] Loading its data source...
[INFO][23:28:02]: [Client #7] Selected by the server.
[INFO][23:28:02]: [Client #7] Loading its data source...
[INFO][23:28:02]: [Client #5] Dataset size: 2018
[INFO][23:28:02]: [Client #5] Sampler: iid
[INFO][23:28:02]: [Client #7] Dataset size: 2018
[INFO][23:28:02]: [Client #7] Sampler: iid
[INFO][23:28:03]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:28:03]: [Client #5] Start to process inbound data.
[INFO][23:28:03]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:28:03]: [Client #7] Start to process inbound data.
[INFO][23:28:04]: [93m[1m[Client #5] Started training in communication round #44.[0m
[INFO][23:28:04]: [93m[1m[Client #7] Started training in communication round #44.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:11,  4.07s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.08s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.51s/it]  4%|â–         | 2/48 [00:05<01:54,  2.49s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.14s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.04s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:40,  1.00it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.03s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:36,  1.07it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:34,  1.10it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:33,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.12it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:33,  1.10it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:31,  1.12it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:32,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.12it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.12it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:28,  1.13it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:26,  1.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:27,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:26,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:25,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:25,  1.13it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:24,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:23,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:23,  1.13it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:22,  1.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:21,  1.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:20,  1.12it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:19,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:18,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.14it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:18,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:18,  1.13it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:17,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:16,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:30<00:15,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:17,  1.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:31<00:14,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:32<00:13,  1.15it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:13,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:12,  1.06it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:11,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:09,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:09,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:39<00:06,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:40<00:05,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:41<00:04,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:42<00:03,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:43<00:02,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:44<00:01,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:45<00:00,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.09it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.03it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.03it/s]
[INFO][23:28:56]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 46.4659, 'train_samples_per_second': 130.289, 'train_steps_per_second': 1.033, 'train_loss': 2.754763603210449, 'epoch': 3.0}
[INFO][23:28:57]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 46.7868, 'train_samples_per_second': 129.396, 'train_steps_per_second': 1.026, 'train_loss': 2.5960489908854165, 'epoch': 3.0}
[INFO][23:28:57]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:28:58]: [Client #7] Model trained.
[INFO][23:28:58]: [Client #7] Inbound data has been processed.
[INFO][23:28:58]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:28:58]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][23:28:58]: [Client #5] Model trained.
[INFO][23:28:58]: [Client #5] Inbound data has been processed.
[INFO][23:28:58]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:29:04]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:29:05]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:29:05]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:29:06]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:29:06]: [Server #3350301] Selecting client #9 for training.
[INFO][23:29:06]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:29:10]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:29:10]: [Client #9] Selected by the server.
[INFO][23:29:10]: [Client #9] Loading its data source...
[INFO][23:29:10]: [Client #9] Dataset size: 2018
[INFO][23:29:10]: [Client #9] Sampler: iid
[INFO][23:29:11]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:29:11]: [Client #9] Start to process inbound data.
[INFO][23:29:11]: [93m[1m[Client #9] Started training in communication round #44.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:29:44]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8342, 'train_samples_per_second': 225.607, 'train_steps_per_second': 1.789, 'train_loss': 2.6661691665649414, 'epoch': 3.0}
[INFO][23:29:46]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:29:46]: [Client #9] Model trained.
[INFO][23:29:46]: [Client #9] Inbound data has been processed.
[INFO][23:29:46]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:29:50]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:29:51]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:29:51]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:29:51]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:29:51]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:29:51]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:29:51]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:29:51]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:29:51]: [Server #3350301] Updated weights have been received.
[INFO][23:29:52]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:29:52]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:29:52]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][23:30:03]: [93m[1m[Server #3350301] Global model perplexity: 30.16
[0m
[INFO][23:30:03]: [Server #3350301] All client reports have been processed.
[INFO][23:30:03]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_44.pth.
[INFO][23:30:06]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_44.pth.
[INFO][23:30:06]: [93m[1m
[Server #3350301] Starting round 45/100.[0m
[INFO][23:30:06]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][23:30:06]: [Server #3350301] Selecting client #4 for training.
[INFO][23:30:06]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][23:30:09]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][23:30:09]: [Server #3350301] Selecting client #1 for training.
[INFO][23:30:09]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:30:13]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:30:13]: [Client #4] Selected by the server.
[INFO][23:30:13]: [Client #4] Loading its data source...
[INFO][23:30:13]: [Client #4] Dataset size: 2018
[INFO][23:30:13]: [Client #4] Sampler: iid
[INFO][23:30:13]: [Client #1] Selected by the server.
[INFO][23:30:13]: [Client #1] Loading its data source...
[INFO][23:30:13]: [Client #1] Dataset size: 2018
[INFO][23:30:13]: [Client #1] Sampler: iid
[INFO][23:30:14]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:30:14]: [Client #4] Start to process inbound data.
[INFO][23:30:15]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:30:15]: [Client #1] Start to process inbound data.
[INFO][23:30:15]: [93m[1m[Client #1] Started training in communication round #45.[0m
[INFO][23:30:15]: [93m[1m[Client #4] Started training in communication round #45.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:49,  4.87s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<02:01,  2.64s/it]  8%|â–Š         | 4/48 [00:06<01:00,  1.37s/it]  6%|â–‹         | 3/48 [00:07<01:26,  1.93s/it] 10%|â–ˆ         | 5/48 [00:07<00:54,  1.26s/it]  8%|â–Š         | 4/48 [00:08<01:09,  1.59s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:50,  1.20s/it] 10%|â–ˆ         | 5/48 [00:09<00:58,  1.36s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:46,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:50,  1.21s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:43,  1.09s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:45,  1.11s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:39,  1.02s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:42,  1.06s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:38,  1.01s/it] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.00s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:36,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.04it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:34,  1.05it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:33,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:30,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:26,  1.15it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:19<00:29,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:20<00:28,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:27,  1.06it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:23,  1.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:22,  1.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:22,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:20,  1.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:18,  1.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:30<00:18,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:31<00:17,  1.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:17,  1.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:33<00:16,  1.06it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:34<00:14,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.07it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:35<00:14,  1.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.03it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:36<00:13,  1.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:37<00:12,  1.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:38<00:11,  1.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:44<00:04,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:45<00:03,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:46<00:02,  1.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:47<00:01,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.06it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:48<00:00,  1.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.34it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
[INFO][23:31:09]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 48.288, 'train_samples_per_second': 125.373, 'train_steps_per_second': 0.994, 'train_loss': 2.225200335184733, 'epoch': 3.0}
[INFO][23:31:10]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 48.5873, 'train_samples_per_second': 124.601, 'train_steps_per_second': 0.988, 'train_loss': 2.9348875681559243, 'epoch': 3.0}
[INFO][23:31:10]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:31:11]: [Client #1] Model trained.
[INFO][23:31:11]: [Client #1] Inbound data has been processed.
[INFO][23:31:11]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:31:11]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][23:31:12]: [Client #4] Model trained.
[INFO][23:31:12]: [Client #4] Inbound data has been processed.
[INFO][23:31:12]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][23:31:17]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:31:18]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:31:18]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:31:19]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][23:31:19]: [Server #3350301] Selecting client #8 for training.
[INFO][23:31:19]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][23:31:23]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][23:31:23]: [Server #3350301] Selecting client #3 for training.
[INFO][23:31:23]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:31:27]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:31:27]: [Client #8] Selected by the server.
[INFO][23:31:27]: [Client #8] Loading its data source...
[INFO][23:31:27]: [Client #3] Selected by the server.
[INFO][23:31:27]: [Client #3] Loading its data source...
[INFO][23:31:27]: [Client #8] Dataset size: 2018
[INFO][23:31:27]: [Client #8] Sampler: iid
[INFO][23:31:27]: [Client #3] Dataset size: 2018
[INFO][23:31:27]: [Client #3] Sampler: iid
[INFO][23:31:28]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:31:28]: [Client #3] Start to process inbound data.
[INFO][23:31:28]: [93m[1m[Client #3] Started training in communication round #45.[0m
[INFO][23:31:28]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:31:28]: [Client #8] Start to process inbound data.
[INFO][23:31:29]: [93m[1m[Client #8] Started training in communication round #45.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.13s/it]  4%|â–         | 2/48 [00:04<01:31,  2.00s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  6%|â–‹         | 3/48 [00:05<01:03,  1.40s/it]  2%|â–         | 1/48 [00:05<03:58,  5.08s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  4%|â–         | 2/48 [00:06<02:03,  2.69s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.14s/it]  6%|â–‹         | 3/48 [00:07<01:24,  1.89s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.08s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.48s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.02s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.27s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.14s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:37,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.07s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:35,  1.07it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:41,  1.04s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:34,  1.06it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.01s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:33,  1.07it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.02it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:34,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:30,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:34,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:31,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.14it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:29,  1.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:24,  1.20it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:26,  1.22it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:23,  1.23it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:25,  1.22it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:21,  1.28it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:24,  1.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.30it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:23,  1.26it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.31it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:21,  1.29it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:21,  1.28it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:18,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:19,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:19,  1.29it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:16,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:12,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.37it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:13,  1.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.40it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:08,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:05,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:02,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.16it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.48it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.61it/s][INFO][23:32:15]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 41.2945, 'train_samples_per_second': 146.605, 'train_steps_per_second': 1.162, 'train_loss': 2.6626838048299155, 'epoch': 3.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.79it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.15it/s]
[INFO][23:32:16]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][23:32:17]: [Client #3] Model trained.
[INFO][23:32:17]: [Client #3] Inbound data has been processed.
[INFO][23:32:17]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:32:17]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 41.861, 'train_samples_per_second': 144.622, 'train_steps_per_second': 1.147, 'train_loss': 2.994601567586263, 'epoch': 3.0}
[INFO][23:32:18]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][23:32:18]: [Client #8] Model trained.
[INFO][23:32:18]: [Client #8] Inbound data has been processed.
[INFO][23:32:18]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][23:32:21]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:32:22]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:32:23]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:32:24]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][23:32:24]: [Server #3350301] Selecting client #10 for training.
[INFO][23:32:24]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:32:28]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:32:28]: [Client #10] Selected by the server.
[INFO][23:32:28]: [Client #10] Loading its data source...
[INFO][23:32:28]: [Client #10] Dataset size: 2018
[INFO][23:32:28]: [Client #10] Sampler: iid
[INFO][23:32:29]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:32:29]: [Client #10] Start to process inbound data.
[INFO][23:32:29]: [93m[1m[Client #10] Started training in communication round #45.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.21s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.90it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.94it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:33:02]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.8351, 'train_samples_per_second': 225.6, 'train_steps_per_second': 1.789, 'train_loss': 2.875599225362142, 'epoch': 3.0}
[INFO][23:33:04]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:33:04]: [Client #10] Model trained.
[INFO][23:33:04]: [Client #10] Inbound data has been processed.
[INFO][23:33:04]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:33:08]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:33:09]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:33:09]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:33:09]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:33:09]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:33:09]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:33:09]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][23:33:09]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:33:09]: [Server #3350301] Updated weights have been received.
[INFO][23:33:09]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:33:10]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:33:10]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.38it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.67it/s]
[INFO][23:33:21]: [93m[1m[Server #3350301] Global model perplexity: 28.77
[0m
[INFO][23:33:21]: [Server #3350301] All client reports have been processed.
[INFO][23:33:21]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_45.pth.
[INFO][23:33:24]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_45.pth.
[INFO][23:33:24]: [93m[1m
[Server #3350301] Starting round 46/100.[0m
[INFO][23:33:24]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][23:33:24]: [Server #3350301] Selecting client #2 for training.
[INFO][23:33:24]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:33:27]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:33:27]: [Server #3350301] Selecting client #5 for training.
[INFO][23:33:27]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:33:31]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:33:31]: [Client #2] Selected by the server.
[INFO][23:33:31]: [Client #2] Loading its data source...
[INFO][23:33:31]: [Client #2] Dataset size: 2018
[INFO][23:33:31]: [Client #2] Sampler: iid
[INFO][23:33:31]: [Client #5] Selected by the server.
[INFO][23:33:31]: [Client #5] Loading its data source...
[INFO][23:33:31]: [Client #5] Dataset size: 2018
[INFO][23:33:31]: [Client #5] Sampler: iid
[INFO][23:33:32]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:33:32]: [Client #5] Start to process inbound data.
[INFO][23:33:32]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:33:32]: [Client #2] Start to process inbound data.
[INFO][23:33:33]: [93m[1m[Client #2] Started training in communication round #46.[0m
[INFO][23:33:33]: [93m[1m[Client #5] Started training in communication round #46.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.11s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:40,  2.18s/it]  2%|â–         | 1/48 [00:04<03:40,  4.68s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  4%|â–         | 2/48 [00:05<01:48,  2.37s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.05it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.32it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:34:18]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.0997, 'train_samples_per_second': 154.835, 'train_steps_per_second': 1.228, 'train_loss': 2.5689798990885415, 'epoch': 3.0}
[INFO][23:34:19]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.3087, 'train_samples_per_second': 154.012, 'train_steps_per_second': 1.221, 'train_loss': 2.7178754806518555, 'epoch': 3.0}
[INFO][23:34:20]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:34:20]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:34:20]: [Client #5] Model trained.
[INFO][23:34:20]: [Client #5] Inbound data has been processed.
[INFO][23:34:20]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:34:21]: [Client #2] Model trained.
[INFO][23:34:21]: [Client #2] Inbound data has been processed.
[INFO][23:34:21]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:34:27]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:34:27]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:34:28]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:34:29]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:34:29]: [Server #3350301] Selecting client #6 for training.
[INFO][23:34:29]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][23:34:32]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][23:34:32]: [Server #3350301] Selecting client #7 for training.
[INFO][23:34:32]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:34:36]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:34:36]: [Client #6] Selected by the server.
[INFO][23:34:36]: [Client #7] Selected by the server.
[INFO][23:34:36]: [Client #6] Loading its data source...
[INFO][23:34:36]: [Client #7] Loading its data source...
[INFO][23:34:36]: [Client #7] Dataset size: 2018
[INFO][23:34:36]: [Client #6] Dataset size: 2018
[INFO][23:34:36]: [Client #7] Sampler: iid
[INFO][23:34:36]: [Client #6] Sampler: iid
[INFO][23:34:37]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:34:37]: [Client #7] Start to process inbound data.
[INFO][23:34:37]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:34:37]: [Client #6] Start to process inbound data.
[INFO][23:34:38]: [93m[1m[Client #7] Started training in communication round #46.[0m
[INFO][23:34:38]: [93m[1m[Client #6] Started training in communication round #46.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:36,  4.60s/it]  2%|â–         | 1/48 [00:04<03:36,  4.61s/it]  4%|â–         | 2/48 [00:05<01:46,  2.30s/it]  4%|â–         | 2/48 [00:05<01:48,  2.37s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.58s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:35:24]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.5688, 'train_samples_per_second': 152.999, 'train_steps_per_second': 1.213, 'train_loss': 2.7157777150472007, 'epoch': 3.0}
[INFO][23:35:24]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.492, 'train_samples_per_second': 153.297, 'train_steps_per_second': 1.215, 'train_loss': 3.014372189839681, 'epoch': 3.0}
[INFO][23:35:25]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][23:35:25]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:35:26]: [Client #6] Model trained.
[INFO][23:35:26]: [Client #6] Inbound data has been processed.
[INFO][23:35:26]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][23:35:26]: [Client #7] Model trained.
[INFO][23:35:26]: [Client #7] Inbound data has been processed.
[INFO][23:35:26]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:35:33]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:35:33]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:35:34]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][23:35:35]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:35:35]: [Server #3350301] Selecting client #9 for training.
[INFO][23:35:35]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:35:39]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:35:39]: [Client #9] Selected by the server.
[INFO][23:35:39]: [Client #9] Loading its data source...
[INFO][23:35:39]: [Client #9] Dataset size: 2018
[INFO][23:35:39]: [Client #9] Sampler: iid
[INFO][23:35:40]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:35:40]: [Client #9] Start to process inbound data.
[INFO][23:35:41]: [93m[1m[Client #9] Started training in communication round #46.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][23:36:13]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.6816, 'train_samples_per_second': 226.898, 'train_steps_per_second': 1.799, 'train_loss': 2.634312629699707, 'epoch': 3.0}
[INFO][23:36:14]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:36:14]: [Client #9] Model trained.
[INFO][23:36:14]: [Client #9] Inbound data has been processed.
[INFO][23:36:14]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:36:18]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:36:20]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:36:20]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:36:20]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:36:20]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:36:20]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:36:20]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:36:20]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:36:20]: [Server #3350301] Updated weights have been received.
[INFO][23:36:20]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:36:21]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:36:21]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.22it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.39it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.67it/s]
[INFO][23:36:32]: [93m[1m[Server #3350301] Global model perplexity: 32.46
[0m
[INFO][23:36:32]: [Server #3350301] All client reports have been processed.
[INFO][23:36:32]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_46.pth.
[INFO][23:36:34]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_46.pth.
[INFO][23:36:34]: [93m[1m
[Server #3350301] Starting round 47/100.[0m
[INFO][23:36:34]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][23:36:34]: [Server #3350301] Selecting client #10 for training.
[INFO][23:36:34]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:36:38]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:36:38]: [Server #3350301] Selecting client #1 for training.
[INFO][23:36:38]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:36:42]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:36:42]: [Client #10] Selected by the server.
[INFO][23:36:42]: [Client #10] Loading its data source...
[INFO][23:36:42]: [Client #10] Dataset size: 2018
[INFO][23:36:42]: [Client #10] Sampler: iid
[INFO][23:36:42]: [Client #1] Selected by the server.
[INFO][23:36:42]: [Client #1] Loading its data source...
[INFO][23:36:42]: [Client #1] Dataset size: 2018
[INFO][23:36:42]: [Client #1] Sampler: iid
[INFO][23:36:43]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:36:43]: [Client #10] Start to process inbound data.
[INFO][23:36:43]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:36:43]: [Client #1] Start to process inbound data.
[INFO][23:36:44]: [93m[1m[Client #10] Started training in communication round #47.[0m
[INFO][23:36:44]: [93m[1m[Client #1] Started training in communication round #47.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:30,  4.48s/it]  2%|â–         | 1/48 [00:04<03:54,  4.98s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  4%|â–         | 2/48 [00:05<01:58,  2.57s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.78s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.43s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.45s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 10%|â–ˆ         | 5/48 [00:08<00:55,  1.29s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.15s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.00s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.00s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.03it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.06it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:25,  1.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:25,  1.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:23,  1.22it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:23,  1.19it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:22,  1.26it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:21,  1.23it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:20,  1.29it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:20,  1.27it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:19,  1.29it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.30it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:41<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:41<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.13it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.13it/s]
[INFO][23:37:33]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 42.6051, 'train_samples_per_second': 142.096, 'train_steps_per_second': 1.127, 'train_loss': 2.155179977416992, 'epoch': 3.0}
[INFO][23:37:33]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 42.5865, 'train_samples_per_second': 142.158, 'train_steps_per_second': 1.127, 'train_loss': 2.8535916010538735, 'epoch': 3.0}
[INFO][23:37:34]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:37:34]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:37:34]: [Client #1] Model trained.
[INFO][23:37:34]: [Client #1] Inbound data has been processed.
[INFO][23:37:34]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:37:35]: [Client #10] Model trained.
[INFO][23:37:35]: [Client #10] Inbound data has been processed.
[INFO][23:37:35]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:37:40]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:37:41]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:37:41]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:37:42]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:37:42]: [Server #3350301] Selecting client #3 for training.
[INFO][23:37:42]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:37:46]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:37:46]: [Server #3350301] Selecting client #5 for training.
[INFO][23:37:46]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:37:49]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:37:49]: [Client #3] Selected by the server.
[INFO][23:37:49]: [Client #3] Loading its data source...
[INFO][23:37:49]: [Client #3] Dataset size: 2018
[INFO][23:37:49]: [Client #3] Sampler: iid
[INFO][23:37:49]: [Client #5] Selected by the server.
[INFO][23:37:49]: [Client #5] Loading its data source...
[INFO][23:37:49]: [Client #5] Dataset size: 2018
[INFO][23:37:49]: [Client #5] Sampler: iid
[INFO][23:37:51]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:37:51]: [Client #3] Start to process inbound data.
[INFO][23:37:51]: [93m[1m[Client #3] Started training in communication round #47.[0m
[INFO][23:37:51]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:37:51]: [Client #5] Start to process inbound data.
[INFO][23:37:52]: [93m[1m[Client #5] Started training in communication round #47.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:23,  4.33s/it]  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
[INFO][23:38:37]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 38.8793, 'train_samples_per_second': 155.713, 'train_steps_per_second': 1.235, 'train_loss': 2.5284366607666016, 'epoch': 3.0}
[INFO][23:38:37]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.2352, 'train_samples_per_second': 154.3, 'train_steps_per_second': 1.223, 'train_loss': 2.629884719848633, 'epoch': 3.0}
[INFO][23:38:38]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:38:38]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][23:38:39]: [Client #5] Model trained.
[INFO][23:38:39]: [Client #5] Inbound data has been processed.
[INFO][23:38:39]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:38:39]: [Client #3] Model trained.
[INFO][23:38:39]: [Client #3] Inbound data has been processed.
[INFO][23:38:39]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:38:45]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:38:45]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:38:46]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:38:47]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:38:47]: [Server #3350301] Selecting client #9 for training.
[INFO][23:38:47]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:38:51]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:38:51]: [Client #9] Selected by the server.
[INFO][23:38:51]: [Client #9] Loading its data source...
[INFO][23:38:51]: [Client #9] Dataset size: 2018
[INFO][23:38:51]: [Client #9] Sampler: iid
[INFO][23:38:52]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:38:52]: [Client #9] Start to process inbound data.
[INFO][23:38:52]: [93m[1m[Client #9] Started training in communication round #47.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.94it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  1.77it/s]
[INFO][23:39:25]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 27.0951, 'train_samples_per_second': 223.435, 'train_steps_per_second': 1.772, 'train_loss': 2.6010208129882812, 'epoch': 3.0}
[INFO][23:39:26]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:39:27]: [Client #9] Model trained.
[INFO][23:39:27]: [Client #9] Inbound data has been processed.
[INFO][23:39:27]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:39:31]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:39:32]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:39:32]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:39:32]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:39:32]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:39:32]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:39:32]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:39:32]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:39:32]: [Server #3350301] Updated weights have been received.
[INFO][23:39:32]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:39:33]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:39:33]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.88it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 12.74it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.93it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.64it/s]
[INFO][23:39:44]: [93m[1m[Server #3350301] Global model perplexity: 31.95
[0m
[INFO][23:39:44]: [Server #3350301] All client reports have been processed.
[INFO][23:39:44]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_47.pth.
[INFO][23:39:47]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_47.pth.
[INFO][23:39:47]: [93m[1m
[Server #3350301] Starting round 48/100.[0m
[INFO][23:39:47]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][23:39:47]: [Server #3350301] Selecting client #2 for training.
[INFO][23:39:47]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:39:50]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:39:50]: [Server #3350301] Selecting client #1 for training.
[INFO][23:39:50]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:39:54]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:39:54]: [Client #2] Selected by the server.
[INFO][23:39:54]: [Client #2] Loading its data source...
[INFO][23:39:54]: [Client #2] Dataset size: 2018
[INFO][23:39:54]: [Client #2] Sampler: iid
[INFO][23:39:54]: [Client #1] Selected by the server.
[INFO][23:39:54]: [Client #1] Loading its data source...
[INFO][23:39:54]: [Client #1] Dataset size: 2018
[INFO][23:39:54]: [Client #1] Sampler: iid
[INFO][23:39:55]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:39:55]: [Client #2] Start to process inbound data.
[INFO][23:39:55]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:39:55]: [Client #1] Start to process inbound data.
[INFO][23:39:56]: [93m[1m[Client #2] Started training in communication round #48.[0m
[INFO][23:39:56]: [93m[1m[Client #1] Started training in communication round #48.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.03s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  2%|â–         | 1/48 [00:04<03:32,  4.53s/it]  6%|â–‹         | 3/48 [00:05<01:04,  1.44s/it]  4%|â–         | 2/48 [00:05<01:46,  2.31s/it]  8%|â–Š         | 4/48 [00:06<00:51,  1.16s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.60s/it] 10%|â–ˆ         | 5/48 [00:06<00:43,  1.01s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.08it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.16it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.22it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:31,  1.25it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.31it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:14<00:22,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:17<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:20<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:16,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:23<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:02,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][23:40:41]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 38.7994, 'train_samples_per_second': 156.033, 'train_steps_per_second': 1.237, 'train_loss': 2.0966151555379233, 'epoch': 3.0}
[INFO][23:40:42]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.1137, 'train_samples_per_second': 154.78, 'train_steps_per_second': 1.227, 'train_loss': 2.664661725362142, 'epoch': 3.0}
[INFO][23:40:42]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:40:43]: [Client #1] Model trained.
[INFO][23:40:43]: [Client #1] Inbound data has been processed.
[INFO][23:40:43]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:40:43]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:40:43]: [Client #2] Model trained.
[INFO][23:40:43]: [Client #2] Inbound data has been processed.
[INFO][23:40:43]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:40:48]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:40:49]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:40:50]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:40:50]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:40:50]: [Server #3350301] Selecting client #4 for training.
[INFO][23:40:50]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][23:40:54]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][23:40:54]: [Server #3350301] Selecting client #7 for training.
[INFO][23:40:54]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:40:58]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:40:58]: [Client #4] Selected by the server.
[INFO][23:40:58]: [Client #4] Loading its data source...
[INFO][23:40:58]: [Client #7] Selected by the server.
[INFO][23:40:58]: [Client #4] Dataset size: 2018
[INFO][23:40:58]: [Client #4] Sampler: iid
[INFO][23:40:58]: [Client #7] Loading its data source...
[INFO][23:40:58]: [Client #7] Dataset size: 2018
[INFO][23:40:58]: [Client #7] Sampler: iid
[INFO][23:40:59]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:40:59]: [Client #7] Start to process inbound data.
[INFO][23:40:59]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:40:59]: [Client #4] Start to process inbound data.
[INFO][23:40:59]: [93m[1m[Client #7] Started training in communication round #48.[0m
[INFO][23:40:59]: [93m[1m[Client #4] Started training in communication round #48.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:29,  4.45s/it]  2%|â–         | 1/48 [00:04<03:39,  4.68s/it]  4%|â–         | 2/48 [00:05<01:46,  2.31s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:41:45]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.4542, 'train_samples_per_second': 153.444, 'train_steps_per_second': 1.217, 'train_loss': 2.9056224822998047, 'epoch': 3.0}
[INFO][23:41:45]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.387, 'train_samples_per_second': 153.706, 'train_steps_per_second': 1.219, 'train_loss': 2.681891759236654, 'epoch': 3.0}
[INFO][23:41:46]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][23:41:46]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:41:47]: [Client #4] Model trained.
[INFO][23:41:47]: [Client #4] Inbound data has been processed.
[INFO][23:41:47]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][23:41:47]: [Client #7] Model trained.
[INFO][23:41:47]: [Client #7] Inbound data has been processed.
[INFO][23:41:47]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:41:54]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:41:54]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:41:55]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][23:41:56]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:41:56]: [Server #3350301] Selecting client #8 for training.
[INFO][23:41:56]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][23:41:59]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][23:42:00]: [Client #8] Selected by the server.
[INFO][23:42:00]: [Client #8] Loading its data source...
[INFO][23:42:00]: [Client #8] Dataset size: 2018
[INFO][23:42:00]: [Client #8] Sampler: iid
[INFO][23:42:01]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:42:01]: [Client #8] Start to process inbound data.
[INFO][23:42:01]: [93m[1m[Client #8] Started training in communication round #48.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:42:34]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.7515, 'train_samples_per_second': 226.305, 'train_steps_per_second': 1.794, 'train_loss': 2.963571548461914, 'epoch': 3.0}
[INFO][23:42:35]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][23:42:35]: [Client #8] Model trained.
[INFO][23:42:35]: [Client #8] Inbound data has been processed.
[INFO][23:42:35]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][23:42:39]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:42:41]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][23:42:41]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:42:41]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:42:41]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:42:41]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:42:41]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][23:42:41]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:42:41]: [Server #3350301] Updated weights have been received.
[INFO][23:42:41]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:42:42]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:42:42]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.57it/s]
[INFO][23:42:52]: [93m[1m[Server #3350301] Global model perplexity: 30.31
[0m
[INFO][23:42:52]: [Server #3350301] All client reports have been processed.
[INFO][23:42:53]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_48.pth.
[INFO][23:42:55]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_48.pth.
[INFO][23:42:55]: [93m[1m
[Server #3350301] Starting round 49/100.[0m
[INFO][23:42:55]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][23:42:55]: [Server #3350301] Selecting client #6 for training.
[INFO][23:42:55]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][23:42:59]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][23:42:59]: [Server #3350301] Selecting client #3 for training.
[INFO][23:42:59]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:43:03]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:43:03]: [Client #6] Selected by the server.
[INFO][23:43:03]: [Client #6] Loading its data source...
[INFO][23:43:03]: [Client #6] Dataset size: 2018
[INFO][23:43:03]: [Client #6] Sampler: iid
[INFO][23:43:03]: [Client #3] Selected by the server.
[INFO][23:43:03]: [Client #3] Loading its data source...
[INFO][23:43:03]: [Client #3] Dataset size: 2018
[INFO][23:43:03]: [Client #3] Sampler: iid
[INFO][23:43:04]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:43:04]: [Client #6] Start to process inbound data.
[INFO][23:43:04]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:43:04]: [Client #3] Start to process inbound data.
[INFO][23:43:05]: [93m[1m[Client #3] Started training in communication round #49.[0m
[INFO][23:43:05]: [93m[1m[Client #6] Started training in communication round #49.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:25,  4.37s/it]  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.79s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.79s/it]  8%|â–Š         | 4/48 [00:07<01:06,  1.51s/it]  8%|â–Š         | 4/48 [00:07<01:06,  1.51s/it] 10%|â–ˆ         | 5/48 [00:08<00:56,  1.32s/it] 10%|â–ˆ         | 5/48 [00:08<00:57,  1.33s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:49,  1.18s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:49,  1.19s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.09s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:46,  1.13s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:41,  1.05s/it] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.11it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:29,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.13it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:26,  1.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:26,  1.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:25,  1.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:25,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:23,  1.13it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:22,  1.14it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.12it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.13it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:15,  1.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.02it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.06it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.03it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.10it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
[INFO][23:43:59]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 47.985, 'train_samples_per_second': 126.164, 'train_steps_per_second': 1.0, 'train_loss': 2.609832286834717, 'epoch': 3.0}
[INFO][23:44:00]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 47.841, 'train_samples_per_second': 126.544, 'train_steps_per_second': 1.003, 'train_loss': 2.9791367848714194, 'epoch': 3.0}
[INFO][23:44:01]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][23:44:01]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][23:44:01]: [Client #6] Model trained.
[INFO][23:44:01]: [Client #6] Inbound data has been processed.
[INFO][23:44:01]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][23:44:01]: [Client #3] Model trained.
[INFO][23:44:01]: [Client #3] Inbound data has been processed.
[INFO][23:44:01]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:44:08]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:44:08]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:44:09]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][23:44:10]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:44:10]: [Server #3350301] Selecting client #10 for training.
[INFO][23:44:10]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:44:13]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:44:13]: [Server #3350301] Selecting client #5 for training.
[INFO][23:44:13]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:44:17]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:44:17]: [Client #10] Selected by the server.
[INFO][23:44:17]: [Client #10] Loading its data source...
[INFO][23:44:17]: [Client #10] Dataset size: 2018
[INFO][23:44:17]: [Client #5] Selected by the server.
[INFO][23:44:17]: [Client #10] Sampler: iid
[INFO][23:44:17]: [Client #5] Loading its data source...
[INFO][23:44:17]: [Client #5] Dataset size: 2018
[INFO][23:44:17]: [Client #5] Sampler: iid
[INFO][23:44:18]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:44:18]: [Client #5] Start to process inbound data.
[INFO][23:44:18]: [93m[1m[Client #5] Started training in communication round #49.[0m
[INFO][23:44:18]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:44:18]: [Client #10] Start to process inbound data.
[INFO][23:44:19]: [93m[1m[Client #10] Started training in communication round #49.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.42s/it]  4%|â–         | 2/48 [00:04<01:37,  2.12s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  6%|â–‹         | 3/48 [00:05<01:05,  1.46s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s]  8%|â–Š         | 4/48 [00:07<00:58,  1.33s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.30it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.36it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.71it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:45:04]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.2915, 'train_samples_per_second': 154.079, 'train_steps_per_second': 1.222, 'train_loss': 2.4949817657470703, 'epoch': 3.0}
[INFO][23:45:05]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.4626, 'train_samples_per_second': 153.411, 'train_steps_per_second': 1.216, 'train_loss': 2.8206822077433267, 'epoch': 3.0}
[INFO][23:45:05]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:45:06]: [Client #5] Model trained.
[INFO][23:45:06]: [Client #5] Inbound data has been processed.
[INFO][23:45:06]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:45:06]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:45:07]: [Client #10] Model trained.
[INFO][23:45:07]: [Client #10] Inbound data has been processed.
[INFO][23:45:07]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:45:11]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:45:12]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:45:13]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:45:14]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:45:14]: [Server #3350301] Selecting client #9 for training.
[INFO][23:45:14]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:45:17]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:45:17]: [Client #9] Selected by the server.
[INFO][23:45:17]: [Client #9] Loading its data source...
[INFO][23:45:17]: [Client #9] Dataset size: 2018
[INFO][23:45:17]: [Client #9] Sampler: iid
[INFO][23:45:19]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:45:19]: [Client #9] Start to process inbound data.
[INFO][23:45:19]: [93m[1m[Client #9] Started training in communication round #49.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.15s/it]  4%|â–         | 2/48 [00:04<01:31,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.30s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.90it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.94it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.96it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:45:52]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7888, 'train_samples_per_second': 225.99, 'train_steps_per_second': 1.792, 'train_loss': 2.574223518371582, 'epoch': 3.0}
[INFO][23:45:53]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:45:53]: [Client #9] Model trained.
[INFO][23:45:53]: [Client #9] Inbound data has been processed.
[INFO][23:45:53]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:45:58]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:45:59]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:45:59]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:45:59]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:45:59]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:45:59]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:45:59]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:45:59]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:45:59]: [Server #3350301] Updated weights have been received.
[INFO][23:45:59]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:46:00]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:46:00]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.79it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.74it/s]
[INFO][23:46:11]: [93m[1m[Server #3350301] Global model perplexity: 36.33
[0m
[INFO][23:46:11]: [Server #3350301] All client reports have been processed.
[INFO][23:46:11]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_49.pth.
[INFO][23:46:13]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_49.pth.
[INFO][23:46:13]: [93m[1m
[Server #3350301] Starting round 50/100.[0m
[INFO][23:46:13]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][23:46:13]: [Server #3350301] Selecting client #2 for training.
[INFO][23:46:13]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:46:17]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:46:17]: [Server #3350301] Selecting client #1 for training.
[INFO][23:46:17]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:46:21]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:46:21]: [Client #2] Selected by the server.
[INFO][23:46:21]: [Client #2] Loading its data source...
[INFO][23:46:21]: [Client #2] Dataset size: 2018
[INFO][23:46:21]: [Client #2] Sampler: iid
[INFO][23:46:21]: [Client #1] Selected by the server.
[INFO][23:46:21]: [Client #1] Loading its data source...
[INFO][23:46:21]: [Client #1] Dataset size: 2018
[INFO][23:46:21]: [Client #1] Sampler: iid
[INFO][23:46:22]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:46:22]: [Client #1] Start to process inbound data.
[INFO][23:46:22]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:46:22]: [Client #2] Start to process inbound data.
[INFO][23:46:23]: [93m[1m[Client #1] Started training in communication round #50.[0m
[INFO][23:46:23]: [93m[1m[Client #2] Started training in communication round #50.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:28,  4.43s/it]  2%|â–         | 1/48 [00:04<03:13,  4.11s/it]  4%|â–         | 2/48 [00:05<01:44,  2.27s/it]  4%|â–         | 2/48 [00:04<01:37,  2.13s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.58s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.49s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.16it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
[INFO][23:47:08]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2015, 'train_samples_per_second': 154.433, 'train_steps_per_second': 1.224, 'train_loss': 2.073273181915283, 'epoch': 3.0}
[INFO][23:47:08]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 38.8348, 'train_samples_per_second': 155.891, 'train_steps_per_second': 1.236, 'train_loss': 2.651996612548828, 'epoch': 3.0}
[INFO][23:47:09]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:47:10]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:47:10]: [Client #2] Model trained.
[INFO][23:47:10]: [Client #2] Inbound data has been processed.
[INFO][23:47:10]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:47:11]: [Client #1] Model trained.
[INFO][23:47:11]: [Client #1] Inbound data has been processed.
[INFO][23:47:11]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:47:16]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:47:17]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:47:17]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:47:18]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:47:18]: [Server #3350301] Selecting client #5 for training.
[INFO][23:47:18]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:47:22]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:47:22]: [Server #3350301] Selecting client #7 for training.
[INFO][23:47:22]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:47:26]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:47:26]: [Client #5] Selected by the server.
[INFO][23:47:26]: [Client #5] Loading its data source...
[INFO][23:47:26]: [Client #5] Dataset size: 2018
[INFO][23:47:26]: [Client #5] Sampler: iid
[INFO][23:47:26]: [Client #7] Selected by the server.
[INFO][23:47:26]: [Client #7] Loading its data source...
[INFO][23:47:26]: [Client #7] Dataset size: 2018
[INFO][23:47:26]: [Client #7] Sampler: iid
[INFO][23:47:27]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:47:27]: [Client #7] Start to process inbound data.
[INFO][23:47:27]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:47:27]: [Client #5] Start to process inbound data.
[INFO][23:47:28]: [93m[1m[Client #7] Started training in communication round #50.[0m
[INFO][23:47:28]: [93m[1m[Client #5] Started training in communication round #50.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.17s/it]  2%|â–         | 1/48 [00:04<03:42,  4.73s/it]  4%|â–         | 2/48 [00:04<01:38,  2.13s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.49s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.08it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:48:13]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.0061, 'train_samples_per_second': 155.206, 'train_steps_per_second': 1.231, 'train_loss': 2.647510210673014, 'epoch': 3.0}
[INFO][23:48:13]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.4143, 'train_samples_per_second': 153.599, 'train_steps_per_second': 1.218, 'train_loss': 2.4487603505452475, 'epoch': 3.0}
[INFO][23:48:14]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:48:14]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][23:48:15]: [Client #7] Model trained.
[INFO][23:48:15]: [Client #7] Inbound data has been processed.
[INFO][23:48:15]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:48:15]: [Client #5] Model trained.
[INFO][23:48:15]: [Client #5] Inbound data has been processed.
[INFO][23:48:15]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:48:21]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:48:22]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:48:22]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:48:23]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:48:23]: [Server #3350301] Selecting client #9 for training.
[INFO][23:48:23]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:48:27]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:48:27]: [Client #9] Selected by the server.
[INFO][23:48:27]: [Client #9] Loading its data source...
[INFO][23:48:27]: [Client #9] Dataset size: 2018
[INFO][23:48:27]: [Client #9] Sampler: iid
[INFO][23:48:29]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:48:29]: [Client #9] Start to process inbound data.
[INFO][23:48:29]: [93m[1m[Client #9] Started training in communication round #50.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][23:49:02]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.6716, 'train_samples_per_second': 226.983, 'train_steps_per_second': 1.8, 'train_loss': 2.531552791595459, 'epoch': 3.0}
[INFO][23:49:03]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:49:03]: [Client #9] Model trained.
[INFO][23:49:03]: [Client #9] Inbound data has been processed.
[INFO][23:49:03]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:49:07]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:49:08]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:49:08]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:49:08]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:49:08]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:49:08]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:49:08]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:49:08]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:49:08]: [Server #3350301] Updated weights have been received.
[INFO][23:49:09]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:49:09]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:49:09]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.70it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.71it/s]
[INFO][23:49:20]: [93m[1m[Server #3350301] Global model perplexity: 33.26
[0m
[INFO][23:49:20]: [Server #3350301] All client reports have been processed.
[INFO][23:49:20]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_50.pth.
[INFO][23:49:23]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_50.pth.
[INFO][23:49:23]: [93m[1m
[Server #3350301] Starting round 51/100.[0m
[INFO][23:49:23]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][23:49:23]: [Server #3350301] Selecting client #4 for training.
[INFO][23:49:23]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][23:49:27]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][23:49:27]: [Server #3350301] Selecting client #1 for training.
[INFO][23:49:27]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:49:31]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:49:31]: [Client #4] Selected by the server.
[INFO][23:49:31]: [Client #4] Loading its data source...
[INFO][23:49:31]: [Client #4] Dataset size: 2018
[INFO][23:49:31]: [Client #4] Sampler: iid
[INFO][23:49:31]: [Client #1] Selected by the server.
[INFO][23:49:31]: [Client #1] Loading its data source...
[INFO][23:49:31]: [Client #1] Dataset size: 2018
[INFO][23:49:31]: [Client #1] Sampler: iid
[INFO][23:49:32]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:49:32]: [Client #1] Start to process inbound data.
[INFO][23:49:32]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:49:32]: [Client #4] Start to process inbound data.
[INFO][23:49:33]: [93m[1m[Client #4] Started training in communication round #51.[0m
[INFO][23:49:33]: [93m[1m[Client #1] Started training in communication round #51.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  2%|â–         | 1/48 [00:04<03:37,  4.63s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.60s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:50:19]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2761, 'train_samples_per_second': 154.14, 'train_steps_per_second': 1.222, 'train_loss': 2.072887102762858, 'epoch': 3.0}
[INFO][23:50:19]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.3257, 'train_samples_per_second': 153.945, 'train_steps_per_second': 1.221, 'train_loss': 2.8752307891845703, 'epoch': 3.0}
[INFO][23:50:20]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:50:20]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][23:50:20]: [Client #1] Model trained.
[INFO][23:50:20]: [Client #1] Inbound data has been processed.
[INFO][23:50:20]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:50:21]: [Client #4] Model trained.
[INFO][23:50:21]: [Client #4] Inbound data has been processed.
[INFO][23:50:21]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][23:50:26]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:50:27]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:50:27]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:50:28]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][23:50:28]: [Server #3350301] Selecting client #8 for training.
[INFO][23:50:28]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][23:50:32]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][23:50:32]: [Server #3350301] Selecting client #3 for training.
[INFO][23:50:32]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:50:35]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:50:35]: [Client #8] Selected by the server.
[INFO][23:50:35]: [Client #8] Loading its data source...
[INFO][23:50:35]: [Client #8] Dataset size: 2018
[INFO][23:50:35]: [Client #8] Sampler: iid
[INFO][23:50:35]: [Client #3] Selected by the server.
[INFO][23:50:35]: [Client #3] Loading its data source...
[INFO][23:50:35]: [Client #3] Dataset size: 2018
[INFO][23:50:35]: [Client #3] Sampler: iid
[INFO][23:50:37]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:50:37]: [Client #3] Start to process inbound data.
[INFO][23:50:37]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:50:37]: [Client #8] Start to process inbound data.
[INFO][23:50:37]: [93m[1m[Client #3] Started training in communication round #51.[0m
[INFO][23:50:38]: [93m[1m[Client #8] Started training in communication round #51.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:11,  4.08s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.08s/it]  2%|â–         | 1/48 [00:04<03:50,  4.91s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<02:02,  2.66s/it]  8%|â–Š         | 4/48 [00:06<01:00,  1.37s/it]  6%|â–‹         | 3/48 [00:06<01:25,  1.90s/it] 10%|â–ˆ         | 5/48 [00:07<00:53,  1.24s/it]  8%|â–Š         | 4/48 [00:07<01:06,  1.52s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:48,  1.14s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.28s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.05s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.13s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.00it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.06s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:38,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:37,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.12it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:33,  1.00s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:30,  1.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:30,  1.00s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:28,  1.00it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:25,  1.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:23,  1.19it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:22,  1.16it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:21,  1.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:20,  1.21it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:20,  1.27it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:19,  1.23it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:19,  1.28it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:18,  1.27it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:18,  1.30it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:16,  1.29it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:17,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:16,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:16,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:13,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:30<00:12,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:29<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:30<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:31<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:33<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:33<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:34<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:35<00:08,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:36<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:36<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:37<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:38<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:39<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:39<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:40<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:41<00:01,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:41<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:42<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:41<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.12it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:42<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.55it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:42<00:00,  1.12it/s]
[INFO][23:51:26]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 42.7624, 'train_samples_per_second': 141.573, 'train_steps_per_second': 1.122, 'train_loss': 2.574531078338623, 'epoch': 3.0}
[INFO][23:51:27]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 42.9449, 'train_samples_per_second': 140.971, 'train_steps_per_second': 1.118, 'train_loss': 2.9320494333902993, 'epoch': 3.0}
[INFO][23:51:27]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][23:51:28]: [Client #3] Model trained.
[INFO][23:51:28]: [Client #3] Inbound data has been processed.
[INFO][23:51:28]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:51:28]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][23:51:28]: [Client #8] Model trained.
[INFO][23:51:28]: [Client #8] Inbound data has been processed.
[INFO][23:51:28]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][23:51:35]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:51:35]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:51:36]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][23:51:37]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:51:37]: [Server #3350301] Selecting client #10 for training.
[INFO][23:51:37]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:51:41]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:51:41]: [Client #10] Selected by the server.
[INFO][23:51:41]: [Client #10] Loading its data source...
[INFO][23:51:41]: [Client #10] Dataset size: 2018
[INFO][23:51:41]: [Client #10] Sampler: iid
[INFO][23:51:42]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:51:42]: [Client #10] Start to process inbound data.
[INFO][23:51:42]: [93m[1m[Client #10] Started training in communication round #51.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][23:52:15]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.8549, 'train_samples_per_second': 225.434, 'train_steps_per_second': 1.787, 'train_loss': 2.783898671468099, 'epoch': 3.0}
[INFO][23:52:16]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:52:16]: [Client #10] Model trained.
[INFO][23:52:16]: [Client #10] Inbound data has been processed.
[INFO][23:52:16]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:52:20]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:52:21]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:52:21]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:52:21]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:52:21]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:52:21]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:52:21]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][23:52:21]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:52:21]: [Server #3350301] Updated weights have been received.
[INFO][23:52:21]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:52:22]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:52:22]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.81it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][23:52:33]: [93m[1m[Server #3350301] Global model perplexity: 33.59
[0m
[INFO][23:52:33]: [Server #3350301] All client reports have been processed.
[INFO][23:52:33]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_51.pth.
[INFO][23:52:33]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_51.pth.
[INFO][23:52:33]: [93m[1m
[Server #3350301] Starting round 52/100.[0m
[INFO][23:52:33]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][23:52:33]: [Server #3350301] Selecting client #2 for training.
[INFO][23:52:33]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:52:37]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:52:37]: [Server #3350301] Selecting client #5 for training.
[INFO][23:52:37]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:52:41]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:52:41]: [Client #2] Selected by the server.
[INFO][23:52:41]: [Client #2] Loading its data source...
[INFO][23:52:41]: [Client #2] Dataset size: 2018
[INFO][23:52:41]: [Client #2] Sampler: iid
[INFO][23:52:41]: [Client #5] Selected by the server.
[INFO][23:52:41]: [Client #5] Loading its data source...
[INFO][23:52:41]: [Client #5] Dataset size: 2018
[INFO][23:52:41]: [Client #5] Sampler: iid
[INFO][23:52:42]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:52:42]: [Client #2] Start to process inbound data.
[INFO][23:52:42]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:52:42]: [Client #5] Start to process inbound data.
[INFO][23:52:43]: [93m[1m[Client #5] Started training in communication round #52.[0m
[INFO][23:52:43]: [93m[1m[Client #2] Started training in communication round #52.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  4%|â–         | 2/48 [00:05<01:52,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.28it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:53:29]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.233, 'train_samples_per_second': 154.309, 'train_steps_per_second': 1.223, 'train_loss': 2.40645170211792, 'epoch': 3.0}
[INFO][23:53:29]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.5855, 'train_samples_per_second': 152.935, 'train_steps_per_second': 1.213, 'train_loss': 2.638584613800049, 'epoch': 3.0}
[INFO][23:53:30]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:53:30]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:53:30]: [Client #5] Model trained.
[INFO][23:53:30]: [Client #5] Inbound data has been processed.
[INFO][23:53:30]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:53:31]: [Client #2] Model trained.
[INFO][23:53:31]: [Client #2] Inbound data has been processed.
[INFO][23:53:31]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:53:37]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:53:37]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:53:38]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:53:39]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:53:39]: [Server #3350301] Selecting client #6 for training.
[INFO][23:53:39]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][23:53:43]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][23:53:43]: [Server #3350301] Selecting client #7 for training.
[INFO][23:53:43]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][23:53:46]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][23:53:46]: [Client #6] Selected by the server.
[INFO][23:53:46]: [Client #6] Loading its data source...
[INFO][23:53:46]: [Client #7] Selected by the server.
[INFO][23:53:46]: [Client #7] Loading its data source...
[INFO][23:53:46]: [Client #6] Dataset size: 2018
[INFO][23:53:46]: [Client #6] Sampler: iid
[INFO][23:53:46]: [Client #7] Dataset size: 2018
[INFO][23:53:46]: [Client #7] Sampler: iid
[INFO][23:53:48]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:53:48]: [Client #6] Start to process inbound data.
[INFO][23:53:48]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:53:48]: [Client #7] Start to process inbound data.
[INFO][23:53:49]: [93m[1m[Client #7] Started training in communication round #52.[0m
[INFO][23:53:49]: [93m[1m[Client #6] Started training in communication round #52.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:54:34]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.0416, 'train_samples_per_second': 155.065, 'train_steps_per_second': 1.229, 'train_loss': 2.94963010152181, 'epoch': 3.0}
[INFO][23:54:34]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.4141, 'train_samples_per_second': 153.6, 'train_steps_per_second': 1.218, 'train_loss': 2.6351609230041504, 'epoch': 3.0}
[INFO][23:54:35]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][23:54:35]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][23:54:36]: [Client #6] Model trained.
[INFO][23:54:36]: [Client #6] Inbound data has been processed.
[INFO][23:54:36]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][23:54:36]: [Client #7] Model trained.
[INFO][23:54:36]: [Client #7] Inbound data has been processed.
[INFO][23:54:36]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][23:54:42]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:54:42]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:54:43]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][23:54:44]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][23:54:44]: [Server #3350301] Selecting client #9 for training.
[INFO][23:54:44]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:54:47]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:54:47]: [Client #9] Selected by the server.
[INFO][23:54:47]: [Client #9] Loading its data source...
[INFO][23:54:47]: [Client #9] Dataset size: 2018
[INFO][23:54:47]: [Client #9] Sampler: iid
[INFO][23:54:49]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:54:49]: [Client #9] Start to process inbound data.
[INFO][23:54:49]: [93m[1m[Client #9] Started training in communication round #52.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.15it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][23:55:22]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.944, 'train_samples_per_second': 224.689, 'train_steps_per_second': 1.781, 'train_loss': 2.4927786191304526, 'epoch': 3.0}
[INFO][23:55:23]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:55:23]: [Client #9] Model trained.
[INFO][23:55:23]: [Client #9] Inbound data has been processed.
[INFO][23:55:23]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:55:28]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:55:29]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:55:29]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:55:29]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][23:55:29]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][23:55:29]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][23:55:29]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][23:55:29]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:55:29]: [Server #3350301] Updated weights have been received.
[INFO][23:55:29]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:55:30]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:55:30]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][23:55:40]: [93m[1m[Server #3350301] Global model perplexity: 39.92
[0m
[INFO][23:55:40]: [Server #3350301] All client reports have been processed.
[INFO][23:55:41]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_52.pth.
[INFO][23:55:41]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_52.pth.
[INFO][23:55:41]: [93m[1m
[Server #3350301] Starting round 53/100.[0m
[INFO][23:55:41]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][23:55:41]: [Server #3350301] Selecting client #10 for training.
[INFO][23:55:41]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][23:55:45]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][23:55:45]: [Server #3350301] Selecting client #1 for training.
[INFO][23:55:45]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:55:49]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:55:49]: [Client #10] Selected by the server.
[INFO][23:55:49]: [Client #10] Loading its data source...
[INFO][23:55:49]: [Client #10] Dataset size: 2018
[INFO][23:55:49]: [Client #10] Sampler: iid
[INFO][23:55:49]: [Client #1] Selected by the server.
[INFO][23:55:49]: [Client #1] Loading its data source...
[INFO][23:55:49]: [Client #1] Dataset size: 2018
[INFO][23:55:49]: [Client #1] Sampler: iid
[INFO][23:55:50]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:55:50]: [Client #10] Start to process inbound data.
[INFO][23:55:50]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:55:50]: [Client #1] Start to process inbound data.
[INFO][23:55:51]: [93m[1m[Client #1] Started training in communication round #53.[0m
[INFO][23:55:51]: [93m[1m[Client #10] Started training in communication round #53.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<03:06,  3.96s/it]  2%|â–         | 1/48 [00:04<03:45,  4.81s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:05,  1.45s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:51,  1.17s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:06<00:43,  1.02s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.08it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.16it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.22it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:31,  1.26it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:20<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:23<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][23:56:36]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 38.8591, 'train_samples_per_second': 155.794, 'train_steps_per_second': 1.235, 'train_loss': 2.7755044301350913, 'epoch': 3.0}
[INFO][23:56:36]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4848, 'train_samples_per_second': 153.325, 'train_steps_per_second': 1.216, 'train_loss': 2.0424795150756836, 'epoch': 3.0}
[INFO][23:56:37]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][23:56:37]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:56:38]: [Client #10] Model trained.
[INFO][23:56:38]: [Client #10] Inbound data has been processed.
[INFO][23:56:38]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][23:56:38]: [Client #1] Model trained.
[INFO][23:56:38]: [Client #1] Inbound data has been processed.
[INFO][23:56:38]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:56:44]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:56:45]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:56:45]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][23:56:46]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:56:46]: [Server #3350301] Selecting client #3 for training.
[INFO][23:56:46]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][23:56:50]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][23:56:50]: [Server #3350301] Selecting client #5 for training.
[INFO][23:56:50]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][23:56:54]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][23:56:54]: [Client #5] Selected by the server.
[INFO][23:56:54]: [Client #3] Selected by the server.
[INFO][23:56:54]: [Client #5] Loading its data source...
[INFO][23:56:54]: [Client #3] Loading its data source...
[INFO][23:56:54]: [Client #5] Dataset size: 2018
[INFO][23:56:54]: [Client #5] Sampler: iid
[INFO][23:56:54]: [Client #3] Dataset size: 2018
[INFO][23:56:54]: [Client #3] Sampler: iid
[INFO][23:56:55]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:56:55]: [Client #3] Start to process inbound data.
[INFO][23:56:55]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:56:55]: [Client #5] Start to process inbound data.
[INFO][23:56:55]: [93m[1m[Client #3] Started training in communication round #53.[0m
[INFO][23:56:55]: [93m[1m[Client #5] Started training in communication round #53.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.33it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][23:57:41]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.1526, 'train_samples_per_second': 154.626, 'train_steps_per_second': 1.226, 'train_loss': 2.539379596710205, 'epoch': 3.0}
[INFO][23:57:41]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.5213, 'train_samples_per_second': 153.183, 'train_steps_per_second': 1.215, 'train_loss': 2.3684547742207847, 'epoch': 3.0}
[INFO][23:57:42]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][23:57:42]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][23:57:43]: [Client #3] Model trained.
[INFO][23:57:43]: [Client #3] Inbound data has been processed.
[INFO][23:57:43]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][23:57:43]: [Client #5] Model trained.
[INFO][23:57:43]: [Client #5] Inbound data has been processed.
[INFO][23:57:43]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][23:57:50]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:57:50]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:57:51]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][23:57:52]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][23:57:52]: [Server #3350301] Selecting client #9 for training.
[INFO][23:57:52]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][23:57:56]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][23:57:56]: [Client #9] Selected by the server.
[INFO][23:57:56]: [Client #9] Loading its data source...
[INFO][23:57:56]: [Client #9] Dataset size: 2018
[INFO][23:57:56]: [Client #9] Sampler: iid
[INFO][23:57:58]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:57:58]: [Client #9] Start to process inbound data.
[INFO][23:57:58]: [93m[1m[Client #9] Started training in communication round #53.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.17s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.15it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][23:58:31]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8936, 'train_samples_per_second': 225.109, 'train_steps_per_second': 1.785, 'train_loss': 2.452106793721517, 'epoch': 3.0}
[INFO][23:58:32]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][23:58:32]: [Client #9] Model trained.
[INFO][23:58:32]: [Client #9] Inbound data has been processed.
[INFO][23:58:32]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][23:58:37]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:58:38]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][23:58:38]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][23:58:38]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][23:58:38]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][23:58:38]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][23:58:38]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][23:58:38]: [Server #3350301] Aggregating 5 clients in total.
[INFO][23:58:38]: [Server #3350301] Updated weights have been received.
[INFO][23:58:38]: [Server #3350301] Aggregating model weight deltas.
[INFO][23:58:39]: [Server #3350301] Finished aggregating updated weights.
[INFO][23:58:39]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.89it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][23:58:50]: [93m[1m[Server #3350301] Global model perplexity: 37.55
[0m
[INFO][23:58:50]: [Server #3350301] All client reports have been processed.
[INFO][23:58:50]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_53.pth.
[INFO][23:58:50]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_53.pth.
[INFO][23:58:50]: [93m[1m
[Server #3350301] Starting round 54/100.[0m
[INFO][23:58:50]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][23:58:50]: [Server #3350301] Selecting client #2 for training.
[INFO][23:58:50]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][23:58:54]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][23:58:54]: [Server #3350301] Selecting client #1 for training.
[INFO][23:58:54]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][23:58:58]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][23:58:58]: [Client #2] Selected by the server.
[INFO][23:58:58]: [Client #2] Loading its data source...
[INFO][23:58:58]: [Client #2] Dataset size: 2018
[INFO][23:58:58]: [Client #2] Sampler: iid
[INFO][23:58:58]: [Client #1] Selected by the server.
[INFO][23:58:58]: [Client #1] Loading its data source...
[INFO][23:58:58]: [Client #1] Dataset size: 2018
[INFO][23:58:58]: [Client #1] Sampler: iid
[INFO][23:58:59]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:58:59]: [Client #2] Start to process inbound data.
[INFO][23:58:59]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][23:58:59]: [Client #1] Start to process inbound data.
[INFO][23:59:00]: [93m[1m[Client #1] Started training in communication round #54.[0m
[INFO][23:59:00]: [93m[1m[Client #2] Started training in communication round #54.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:29,  4.46s/it]  2%|â–         | 1/48 [00:05<03:55,  5.01s/it]  4%|â–         | 2/48 [00:05<01:42,  2.23s/it]  4%|â–         | 2/48 [00:05<01:56,  2.54s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.71s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][23:59:46]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.4484, 'train_samples_per_second': 153.466, 'train_steps_per_second': 1.217, 'train_loss': 2.588995933532715, 'epoch': 3.0}
[INFO][23:59:46]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.9019, 'train_samples_per_second': 151.722, 'train_steps_per_second': 1.203, 'train_loss': 2.0359158515930176, 'epoch': 3.0}
[INFO][23:59:47]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][23:59:47]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][23:59:47]: [Client #2] Model trained.
[INFO][23:59:47]: [Client #2] Inbound data has been processed.
[INFO][23:59:47]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][23:59:48]: [Client #1] Model trained.
[INFO][23:59:48]: [Client #1] Inbound data has been processed.
[INFO][23:59:48]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][23:59:55]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:59:55]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][23:59:56]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][23:59:57]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][23:59:57]: [Server #3350301] Selecting client #4 for training.
[INFO][23:59:57]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:00:00]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:00:00]: [Server #3350301] Selecting client #7 for training.
[INFO][00:00:00]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:00:04]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:00:04]: [Client #4] Selected by the server.
[INFO][00:00:04]: [Client #4] Loading its data source...
[INFO][00:00:04]: [Client #7] Selected by the server.
[INFO][00:00:04]: [Client #7] Loading its data source...
[INFO][00:00:04]: [Client #4] Dataset size: 2018
[INFO][00:00:04]: [Client #4] Sampler: iid
[INFO][00:00:04]: [Client #7] Dataset size: 2018
[INFO][00:00:04]: [Client #7] Sampler: iid
[INFO][00:00:06]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:00:06]: [Client #7] Start to process inbound data.
[INFO][00:00:06]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:00:06]: [Client #4] Start to process inbound data.
[INFO][00:00:06]: [93m[1m[Client #7] Started training in communication round #54.[0m
[INFO][00:00:06]: [93m[1m[Client #4] Started training in communication round #54.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:39,  4.66s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:00:51]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 38.8693, 'train_samples_per_second': 155.753, 'train_steps_per_second': 1.235, 'train_loss': 2.5967373847961426, 'epoch': 3.0}
[INFO][00:00:52]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.3874, 'train_samples_per_second': 153.704, 'train_steps_per_second': 1.219, 'train_loss': 2.8492698669433594, 'epoch': 3.0}
[INFO][00:00:52]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:00:53]: [Client #7] Model trained.
[INFO][00:00:53]: [Client #7] Inbound data has been processed.
[INFO][00:00:53]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:00:53]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:00:54]: [Client #4] Model trained.
[INFO][00:00:54]: [Client #4] Inbound data has been processed.
[INFO][00:00:54]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:00:59]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:00:59]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:01:00]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:01:01]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:01:01]: [Server #3350301] Selecting client #8 for training.
[INFO][00:01:01]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:01:04]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:01:04]: [Client #8] Selected by the server.
[INFO][00:01:04]: [Client #8] Loading its data source...
[INFO][00:01:04]: [Client #8] Dataset size: 2018
[INFO][00:01:04]: [Client #8] Sampler: iid
[INFO][00:01:06]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:01:06]: [Client #8] Start to process inbound data.
[INFO][00:01:06]: [93m[1m[Client #8] Started training in communication round #54.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][00:01:39]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.7877, 'train_samples_per_second': 225.999, 'train_steps_per_second': 1.792, 'train_loss': 2.9057321548461914, 'epoch': 3.0}
[INFO][00:01:40]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:01:41]: [Client #8] Model trained.
[INFO][00:01:41]: [Client #8] Inbound data has been processed.
[INFO][00:01:41]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:01:45]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:01:46]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:01:46]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:01:46]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:01:46]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:01:46]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:01:46]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:01:46]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:01:46]: [Server #3350301] Updated weights have been received.
[INFO][00:01:46]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:01:47]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:01:47]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.38it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.39it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.57it/s]
[INFO][00:01:58]: [93m[1m[Server #3350301] Global model perplexity: 36.36
[0m
[INFO][00:01:58]: [Server #3350301] All client reports have been processed.
[INFO][00:01:58]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_54.pth.
[INFO][00:01:58]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_54.pth.
[INFO][00:01:58]: [93m[1m
[Server #3350301] Starting round 55/100.[0m
[INFO][00:01:58]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][00:01:58]: [Server #3350301] Selecting client #6 for training.
[INFO][00:01:58]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:02:02]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:02:02]: [Server #3350301] Selecting client #3 for training.
[INFO][00:02:02]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:02:06]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:02:06]: [Client #6] Selected by the server.
[INFO][00:02:06]: [Client #6] Loading its data source...
[INFO][00:02:06]: [Client #6] Dataset size: 2018
[INFO][00:02:06]: [Client #6] Sampler: iid
[INFO][00:02:06]: [Client #3] Selected by the server.
[INFO][00:02:06]: [Client #3] Loading its data source...
[INFO][00:02:06]: [Client #3] Dataset size: 2018
[INFO][00:02:06]: [Client #3] Sampler: iid
[INFO][00:02:07]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:02:07]: [Client #6] Start to process inbound data.
[INFO][00:02:07]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:02:07]: [Client #3] Start to process inbound data.
[INFO][00:02:08]: [93m[1m[Client #6] Started training in communication round #55.[0m
[INFO][00:02:08]: [93m[1m[Client #3] Started training in communication round #55.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:11,  4.07s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.48s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it] 10%|â–ˆ         | 5/48 [00:06<00:43,  1.02s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.21it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:31,  1.24it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:23,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.32it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:02:53]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 38.8912, 'train_samples_per_second': 155.665, 'train_steps_per_second': 1.234, 'train_loss': 2.515680948893229, 'epoch': 3.0}
[INFO][00:02:53]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.3785, 'train_samples_per_second': 153.739, 'train_steps_per_second': 1.219, 'train_loss': 2.919920285542806, 'epoch': 3.0}
[INFO][00:02:54]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][00:02:54]: [Client #3] Model trained.
[INFO][00:02:54]: [Client #3] Inbound data has been processed.
[INFO][00:02:54]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:02:54]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][00:02:55]: [Client #6] Model trained.
[INFO][00:02:55]: [Client #6] Inbound data has been processed.
[INFO][00:02:55]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][00:03:01]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:03:02]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:03:02]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:03:02]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][00:03:02]: [Server #3350301] Selecting client #10 for training.
[INFO][00:03:02]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:03:06]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:03:06]: [Server #3350301] Selecting client #5 for training.
[INFO][00:03:06]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:03:10]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:03:10]: [Client #10] Selected by the server.
[INFO][00:03:10]: [Client #10] Loading its data source...
[INFO][00:03:10]: [Client #5] Selected by the server.
[INFO][00:03:10]: [Client #10] Dataset size: 2018
[INFO][00:03:10]: [Client #10] Sampler: iid
[INFO][00:03:10]: [Client #5] Loading its data source...
[INFO][00:03:10]: [Client #5] Dataset size: 2018
[INFO][00:03:10]: [Client #5] Sampler: iid
[INFO][00:03:11]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:03:11]: [Client #10] Start to process inbound data.
[INFO][00:03:11]: [93m[1m[Client #10] Started training in communication round #55.[0m
[INFO][00:03:11]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:03:11]: [Client #5] Start to process inbound data.
[INFO][00:03:12]: [93m[1m[Client #5] Started training in communication round #55.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:37,  4.63s/it]  2%|â–         | 1/48 [00:04<03:36,  4.60s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.60s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.60s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:03:57]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.325, 'train_samples_per_second': 153.948, 'train_steps_per_second': 1.221, 'train_loss': 2.3228262265523276, 'epoch': 3.0}
[INFO][00:03:57]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.3579, 'train_samples_per_second': 153.819, 'train_steps_per_second': 1.22, 'train_loss': 2.7702344258626304, 'epoch': 3.0}
[INFO][00:03:58]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:03:58]: [Client #5] Model trained.
[INFO][00:03:58]: [Client #5] Inbound data has been processed.
[INFO][00:03:58]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:03:58]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:03:59]: [Client #10] Model trained.
[INFO][00:03:59]: [Client #10] Inbound data has been processed.
[INFO][00:03:59]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:04:05]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:04:05]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:04:06]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:04:07]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:04:07]: [Server #3350301] Selecting client #9 for training.
[INFO][00:04:07]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:04:11]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:04:11]: [Client #9] Selected by the server.
[INFO][00:04:11]: [Client #9] Loading its data source...
[INFO][00:04:11]: [Client #9] Dataset size: 2018
[INFO][00:04:11]: [Client #9] Sampler: iid
[INFO][00:04:12]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:04:12]: [Client #9] Start to process inbound data.
[INFO][00:04:12]: [93m[1m[Client #9] Started training in communication round #55.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:12,  4.10s/it]  4%|â–         | 2/48 [00:04<01:30,  1.97s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.29s/it]  8%|â–Š         | 4/48 [00:05<00:42,  1.03it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.26it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][00:04:45]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.9128, 'train_samples_per_second': 224.949, 'train_steps_per_second': 1.784, 'train_loss': 2.40427303314209, 'epoch': 3.0}
[INFO][00:04:47]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:04:47]: [Client #9] Model trained.
[INFO][00:04:47]: [Client #9] Inbound data has been processed.
[INFO][00:04:47]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:04:51]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:04:52]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:04:52]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:04:52]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:04:52]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:04:52]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:04:52]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:04:52]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:04:52]: [Server #3350301] Updated weights have been received.
[INFO][00:04:53]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:04:53]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:04:53]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.84it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][00:05:04]: [93m[1m[Server #3350301] Global model perplexity: 44.55
[0m
[INFO][00:05:04]: [Server #3350301] All client reports have been processed.
[INFO][00:05:04]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_55.pth.
[INFO][00:05:05]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_55.pth.
[INFO][00:05:05]: [93m[1m
[Server #3350301] Starting round 56/100.[0m
[INFO][00:05:05]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][00:05:05]: [Server #3350301] Selecting client #2 for training.
[INFO][00:05:05]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:05:09]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:05:09]: [Server #3350301] Selecting client #1 for training.
[INFO][00:05:09]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:05:12]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:05:12]: [Client #2] Selected by the server.
[INFO][00:05:12]: [Client #2] Loading its data source...
[INFO][00:05:12]: [Client #2] Dataset size: 2018
[INFO][00:05:12]: [Client #2] Sampler: iid
[INFO][00:05:12]: [Client #1] Selected by the server.
[INFO][00:05:12]: [Client #1] Loading its data source...
[INFO][00:05:12]: [Client #1] Dataset size: 2018
[INFO][00:05:12]: [Client #1] Sampler: iid
[INFO][00:05:14]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:05:14]: [Client #2] Start to process inbound data.
[INFO][00:05:14]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:05:14]: [Client #1] Start to process inbound data.
[INFO][00:05:14]: [93m[1m[Client #2] Started training in communication round #56.[0m
[INFO][00:05:14]: [93m[1m[Client #1] Started training in communication round #56.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.03s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:37,  2.11s/it]  2%|â–         | 1/48 [00:04<03:38,  4.66s/it]  6%|â–‹         | 3/48 [00:05<01:12,  1.60s/it]  4%|â–         | 2/48 [00:05<01:57,  2.56s/it]  8%|â–Š         | 4/48 [00:06<01:01,  1.39s/it]  6%|â–‹         | 3/48 [00:06<01:24,  1.89s/it] 10%|â–ˆ         | 5/48 [00:07<00:55,  1.29s/it]  8%|â–Š         | 4/48 [00:07<01:09,  1.58s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:50,  1.21s/it] 10%|â–ˆ         | 5/48 [00:09<01:00,  1.40s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:46,  1.14s/it] 12%|â–ˆâ–Ž        | 6/48 [00:10<00:52,  1.26s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:43,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:47,  1.16s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:39,  1.01s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:43,  1.09s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:40,  1.05s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:38,  1.01s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:36,  1.02it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:34,  1.04it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:33,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:33,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:30,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.13it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:19<00:28,  1.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:26,  1.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:20<00:27,  1.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:25,  1.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:26,  1.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:23,  1.13it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:21,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:20,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:19,  1.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:18,  1.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:17,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:17,  1.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.05it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.10it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:13,  1.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.08it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:12,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:11,  1.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:09,  1.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:10,  1.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:09,  1.11it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
[INFO][00:06:08]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.4789, 'train_samples_per_second': 127.509, 'train_steps_per_second': 1.011, 'train_loss': 1.975766658782959, 'epoch': 3.0}
[INFO][00:06:08]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 47.8214, 'train_samples_per_second': 126.596, 'train_steps_per_second': 1.004, 'train_loss': 2.571589152018229, 'epoch': 3.0}
[INFO][00:06:09]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:06:09]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:06:10]: [Client #1] Model trained.
[INFO][00:06:10]: [Client #1] Inbound data has been processed.
[INFO][00:06:10]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:06:10]: [Client #2] Model trained.
[INFO][00:06:10]: [Client #2] Inbound data has been processed.
[INFO][00:06:10]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:06:16]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:06:16]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:06:17]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:06:18]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:06:18]: [Server #3350301] Selecting client #5 for training.
[INFO][00:06:18]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:06:22]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:06:22]: [Server #3350301] Selecting client #7 for training.
[INFO][00:06:22]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:06:25]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:06:25]: [Client #5] Selected by the server.
[INFO][00:06:25]: [Client #5] Loading its data source...
[INFO][00:06:25]: [Client #5] Dataset size: 2018
[INFO][00:06:25]: [Client #5] Sampler: iid
[INFO][00:06:25]: [Client #7] Selected by the server.
[INFO][00:06:25]: [Client #7] Loading its data source...
[INFO][00:06:25]: [Client #7] Dataset size: 2018
[INFO][00:06:25]: [Client #7] Sampler: iid
[INFO][00:06:27]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:06:27]: [Client #5] Start to process inbound data.
[INFO][00:06:27]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:06:27]: [Client #7] Start to process inbound data.
[INFO][00:06:27]: [93m[1m[Client #5] Started training in communication round #56.[0m
[INFO][00:06:27]: [93m[1m[Client #7] Started training in communication round #56.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:51,  4.92s/it]  2%|â–         | 1/48 [00:04<03:52,  4.96s/it]  4%|â–         | 2/48 [00:05<01:58,  2.57s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  6%|â–‹         | 3/48 [00:06<01:20,  1.78s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.80s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.39s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.41s/it] 10%|â–ˆ         | 5/48 [00:08<00:49,  1.15s/it] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.18s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.01s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.03s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
[INFO][00:07:14]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.936, 'train_samples_per_second': 151.592, 'train_steps_per_second': 1.202, 'train_loss': 2.288491725921631, 'epoch': 3.0}
[INFO][00:07:14]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 40.0683, 'train_samples_per_second': 151.092, 'train_steps_per_second': 1.198, 'train_loss': 2.554469585418701, 'epoch': 3.0}
[INFO][00:07:15]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:07:15]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][00:07:15]: [Client #7] Model trained.
[INFO][00:07:15]: [Client #7] Inbound data has been processed.
[INFO][00:07:15]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:07:16]: [Client #5] Model trained.
[INFO][00:07:16]: [Client #5] Inbound data has been processed.
[INFO][00:07:16]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:07:21]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:07:22]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:07:23]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:07:24]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:07:24]: [Server #3350301] Selecting client #9 for training.
[INFO][00:07:24]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:07:27]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:07:27]: [Client #9] Selected by the server.
[INFO][00:07:27]: [Client #9] Loading its data source...
[INFO][00:07:27]: [Client #9] Dataset size: 2018
[INFO][00:07:27]: [Client #9] Sampler: iid
[INFO][00:07:29]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:07:29]: [Client #9] Start to process inbound data.
[INFO][00:07:29]: [93m[1m[Client #9] Started training in communication round #56.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:08:02]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.6742, 'train_samples_per_second': 226.961, 'train_steps_per_second': 1.799, 'train_loss': 2.366253693898519, 'epoch': 3.0}
[INFO][00:08:03]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:08:03]: [Client #9] Model trained.
[INFO][00:08:03]: [Client #9] Inbound data has been processed.
[INFO][00:08:03]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:08:07]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:08:09]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:08:09]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:08:09]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:08:09]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][00:08:09]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][00:08:09]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:08:09]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:08:09]: [Server #3350301] Updated weights have been received.
[INFO][00:08:09]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:08:10]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:08:10]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.68it/s]
[INFO][00:08:21]: [93m[1m[Server #3350301] Global model perplexity: 39.40
[0m
[INFO][00:08:21]: [Server #3350301] All client reports have been processed.
[INFO][00:08:21]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_56.pth.
[INFO][00:08:21]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_56.pth.
[INFO][00:08:21]: [93m[1m
[Server #3350301] Starting round 57/100.[0m
[INFO][00:08:21]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][00:08:21]: [Server #3350301] Selecting client #4 for training.
[INFO][00:08:21]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:08:25]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:08:25]: [Server #3350301] Selecting client #1 for training.
[INFO][00:08:25]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:08:28]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:08:28]: [Client #4] Selected by the server.
[INFO][00:08:28]: [Client #4] Loading its data source...
[INFO][00:08:28]: [Client #1] Selected by the server.
[INFO][00:08:28]: [Client #4] Dataset size: 2018
[INFO][00:08:28]: [Client #1] Loading its data source...
[INFO][00:08:28]: [Client #4] Sampler: iid
[INFO][00:08:28]: [Client #1] Dataset size: 2018
[INFO][00:08:28]: [Client #1] Sampler: iid
[INFO][00:08:30]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:08:30]: [Client #4] Start to process inbound data.
[INFO][00:08:30]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:08:30]: [Client #1] Start to process inbound data.
[INFO][00:08:30]: [93m[1m[Client #4] Started training in communication round #57.[0m
[INFO][00:08:30]: [93m[1m[Client #1] Started training in communication round #57.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  2%|â–         | 1/48 [00:04<03:47,  4.83s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:09:16]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.0979, 'train_samples_per_second': 154.842, 'train_steps_per_second': 1.228, 'train_loss': 2.82865301767985, 'epoch': 3.0}
[INFO][00:09:16]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4532, 'train_samples_per_second': 153.448, 'train_steps_per_second': 1.217, 'train_loss': 1.9463597933451335, 'epoch': 3.0}
[INFO][00:09:17]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:09:17]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:09:18]: [Client #4] Model trained.
[INFO][00:09:18]: [Client #4] Inbound data has been processed.
[INFO][00:09:18]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:09:18]: [Client #1] Model trained.
[INFO][00:09:18]: [Client #1] Inbound data has been processed.
[INFO][00:09:18]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:09:25]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:09:25]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:09:26]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:09:27]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:09:27]: [Server #3350301] Selecting client #8 for training.
[INFO][00:09:27]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:09:30]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:09:30]: [Server #3350301] Selecting client #3 for training.
[INFO][00:09:30]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:09:34]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:09:34]: [Client #8] Selected by the server.
[INFO][00:09:34]: [Client #8] Loading its data source...
[INFO][00:09:34]: [Client #8] Dataset size: 2018
[INFO][00:09:34]: [Client #8] Sampler: iid
[INFO][00:09:34]: [Client #3] Selected by the server.
[INFO][00:09:34]: [Client #3] Loading its data source...
[INFO][00:09:34]: [Client #3] Dataset size: 2018
[INFO][00:09:34]: [Client #3] Sampler: iid
[INFO][00:09:35]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:09:35]: [Client #8] Start to process inbound data.
[INFO][00:09:35]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:09:35]: [Client #3] Start to process inbound data.
[INFO][00:09:36]: [93m[1m[Client #8] Started training in communication round #57.[0m
[INFO][00:09:36]: [93m[1m[Client #3] Started training in communication round #57.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  2%|â–         | 1/48 [00:04<03:45,  4.79s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.49s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:10:21]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.0123, 'train_samples_per_second': 155.182, 'train_steps_per_second': 1.23, 'train_loss': 2.882293701171875, 'epoch': 3.0}
[INFO][00:10:21]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.4346, 'train_samples_per_second': 153.52, 'train_steps_per_second': 1.217, 'train_loss': 2.480778535207113, 'epoch': 3.0}
[INFO][00:10:22]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:10:22]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][00:10:23]: [Client #8] Model trained.
[INFO][00:10:23]: [Client #8] Inbound data has been processed.
[INFO][00:10:23]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:10:23]: [Client #3] Model trained.
[INFO][00:10:23]: [Client #3] Inbound data has been processed.
[INFO][00:10:23]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:10:28]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:10:29]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:10:29]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:10:30]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:10:30]: [Server #3350301] Selecting client #10 for training.
[INFO][00:10:30]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:10:34]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:10:34]: [Client #10] Selected by the server.
[INFO][00:10:34]: [Client #10] Loading its data source...
[INFO][00:10:34]: [Client #10] Dataset size: 2018
[INFO][00:10:34]: [Client #10] Sampler: iid
[INFO][00:10:35]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:10:35]: [Client #10] Start to process inbound data.
[INFO][00:10:35]: [93m[1m[Client #10] Started training in communication round #57.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:11:08]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.6943, 'train_samples_per_second': 226.79, 'train_steps_per_second': 1.798, 'train_loss': 2.7238858540852866, 'epoch': 3.0}
[INFO][00:11:09]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:11:09]: [Client #10] Model trained.
[INFO][00:11:09]: [Client #10] Inbound data has been processed.
[INFO][00:11:09]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:11:14]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:11:15]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:11:15]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:11:15]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:11:15]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:11:15]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:11:15]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:11:15]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:11:15]: [Server #3350301] Updated weights have been received.
[INFO][00:11:15]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:11:16]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:11:16]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][00:11:27]: [93m[1m[Server #3350301] Global model perplexity: 40.33
[0m
[INFO][00:11:27]: [Server #3350301] All client reports have been processed.
[INFO][00:11:27]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_57.pth.
[INFO][00:11:27]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_57.pth.
[INFO][00:11:27]: [93m[1m
[Server #3350301] Starting round 58/100.[0m
[INFO][00:11:27]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][00:11:27]: [Server #3350301] Selecting client #2 for training.
[INFO][00:11:27]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:11:31]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:11:31]: [Server #3350301] Selecting client #5 for training.
[INFO][00:11:31]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:11:35]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:11:35]: [Client #2] Selected by the server.
[INFO][00:11:35]: [Client #2] Loading its data source...
[INFO][00:11:35]: [Client #2] Dataset size: 2018
[INFO][00:11:35]: [Client #2] Sampler: iid
[INFO][00:11:35]: [Client #5] Selected by the server.
[INFO][00:11:35]: [Client #5] Loading its data source...
[INFO][00:11:35]: [Client #5] Dataset size: 2018
[INFO][00:11:35]: [Client #5] Sampler: iid
[INFO][00:11:36]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:11:36]: [Client #2] Start to process inbound data.
[INFO][00:11:36]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:11:36]: [Client #5] Start to process inbound data.
[INFO][00:11:37]: [93m[1m[Client #5] Started training in communication round #58.[0m
[INFO][00:11:37]: [93m[1m[Client #2] Started training in communication round #58.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.02s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  6%|â–‹         | 3/48 [00:05<01:03,  1.41s/it]  4%|â–         | 2/48 [00:05<01:49,  2.37s/it]  8%|â–Š         | 4/48 [00:06<00:50,  1.14s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it] 10%|â–ˆ         | 5/48 [00:06<00:43,  1.00s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.09it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.17it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.22it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:30,  1.26it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:11<00:27,  1.32it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:14<00:23,  1.38it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:23,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:17<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:20<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:23<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.37it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:34<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.67it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][00:12:22]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 38.7038, 'train_samples_per_second': 156.419, 'train_steps_per_second': 1.24, 'train_loss': 2.22884464263916, 'epoch': 3.0}
[INFO][00:12:23]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.0863, 'train_samples_per_second': 154.888, 'train_steps_per_second': 1.228, 'train_loss': 2.5389556884765625, 'epoch': 3.0}
[INFO][00:12:23]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:12:23]: [Client #5] Model trained.
[INFO][00:12:23]: [Client #5] Inbound data has been processed.
[INFO][00:12:23]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:12:24]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:12:24]: [Client #2] Model trained.
[INFO][00:12:24]: [Client #2] Inbound data has been processed.
[INFO][00:12:24]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:12:29]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:12:30]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:12:30]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:12:31]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:12:31]: [Server #3350301] Selecting client #6 for training.
[INFO][00:12:31]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:12:35]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:12:35]: [Server #3350301] Selecting client #7 for training.
[INFO][00:12:35]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:12:39]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:12:39]: [Client #6] Selected by the server.
[INFO][00:12:39]: [Client #6] Loading its data source...
[INFO][00:12:39]: [Client #6] Dataset size: 2018
[INFO][00:12:39]: [Client #6] Sampler: iid
[INFO][00:12:39]: [Client #7] Selected by the server.
[INFO][00:12:39]: [Client #7] Loading its data source...
[INFO][00:12:39]: [Client #7] Dataset size: 2018
[INFO][00:12:39]: [Client #7] Sampler: iid
[INFO][00:12:40]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:12:40]: [Client #7] Start to process inbound data.
[INFO][00:12:40]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:12:40]: [Client #6] Start to process inbound data.
[INFO][00:12:41]: [93m[1m[Client #7] Started training in communication round #58.[0m
[INFO][00:12:41]: [93m[1m[Client #6] Started training in communication round #58.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:24,  4.36s/it]  2%|â–         | 1/48 [00:04<03:30,  4.48s/it]  4%|â–         | 2/48 [00:05<01:47,  2.35s/it]  4%|â–         | 2/48 [00:05<01:49,  2.37s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.20s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:42,  1.02s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.02s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.04it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.04it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:28,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:30,  1.03it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.06it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:30,  1.00s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:29,  1.01it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:28,  1.01it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:28,  1.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:27,  1.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:27,  1.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:26,  1.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.03it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.06it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.05it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.05it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.00s/it]
[INFO][00:13:35]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 48.3481, 'train_samples_per_second': 125.217, 'train_steps_per_second': 0.993, 'train_loss': 2.535979906717936, 'epoch': 3.0}
[INFO][00:13:35]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 48.1123, 'train_samples_per_second': 125.831, 'train_steps_per_second': 0.998, 'train_loss': 2.8900779088338218, 'epoch': 3.0}
[INFO][00:13:36]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][00:13:36]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:13:37]: [Client #6] Model trained.
[INFO][00:13:37]: [Client #6] Inbound data has been processed.
[INFO][00:13:37]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][00:13:37]: [Client #7] Model trained.
[INFO][00:13:37]: [Client #7] Inbound data has been processed.
[INFO][00:13:37]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:13:42]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:13:43]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:13:43]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][00:13:45]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:13:45]: [Server #3350301] Selecting client #9 for training.
[INFO][00:13:45]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:13:48]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:13:48]: [Client #9] Selected by the server.
[INFO][00:13:48]: [Client #9] Loading its data source...
[INFO][00:13:48]: [Client #9] Dataset size: 2018
[INFO][00:13:48]: [Client #9] Sampler: iid
[INFO][00:13:50]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:13:50]: [Client #9] Start to process inbound data.
[INFO][00:13:50]: [93m[1m[Client #9] Started training in communication round #58.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.85it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.93it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.96it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.13it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  1.78it/s]
[INFO][00:14:24]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 27.0312, 'train_samples_per_second': 223.964, 'train_steps_per_second': 1.776, 'train_loss': 2.3048222859700522, 'epoch': 3.0}
[INFO][00:14:25]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:14:25]: [Client #9] Model trained.
[INFO][00:14:25]: [Client #9] Inbound data has been processed.
[INFO][00:14:25]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:14:29]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:14:30]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:14:30]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:14:30]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:14:30]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:14:30]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:14:30]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:14:30]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:14:30]: [Server #3350301] Updated weights have been received.
[INFO][00:14:31]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:14:31]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:14:31]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.72it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]
[INFO][00:14:42]: [93m[1m[Server #3350301] Global model perplexity: 46.49
[0m
[INFO][00:14:42]: [Server #3350301] All client reports have been processed.
[INFO][00:14:42]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_58.pth.
[INFO][00:14:43]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_58.pth.
[INFO][00:14:43]: [93m[1m
[Server #3350301] Starting round 59/100.[0m
[INFO][00:14:43]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][00:14:43]: [Server #3350301] Selecting client #10 for training.
[INFO][00:14:43]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:14:47]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:14:47]: [Server #3350301] Selecting client #1 for training.
[INFO][00:14:47]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:14:50]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:14:50]: [Client #10] Selected by the server.
[INFO][00:14:50]: [Client #10] Loading its data source...
[INFO][00:14:50]: [Client #10] Dataset size: 2018
[INFO][00:14:50]: [Client #1] Selected by the server.
[INFO][00:14:50]: [Client #10] Sampler: iid
[INFO][00:14:50]: [Client #1] Loading its data source...
[INFO][00:14:50]: [Client #1] Dataset size: 2018
[INFO][00:14:50]: [Client #1] Sampler: iid
[INFO][00:14:52]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:14:52]: [Client #1] Start to process inbound data.
[INFO][00:14:52]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:14:52]: [Client #10] Start to process inbound data.
[INFO][00:14:53]: [93m[1m[Client #10] Started training in communication round #59.[0m
[INFO][00:14:53]: [93m[1m[Client #1] Started training in communication round #59.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:37,  4.62s/it]  2%|â–         | 1/48 [00:05<03:58,  5.08s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  4%|â–         | 2/48 [00:06<02:05,  2.72s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.82s/it]  6%|â–‹         | 3/48 [00:07<01:25,  1.89s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.47s/it]  8%|â–Š         | 4/48 [00:07<01:05,  1.49s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.26s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.16s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.13s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.06s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.06s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:39,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.03it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:22,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:19,  1.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:19,  1.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.04it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.05it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:44<00:04,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:45<00:03,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:46<00:02,  1.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:48<00:00,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.05it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.01s/it]
[INFO][00:15:47]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 48.482, 'train_samples_per_second': 124.871, 'train_steps_per_second': 0.99, 'train_loss': 1.927517573038737, 'epoch': 3.0}
[INFO][00:15:48]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 48.6006, 'train_samples_per_second': 124.566, 'train_steps_per_second': 0.988, 'train_loss': 2.6969242095947266, 'epoch': 3.0}
[INFO][00:15:49]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:15:49]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:15:50]: [Client #10] Model trained.
[INFO][00:15:50]: [Client #10] Inbound data has been processed.
[INFO][00:15:50]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:15:50]: [Client #1] Model trained.
[INFO][00:15:50]: [Client #1] Inbound data has been processed.
[INFO][00:15:50]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:15:56]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:15:56]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:15:57]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:15:58]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:15:58]: [Server #3350301] Selecting client #3 for training.
[INFO][00:15:58]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:16:02]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:16:02]: [Server #3350301] Selecting client #5 for training.
[INFO][00:16:02]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:16:06]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:16:06]: [Client #3] Selected by the server.
[INFO][00:16:06]: [Client #3] Loading its data source...
[INFO][00:16:06]: [Client #5] Selected by the server.
[INFO][00:16:06]: [Client #3] Dataset size: 2018
[INFO][00:16:06]: [Client #5] Loading its data source...
[INFO][00:16:06]: [Client #3] Sampler: iid
[INFO][00:16:06]: [Client #5] Dataset size: 2018
[INFO][00:16:06]: [Client #5] Sampler: iid
[INFO][00:16:07]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:16:07]: [Client #3] Start to process inbound data.
[INFO][00:16:07]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:16:07]: [Client #5] Start to process inbound data.
[INFO][00:16:08]: [93m[1m[Client #3] Started training in communication round #59.[0m
[INFO][00:16:08]: [93m[1m[Client #5] Started training in communication round #59.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.26s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:16:54]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.287, 'train_samples_per_second': 154.097, 'train_steps_per_second': 1.222, 'train_loss': 2.43357785542806, 'epoch': 3.0}
[INFO][00:16:54]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.6691, 'train_samples_per_second': 152.612, 'train_steps_per_second': 1.21, 'train_loss': 2.198692003885905, 'epoch': 3.0}
[INFO][00:16:55]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][00:16:55]: [Client #3] Model trained.
[INFO][00:16:55]: [Client #3] Inbound data has been processed.
[INFO][00:16:55]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:16:56]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:16:56]: [Client #5] Model trained.
[INFO][00:16:56]: [Client #5] Inbound data has been processed.
[INFO][00:16:56]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:17:01]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:17:02]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:17:02]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:17:04]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:17:04]: [Server #3350301] Selecting client #9 for training.
[INFO][00:17:04]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:17:07]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:17:07]: [Client #9] Selected by the server.
[INFO][00:17:07]: [Client #9] Loading its data source...
[INFO][00:17:07]: [Client #9] Dataset size: 2018
[INFO][00:17:07]: [Client #9] Sampler: iid
[INFO][00:17:09]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:17:09]: [Client #9] Start to process inbound data.
[INFO][00:17:09]: [93m[1m[Client #9] Started training in communication round #59.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:17:42]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7202, 'train_samples_per_second': 226.57, 'train_steps_per_second': 1.796, 'train_loss': 2.257978598276774, 'epoch': 3.0}
[INFO][00:17:43]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:17:44]: [Client #9] Model trained.
[INFO][00:17:44]: [Client #9] Inbound data has been processed.
[INFO][00:17:44]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:17:48]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:17:49]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:17:49]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:17:49]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:17:49]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][00:17:49]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][00:17:49]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:17:49]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:17:49]: [Server #3350301] Updated weights have been received.
[INFO][00:17:50]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:17:50]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:17:50]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.82it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.22it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.67it/s]
[INFO][00:18:01]: [93m[1m[Server #3350301] Global model perplexity: 43.43
[0m
[INFO][00:18:01]: [Server #3350301] All client reports have been processed.
[INFO][00:18:01]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_59.pth.
[INFO][00:18:02]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_59.pth.
[INFO][00:18:02]: [93m[1m
[Server #3350301] Starting round 60/100.[0m
[INFO][00:18:02]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][00:18:02]: [Server #3350301] Selecting client #2 for training.
[INFO][00:18:02]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:18:05]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:18:05]: [Server #3350301] Selecting client #1 for training.
[INFO][00:18:05]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:18:09]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:18:09]: [Client #2] Selected by the server.
[INFO][00:18:09]: [Client #2] Loading its data source...
[INFO][00:18:09]: [Client #2] Dataset size: 2018
[INFO][00:18:09]: [Client #2] Sampler: iid
[INFO][00:18:09]: [Client #1] Selected by the server.
[INFO][00:18:09]: [Client #1] Loading its data source...
[INFO][00:18:09]: [Client #1] Dataset size: 2018
[INFO][00:18:09]: [Client #1] Sampler: iid
[INFO][00:18:10]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:18:10]: [Client #2] Start to process inbound data.
[INFO][00:18:11]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:18:11]: [Client #1] Start to process inbound data.
[INFO][00:18:11]: [93m[1m[Client #2] Started training in communication round #60.[0m
[INFO][00:18:11]: [93m[1m[Client #1] Started training in communication round #60.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.04s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:37,  2.11s/it]  2%|â–         | 1/48 [00:04<03:39,  4.68s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.48s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.08it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.24it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.58it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:18:56]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 38.8565, 'train_samples_per_second': 155.804, 'train_steps_per_second': 1.235, 'train_loss': 1.8773307800292969, 'epoch': 3.0}
[INFO][00:18:57]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.1969, 'train_samples_per_second': 154.451, 'train_steps_per_second': 1.225, 'train_loss': 2.504683176676432, 'epoch': 3.0}
[INFO][00:18:57]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:18:58]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:18:58]: [Client #1] Model trained.
[INFO][00:18:58]: [Client #1] Inbound data has been processed.
[INFO][00:18:58]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:18:58]: [Client #2] Model trained.
[INFO][00:18:58]: [Client #2] Inbound data has been processed.
[INFO][00:18:58]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:19:03]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:19:04]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:19:05]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:19:06]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:19:06]: [Server #3350301] Selecting client #4 for training.
[INFO][00:19:06]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:19:10]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:19:10]: [Server #3350301] Selecting client #7 for training.
[INFO][00:19:10]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:19:14]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:19:14]: [Client #7] Selected by the server.
[INFO][00:19:14]: [Client #4] Selected by the server.
[INFO][00:19:14]: [Client #7] Loading its data source...
[INFO][00:19:14]: [Client #4] Loading its data source...
[INFO][00:19:14]: [Client #7] Dataset size: 2018
[INFO][00:19:14]: [Client #7] Sampler: iid
[INFO][00:19:14]: [Client #4] Dataset size: 2018
[INFO][00:19:14]: [Client #4] Sampler: iid
[INFO][00:19:15]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:19:15]: [Client #7] Start to process inbound data.
[INFO][00:19:15]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:19:15]: [Client #4] Start to process inbound data.
[INFO][00:19:16]: [93m[1m[Client #7] Started training in communication round #60.[0m
[INFO][00:19:16]: [93m[1m[Client #4] Started training in communication round #60.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:08,  4.00s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.10s/it]  2%|â–         | 1/48 [00:04<03:37,  4.62s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.60s/it]  4%|â–         | 2/48 [00:05<01:56,  2.54s/it]  8%|â–Š         | 4/48 [00:06<01:01,  1.40s/it]  6%|â–‹         | 3/48 [00:06<01:24,  1.88s/it] 10%|â–ˆ         | 5/48 [00:07<00:55,  1.29s/it]  8%|â–Š         | 4/48 [00:07<01:08,  1.56s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:50,  1.20s/it] 10%|â–ˆ         | 5/48 [00:08<00:58,  1.35s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:44,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.14s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:41,  1.01s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:35,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:37,  1.08it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:32,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.15it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:30,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:31,  1.20it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:29,  1.25it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:27,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:28,  1.27it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.27it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:27,  1.28it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.29it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:25,  1.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:23,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.18it/s]
[INFO][00:20:02]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 40.3817, 'train_samples_per_second': 149.92, 'train_steps_per_second': 1.189, 'train_loss': 2.499999205271403, 'epoch': 3.0}
[INFO][00:20:03]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 40.5353, 'train_samples_per_second': 149.351, 'train_steps_per_second': 1.184, 'train_loss': 2.810024897257487, 'epoch': 3.0}
[INFO][00:20:04]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:20:04]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:20:04]: [Client #7] Model trained.
[INFO][00:20:04]: [Client #7] Inbound data has been processed.
[INFO][00:20:04]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:20:04]: [Client #4] Model trained.
[INFO][00:20:04]: [Client #4] Inbound data has been processed.
[INFO][00:20:04]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:20:10]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:20:11]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:20:11]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:20:12]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:20:12]: [Server #3350301] Selecting client #8 for training.
[INFO][00:20:12]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:20:16]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:20:16]: [Client #8] Selected by the server.
[INFO][00:20:16]: [Client #8] Loading its data source...
[INFO][00:20:16]: [Client #8] Dataset size: 2018
[INFO][00:20:16]: [Client #8] Sampler: iid
[INFO][00:20:17]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:20:17]: [Client #8] Start to process inbound data.
[INFO][00:20:18]: [93m[1m[Client #8] Started training in communication round #60.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:20:50]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.7364, 'train_samples_per_second': 226.433, 'train_steps_per_second': 1.795, 'train_loss': 2.859490076700846, 'epoch': 3.0}
[INFO][00:20:52]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:20:52]: [Client #8] Model trained.
[INFO][00:20:52]: [Client #8] Inbound data has been processed.
[INFO][00:20:52]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:20:56]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:20:57]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:20:57]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:20:57]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:20:57]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:20:57]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:20:57]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:20:57]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:20:57]: [Server #3350301] Updated weights have been received.
[INFO][00:20:58]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:20:58]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:20:58]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.79it/s]
[INFO][00:21:09]: [93m[1m[Server #3350301] Global model perplexity: 42.35
[0m
[INFO][00:21:09]: [Server #3350301] All client reports have been processed.
[INFO][00:21:09]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_60.pth.
[INFO][00:21:10]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_60.pth.
[INFO][00:21:10]: [93m[1m
[Server #3350301] Starting round 61/100.[0m
[INFO][00:21:10]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][00:21:10]: [Server #3350301] Selecting client #6 for training.
[INFO][00:21:10]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:21:13]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:21:13]: [Server #3350301] Selecting client #3 for training.
[INFO][00:21:13]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:21:17]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:21:17]: [Client #6] Selected by the server.
[INFO][00:21:17]: [Client #6] Loading its data source...
[INFO][00:21:17]: [Client #6] Dataset size: 2018
[INFO][00:21:17]: [Client #6] Sampler: iid
[INFO][00:21:17]: [Client #3] Selected by the server.
[INFO][00:21:17]: [Client #3] Loading its data source...
[INFO][00:21:17]: [Client #3] Dataset size: 2018
[INFO][00:21:17]: [Client #3] Sampler: iid
[INFO][00:21:18]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:21:18]: [Client #6] Start to process inbound data.
[INFO][00:21:18]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:21:18]: [Client #3] Start to process inbound data.
[INFO][00:21:19]: [93m[1m[Client #3] Started training in communication round #61.[0m
[INFO][00:21:19]: [93m[1m[Client #6] Started training in communication round #61.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.69s/it]  2%|â–         | 1/48 [00:04<03:44,  4.77s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:22:05]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.637, 'train_samples_per_second': 152.736, 'train_steps_per_second': 1.211, 'train_loss': 2.864424387613932, 'epoch': 3.0}
[INFO][00:22:05]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.5923, 'train_samples_per_second': 152.908, 'train_steps_per_second': 1.212, 'train_loss': 2.3909271558125815, 'epoch': 3.0}
[INFO][00:22:06]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][00:22:06]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][00:22:06]: [Client #6] Model trained.
[INFO][00:22:07]: [Client #6] Inbound data has been processed.
[INFO][00:22:07]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][00:22:07]: [Client #3] Model trained.
[INFO][00:22:07]: [Client #3] Inbound data has been processed.
[INFO][00:22:07]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:22:13]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:22:13]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:22:14]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][00:22:15]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:22:15]: [Server #3350301] Selecting client #10 for training.
[INFO][00:22:15]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:22:19]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:22:19]: [Server #3350301] Selecting client #5 for training.
[INFO][00:22:19]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:22:23]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:22:23]: [Client #10] Selected by the server.
[INFO][00:22:23]: [Client #5] Selected by the server.
[INFO][00:22:23]: [Client #10] Loading its data source...
[INFO][00:22:23]: [Client #5] Loading its data source...
[INFO][00:22:23]: [Client #5] Dataset size: 2018
[INFO][00:22:23]: [Client #10] Dataset size: 2018
[INFO][00:22:23]: [Client #5] Sampler: iid
[INFO][00:22:23]: [Client #10] Sampler: iid
[INFO][00:22:24]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:22:24]: [Client #10] Start to process inbound data.
[INFO][00:22:24]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:22:24]: [Client #5] Start to process inbound data.
[INFO][00:22:24]: [93m[1m[Client #10] Started training in communication round #61.[0m
[INFO][00:22:24]: [93m[1m[Client #5] Started training in communication round #61.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.12s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  4%|â–         | 2/48 [00:05<01:46,  2.31s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:23:09]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.087, 'train_samples_per_second': 154.885, 'train_steps_per_second': 1.228, 'train_loss': 2.1325974464416504, 'epoch': 3.0}
[INFO][00:23:10]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.2423, 'train_samples_per_second': 154.272, 'train_steps_per_second': 1.223, 'train_loss': 2.687737782796224, 'epoch': 3.0}
[INFO][00:23:10]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:23:11]: [Client #5] Model trained.
[INFO][00:23:11]: [Client #5] Inbound data has been processed.
[INFO][00:23:11]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:23:11]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:23:11]: [Client #10] Model trained.
[INFO][00:23:11]: [Client #10] Inbound data has been processed.
[INFO][00:23:11]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:23:17]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:23:18]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:23:18]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:23:19]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:23:19]: [Server #3350301] Selecting client #9 for training.
[INFO][00:23:19]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:23:23]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:23:23]: [Client #9] Selected by the server.
[INFO][00:23:23]: [Client #9] Loading its data source...
[INFO][00:23:23]: [Client #9] Dataset size: 2018
[INFO][00:23:23]: [Client #9] Sampler: iid
[INFO][00:23:24]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:23:24]: [Client #9] Start to process inbound data.
[INFO][00:23:25]: [93m[1m[Client #9] Started training in communication round #61.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.15s/it]  4%|â–         | 2/48 [00:04<01:31,  1.99s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.30s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:23:57]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7108, 'train_samples_per_second': 226.65, 'train_steps_per_second': 1.797, 'train_loss': 2.201404253641764, 'epoch': 3.0}
[INFO][00:23:59]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:23:59]: [Client #9] Model trained.
[INFO][00:23:59]: [Client #9] Inbound data has been processed.
[INFO][00:23:59]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:24:03]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:24:04]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:24:04]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:24:04]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:24:04]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:24:04]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:24:04]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:24:04]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:24:04]: [Server #3350301] Updated weights have been received.
[INFO][00:24:05]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:24:05]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:24:05]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.89it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.68it/s]
[INFO][00:24:16]: [93m[1m[Server #3350301] Global model perplexity: 50.27
[0m
[INFO][00:24:16]: [Server #3350301] All client reports have been processed.
[INFO][00:24:16]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_61.pth.
[INFO][00:24:17]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_61.pth.
[INFO][00:24:17]: [93m[1m
[Server #3350301] Starting round 62/100.[0m
[INFO][00:24:17]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][00:24:17]: [Server #3350301] Selecting client #2 for training.
[INFO][00:24:17]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:24:20]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:24:20]: [Server #3350301] Selecting client #1 for training.
[INFO][00:24:20]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:24:24]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:24:24]: [Client #2] Selected by the server.
[INFO][00:24:24]: [Client #2] Loading its data source...
[INFO][00:24:24]: [Client #2] Dataset size: 2018
[INFO][00:24:24]: [Client #2] Sampler: iid
[INFO][00:24:24]: [Client #1] Selected by the server.
[INFO][00:24:24]: [Client #1] Loading its data source...
[INFO][00:24:24]: [Client #1] Dataset size: 2018
[INFO][00:24:24]: [Client #1] Sampler: iid
[INFO][00:24:26]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:24:26]: [Client #2] Start to process inbound data.
[INFO][00:24:26]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:24:26]: [Client #1] Start to process inbound data.
[INFO][00:24:26]: [93m[1m[Client #2] Started training in communication round #62.[0m
[INFO][00:24:26]: [93m[1m[Client #1] Started training in communication round #62.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.03s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:34,  2.05s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.16s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.07s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.23s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.00s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.10s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.04s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.01s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:35,  1.07it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:34,  1.08it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:30,  1.11it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:33,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:28,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:26,  1.17it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:30,  1.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:27,  1.04it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:29,  1.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:27,  1.01it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:28,  1.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:26,  1.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:24,  1.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:23,  1.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:21,  1.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:20,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:19,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.14it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:12,  1.10it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:12,  1.08it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:11,  1.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:10,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:09,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:02,  1.00s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.06it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.02it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
[INFO][00:25:19]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.228, 'train_samples_per_second': 128.187, 'train_steps_per_second': 1.016, 'train_loss': 1.8224318822224934, 'epoch': 3.0}
[INFO][00:25:20]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 47.5627, 'train_samples_per_second': 127.285, 'train_steps_per_second': 1.009, 'train_loss': 2.469102064768473, 'epoch': 3.0}
[INFO][00:25:21]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:25:21]: [Client #1] Model trained.
[INFO][00:25:21]: [Client #1] Inbound data has been processed.
[INFO][00:25:21]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:25:21]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:25:22]: [Client #2] Model trained.
[INFO][00:25:22]: [Client #2] Inbound data has been processed.
[INFO][00:25:22]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:25:26]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:25:27]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:25:27]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:25:28]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:25:28]: [Server #3350301] Selecting client #5 for training.
[INFO][00:25:28]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:25:32]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:25:32]: [Server #3350301] Selecting client #7 for training.
[INFO][00:25:32]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:25:36]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:25:36]: [Client #5] Selected by the server.
[INFO][00:25:36]: [Client #7] Selected by the server.
[INFO][00:25:36]: [Client #5] Loading its data source...
[INFO][00:25:36]: [Client #7] Loading its data source...
[INFO][00:25:36]: [Client #5] Dataset size: 2018
[INFO][00:25:36]: [Client #7] Dataset size: 2018
[INFO][00:25:36]: [Client #5] Sampler: iid
[INFO][00:25:36]: [Client #7] Sampler: iid
[INFO][00:25:37]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:25:37]: [Client #7] Start to process inbound data.
[INFO][00:25:37]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:25:37]: [Client #5] Start to process inbound data.
[INFO][00:25:38]: [93m[1m[Client #5] Started training in communication round #62.[0m
[INFO][00:25:38]: [93m[1m[Client #7] Started training in communication round #62.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:50,  4.90s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  4%|â–         | 2/48 [00:05<02:02,  2.66s/it]  8%|â–Š         | 4/48 [00:06<01:00,  1.38s/it]  6%|â–‹         | 3/48 [00:07<01:27,  1.95s/it] 10%|â–ˆ         | 5/48 [00:07<00:54,  1.27s/it]  8%|â–Š         | 4/48 [00:08<01:09,  1.58s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:49,  1.17s/it] 10%|â–ˆ         | 5/48 [00:09<00:57,  1.34s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.07s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.15s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.04s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:34,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:37,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:32,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:34,  1.13it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:30,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:31,  1.19it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:30,  1.22it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:27,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:28,  1.26it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:27,  1.29it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.30it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.35it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:25,  1.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:23,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:23,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:23,  1.32it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:15,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.36it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:13,  1.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.31it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:09,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:06,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.34it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.18it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.66it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.17it/s]
[INFO][00:26:25]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 40.5244, 'train_samples_per_second': 149.391, 'train_steps_per_second': 1.184, 'train_loss': 2.452270825703939, 'epoch': 3.0}
[INFO][00:26:25]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 40.9475, 'train_samples_per_second': 147.848, 'train_steps_per_second': 1.172, 'train_loss': 2.0997751553853354, 'epoch': 3.0}
[INFO][00:26:26]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:26:26]: [Client #7] Model trained.
[INFO][00:26:26]: [Client #7] Inbound data has been processed.
[INFO][00:26:26]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:26:26]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][00:26:27]: [Client #5] Model trained.
[INFO][00:26:27]: [Client #5] Inbound data has been processed.
[INFO][00:26:27]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:26:32]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:26:33]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:26:33]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:26:34]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:26:34]: [Server #3350301] Selecting client #9 for training.
[INFO][00:26:34]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:26:38]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:26:38]: [Client #9] Selected by the server.
[INFO][00:26:38]: [Client #9] Loading its data source...
[INFO][00:26:38]: [Client #9] Dataset size: 2018
[INFO][00:26:38]: [Client #9] Sampler: iid
[INFO][00:26:40]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:26:40]: [Client #9] Start to process inbound data.
[INFO][00:26:40]: [93m[1m[Client #9] Started training in communication round #62.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.99it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][00:27:13]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7483, 'train_samples_per_second': 226.332, 'train_steps_per_second': 1.795, 'train_loss': 2.174024740854899, 'epoch': 3.0}
[INFO][00:27:14]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:27:15]: [Client #9] Model trained.
[INFO][00:27:15]: [Client #9] Inbound data has been processed.
[INFO][00:27:15]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:27:19]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:27:20]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:27:20]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:27:20]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:27:20]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][00:27:20]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][00:27:20]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:27:20]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:27:20]: [Server #3350301] Updated weights have been received.
[INFO][00:27:20]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:27:21]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:27:21]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][00:27:32]: [93m[1m[Server #3350301] Global model perplexity: 45.04
[0m
[INFO][00:27:32]: [Server #3350301] All client reports have been processed.
[INFO][00:27:32]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_62.pth.
[INFO][00:27:32]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_62.pth.
[INFO][00:27:32]: [93m[1m
[Server #3350301] Starting round 63/100.[0m
[INFO][00:27:32]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][00:27:32]: [Server #3350301] Selecting client #4 for training.
[INFO][00:27:32]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:27:36]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:27:36]: [Server #3350301] Selecting client #1 for training.
[INFO][00:27:36]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:27:40]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:27:40]: [Client #4] Selected by the server.
[INFO][00:27:40]: [Client #4] Loading its data source...
[INFO][00:27:40]: [Client #4] Dataset size: 2018
[INFO][00:27:40]: [Client #4] Sampler: iid
[INFO][00:27:40]: [Client #1] Selected by the server.
[INFO][00:27:40]: [Client #1] Loading its data source...
[INFO][00:27:40]: [Client #1] Dataset size: 2018
[INFO][00:27:40]: [Client #1] Sampler: iid
[INFO][00:27:41]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:27:41]: [Client #4] Start to process inbound data.
[INFO][00:27:41]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:27:41]: [Client #1] Start to process inbound data.
[INFO][00:27:42]: [93m[1m[Client #1] Started training in communication round #63.[0m
[INFO][00:27:42]: [93m[1m[Client #4] Started training in communication round #63.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.26s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  4%|â–         | 2/48 [00:04<01:39,  2.16s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:28:27]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.1523, 'train_samples_per_second': 154.627, 'train_steps_per_second': 1.226, 'train_loss': 2.785994529724121, 'epoch': 3.0}
[INFO][00:28:28]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4936, 'train_samples_per_second': 153.291, 'train_steps_per_second': 1.215, 'train_loss': 1.7802244822184246, 'epoch': 3.0}
[INFO][00:28:28]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:28:29]: [Client #4] Model trained.
[INFO][00:28:29]: [Client #4] Inbound data has been processed.
[INFO][00:28:29]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:28:29]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:28:30]: [Client #1] Model trained.
[INFO][00:28:30]: [Client #1] Inbound data has been processed.
[INFO][00:28:30]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:28:35]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:28:35]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:28:36]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:28:37]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:28:37]: [Server #3350301] Selecting client #8 for training.
[INFO][00:28:37]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:28:40]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:28:40]: [Server #3350301] Selecting client #3 for training.
[INFO][00:28:40]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:28:44]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:28:44]: [Client #8] Selected by the server.
[INFO][00:28:44]: [Client #8] Loading its data source...
[INFO][00:28:44]: [Client #8] Dataset size: 2018
[INFO][00:28:44]: [Client #8] Sampler: iid
[INFO][00:28:44]: [Client #3] Selected by the server.
[INFO][00:28:44]: [Client #3] Loading its data source...
[INFO][00:28:44]: [Client #3] Dataset size: 2018
[INFO][00:28:44]: [Client #3] Sampler: iid
[INFO][00:28:45]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:28:45]: [Client #8] Start to process inbound data.
[INFO][00:28:45]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:28:45]: [Client #3] Start to process inbound data.
[INFO][00:28:46]: [93m[1m[Client #8] Started training in communication round #63.[0m
[INFO][00:28:46]: [93m[1m[Client #3] Started training in communication round #63.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:42,  4.74s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.47s/it]  4%|â–         | 2/48 [00:05<01:54,  2.48s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.16s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.41s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.05s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.25s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.00s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.15s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.06s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:37,  1.05it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.01s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:36,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:34,  1.07it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:34,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:29,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:33,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.04it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.14it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:24,  1.20it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:26,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:23,  1.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:24,  1.22it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:21,  1.28it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:23,  1.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.30it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:21,  1.28it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.31it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:20,  1.29it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:19,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:12,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:11,  1.36it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:13,  1.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.33it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:31<00:10,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.16it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.66it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.15it/s]
[INFO][00:29:33]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 41.4016, 'train_samples_per_second': 146.226, 'train_steps_per_second': 1.159, 'train_loss': 2.35835599899292, 'epoch': 3.0}
[INFO][00:29:34]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 41.905, 'train_samples_per_second': 144.47, 'train_steps_per_second': 1.145, 'train_loss': 2.8388086954752603, 'epoch': 3.0}
[INFO][00:29:34]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][00:29:35]: [Client #3] Model trained.
[INFO][00:29:35]: [Client #3] Inbound data has been processed.
[INFO][00:29:35]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:29:35]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:29:36]: [Client #8] Model trained.
[INFO][00:29:36]: [Client #8] Inbound data has been processed.
[INFO][00:29:36]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:29:41]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:29:41]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:29:42]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:29:43]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:29:43]: [Server #3350301] Selecting client #10 for training.
[INFO][00:29:43]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:29:47]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:29:47]: [Client #10] Selected by the server.
[INFO][00:29:47]: [Client #10] Loading its data source...
[INFO][00:29:47]: [Client #10] Dataset size: 2018
[INFO][00:29:47]: [Client #10] Sampler: iid
[INFO][00:29:48]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:29:48]: [Client #10] Start to process inbound data.
[INFO][00:29:48]: [93m[1m[Client #10] Started training in communication round #63.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:30:21]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.7214, 'train_samples_per_second': 226.56, 'train_steps_per_second': 1.796, 'train_loss': 2.641239802042643, 'epoch': 3.0}
[INFO][00:30:22]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:30:23]: [Client #10] Model trained.
[INFO][00:30:23]: [Client #10] Inbound data has been processed.
[INFO][00:30:23]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:30:27]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:30:28]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:30:28]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:30:28]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:30:28]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:30:28]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:30:28]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:30:28]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:30:28]: [Server #3350301] Updated weights have been received.
[INFO][00:30:28]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:30:29]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:30:29]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.81it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.55it/s]
[INFO][00:30:40]: [93m[1m[Server #3350301] Global model perplexity: 45.99
[0m
[INFO][00:30:40]: [Server #3350301] All client reports have been processed.
[INFO][00:30:40]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_63.pth.
[INFO][00:30:40]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_63.pth.
[INFO][00:30:40]: [93m[1m
[Server #3350301] Starting round 64/100.[0m
[INFO][00:30:40]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][00:30:40]: [Server #3350301] Selecting client #2 for training.
[INFO][00:30:40]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:30:44]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:30:44]: [Server #3350301] Selecting client #5 for training.
[INFO][00:30:44]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:30:48]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:30:48]: [Client #2] Selected by the server.
[INFO][00:30:48]: [Client #2] Loading its data source...
[INFO][00:30:48]: [Client #2] Dataset size: 2018
[INFO][00:30:48]: [Client #2] Sampler: iid
[INFO][00:30:48]: [Client #5] Selected by the server.
[INFO][00:30:48]: [Client #5] Loading its data source...
[INFO][00:30:48]: [Client #5] Dataset size: 2018
[INFO][00:30:48]: [Client #5] Sampler: iid
[INFO][00:30:49]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:30:49]: [Client #5] Start to process inbound data.
[INFO][00:30:49]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:30:49]: [Client #2] Start to process inbound data.
[INFO][00:30:50]: [93m[1m[Client #5] Started training in communication round #64.[0m
[INFO][00:30:50]: [93m[1m[Client #2] Started training in communication round #64.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.57s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
[INFO][00:31:36]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 38.9073, 'train_samples_per_second': 155.6, 'train_steps_per_second': 1.234, 'train_loss': 2.428053061167399, 'epoch': 3.0}
[INFO][00:31:36]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.23, 'train_samples_per_second': 154.321, 'train_steps_per_second': 1.224, 'train_loss': 2.044635772705078, 'epoch': 3.0}
[INFO][00:31:37]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:31:37]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:31:37]: [Client #2] Model trained.
[INFO][00:31:37]: [Client #2] Inbound data has been processed.
[INFO][00:31:37]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:31:38]: [Client #5] Model trained.
[INFO][00:31:38]: [Client #5] Inbound data has been processed.
[INFO][00:31:38]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:31:44]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:31:44]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:31:45]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:31:46]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:31:46]: [Server #3350301] Selecting client #6 for training.
[INFO][00:31:46]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:31:50]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:31:50]: [Server #3350301] Selecting client #7 for training.
[INFO][00:31:50]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:31:53]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:31:53]: [Client #6] Selected by the server.
[INFO][00:31:53]: [Client #7] Selected by the server.
[INFO][00:31:53]: [Client #6] Loading its data source...
[INFO][00:31:53]: [Client #7] Loading its data source...
[INFO][00:31:53]: [Client #6] Dataset size: 2018
[INFO][00:31:53]: [Client #7] Dataset size: 2018
[INFO][00:31:53]: [Client #6] Sampler: iid
[INFO][00:31:53]: [Client #7] Sampler: iid
[INFO][00:31:55]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:31:55]: [Client #6] Start to process inbound data.
[INFO][00:31:55]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:31:55]: [Client #7] Start to process inbound data.
[INFO][00:31:55]: [93m[1m[Client #6] Started training in communication round #64.[0m
[INFO][00:31:56]: [93m[1m[Client #7] Started training in communication round #64.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:11,  4.08s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.08s/it]  2%|â–         | 1/48 [00:04<03:38,  4.66s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.53s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.05s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:32:41]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.167, 'train_samples_per_second': 154.569, 'train_steps_per_second': 1.226, 'train_loss': 2.4180148442586265, 'epoch': 3.0}
[INFO][00:32:42]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.6105, 'train_samples_per_second': 152.838, 'train_steps_per_second': 1.212, 'train_loss': 2.8375066121419272, 'epoch': 3.0}
[INFO][00:32:42]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:32:42]: [Client #7] Model trained.
[INFO][00:32:42]: [Client #7] Inbound data has been processed.
[INFO][00:32:42]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:32:43]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][00:32:43]: [Client #6] Model trained.
[INFO][00:32:43]: [Client #6] Inbound data has been processed.
[INFO][00:32:43]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][00:32:48]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:32:49]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:32:49]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:32:50]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][00:32:50]: [Server #3350301] Selecting client #9 for training.
[INFO][00:32:50]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:32:53]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:32:53]: [Client #9] Selected by the server.
[INFO][00:32:53]: [Client #9] Loading its data source...
[INFO][00:32:53]: [Client #9] Dataset size: 2018
[INFO][00:32:53]: [Client #9] Sampler: iid
[INFO][00:32:55]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:32:55]: [Client #9] Start to process inbound data.
[INFO][00:32:55]: [93m[1m[Client #9] Started training in communication round #64.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][00:33:28]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7809, 'train_samples_per_second': 226.057, 'train_steps_per_second': 1.792, 'train_loss': 2.111049016316732, 'epoch': 3.0}
[INFO][00:33:29]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:33:30]: [Client #9] Model trained.
[INFO][00:33:30]: [Client #9] Inbound data has been processed.
[INFO][00:33:30]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:33:34]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:33:35]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:33:35]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:33:35]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:33:35]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:33:35]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:33:35]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:33:35]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:33:35]: [Server #3350301] Updated weights have been received.
[INFO][00:33:36]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:33:36]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:33:36]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.95it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.62it/s]
[INFO][00:33:47]: [93m[1m[Server #3350301] Global model perplexity: 52.13
[0m
[INFO][00:33:47]: [Server #3350301] All client reports have been processed.
[INFO][00:33:47]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_64.pth.
[INFO][00:33:48]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_64.pth.
[INFO][00:33:48]: [93m[1m
[Server #3350301] Starting round 65/100.[0m
[INFO][00:33:48]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][00:33:48]: [Server #3350301] Selecting client #10 for training.
[INFO][00:33:48]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:33:51]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:33:51]: [Server #3350301] Selecting client #1 for training.
[INFO][00:33:51]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:33:55]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:33:55]: [Client #10] Selected by the server.
[INFO][00:33:55]: [Client #10] Loading its data source...
[INFO][00:33:55]: [Client #10] Dataset size: 2018
[INFO][00:33:55]: [Client #1] Selected by the server.
[INFO][00:33:55]: [Client #10] Sampler: iid
[INFO][00:33:55]: [Client #1] Loading its data source...
[INFO][00:33:55]: [Client #1] Dataset size: 2018
[INFO][00:33:55]: [Client #1] Sampler: iid
[INFO][00:33:56]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:33:56]: [Client #10] Start to process inbound data.
[INFO][00:33:56]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:33:56]: [Client #1] Start to process inbound data.
[INFO][00:33:57]: [93m[1m[Client #1] Started training in communication round #65.[0m
[INFO][00:33:57]: [93m[1m[Client #10] Started training in communication round #65.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.69s/it]  2%|â–         | 1/48 [00:04<03:42,  4.73s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:34:43]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.5283, 'train_samples_per_second': 153.156, 'train_steps_per_second': 1.214, 'train_loss': 2.5935861269632974, 'epoch': 3.0}
[INFO][00:34:43]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4737, 'train_samples_per_second': 153.368, 'train_steps_per_second': 1.216, 'train_loss': 1.7418971061706543, 'epoch': 3.0}
[INFO][00:34:44]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:34:44]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:34:45]: [Client #10] Model trained.
[INFO][00:34:45]: [Client #10] Inbound data has been processed.
[INFO][00:34:45]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:34:45]: [Client #1] Model trained.
[INFO][00:34:45]: [Client #1] Inbound data has been processed.
[INFO][00:34:45]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:34:51]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:34:51]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:34:51]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:34:52]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:34:52]: [Server #3350301] Selecting client #3 for training.
[INFO][00:34:52]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:34:56]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:34:56]: [Server #3350301] Selecting client #5 for training.
[INFO][00:34:56]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:35:00]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:35:00]: [Client #3] Selected by the server.
[INFO][00:35:00]: [Client #3] Loading its data source...
[INFO][00:35:00]: [Client #3] Dataset size: 2018
[INFO][00:35:00]: [Client #3] Sampler: iid
[INFO][00:35:00]: [Client #5] Selected by the server.
[INFO][00:35:00]: [Client #5] Loading its data source...
[INFO][00:35:00]: [Client #5] Dataset size: 2018
[INFO][00:35:00]: [Client #5] Sampler: iid
[INFO][00:35:01]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:35:01]: [Client #5] Start to process inbound data.
[INFO][00:35:01]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:35:01]: [Client #3] Start to process inbound data.
[INFO][00:35:02]: [93m[1m[Client #3] Started training in communication round #65.[0m
[INFO][00:35:02]: [93m[1m[Client #5] Started training in communication round #65.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:29,  4.46s/it]  2%|â–         | 1/48 [00:05<03:58,  5.06s/it]  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  4%|â–         | 2/48 [00:05<01:57,  2.54s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:08<00:49,  1.14s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.01s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][00:35:48]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.4437, 'train_samples_per_second': 153.485, 'train_steps_per_second': 1.217, 'train_loss': 2.0039416948954263, 'epoch': 3.0}
[INFO][00:35:48]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.9349, 'train_samples_per_second': 151.597, 'train_steps_per_second': 1.202, 'train_loss': 2.312446435292562, 'epoch': 3.0}
[INFO][00:35:49]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:35:49]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][00:35:49]: [Client #5] Model trained.
[INFO][00:35:49]: [Client #5] Inbound data has been processed.
[INFO][00:35:49]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:35:50]: [Client #3] Model trained.
[INFO][00:35:50]: [Client #3] Inbound data has been processed.
[INFO][00:35:50]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:35:55]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:35:55]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:35:56]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:35:57]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:35:57]: [Server #3350301] Selecting client #9 for training.
[INFO][00:35:57]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:36:01]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:36:01]: [Client #9] Selected by the server.
[INFO][00:36:01]: [Client #9] Loading its data source...
[INFO][00:36:01]: [Client #9] Dataset size: 2018
[INFO][00:36:01]: [Client #9] Sampler: iid
[INFO][00:36:02]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:36:02]: [Client #9] Start to process inbound data.
[INFO][00:36:02]: [93m[1m[Client #9] Started training in communication round #65.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.00s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.41it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.55it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.68it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.84it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.89it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.94it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:27<00:00,  1.78it/s]
[INFO][00:36:36]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 27.0318, 'train_samples_per_second': 223.959, 'train_steps_per_second': 1.776, 'train_loss': 2.085134824117025, 'epoch': 3.0}
[INFO][00:36:37]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:36:37]: [Client #9] Model trained.
[INFO][00:36:37]: [Client #9] Inbound data has been processed.
[INFO][00:36:37]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:36:41]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:36:42]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:36:42]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:36:42]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:36:42]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][00:36:42]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][00:36:42]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:36:42]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:36:42]: [Server #3350301] Updated weights have been received.
[INFO][00:36:43]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:36:44]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:36:44]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.94it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.77it/s]
[INFO][00:36:54]: [93m[1m[Server #3350301] Global model perplexity: 48.37
[0m
[INFO][00:36:54]: [Server #3350301] All client reports have been processed.
[INFO][00:36:55]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_65.pth.
[INFO][00:36:55]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_65.pth.
[INFO][00:36:55]: [93m[1m
[Server #3350301] Starting round 66/100.[0m
[INFO][00:36:55]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][00:36:55]: [Server #3350301] Selecting client #2 for training.
[INFO][00:36:55]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:36:59]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:36:59]: [Server #3350301] Selecting client #1 for training.
[INFO][00:36:59]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:37:03]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:37:03]: [Client #2] Selected by the server.
[INFO][00:37:03]: [Client #2] Loading its data source...
[INFO][00:37:03]: [Client #2] Dataset size: 2018
[INFO][00:37:03]: [Client #2] Sampler: iid
[INFO][00:37:03]: [Client #1] Selected by the server.
[INFO][00:37:03]: [Client #1] Loading its data source...
[INFO][00:37:03]: [Client #1] Dataset size: 2018
[INFO][00:37:03]: [Client #1] Sampler: iid
[INFO][00:37:04]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:37:04]: [Client #2] Start to process inbound data.
[INFO][00:37:04]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:37:04]: [Client #1] Start to process inbound data.
[INFO][00:37:05]: [93m[1m[Client #2] Started training in communication round #66.[0m
[INFO][00:37:05]: [93m[1m[Client #1] Started training in communication round #66.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:23,  4.33s/it]  2%|â–         | 1/48 [00:04<03:53,  4.97s/it]  4%|â–         | 2/48 [00:05<01:47,  2.34s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.71s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.38s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.45s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.20s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.25s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:46,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.13s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.06s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.08s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.01s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.00s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.08it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:35,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:28,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:26,  1.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:25,  1.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.12it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:17,  1.14it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:17,  1.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:15,  1.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:14,  1.01it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.05it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:14,  1.02s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.00it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.00s/it]
[INFO][00:37:59]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.7819, 'train_samples_per_second': 126.701, 'train_steps_per_second': 1.005, 'train_loss': 1.6986072858174641, 'epoch': 3.0}
[INFO][00:37:59]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 48.0779, 'train_samples_per_second': 125.921, 'train_steps_per_second': 0.998, 'train_loss': 2.3810208638509116, 'epoch': 3.0}
[INFO][00:38:00]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:38:00]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:38:00]: [Client #1] Model trained.
[INFO][00:38:00]: [Client #1] Inbound data has been processed.
[INFO][00:38:00]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:38:01]: [Client #2] Model trained.
[INFO][00:38:01]: [Client #2] Inbound data has been processed.
[INFO][00:38:01]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:38:06]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:38:07]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:38:07]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:38:08]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:38:08]: [Server #3350301] Selecting client #4 for training.
[INFO][00:38:08]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:38:12]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:38:12]: [Server #3350301] Selecting client #7 for training.
[INFO][00:38:12]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:38:16]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:38:16]: [Client #4] Selected by the server.
[INFO][00:38:16]: [Client #4] Loading its data source...
[INFO][00:38:16]: [Client #7] Selected by the server.
[INFO][00:38:16]: [Client #7] Loading its data source...
[INFO][00:38:16]: [Client #4] Dataset size: 2018
[INFO][00:38:16]: [Client #4] Sampler: iid
[INFO][00:38:16]: [Client #7] Dataset size: 2018
[INFO][00:38:16]: [Client #7] Sampler: iid
[INFO][00:38:17]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:38:17]: [Client #7] Start to process inbound data.
[INFO][00:38:17]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:38:17]: [Client #4] Start to process inbound data.
[INFO][00:38:18]: [93m[1m[Client #7] Started training in communication round #66.[0m
[INFO][00:38:18]: [93m[1m[Client #4] Started training in communication round #66.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  2%|â–         | 1/48 [00:04<03:48,  4.86s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  4%|â–         | 2/48 [00:05<01:53,  2.48s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][00:39:04]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.9446, 'train_samples_per_second': 151.56, 'train_steps_per_second': 1.202, 'train_loss': 2.3870609601338706, 'epoch': 3.0}
[INFO][00:39:04]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.8235, 'train_samples_per_second': 152.021, 'train_steps_per_second': 1.205, 'train_loss': 2.7626431783040366, 'epoch': 3.0}
[INFO][00:39:05]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:39:05]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:39:06]: [Client #7] Model trained.
[INFO][00:39:06]: [Client #7] Inbound data has been processed.
[INFO][00:39:06]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:39:06]: [Client #4] Model trained.
[INFO][00:39:06]: [Client #4] Inbound data has been processed.
[INFO][00:39:06]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:39:12]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:39:12]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:39:13]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:39:14]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:39:14]: [Server #3350301] Selecting client #8 for training.
[INFO][00:39:14]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:39:18]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:39:18]: [Client #8] Selected by the server.
[INFO][00:39:18]: [Client #8] Loading its data source...
[INFO][00:39:18]: [Client #8] Dataset size: 2018
[INFO][00:39:18]: [Client #8] Sampler: iid
[INFO][00:39:19]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:39:19]: [Client #8] Start to process inbound data.
[INFO][00:39:20]: [93m[1m[Client #8] Started training in communication round #66.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][00:39:53]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.8321, 'train_samples_per_second': 225.626, 'train_steps_per_second': 1.789, 'train_loss': 2.820958137512207, 'epoch': 3.0}
[INFO][00:39:54]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:39:54]: [Client #8] Model trained.
[INFO][00:39:54]: [Client #8] Inbound data has been processed.
[INFO][00:39:54]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:39:58]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:39:59]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:39:59]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:39:59]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:39:59]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:39:59]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:39:59]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:39:59]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:39:59]: [Server #3350301] Updated weights have been received.
[INFO][00:39:59]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:40:00]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:40:00]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.79it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.74it/s]
[INFO][00:40:11]: [93m[1m[Server #3350301] Global model perplexity: 48.03
[0m
[INFO][00:40:11]: [Server #3350301] All client reports have been processed.
[INFO][00:40:11]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_66.pth.
[INFO][00:40:11]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_66.pth.
[INFO][00:40:11]: [93m[1m
[Server #3350301] Starting round 67/100.[0m
[INFO][00:40:11]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][00:40:11]: [Server #3350301] Selecting client #6 for training.
[INFO][00:40:11]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:40:15]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:40:15]: [Server #3350301] Selecting client #3 for training.
[INFO][00:40:15]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:40:19]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:40:19]: [Client #6] Selected by the server.
[INFO][00:40:19]: [Client #6] Loading its data source...
[INFO][00:40:19]: [Client #6] Dataset size: 2018
[INFO][00:40:19]: [Client #6] Sampler: iid
[INFO][00:40:19]: [Client #3] Selected by the server.
[INFO][00:40:19]: [Client #3] Loading its data source...
[INFO][00:40:19]: [Client #3] Dataset size: 2018
[INFO][00:40:19]: [Client #3] Sampler: iid
[INFO][00:40:20]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:40:20]: [Client #3] Start to process inbound data.
[INFO][00:40:20]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:40:20]: [Client #6] Start to process inbound data.
[INFO][00:40:21]: [93m[1m[Client #6] Started training in communication round #67.[0m
[INFO][00:40:21]: [93m[1m[Client #3] Started training in communication round #67.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:31,  4.50s/it]  2%|â–         | 1/48 [00:04<03:44,  4.77s/it]  4%|â–         | 2/48 [00:05<01:45,  2.29s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:41:06]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.4157, 'train_samples_per_second': 153.594, 'train_steps_per_second': 1.218, 'train_loss': 2.2707347869873047, 'epoch': 3.0}
[INFO][00:41:07]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.5918, 'train_samples_per_second': 152.91, 'train_steps_per_second': 1.212, 'train_loss': 2.81407101949056, 'epoch': 3.0}
[INFO][00:41:07]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][00:41:08]: [Client #3] Model trained.
[INFO][00:41:08]: [Client #3] Inbound data has been processed.
[INFO][00:41:08]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:41:08]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][00:41:08]: [Client #6] Model trained.
[INFO][00:41:08]: [Client #6] Inbound data has been processed.
[INFO][00:41:08]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][00:41:14]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:41:14]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:41:15]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:41:16]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][00:41:16]: [Server #3350301] Selecting client #10 for training.
[INFO][00:41:16]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:41:20]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:41:20]: [Server #3350301] Selecting client #5 for training.
[INFO][00:41:20]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:41:24]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:41:24]: [Client #10] Selected by the server.
[INFO][00:41:24]: [Client #10] Loading its data source...
[INFO][00:41:24]: [Client #5] Selected by the server.
[INFO][00:41:24]: [Client #5] Loading its data source...
[INFO][00:41:24]: [Client #10] Dataset size: 2018
[INFO][00:41:24]: [Client #10] Sampler: iid
[INFO][00:41:24]: [Client #5] Dataset size: 2018
[INFO][00:41:24]: [Client #5] Sampler: iid
[INFO][00:41:25]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:41:25]: [Client #10] Start to process inbound data.
[INFO][00:41:25]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:41:25]: [Client #5] Start to process inbound data.
[INFO][00:41:26]: [93m[1m[Client #10] Started training in communication round #67.[0m
[INFO][00:41:26]: [93m[1m[Client #5] Started training in communication round #67.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:51,  4.93s/it]  2%|â–         | 1/48 [00:04<03:53,  4.97s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  4%|â–         | 2/48 [00:05<02:00,  2.63s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.83s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.43s/it] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.16s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:42,  1.02s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.05it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.13it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:31,  1.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.18it/s]
[INFO][00:42:13]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 40.3782, 'train_samples_per_second': 149.932, 'train_steps_per_second': 1.189, 'train_loss': 1.9533422787984211, 'epoch': 3.0}
[INFO][00:42:13]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 40.5096, 'train_samples_per_second': 149.446, 'train_steps_per_second': 1.185, 'train_loss': 2.5745577812194824, 'epoch': 3.0}
[INFO][00:42:14]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:42:15]: [Client #5] Model trained.
[INFO][00:42:15]: [Client #5] Inbound data has been processed.
[INFO][00:42:15]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:42:15]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:42:15]: [Client #10] Model trained.
[INFO][00:42:15]: [Client #10] Inbound data has been processed.
[INFO][00:42:15]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:42:20]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:42:21]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:42:21]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:42:22]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:42:22]: [Server #3350301] Selecting client #9 for training.
[INFO][00:42:22]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:42:26]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:42:26]: [Client #9] Selected by the server.
[INFO][00:42:26]: [Client #9] Loading its data source...
[INFO][00:42:26]: [Client #9] Dataset size: 2018
[INFO][00:42:26]: [Client #9] Sampler: iid
[INFO][00:42:27]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:42:27]: [Client #9] Start to process inbound data.
[INFO][00:42:27]: [93m[1m[Client #9] Started training in communication round #67.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.15it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][00:43:00]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.9309, 'train_samples_per_second': 224.797, 'train_steps_per_second': 1.782, 'train_loss': 2.0361345609029136, 'epoch': 3.0}
[INFO][00:43:02]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:43:02]: [Client #9] Model trained.
[INFO][00:43:02]: [Client #9] Inbound data has been processed.
[INFO][00:43:02]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:43:06]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:43:07]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:43:07]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:43:07]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:43:07]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:43:07]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:43:07]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:43:07]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:43:07]: [Server #3350301] Updated weights have been received.
[INFO][00:43:07]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:43:08]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:43:08]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.13it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.68it/s]
[INFO][00:43:19]: [93m[1m[Server #3350301] Global model perplexity: 56.07
[0m
[INFO][00:43:19]: [Server #3350301] All client reports have been processed.
[INFO][00:43:19]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_67.pth.
[INFO][00:43:19]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_67.pth.
[INFO][00:43:19]: [93m[1m
[Server #3350301] Starting round 68/100.[0m
[INFO][00:43:19]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][00:43:19]: [Server #3350301] Selecting client #2 for training.
[INFO][00:43:19]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:43:23]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:43:23]: [Server #3350301] Selecting client #1 for training.
[INFO][00:43:23]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:43:27]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:43:27]: [Client #2] Selected by the server.
[INFO][00:43:27]: [Client #2] Loading its data source...
[INFO][00:43:27]: [Client #2] Dataset size: 2018
[INFO][00:43:27]: [Client #2] Sampler: iid
[INFO][00:43:27]: [Client #1] Selected by the server.
[INFO][00:43:27]: [Client #1] Loading its data source...
[INFO][00:43:27]: [Client #1] Dataset size: 2018
[INFO][00:43:27]: [Client #1] Sampler: iid
[INFO][00:43:29]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:43:29]: [Client #2] Start to process inbound data.
[INFO][00:43:29]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:43:29]: [Client #1] Start to process inbound data.
[INFO][00:43:29]: [93m[1m[Client #2] Started training in communication round #68.[0m
[INFO][00:43:29]: [93m[1m[Client #1] Started training in communication round #68.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  2%|â–         | 1/48 [00:04<03:38,  4.65s/it]  4%|â–         | 2/48 [00:05<01:46,  2.31s/it]  4%|â–         | 2/48 [00:05<01:54,  2.48s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.80s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.47s/it] 10%|â–ˆ         | 5/48 [00:07<00:51,  1.21s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.26s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.05s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.10s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:40,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:36,  1.10it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:31,  1.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.26it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:27,  1.28it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][00:44:16]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 40.3405, 'train_samples_per_second': 150.072, 'train_steps_per_second': 1.19, 'train_loss': 2.364719867706299, 'epoch': 3.0}
[INFO][00:44:16]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.8274, 'train_samples_per_second': 152.006, 'train_steps_per_second': 1.205, 'train_loss': 1.7127054532368977, 'epoch': 3.0}
[INFO][00:44:17]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:44:17]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:44:18]: [Client #2] Model trained.
[INFO][00:44:18]: [Client #2] Inbound data has been processed.
[INFO][00:44:18]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:44:18]: [Client #1] Model trained.
[INFO][00:44:18]: [Client #1] Inbound data has been processed.
[INFO][00:44:18]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:44:24]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:44:24]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:44:25]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:44:26]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:44:26]: [Server #3350301] Selecting client #5 for training.
[INFO][00:44:26]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:44:30]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:44:30]: [Server #3350301] Selecting client #7 for training.
[INFO][00:44:30]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:44:34]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:44:34]: [Client #5] Selected by the server.
[INFO][00:44:34]: [Client #7] Selected by the server.
[INFO][00:44:34]: [Client #5] Loading its data source...
[INFO][00:44:34]: [Client #7] Loading its data source...
[INFO][00:44:34]: [Client #7] Dataset size: 2018
[INFO][00:44:34]: [Client #5] Dataset size: 2018
[INFO][00:44:34]: [Client #7] Sampler: iid
[INFO][00:44:34]: [Client #5] Sampler: iid
[INFO][00:44:35]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:44:35]: [Client #7] Start to process inbound data.
[INFO][00:44:35]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:44:35]: [Client #5] Start to process inbound data.
[INFO][00:44:36]: [93m[1m[Client #7] Started training in communication round #68.[0m
[INFO][00:44:36]: [93m[1m[Client #5] Started training in communication round #68.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.16s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  4%|â–         | 2/48 [00:04<01:38,  2.13s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:45:21]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.0838, 'train_samples_per_second': 154.898, 'train_steps_per_second': 1.228, 'train_loss': 2.3302907943725586, 'epoch': 3.0}
[INFO][00:45:22]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.4521, 'train_samples_per_second': 153.452, 'train_steps_per_second': 1.217, 'train_loss': 1.9487822850545247, 'epoch': 3.0}
[INFO][00:45:22]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:45:23]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][00:45:23]: [Client #7] Model trained.
[INFO][00:45:23]: [Client #7] Inbound data has been processed.
[INFO][00:45:23]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:45:23]: [Client #5] Model trained.
[INFO][00:45:23]: [Client #5] Inbound data has been processed.
[INFO][00:45:23]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:45:29]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:45:30]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:45:30]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:45:31]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:45:31]: [Server #3350301] Selecting client #9 for training.
[INFO][00:45:31]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:45:35]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:45:35]: [Client #9] Selected by the server.
[INFO][00:45:35]: [Client #9] Loading its data source...
[INFO][00:45:35]: [Client #9] Dataset size: 2018
[INFO][00:45:35]: [Client #9] Sampler: iid
[INFO][00:45:36]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:45:36]: [Client #9] Start to process inbound data.
[INFO][00:45:36]: [93m[1m[Client #9] Started training in communication round #68.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][00:46:09]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7154, 'train_samples_per_second': 226.611, 'train_steps_per_second': 1.797, 'train_loss': 2.011956214904785, 'epoch': 3.0}
[INFO][00:46:10]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:46:11]: [Client #9] Model trained.
[INFO][00:46:11]: [Client #9] Inbound data has been processed.
[INFO][00:46:11]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:46:15]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:46:16]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:46:16]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:46:16]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:46:16]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][00:46:16]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][00:46:16]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:46:16]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:46:16]: [Server #3350301] Updated weights have been received.
[INFO][00:46:17]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:46:17]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:46:17]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.15it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.45it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.80it/s]
[INFO][00:46:28]: [93m[1m[Server #3350301] Global model perplexity: 50.02
[0m
[INFO][00:46:28]: [Server #3350301] All client reports have been processed.
[INFO][00:46:28]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_68.pth.
[INFO][00:46:29]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_68.pth.
[INFO][00:46:29]: [93m[1m
[Server #3350301] Starting round 69/100.[0m
[INFO][00:46:29]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][00:46:29]: [Server #3350301] Selecting client #4 for training.
[INFO][00:46:29]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:46:33]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:46:33]: [Server #3350301] Selecting client #1 for training.
[INFO][00:46:33]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:46:36]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:46:36]: [Client #4] Selected by the server.
[INFO][00:46:36]: [Client #4] Loading its data source...
[INFO][00:46:36]: [Client #4] Dataset size: 2018
[INFO][00:46:36]: [Client #4] Sampler: iid
[INFO][00:46:36]: [Client #1] Selected by the server.
[INFO][00:46:36]: [Client #1] Loading its data source...
[INFO][00:46:36]: [Client #1] Dataset size: 2018
[INFO][00:46:36]: [Client #1] Sampler: iid
[INFO][00:46:38]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:46:38]: [Client #1] Start to process inbound data.
[INFO][00:46:38]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:46:38]: [Client #4] Start to process inbound data.
[INFO][00:46:38]: [93m[1m[Client #4] Started training in communication round #69.[0m
[INFO][00:46:38]: [93m[1m[Client #1] Started training in communication round #69.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.12s/it]  2%|â–         | 1/48 [00:04<03:46,  4.82s/it]  4%|â–         | 2/48 [00:04<01:36,  2.10s/it]  4%|â–         | 2/48 [00:05<01:55,  2.51s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.36s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:37,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:47:24]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.2764, 'train_samples_per_second': 154.138, 'train_steps_per_second': 1.222, 'train_loss': 1.6861526171366374, 'epoch': 3.0}
[INFO][00:47:24]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.679, 'train_samples_per_second': 152.575, 'train_steps_per_second': 1.21, 'train_loss': 2.7506275177001953, 'epoch': 3.0}
[INFO][00:47:25]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:47:25]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:47:26]: [Client #1] Model trained.
[INFO][00:47:26]: [Client #1] Inbound data has been processed.
[INFO][00:47:26]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:47:26]: [Client #4] Model trained.
[INFO][00:47:26]: [Client #4] Inbound data has been processed.
[INFO][00:47:26]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:47:31]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:47:32]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:47:33]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:47:33]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:47:33]: [Server #3350301] Selecting client #8 for training.
[INFO][00:47:33]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:47:37]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:47:37]: [Server #3350301] Selecting client #3 for training.
[INFO][00:47:37]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:47:41]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:47:41]: [Client #8] Selected by the server.
[INFO][00:47:41]: [Client #8] Loading its data source...
[INFO][00:47:41]: [Client #3] Selected by the server.
[INFO][00:47:41]: [Client #3] Loading its data source...
[INFO][00:47:41]: [Client #8] Dataset size: 2018
[INFO][00:47:41]: [Client #8] Sampler: iid
[INFO][00:47:41]: [Client #3] Dataset size: 2018
[INFO][00:47:41]: [Client #3] Sampler: iid
[INFO][00:47:42]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:47:42]: [Client #3] Start to process inbound data.
[INFO][00:47:42]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:47:42]: [Client #8] Start to process inbound data.
[INFO][00:47:43]: [93m[1m[Client #3] Started training in communication round #69.[0m
[INFO][00:47:43]: [93m[1m[Client #8] Started training in communication round #69.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.38s/it]  2%|â–         | 1/48 [00:04<03:49,  4.88s/it]  4%|â–         | 2/48 [00:05<01:42,  2.23s/it]  4%|â–         | 2/48 [00:05<01:53,  2.47s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.69s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.00it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.27it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.33it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.30it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][00:48:29]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.5345, 'train_samples_per_second': 153.132, 'train_steps_per_second': 1.214, 'train_loss': 2.7982142766316733, 'epoch': 3.0}
[INFO][00:48:29]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.8987, 'train_samples_per_second': 151.734, 'train_steps_per_second': 1.203, 'train_loss': 2.2414490381876626, 'epoch': 3.0}
[INFO][00:48:30]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:48:30]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][00:48:31]: [Client #8] Model trained.
[INFO][00:48:31]: [Client #8] Inbound data has been processed.
[INFO][00:48:31]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:48:31]: [Client #3] Model trained.
[INFO][00:48:31]: [Client #3] Inbound data has been processed.
[INFO][00:48:31]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:48:37]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:48:37]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:48:38]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:48:39]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:48:39]: [Server #3350301] Selecting client #10 for training.
[INFO][00:48:39]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:48:43]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:48:43]: [Client #10] Selected by the server.
[INFO][00:48:43]: [Client #10] Loading its data source...
[INFO][00:48:43]: [Client #10] Dataset size: 2018
[INFO][00:48:43]: [Client #10] Sampler: iid
[INFO][00:48:44]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:48:44]: [Client #10] Start to process inbound data.
[INFO][00:48:44]: [93m[1m[Client #10] Started training in communication round #69.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.00s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.96it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][00:49:17]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.9081, 'train_samples_per_second': 224.988, 'train_steps_per_second': 1.784, 'train_loss': 2.5265841484069824, 'epoch': 3.0}
[INFO][00:49:18]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:49:19]: [Client #10] Model trained.
[INFO][00:49:19]: [Client #10] Inbound data has been processed.
[INFO][00:49:19]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:49:23]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:49:24]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:49:24]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:49:24]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:49:24]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:49:24]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:49:24]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:49:24]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:49:24]: [Server #3350301] Updated weights have been received.
[INFO][00:49:24]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:49:25]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:49:25]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.23it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.46it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.80it/s]
[INFO][00:49:36]: [93m[1m[Server #3350301] Global model perplexity: 51.41
[0m
[INFO][00:49:36]: [Server #3350301] All client reports have been processed.
[INFO][00:49:36]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_69.pth.
[INFO][00:49:37]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_69.pth.
[INFO][00:49:37]: [93m[1m
[Server #3350301] Starting round 70/100.[0m
[INFO][00:49:37]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][00:49:37]: [Server #3350301] Selecting client #2 for training.
[INFO][00:49:37]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:49:41]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:49:41]: [Server #3350301] Selecting client #5 for training.
[INFO][00:49:41]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:49:44]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:49:44]: [Client #2] Selected by the server.
[INFO][00:49:44]: [Client #2] Loading its data source...
[INFO][00:49:44]: [Client #2] Dataset size: 2018
[INFO][00:49:44]: [Client #2] Sampler: iid
[INFO][00:49:44]: [Client #5] Selected by the server.
[INFO][00:49:44]: [Client #5] Loading its data source...
[INFO][00:49:44]: [Client #5] Dataset size: 2018
[INFO][00:49:44]: [Client #5] Sampler: iid
[INFO][00:49:46]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:49:46]: [Client #5] Start to process inbound data.
[INFO][00:49:46]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:49:46]: [Client #2] Start to process inbound data.
[INFO][00:49:47]: [93m[1m[Client #2] Started training in communication round #70.[0m
[INFO][00:49:47]: [93m[1m[Client #5] Started training in communication round #70.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:38,  4.64s/it]  2%|â–         | 1/48 [00:04<03:42,  4.73s/it]  4%|â–         | 2/48 [00:05<01:47,  2.35s/it]  4%|â–         | 2/48 [00:05<01:48,  2.37s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][00:50:33]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.4752, 'train_samples_per_second': 153.362, 'train_steps_per_second': 1.216, 'train_loss': 2.313490708669027, 'epoch': 3.0}
[INFO][00:50:33]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.4564, 'train_samples_per_second': 153.435, 'train_steps_per_second': 1.217, 'train_loss': 1.9114432334899902, 'epoch': 3.0}
[INFO][00:50:34]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:50:34]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:50:34]: [Client #2] Model trained.
[INFO][00:50:34]: [Client #2] Inbound data has been processed.
[INFO][00:50:34]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:50:34]: [Client #5] Model trained.
[INFO][00:50:34]: [Client #5] Inbound data has been processed.
[INFO][00:50:34]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:50:42]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:50:42]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:50:43]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:50:44]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:50:44]: [Server #3350301] Selecting client #6 for training.
[INFO][00:50:44]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:50:48]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:50:48]: [Server #3350301] Selecting client #7 for training.
[INFO][00:50:48]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:50:51]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:50:51]: [Client #6] Selected by the server.
[INFO][00:50:51]: [Client #7] Selected by the server.
[INFO][00:50:51]: [Client #6] Loading its data source...
[INFO][00:50:51]: [Client #7] Loading its data source...
[INFO][00:50:51]: [Client #6] Dataset size: 2018
[INFO][00:50:51]: [Client #7] Dataset size: 2018
[INFO][00:50:51]: [Client #6] Sampler: iid
[INFO][00:50:51]: [Client #7] Sampler: iid
[INFO][00:50:53]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:50:53]: [Client #7] Start to process inbound data.
[INFO][00:50:53]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:50:53]: [Client #6] Start to process inbound data.
[INFO][00:50:53]: [93m[1m[Client #7] Started training in communication round #70.[0m
[INFO][00:50:54]: [93m[1m[Client #6] Started training in communication round #70.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:30,  4.48s/it]  2%|â–         | 1/48 [00:04<03:34,  4.57s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.58s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.60s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.25s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.25s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][00:51:39]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.3431, 'train_samples_per_second': 153.877, 'train_steps_per_second': 1.22, 'train_loss': 2.286750316619873, 'epoch': 3.0}
[INFO][00:51:39]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.1826, 'train_samples_per_second': 154.507, 'train_steps_per_second': 1.225, 'train_loss': 2.787869453430176, 'epoch': 3.0}
[INFO][00:51:40]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:51:40]: [Client #7] Model trained.
[INFO][00:51:40]: [Client #7] Inbound data has been processed.
[INFO][00:51:40]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:51:40]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][00:51:41]: [Client #6] Model trained.
[INFO][00:51:41]: [Client #6] Inbound data has been processed.
[INFO][00:51:41]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][00:51:46]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:51:47]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:51:47]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:51:48]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][00:51:48]: [Server #3350301] Selecting client #9 for training.
[INFO][00:51:48]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:51:52]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:51:52]: [Client #9] Selected by the server.
[INFO][00:51:52]: [Client #9] Loading its data source...
[INFO][00:51:52]: [Client #9] Dataset size: 2018
[INFO][00:51:52]: [Client #9] Sampler: iid
[INFO][00:51:53]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:51:53]: [Client #9] Start to process inbound data.
[INFO][00:51:53]: [93m[1m[Client #9] Started training in communication round #70.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.17s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][00:52:26]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8496, 'train_samples_per_second': 225.478, 'train_steps_per_second': 1.788, 'train_loss': 1.9598623911539714, 'epoch': 3.0}
[INFO][00:52:28]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:52:28]: [Client #9] Model trained.
[INFO][00:52:28]: [Client #9] Inbound data has been processed.
[INFO][00:52:28]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:52:32]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:52:33]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:52:33]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:52:33]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:52:33]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:52:33]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:52:33]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:52:33]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:52:33]: [Server #3350301] Updated weights have been received.
[INFO][00:52:34]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:52:35]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:52:35]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.49it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.42it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]
[INFO][00:52:45]: [93m[1m[Server #3350301] Global model perplexity: 57.43
[0m
[INFO][00:52:45]: [Server #3350301] All client reports have been processed.
[INFO][00:52:46]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_70.pth.
[INFO][00:52:46]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_70.pth.
[INFO][00:52:46]: [93m[1m
[Server #3350301] Starting round 71/100.[0m
[INFO][00:52:46]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][00:52:46]: [Server #3350301] Selecting client #10 for training.
[INFO][00:52:46]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][00:52:50]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][00:52:50]: [Server #3350301] Selecting client #1 for training.
[INFO][00:52:50]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:52:53]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:52:53]: [Client #10] Selected by the server.
[INFO][00:52:53]: [Client #10] Loading its data source...
[INFO][00:52:53]: [Client #1] Selected by the server.
[INFO][00:52:53]: [Client #10] Dataset size: 2018
[INFO][00:52:53]: [Client #1] Loading its data source...
[INFO][00:52:53]: [Client #10] Sampler: iid
[INFO][00:52:53]: [Client #1] Dataset size: 2018
[INFO][00:52:53]: [Client #1] Sampler: iid
[INFO][00:52:55]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:52:55]: [Client #1] Start to process inbound data.
[INFO][00:52:55]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:52:55]: [Client #10] Start to process inbound data.
[INFO][00:52:56]: [93m[1m[Client #1] Started training in communication round #71.[0m
[INFO][00:52:56]: [93m[1m[Client #10] Started training in communication round #71.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  4%|â–         | 2/48 [00:05<01:54,  2.49s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.84s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.16s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.05s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.02s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.30it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.30it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][00:53:42]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 40.1827, 'train_samples_per_second': 150.662, 'train_steps_per_second': 1.195, 'train_loss': 1.744943618774414, 'epoch': 3.0}
[INFO][00:53:42]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 40.211, 'train_samples_per_second': 150.556, 'train_steps_per_second': 1.194, 'train_loss': 2.4904467264811196, 'epoch': 3.0}
[INFO][00:53:43]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:53:43]: [Client #1] Model trained.
[INFO][00:53:43]: [Client #1] Inbound data has been processed.
[INFO][00:53:43]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:53:43]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][00:53:44]: [Client #10] Model trained.
[INFO][00:53:44]: [Client #10] Inbound data has been processed.
[INFO][00:53:44]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][00:53:50]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:53:50]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:53:51]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:53:52]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][00:53:52]: [Server #3350301] Selecting client #3 for training.
[INFO][00:53:52]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:53:55]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:53:55]: [Server #3350301] Selecting client #5 for training.
[INFO][00:53:55]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][00:53:59]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][00:53:59]: [Client #3] Selected by the server.
[INFO][00:53:59]: [Client #3] Loading its data source...
[INFO][00:53:59]: [Client #3] Dataset size: 2018
[INFO][00:53:59]: [Client #3] Sampler: iid
[INFO][00:53:59]: [Client #5] Selected by the server.
[INFO][00:53:59]: [Client #5] Loading its data source...
[INFO][00:53:59]: [Client #5] Dataset size: 2018
[INFO][00:53:59]: [Client #5] Sampler: iid
[INFO][00:54:00]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:54:00]: [Client #5] Start to process inbound data.
[INFO][00:54:00]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:54:00]: [Client #3] Start to process inbound data.
[INFO][00:54:01]: [93m[1m[Client #3] Started training in communication round #71.[0m
[INFO][00:54:01]: [93m[1m[Client #5] Started training in communication round #71.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.28s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  4%|â–         | 2/48 [00:04<01:40,  2.17s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.31it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.30it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:54:47]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.3136, 'train_samples_per_second': 153.992, 'train_steps_per_second': 1.221, 'train_loss': 2.1990866661071777, 'epoch': 3.0}
[INFO][00:54:47]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.68, 'train_samples_per_second': 152.57, 'train_steps_per_second': 1.21, 'train_loss': 1.8800613085428874, 'epoch': 3.0}
[INFO][00:54:48]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][00:54:48]: [Client #3] Model trained.
[INFO][00:54:48]: [Client #3] Inbound data has been processed.
[INFO][00:54:48]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][00:54:48]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][00:54:49]: [Client #5] Model trained.
[INFO][00:54:49]: [Client #5] Inbound data has been processed.
[INFO][00:54:49]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][00:54:55]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:54:56]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:54:56]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][00:54:58]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][00:54:58]: [Server #3350301] Selecting client #9 for training.
[INFO][00:54:58]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][00:55:01]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][00:55:01]: [Client #9] Selected by the server.
[INFO][00:55:01]: [Client #9] Loading its data source...
[INFO][00:55:01]: [Client #9] Dataset size: 2018
[INFO][00:55:01]: [Client #9] Sampler: iid
[INFO][00:55:03]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:55:03]: [Client #9] Start to process inbound data.
[INFO][00:55:03]: [93m[1m[Client #9] Started training in communication round #71.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][00:55:36]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7594, 'train_samples_per_second': 226.238, 'train_steps_per_second': 1.794, 'train_loss': 1.9383637110392253, 'epoch': 3.0}
[INFO][00:55:37]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][00:55:37]: [Client #9] Model trained.
[INFO][00:55:37]: [Client #9] Inbound data has been processed.
[INFO][00:55:37]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][00:55:42]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:55:43]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][00:55:43]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][00:55:43]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][00:55:43]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][00:55:43]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][00:55:43]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][00:55:43]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:55:43]: [Server #3350301] Updated weights have been received.
[INFO][00:55:43]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:55:44]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:55:44]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.79it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][00:55:55]: [93m[1m[Server #3350301] Global model perplexity: 53.03
[0m
[INFO][00:55:55]: [Server #3350301] All client reports have been processed.
[INFO][00:55:55]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_71.pth.
[INFO][00:55:55]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_71.pth.
[INFO][00:55:55]: [93m[1m
[Server #3350301] Starting round 72/100.[0m
[INFO][00:55:55]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][00:55:55]: [Server #3350301] Selecting client #2 for training.
[INFO][00:55:55]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][00:55:59]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][00:55:59]: [Server #3350301] Selecting client #1 for training.
[INFO][00:55:59]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][00:56:03]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][00:56:03]: [Client #2] Selected by the server.
[INFO][00:56:03]: [Client #2] Loading its data source...
[INFO][00:56:03]: [Client #2] Dataset size: 2018
[INFO][00:56:03]: [Client #2] Sampler: iid
[INFO][00:56:03]: [Client #1] Selected by the server.
[INFO][00:56:03]: [Client #1] Loading its data source...
[INFO][00:56:03]: [Client #1] Dataset size: 2018
[INFO][00:56:03]: [Client #1] Sampler: iid
[INFO][00:56:04]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:56:04]: [Client #2] Start to process inbound data.
[INFO][00:56:04]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:56:04]: [Client #1] Start to process inbound data.
[INFO][00:56:05]: [93m[1m[Client #2] Started training in communication round #72.[0m
[INFO][00:56:05]: [93m[1m[Client #1] Started training in communication round #72.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:53,  4.97s/it]  2%|â–         | 1/48 [00:04<03:54,  4.98s/it]  4%|â–         | 2/48 [00:05<01:59,  2.59s/it]  4%|â–         | 2/48 [00:05<01:59,  2.61s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.82s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.16s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.19s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:42,  1.02s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.13it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.29it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][00:56:52]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 40.3618, 'train_samples_per_second': 149.993, 'train_steps_per_second': 1.189, 'train_loss': 1.6131852467854817, 'epoch': 3.0}
[INFO][00:56:52]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 40.2756, 'train_samples_per_second': 150.314, 'train_steps_per_second': 1.192, 'train_loss': 2.2764245669047036, 'epoch': 3.0}
[INFO][00:56:53]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][00:56:53]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][00:56:53]: [Client #1] Model trained.
[INFO][00:56:53]: [Client #1] Inbound data has been processed.
[INFO][00:56:53]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][00:56:53]: [Client #2] Model trained.
[INFO][00:56:53]: [Client #2] Inbound data has been processed.
[INFO][00:56:53]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][00:57:00]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:57:00]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:57:01]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][00:57:02]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][00:57:02]: [Server #3350301] Selecting client #4 for training.
[INFO][00:57:02]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][00:57:05]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][00:57:05]: [Server #3350301] Selecting client #7 for training.
[INFO][00:57:05]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][00:57:09]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][00:57:09]: [Client #4] Selected by the server.
[INFO][00:57:09]: [Client #4] Loading its data source...
[INFO][00:57:09]: [Client #4] Dataset size: 2018
[INFO][00:57:09]: [Client #7] Selected by the server.
[INFO][00:57:09]: [Client #4] Sampler: iid
[INFO][00:57:09]: [Client #7] Loading its data source...
[INFO][00:57:09]: [Client #7] Dataset size: 2018
[INFO][00:57:09]: [Client #7] Sampler: iid
[INFO][00:57:10]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:57:10]: [Client #7] Start to process inbound data.
[INFO][00:57:10]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:57:10]: [Client #4] Start to process inbound data.
[INFO][00:57:11]: [93m[1m[Client #4] Started training in communication round #72.[0m
[INFO][00:57:11]: [93m[1m[Client #7] Started training in communication round #72.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:37,  4.63s/it]  2%|â–         | 1/48 [00:04<03:42,  4.73s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][00:57:57]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.6861, 'train_samples_per_second': 152.547, 'train_steps_per_second': 1.209, 'train_loss': 2.7276172637939453, 'epoch': 3.0}
[INFO][00:57:57]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.6211, 'train_samples_per_second': 152.797, 'train_steps_per_second': 1.211, 'train_loss': 2.257548173268636, 'epoch': 3.0}
[INFO][00:57:58]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][00:57:59]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][00:57:59]: [Client #4] Model trained.
[INFO][00:57:59]: [Client #4] Inbound data has been processed.
[INFO][00:57:59]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][00:57:59]: [Client #7] Model trained.
[INFO][00:57:59]: [Client #7] Inbound data has been processed.
[INFO][00:57:59]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][00:58:05]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:58:05]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:58:06]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][00:58:07]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][00:58:07]: [Server #3350301] Selecting client #8 for training.
[INFO][00:58:07]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][00:58:10]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][00:58:10]: [Client #8] Selected by the server.
[INFO][00:58:10]: [Client #8] Loading its data source...
[INFO][00:58:10]: [Client #8] Dataset size: 2018
[INFO][00:58:10]: [Client #8] Sampler: iid
[INFO][00:58:12]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:58:12]: [Client #8] Start to process inbound data.
[INFO][00:58:12]: [93m[1m[Client #8] Started training in communication round #72.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.45it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.61it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][00:58:45]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.5207, 'train_samples_per_second': 228.275, 'train_steps_per_second': 1.81, 'train_loss': 2.78092892964681, 'epoch': 3.0}
[INFO][00:58:46]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][00:58:46]: [Client #8] Model trained.
[INFO][00:58:46]: [Client #8] Inbound data has been processed.
[INFO][00:58:46]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][00:58:50]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][00:58:51]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][00:58:51]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][00:58:51]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][00:58:51]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][00:58:51]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][00:58:51]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][00:58:51]: [Server #3350301] Aggregating 5 clients in total.
[INFO][00:58:51]: [Server #3350301] Updated weights have been received.
[INFO][00:58:52]: [Server #3350301] Aggregating model weight deltas.
[INFO][00:58:52]: [Server #3350301] Finished aggregating updated weights.
[INFO][00:58:52]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.43it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.78it/s]
[INFO][00:59:03]: [93m[1m[Server #3350301] Global model perplexity: 52.81
[0m
[INFO][00:59:03]: [Server #3350301] All client reports have been processed.
[INFO][00:59:03]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_72.pth.
[INFO][00:59:04]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_72.pth.
[INFO][00:59:04]: [93m[1m
[Server #3350301] Starting round 73/100.[0m
[INFO][00:59:04]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][00:59:04]: [Server #3350301] Selecting client #6 for training.
[INFO][00:59:04]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][00:59:08]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][00:59:08]: [Server #3350301] Selecting client #3 for training.
[INFO][00:59:08]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][00:59:12]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][00:59:12]: [Client #6] Selected by the server.
[INFO][00:59:12]: [Client #6] Loading its data source...
[INFO][00:59:12]: [Client #6] Dataset size: 2018
[INFO][00:59:12]: [Client #6] Sampler: iid
[INFO][00:59:12]: [Client #3] Selected by the server.
[INFO][00:59:12]: [Client #3] Loading its data source...
[INFO][00:59:12]: [Client #3] Dataset size: 2018
[INFO][00:59:12]: [Client #3] Sampler: iid
[INFO][00:59:13]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:59:13]: [Client #6] Start to process inbound data.
[INFO][00:59:13]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][00:59:13]: [Client #3] Start to process inbound data.
[INFO][00:59:13]: [93m[1m[Client #3] Started training in communication round #73.[0m
[INFO][00:59:14]: [93m[1m[Client #6] Started training in communication round #73.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:45,  4.79s/it]  2%|â–         | 1/48 [00:04<03:53,  4.98s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  4%|â–         | 2/48 [00:05<01:56,  2.52s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:00:00]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.7343, 'train_samples_per_second': 152.362, 'train_steps_per_second': 1.208, 'train_loss': 2.16629425684611, 'epoch': 3.0}
[INFO][01:00:00]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.7345, 'train_samples_per_second': 152.361, 'train_steps_per_second': 1.208, 'train_loss': 2.762963612874349, 'epoch': 3.0}
[INFO][01:00:01]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:00:01]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:00:01]: [Client #3] Model trained.
[INFO][01:00:01]: [Client #3] Inbound data has been processed.
[INFO][01:00:01]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:00:02]: [Client #6] Model trained.
[INFO][01:00:02]: [Client #6] Inbound data has been processed.
[INFO][01:00:02]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:00:07]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:00:08]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:00:08]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:00:09]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:00:09]: [Server #3350301] Selecting client #10 for training.
[INFO][01:00:09]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:00:13]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:00:13]: [Server #3350301] Selecting client #5 for training.
[INFO][01:00:13]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:00:16]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:00:16]: [Client #10] Selected by the server.
[INFO][01:00:16]: [Client #10] Loading its data source...
[INFO][01:00:16]: [Client #10] Dataset size: 2018
[INFO][01:00:16]: [Client #5] Selected by the server.
[INFO][01:00:16]: [Client #10] Sampler: iid
[INFO][01:00:16]: [Client #5] Loading its data source...
[INFO][01:00:16]: [Client #5] Dataset size: 2018
[INFO][01:00:16]: [Client #5] Sampler: iid
[INFO][01:00:18]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:00:18]: [Client #5] Start to process inbound data.
[INFO][01:00:18]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:00:18]: [Client #10] Start to process inbound data.
[INFO][01:00:18]: [93m[1m[Client #5] Started training in communication round #73.[0m
[INFO][01:00:18]: [93m[1m[Client #10] Started training in communication round #73.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:23,  4.33s/it]  2%|â–         | 1/48 [00:04<03:47,  4.84s/it]  4%|â–         | 2/48 [00:05<01:41,  2.21s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:01:04]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.221, 'train_samples_per_second': 154.356, 'train_steps_per_second': 1.224, 'train_loss': 1.8152310053507488, 'epoch': 3.0}
[INFO][01:01:04]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.5803, 'train_samples_per_second': 152.955, 'train_steps_per_second': 1.213, 'train_loss': 2.4676461219787598, 'epoch': 3.0}
[INFO][01:01:05]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:01:05]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:01:06]: [Client #5] Model trained.
[INFO][01:01:06]: [Client #5] Inbound data has been processed.
[INFO][01:01:06]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:01:06]: [Client #10] Model trained.
[INFO][01:01:06]: [Client #10] Inbound data has been processed.
[INFO][01:01:06]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:01:12]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:01:12]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:01:13]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:01:14]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:01:14]: [Server #3350301] Selecting client #9 for training.
[INFO][01:01:14]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:01:18]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:01:18]: [Client #9] Selected by the server.
[INFO][01:01:18]: [Client #9] Loading its data source...
[INFO][01:01:18]: [Client #9] Dataset size: 2018
[INFO][01:01:18]: [Client #9] Sampler: iid
[INFO][01:01:20]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:01:20]: [Client #9] Start to process inbound data.
[INFO][01:01:20]: [93m[1m[Client #9] Started training in communication round #73.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][01:01:53]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7044, 'train_samples_per_second': 226.704, 'train_steps_per_second': 1.797, 'train_loss': 1.8754819234212239, 'epoch': 3.0}
[INFO][01:01:54]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:01:54]: [Client #9] Model trained.
[INFO][01:01:54]: [Client #9] Inbound data has been processed.
[INFO][01:01:54]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:01:58]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:01:59]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:01:59]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:01:59]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:01:59]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:01:59]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:01:59]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:01:59]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:01:59]: [Server #3350301] Updated weights have been received.
[INFO][01:01:59]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:02:00]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:02:00]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.23it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.48it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.80it/s]
[INFO][01:02:11]: [93m[1m[Server #3350301] Global model perplexity: 60.98
[0m
[INFO][01:02:11]: [Server #3350301] All client reports have been processed.
[INFO][01:02:11]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_73.pth.
[INFO][01:02:12]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_73.pth.
[INFO][01:02:12]: [93m[1m
[Server #3350301] Starting round 74/100.[0m
[INFO][01:02:12]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][01:02:12]: [Server #3350301] Selecting client #2 for training.
[INFO][01:02:12]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:02:15]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:02:15]: [Server #3350301] Selecting client #1 for training.
[INFO][01:02:15]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:02:19]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:02:19]: [Client #2] Selected by the server.
[INFO][01:02:19]: [Client #2] Loading its data source...
[INFO][01:02:19]: [Client #2] Dataset size: 2018
[INFO][01:02:19]: [Client #2] Sampler: iid
[INFO][01:02:19]: [Client #1] Selected by the server.
[INFO][01:02:19]: [Client #1] Loading its data source...
[INFO][01:02:19]: [Client #1] Dataset size: 2018
[INFO][01:02:19]: [Client #1] Sampler: iid
[INFO][01:02:21]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:02:21]: [Client #1] Start to process inbound data.
[INFO][01:02:21]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:02:21]: [Client #2] Start to process inbound data.
[INFO][01:02:21]: [93m[1m[Client #2] Started training in communication round #74.[0m
[INFO][01:02:21]: [93m[1m[Client #1] Started training in communication round #74.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.17s/it]  2%|â–         | 1/48 [00:04<03:44,  4.77s/it]  4%|â–         | 2/48 [00:04<01:37,  2.13s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:03:07]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.0978, 'train_samples_per_second': 154.842, 'train_steps_per_second': 1.228, 'train_loss': 1.6049394607543945, 'epoch': 3.0}
[INFO][01:03:07]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.4516, 'train_samples_per_second': 153.454, 'train_steps_per_second': 1.217, 'train_loss': 2.281966050465902, 'epoch': 3.0}
[INFO][01:03:08]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:03:08]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:03:09]: [Client #1] Model trained.
[INFO][01:03:09]: [Client #1] Inbound data has been processed.
[INFO][01:03:09]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:03:09]: [Client #2] Model trained.
[INFO][01:03:09]: [Client #2] Inbound data has been processed.
[INFO][01:03:09]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:03:15]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:03:15]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:03:16]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:03:17]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:03:17]: [Server #3350301] Selecting client #5 for training.
[INFO][01:03:17]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:03:21]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:03:21]: [Server #3350301] Selecting client #7 for training.
[INFO][01:03:21]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:03:24]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:03:24]: [Client #5] Selected by the server.
[INFO][01:03:24]: [Client #5] Loading its data source...
[INFO][01:03:24]: [Client #5] Dataset size: 2018
[INFO][01:03:24]: [Client #7] Selected by the server.
[INFO][01:03:24]: [Client #5] Sampler: iid
[INFO][01:03:24]: [Client #7] Loading its data source...
[INFO][01:03:24]: [Client #7] Dataset size: 2018
[INFO][01:03:24]: [Client #7] Sampler: iid
[INFO][01:03:26]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:03:26]: [Client #7] Start to process inbound data.
[INFO][01:03:26]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:03:26]: [Client #5] Start to process inbound data.
[INFO][01:03:27]: [93m[1m[Client #7] Started training in communication round #74.[0m
[INFO][01:03:27]: [93m[1m[Client #5] Started training in communication round #74.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:36,  4.61s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.60s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.31it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:04:13]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.7785, 'train_samples_per_second': 152.193, 'train_steps_per_second': 1.207, 'train_loss': 2.22517983118693, 'epoch': 3.0}
[INFO][01:04:13]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.6284, 'train_samples_per_second': 152.769, 'train_steps_per_second': 1.211, 'train_loss': 1.782000223795573, 'epoch': 3.0}
[INFO][01:04:14]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:04:14]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][01:04:14]: [Client #7] Model trained.
[INFO][01:04:14]: [Client #7] Inbound data has been processed.
[INFO][01:04:14]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:04:14]: [Client #5] Model trained.
[INFO][01:04:14]: [Client #5] Inbound data has been processed.
[INFO][01:04:14]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:04:20]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:04:20]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:04:21]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:04:22]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:04:22]: [Server #3350301] Selecting client #9 for training.
[INFO][01:04:22]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:04:26]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:04:26]: [Client #9] Selected by the server.
[INFO][01:04:26]: [Client #9] Loading its data source...
[INFO][01:04:26]: [Client #9] Dataset size: 2018
[INFO][01:04:26]: [Client #9] Sampler: iid
[INFO][01:04:28]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:04:28]: [Client #9] Start to process inbound data.
[INFO][01:04:28]: [93m[1m[Client #9] Started training in communication round #74.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.26s/it]  4%|â–         | 2/48 [00:04<01:34,  2.05s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.00s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.69it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][01:05:00]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.9617, 'train_samples_per_second': 224.54, 'train_steps_per_second': 1.78, 'train_loss': 1.8512412707010906, 'epoch': 3.0}
[INFO][01:05:01]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:05:02]: [Client #9] Model trained.
[INFO][01:05:02]: [Client #9] Inbound data has been processed.
[INFO][01:05:02]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:05:05]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:05:07]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:05:07]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:05:07]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:05:07]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][01:05:07]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][01:05:07]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:05:07]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:05:07]: [Server #3350301] Updated weights have been received.
[INFO][01:05:07]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:05:08]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:05:08]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.68it/s]
[INFO][01:05:19]: [93m[1m[Server #3350301] Global model perplexity: 55.13
[0m
[INFO][01:05:19]: [Server #3350301] All client reports have been processed.
[INFO][01:05:19]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_74.pth.
[INFO][01:05:19]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_74.pth.
[INFO][01:05:19]: [93m[1m
[Server #3350301] Starting round 75/100.[0m
[INFO][01:05:19]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][01:05:19]: [Server #3350301] Selecting client #4 for training.
[INFO][01:05:19]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][01:05:23]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][01:05:23]: [Server #3350301] Selecting client #1 for training.
[INFO][01:05:23]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:05:27]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:05:27]: [Client #4] Selected by the server.
[INFO][01:05:27]: [Client #4] Loading its data source...
[INFO][01:05:27]: [Client #4] Dataset size: 2018
[INFO][01:05:27]: [Client #4] Sampler: iid
[INFO][01:05:27]: [Client #1] Selected by the server.
[INFO][01:05:27]: [Client #1] Loading its data source...
[INFO][01:05:27]: [Client #1] Dataset size: 2018
[INFO][01:05:27]: [Client #1] Sampler: iid
[INFO][01:05:29]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:05:29]: [Client #4] Start to process inbound data.
[INFO][01:05:29]: [93m[1m[Client #4] Started training in communication round #75.[0m
[INFO][01:05:29]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:05:29]: [Client #1] Start to process inbound data.
[INFO][01:05:29]: [93m[1m[Client #1] Started training in communication round #75.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:29,  4.46s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:05<01:42,  2.24s/it]  2%|â–         | 1/48 [00:04<03:36,  4.61s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.31it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:06:14]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.4233, 'train_samples_per_second': 153.564, 'train_steps_per_second': 1.218, 'train_loss': 2.7066739400227866, 'epoch': 3.0}
[INFO][01:06:15]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4052, 'train_samples_per_second': 153.635, 'train_steps_per_second': 1.218, 'train_loss': 1.5674560864766438, 'epoch': 3.0}
[INFO][01:06:16]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][01:06:16]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:06:16]: [Client #4] Model trained.
[INFO][01:06:16]: [Client #4] Inbound data has been processed.
[INFO][01:06:16]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][01:06:17]: [Client #1] Model trained.
[INFO][01:06:17]: [Client #1] Inbound data has been processed.
[INFO][01:06:17]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:06:22]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:06:23]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:06:23]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][01:06:24]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:06:24]: [Server #3350301] Selecting client #8 for training.
[INFO][01:06:24]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][01:06:28]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][01:06:28]: [Server #3350301] Selecting client #3 for training.
[INFO][01:06:28]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:06:32]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:06:32]: [Client #8] Selected by the server.
[INFO][01:06:32]: [Client #3] Selected by the server.
[INFO][01:06:32]: [Client #8] Loading its data source...
[INFO][01:06:32]: [Client #3] Loading its data source...
[INFO][01:06:32]: [Client #8] Dataset size: 2018
[INFO][01:06:32]: [Client #3] Dataset size: 2018
[INFO][01:06:32]: [Client #8] Sampler: iid
[INFO][01:06:32]: [Client #3] Sampler: iid
[INFO][01:06:33]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:06:33]: [Client #3] Start to process inbound data.
[INFO][01:06:34]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:06:34]: [Client #8] Start to process inbound data.
[INFO][01:06:34]: [93m[1m[Client #8] Started training in communication round #75.[0m
[INFO][01:06:34]: [93m[1m[Client #3] Started training in communication round #75.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:38,  4.66s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  4%|â–         | 2/48 [00:05<01:47,  2.35s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:07:20]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.8114, 'train_samples_per_second': 152.067, 'train_steps_per_second': 1.206, 'train_loss': 2.134960174560547, 'epoch': 3.0}
[INFO][01:07:20]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.6808, 'train_samples_per_second': 152.568, 'train_steps_per_second': 1.21, 'train_loss': 2.7566372553507485, 'epoch': 3.0}
[INFO][01:07:21]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:07:22]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][01:07:22]: [Client #3] Model trained.
[INFO][01:07:22]: [Client #3] Inbound data has been processed.
[INFO][01:07:22]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:07:22]: [Client #8] Model trained.
[INFO][01:07:22]: [Client #8] Inbound data has been processed.
[INFO][01:07:22]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][01:07:28]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:07:28]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:07:29]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:07:30]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][01:07:30]: [Server #3350301] Selecting client #10 for training.
[INFO][01:07:30]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:07:33]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:07:33]: [Client #10] Selected by the server.
[INFO][01:07:33]: [Client #10] Loading its data source...
[INFO][01:07:33]: [Client #10] Dataset size: 2018
[INFO][01:07:33]: [Client #10] Sampler: iid
[INFO][01:07:35]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:07:35]: [Client #10] Start to process inbound data.
[INFO][01:07:35]: [93m[1m[Client #10] Started training in communication round #75.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.69it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.94it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.97it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:14,  2.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:08:08]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.8912, 'train_samples_per_second': 225.129, 'train_steps_per_second': 1.785, 'train_loss': 2.4171180725097656, 'epoch': 3.0}
[INFO][01:08:09]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:08:09]: [Client #10] Model trained.
[INFO][01:08:09]: [Client #10] Inbound data has been processed.
[INFO][01:08:09]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:08:13]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:08:14]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:08:14]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:08:14]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:08:14]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:08:14]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:08:14]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][01:08:14]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:08:14]: [Server #3350301] Updated weights have been received.
[INFO][01:08:15]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:08:15]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:08:15]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.63it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.42it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][01:08:26]: [93m[1m[Server #3350301] Global model perplexity: 56.96
[0m
[INFO][01:08:26]: [Server #3350301] All client reports have been processed.
[INFO][01:08:26]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_75.pth.
[INFO][01:08:27]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_75.pth.
[INFO][01:08:27]: [93m[1m
[Server #3350301] Starting round 76/100.[0m
[INFO][01:08:27]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][01:08:27]: [Server #3350301] Selecting client #2 for training.
[INFO][01:08:27]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:08:31]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:08:31]: [Server #3350301] Selecting client #5 for training.
[INFO][01:08:31]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:08:34]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:08:34]: [Client #2] Selected by the server.
[INFO][01:08:34]: [Client #2] Loading its data source...
[INFO][01:08:34]: [Client #2] Dataset size: 2018
[INFO][01:08:34]: [Client #2] Sampler: iid
[INFO][01:08:34]: [Client #5] Selected by the server.
[INFO][01:08:34]: [Client #5] Loading its data source...
[INFO][01:08:34]: [Client #5] Dataset size: 2018
[INFO][01:08:34]: [Client #5] Sampler: iid
[INFO][01:08:36]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:08:36]: [Client #5] Start to process inbound data.
[INFO][01:08:36]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:08:36]: [Client #2] Start to process inbound data.
[INFO][01:08:36]: [93m[1m[Client #2] Started training in communication round #76.[0m
[INFO][01:08:37]: [93m[1m[Client #5] Started training in communication round #76.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:38,  4.65s/it]  2%|â–         | 1/48 [00:04<03:38,  4.64s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.60s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:09:22]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.455, 'train_samples_per_second': 153.441, 'train_steps_per_second': 1.217, 'train_loss': 2.232616106669108, 'epoch': 3.0}
[INFO][01:09:23]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.4719, 'train_samples_per_second': 153.375, 'train_steps_per_second': 1.216, 'train_loss': 1.7767957051595051, 'epoch': 3.0}
[INFO][01:09:23]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:09:24]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:09:24]: [Client #2] Model trained.
[INFO][01:09:24]: [Client #2] Inbound data has been processed.
[INFO][01:09:24]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:09:24]: [Client #5] Model trained.
[INFO][01:09:24]: [Client #5] Inbound data has been processed.
[INFO][01:09:24]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:09:30]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:09:30]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:09:31]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:09:32]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:09:32]: [Server #3350301] Selecting client #6 for training.
[INFO][01:09:32]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][01:09:35]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][01:09:35]: [Server #3350301] Selecting client #7 for training.
[INFO][01:09:35]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:09:39]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:09:39]: [Client #6] Selected by the server.
[INFO][01:09:39]: [Client #6] Loading its data source...
[INFO][01:09:39]: [Client #7] Selected by the server.
[INFO][01:09:39]: [Client #7] Loading its data source...
[INFO][01:09:39]: [Client #6] Dataset size: 2018
[INFO][01:09:39]: [Client #6] Sampler: iid
[INFO][01:09:39]: [Client #7] Dataset size: 2018
[INFO][01:09:39]: [Client #7] Sampler: iid
[INFO][01:09:40]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:09:40]: [Client #7] Start to process inbound data.
[INFO][01:09:41]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:09:41]: [Client #6] Start to process inbound data.
[INFO][01:09:41]: [93m[1m[Client #7] Started training in communication round #76.[0m
[INFO][01:09:42]: [93m[1m[Client #6] Started training in communication round #76.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:50,  4.90s/it]  2%|â–         | 1/48 [00:04<03:47,  4.85s/it]  4%|â–         | 2/48 [00:05<01:56,  2.52s/it]  4%|â–         | 2/48 [00:05<01:55,  2.51s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.14s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][01:10:27]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.9344, 'train_samples_per_second': 151.599, 'train_steps_per_second': 1.202, 'train_loss': 2.7335780461629233, 'epoch': 3.0}
[INFO][01:10:28]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.9279, 'train_samples_per_second': 151.623, 'train_steps_per_second': 1.202, 'train_loss': 2.1605726877848306, 'epoch': 3.0}
[INFO][01:10:29]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:10:29]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:10:29]: [Client #6] Model trained.
[INFO][01:10:29]: [Client #6] Inbound data has been processed.
[INFO][01:10:29]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:10:29]: [Client #7] Model trained.
[INFO][01:10:29]: [Client #7] Inbound data has been processed.
[INFO][01:10:29]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:10:35]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:10:35]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:10:36]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:10:37]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:10:37]: [Server #3350301] Selecting client #9 for training.
[INFO][01:10:37]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:10:41]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:10:41]: [Client #9] Selected by the server.
[INFO][01:10:41]: [Client #9] Loading its data source...
[INFO][01:10:41]: [Client #9] Dataset size: 2018
[INFO][01:10:41]: [Client #9] Sampler: iid
[INFO][01:10:43]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:10:43]: [Client #9] Start to process inbound data.
[INFO][01:10:43]: [93m[1m[Client #9] Started training in communication round #76.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.99it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:11:16]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7502, 'train_samples_per_second': 226.316, 'train_steps_per_second': 1.794, 'train_loss': 1.792490800221761, 'epoch': 3.0}
[INFO][01:11:17]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:11:17]: [Client #9] Model trained.
[INFO][01:11:17]: [Client #9] Inbound data has been processed.
[INFO][01:11:17]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:11:21]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:11:22]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:11:22]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:11:22]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:11:22]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:11:22]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:11:22]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:11:22]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:11:22]: [Server #3350301] Updated weights have been received.
[INFO][01:11:23]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:11:23]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:11:23]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.43it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.47it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.61it/s]
[INFO][01:11:34]: [93m[1m[Server #3350301] Global model perplexity: 62.92
[0m
[INFO][01:11:34]: [Server #3350301] All client reports have been processed.
[INFO][01:11:34]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_76.pth.
[INFO][01:11:35]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_76.pth.
[INFO][01:11:35]: [93m[1m
[Server #3350301] Starting round 77/100.[0m
[INFO][01:11:35]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][01:11:35]: [Server #3350301] Selecting client #10 for training.
[INFO][01:11:35]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:11:38]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:11:38]: [Server #3350301] Selecting client #1 for training.
[INFO][01:11:38]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:11:42]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:11:42]: [Client #10] Selected by the server.
[INFO][01:11:42]: [Client #10] Loading its data source...
[INFO][01:11:42]: [Client #10] Dataset size: 2018
[INFO][01:11:42]: [Client #10] Sampler: iid
[INFO][01:11:42]: [Client #1] Selected by the server.
[INFO][01:11:42]: [Client #1] Loading its data source...
[INFO][01:11:42]: [Client #1] Dataset size: 2018
[INFO][01:11:42]: [Client #1] Sampler: iid
[INFO][01:11:44]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:11:44]: [Client #10] Start to process inbound data.
[INFO][01:11:44]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:11:44]: [Client #1] Start to process inbound data.
[INFO][01:11:45]: [93m[1m[Client #10] Started training in communication round #77.[0m
[INFO][01:11:45]: [93m[1m[Client #1] Started training in communication round #77.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:30,  4.48s/it]  2%|â–         | 1/48 [00:04<03:10,  4.06s/it]  4%|â–         | 2/48 [00:05<01:44,  2.27s/it]  4%|â–         | 2/48 [00:04<01:37,  2.12s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.57s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.49s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
[INFO][01:12:30]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 38.9943, 'train_samples_per_second': 155.254, 'train_steps_per_second': 1.231, 'train_loss': 2.392869154612223, 'epoch': 3.0}
[INFO][01:12:30]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4092, 'train_samples_per_second': 153.619, 'train_steps_per_second': 1.218, 'train_loss': 1.5494823455810547, 'epoch': 3.0}
[INFO][01:12:31]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:12:32]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:12:32]: [Client #10] Model trained.
[INFO][01:12:32]: [Client #10] Inbound data has been processed.
[INFO][01:12:32]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:12:32]: [Client #1] Model trained.
[INFO][01:12:32]: [Client #1] Inbound data has been processed.
[INFO][01:12:32]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:12:39]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:12:39]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:12:40]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:12:41]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:12:41]: [Server #3350301] Selecting client #3 for training.
[INFO][01:12:41]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:12:44]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:12:44]: [Server #3350301] Selecting client #5 for training.
[INFO][01:12:44]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:12:48]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:12:48]: [Client #3] Selected by the server.
[INFO][01:12:48]: [Client #5] Selected by the server.
[INFO][01:12:48]: [Client #3] Loading its data source...
[INFO][01:12:48]: [Client #5] Loading its data source...
[INFO][01:12:48]: [Client #3] Dataset size: 2018
[INFO][01:12:48]: [Client #3] Sampler: iid
[INFO][01:12:48]: [Client #5] Dataset size: 2018
[INFO][01:12:48]: [Client #5] Sampler: iid
[INFO][01:12:49]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:12:49]: [Client #3] Start to process inbound data.
[INFO][01:12:49]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:12:49]: [Client #5] Start to process inbound data.
[INFO][01:12:50]: [93m[1m[Client #5] Started training in communication round #77.[0m
[INFO][01:12:50]: [93m[1m[Client #3] Started training in communication round #77.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.03s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  2%|â–         | 1/48 [00:04<03:42,  4.73s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.47s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.69s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.12s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.38s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:43,  1.03s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:40,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.12s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:38,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.04s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:36,  1.08it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:35,  1.07it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:34,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:33,  1.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:33,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.05it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:30,  1.10it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:33,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.14it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:27,  1.04it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:24,  1.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:23,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:22,  1.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:21,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:20,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:21,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:19,  1.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:17,  1.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:16,  1.13it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.11it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:32<00:12,  1.16it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:13,  1.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:11,  1.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:12,  1.17it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:11,  1.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:11,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:10,  1.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:09,  1.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:42<00:03,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:43<00:02,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:44<00:01,  1.10it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:45<00:00,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.10it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.03it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.02it/s]
[INFO][01:13:42]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 46.5761, 'train_samples_per_second': 129.981, 'train_steps_per_second': 1.031, 'train_loss': 1.7226134936014812, 'epoch': 3.0}
[INFO][01:13:43]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 46.9164, 'train_samples_per_second': 129.038, 'train_steps_per_second': 1.023, 'train_loss': 2.105772018432617, 'epoch': 3.0}
[INFO][01:13:43]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:13:44]: [Client #5] Model trained.
[INFO][01:13:44]: [Client #5] Inbound data has been processed.
[INFO][01:13:44]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:13:44]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][01:13:45]: [Client #3] Model trained.
[INFO][01:13:45]: [Client #3] Inbound data has been processed.
[INFO][01:13:45]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:13:50]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:13:51]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:13:51]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:13:52]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:13:52]: [Server #3350301] Selecting client #9 for training.
[INFO][01:13:52]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:13:56]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:13:56]: [Client #9] Selected by the server.
[INFO][01:13:56]: [Client #9] Loading its data source...
[INFO][01:13:56]: [Client #9] Dataset size: 2018
[INFO][01:13:56]: [Client #9] Sampler: iid
[INFO][01:13:58]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:13:58]: [Client #9] Start to process inbound data.
[INFO][01:13:58]: [93m[1m[Client #9] Started training in communication round #77.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][01:14:31]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7153, 'train_samples_per_second': 226.612, 'train_steps_per_second': 1.797, 'train_loss': 1.7835057576497395, 'epoch': 3.0}
[INFO][01:14:32]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:14:33]: [Client #9] Model trained.
[INFO][01:14:33]: [Client #9] Inbound data has been processed.
[INFO][01:14:33]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:14:36]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:14:38]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:14:38]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:14:38]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:14:38]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][01:14:38]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][01:14:38]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:14:38]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:14:38]: [Server #3350301] Updated weights have been received.
[INFO][01:14:38]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:14:39]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:14:39]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][01:14:49]: [93m[1m[Server #3350301] Global model perplexity: 58.45
[0m
[INFO][01:14:49]: [Server #3350301] All client reports have been processed.
[INFO][01:14:50]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_77.pth.
[INFO][01:14:50]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_77.pth.
[INFO][01:14:50]: [93m[1m
[Server #3350301] Starting round 78/100.[0m
[INFO][01:14:50]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][01:14:50]: [Server #3350301] Selecting client #2 for training.
[INFO][01:14:50]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:14:54]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:14:54]: [Server #3350301] Selecting client #1 for training.
[INFO][01:14:54]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:14:58]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:14:58]: [Client #2] Selected by the server.
[INFO][01:14:58]: [Client #2] Loading its data source...
[INFO][01:14:58]: [Client #2] Dataset size: 2018
[INFO][01:14:58]: [Client #2] Sampler: iid
[INFO][01:14:58]: [Client #1] Selected by the server.
[INFO][01:14:58]: [Client #1] Loading its data source...
[INFO][01:14:58]: [Client #1] Dataset size: 2018
[INFO][01:14:58]: [Client #1] Sampler: iid
[INFO][01:14:59]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:14:59]: [Client #1] Start to process inbound data.
[INFO][01:14:59]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:14:59]: [Client #2] Start to process inbound data.
[INFO][01:15:00]: [93m[1m[Client #2] Started training in communication round #78.[0m
[INFO][01:15:00]: [93m[1m[Client #1] Started training in communication round #78.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:33,  4.53s/it]  2%|â–         | 1/48 [00:04<03:22,  4.32s/it]  4%|â–         | 2/48 [00:05<01:46,  2.32s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.52s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.38it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.30it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
[INFO][01:15:45]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4081, 'train_samples_per_second': 153.623, 'train_steps_per_second': 1.218, 'train_loss': 1.531294345855713, 'epoch': 3.0}
[INFO][01:15:46]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.062, 'train_samples_per_second': 154.984, 'train_steps_per_second': 1.229, 'train_loss': 2.2150119145711265, 'epoch': 3.0}
[INFO][01:15:47]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:15:47]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:15:47]: [Client #2] Model trained.
[INFO][01:15:47]: [Client #2] Inbound data has been processed.
[INFO][01:15:47]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:15:48]: [Client #1] Model trained.
[INFO][01:15:48]: [Client #1] Inbound data has been processed.
[INFO][01:15:48]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:15:53]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:15:54]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:15:54]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:15:55]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:15:55]: [Server #3350301] Selecting client #4 for training.
[INFO][01:15:55]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][01:15:59]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][01:15:59]: [Server #3350301] Selecting client #7 for training.
[INFO][01:15:59]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:16:02]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:16:02]: [Client #4] Selected by the server.
[INFO][01:16:02]: [Client #4] Loading its data source...
[INFO][01:16:02]: [Client #4] Dataset size: 2018
[INFO][01:16:02]: [Client #4] Sampler: iid
[INFO][01:16:02]: [Client #7] Selected by the server.
[INFO][01:16:02]: [Client #7] Loading its data source...
[INFO][01:16:02]: [Client #7] Dataset size: 2018
[INFO][01:16:02]: [Client #7] Sampler: iid
[INFO][01:16:04]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:16:04]: [Client #7] Start to process inbound data.
[INFO][01:16:04]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:16:04]: [Client #4] Start to process inbound data.
[INFO][01:16:05]: [93m[1m[Client #7] Started training in communication round #78.[0m
[INFO][01:16:05]: [93m[1m[Client #4] Started training in communication round #78.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.18s/it]  2%|â–         | 1/48 [00:04<03:45,  4.79s/it]  4%|â–         | 2/48 [00:04<01:37,  2.12s/it]  4%|â–         | 2/48 [00:05<01:54,  2.50s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.56s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.71s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.28it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.34it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:16:51]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.4072, 'train_samples_per_second': 153.627, 'train_steps_per_second': 1.218, 'train_loss': 2.1358014742533364, 'epoch': 3.0}
[INFO][01:16:51]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.7739, 'train_samples_per_second': 152.211, 'train_steps_per_second': 1.207, 'train_loss': 2.686957677205404, 'epoch': 3.0}
[INFO][01:16:52]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:16:52]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][01:16:53]: [Client #7] Model trained.
[INFO][01:16:53]: [Client #7] Inbound data has been processed.
[INFO][01:16:53]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:16:53]: [Client #4] Model trained.
[INFO][01:16:53]: [Client #4] Inbound data has been processed.
[INFO][01:16:53]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][01:16:59]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:16:59]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:17:00]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][01:17:01]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:17:01]: [Server #3350301] Selecting client #8 for training.
[INFO][01:17:01]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][01:17:05]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][01:17:05]: [Client #8] Selected by the server.
[INFO][01:17:05]: [Client #8] Loading its data source...
[INFO][01:17:05]: [Client #8] Dataset size: 2018
[INFO][01:17:05]: [Client #8] Sampler: iid
[INFO][01:17:07]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:17:07]: [Client #8] Start to process inbound data.
[INFO][01:17:07]: [93m[1m[Client #8] Started training in communication round #78.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:17:40]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.8743, 'train_samples_per_second': 225.271, 'train_steps_per_second': 1.786, 'train_loss': 2.737546920776367, 'epoch': 3.0}
[INFO][01:17:41]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][01:17:41]: [Client #8] Model trained.
[INFO][01:17:41]: [Client #8] Inbound data has been processed.
[INFO][01:17:41]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][01:17:45]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:17:47]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][01:17:47]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:17:47]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:17:47]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:17:47]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:17:47]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][01:17:47]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:17:47]: [Server #3350301] Updated weights have been received.
[INFO][01:17:47]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:17:48]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:17:48]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.38it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.71it/s]
[INFO][01:17:59]: [93m[1m[Server #3350301] Global model perplexity: 58.33
[0m
[INFO][01:17:59]: [Server #3350301] All client reports have been processed.
[INFO][01:17:59]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_78.pth.
[INFO][01:17:59]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_78.pth.
[INFO][01:17:59]: [93m[1m
[Server #3350301] Starting round 79/100.[0m
[INFO][01:17:59]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][01:17:59]: [Server #3350301] Selecting client #6 for training.
[INFO][01:17:59]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][01:18:03]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][01:18:03]: [Server #3350301] Selecting client #3 for training.
[INFO][01:18:03]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:18:07]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:18:07]: [Client #6] Selected by the server.
[INFO][01:18:07]: [Client #6] Loading its data source...
[INFO][01:18:07]: [Client #6] Dataset size: 2018
[INFO][01:18:07]: [Client #6] Sampler: iid
[INFO][01:18:07]: [Client #3] Selected by the server.
[INFO][01:18:07]: [Client #3] Loading its data source...
[INFO][01:18:07]: [Client #3] Dataset size: 2018
[INFO][01:18:07]: [Client #3] Sampler: iid
[INFO][01:18:09]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:18:09]: [Client #3] Start to process inbound data.
[INFO][01:18:09]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:18:09]: [Client #6] Start to process inbound data.
[INFO][01:18:09]: [93m[1m[Client #3] Started training in communication round #79.[0m
[INFO][01:18:09]: [93m[1m[Client #6] Started training in communication round #79.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:12,  4.11s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  2%|â–         | 1/48 [00:04<03:49,  4.88s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<01:57,  2.55s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.05it/s] 10%|â–ˆ         | 5/48 [00:08<00:49,  1.14s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.01s/it] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.32it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:18:54]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.0826, 'train_samples_per_second': 154.903, 'train_steps_per_second': 1.228, 'train_loss': 2.038462479909261, 'epoch': 3.0}
[INFO][01:18:55]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.7336, 'train_samples_per_second': 152.365, 'train_steps_per_second': 1.208, 'train_loss': 2.7142699559529624, 'epoch': 3.0}
[INFO][01:18:55]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:18:56]: [Client #3] Model trained.
[INFO][01:18:56]: [Client #3] Inbound data has been processed.
[INFO][01:18:56]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:18:56]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:18:57]: [Client #6] Model trained.
[INFO][01:18:57]: [Client #6] Inbound data has been processed.
[INFO][01:18:57]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:19:02]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:19:03]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:19:03]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:19:04]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:19:04]: [Server #3350301] Selecting client #10 for training.
[INFO][01:19:04]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:19:07]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:19:07]: [Server #3350301] Selecting client #5 for training.
[INFO][01:19:07]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:19:11]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:19:11]: [Client #10] Selected by the server.
[INFO][01:19:11]: [Client #10] Loading its data source...
[INFO][01:19:11]: [Client #10] Dataset size: 2018
[INFO][01:19:11]: [Client #10] Sampler: iid
[INFO][01:19:11]: [Client #5] Selected by the server.
[INFO][01:19:11]: [Client #5] Loading its data source...
[INFO][01:19:11]: [Client #5] Dataset size: 2018
[INFO][01:19:11]: [Client #5] Sampler: iid
[INFO][01:19:13]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:19:13]: [Client #10] Start to process inbound data.
[INFO][01:19:13]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:19:13]: [Client #5] Start to process inbound data.
[INFO][01:19:14]: [93m[1m[Client #5] Started training in communication round #79.[0m
[INFO][01:19:14]: [93m[1m[Client #10] Started training in communication round #79.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:30,  4.48s/it]  2%|â–         | 1/48 [00:04<03:53,  4.97s/it]  4%|â–         | 2/48 [00:05<01:44,  2.27s/it]  4%|â–         | 2/48 [00:05<01:55,  2.50s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.71s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.33s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.30it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.30it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:16,  1.31it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.30it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][01:20:00]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.5048, 'train_samples_per_second': 153.247, 'train_steps_per_second': 1.215, 'train_loss': 1.6805977821350098, 'epoch': 3.0}
[INFO][01:20:00]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.8685, 'train_samples_per_second': 151.849, 'train_steps_per_second': 1.204, 'train_loss': 2.3402366638183594, 'epoch': 3.0}
[INFO][01:20:01]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:20:01]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:20:01]: [Client #5] Model trained.
[INFO][01:20:01]: [Client #5] Inbound data has been processed.
[INFO][01:20:01]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:20:02]: [Client #10] Model trained.
[INFO][01:20:02]: [Client #10] Inbound data has been processed.
[INFO][01:20:02]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:20:07]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:20:08]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:20:08]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:20:10]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:20:10]: [Server #3350301] Selecting client #9 for training.
[INFO][01:20:10]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:20:13]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:20:13]: [Client #9] Selected by the server.
[INFO][01:20:13]: [Client #9] Loading its data source...
[INFO][01:20:13]: [Client #9] Dataset size: 2018
[INFO][01:20:13]: [Client #9] Sampler: iid
[INFO][01:20:15]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:20:15]: [Client #9] Start to process inbound data.
[INFO][01:20:15]: [93m[1m[Client #9] Started training in communication round #79.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.92it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.96it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.15it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:20:48]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8611, 'train_samples_per_second': 225.381, 'train_steps_per_second': 1.787, 'train_loss': 1.733014424641927, 'epoch': 3.0}
[INFO][01:20:50]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:20:50]: [Client #9] Model trained.
[INFO][01:20:50]: [Client #9] Inbound data has been processed.
[INFO][01:20:50]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:20:54]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:20:55]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:20:55]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:20:55]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:20:55]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:20:55]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:20:55]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:20:55]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:20:55]: [Server #3350301] Updated weights have been received.
[INFO][01:20:56]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:20:56]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:20:56]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.77it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.38it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.56it/s]
[INFO][01:21:07]: [93m[1m[Server #3350301] Global model perplexity: 66.50
[0m
[INFO][01:21:07]: [Server #3350301] All client reports have been processed.
[INFO][01:21:07]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_79.pth.
[INFO][01:21:08]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_79.pth.
[INFO][01:21:08]: [93m[1m
[Server #3350301] Starting round 80/100.[0m
[INFO][01:21:08]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][01:21:08]: [Server #3350301] Selecting client #2 for training.
[INFO][01:21:08]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:21:12]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:21:12]: [Server #3350301] Selecting client #1 for training.
[INFO][01:21:12]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:21:15]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:21:15]: [Client #2] Selected by the server.
[INFO][01:21:15]: [Client #1] Selected by the server.
[INFO][01:21:15]: [Client #2] Loading its data source...
[INFO][01:21:15]: [Client #1] Loading its data source...
[INFO][01:21:15]: [Client #1] Dataset size: 2018
[INFO][01:21:15]: [Client #2] Dataset size: 2018
[INFO][01:21:15]: [Client #1] Sampler: iid
[INFO][01:21:15]: [Client #2] Sampler: iid
[INFO][01:21:17]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:21:17]: [Client #2] Start to process inbound data.
[INFO][01:21:17]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:21:17]: [Client #1] Start to process inbound data.
[INFO][01:21:18]: [93m[1m[Client #2] Started training in communication round #80.[0m
[INFO][01:21:18]: [93m[1m[Client #1] Started training in communication round #80.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  2%|â–         | 1/48 [00:04<03:43,  4.75s/it]  4%|â–         | 2/48 [00:04<01:38,  2.15s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:22:03]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.1043, 'train_samples_per_second': 154.817, 'train_steps_per_second': 1.227, 'train_loss': 2.170349597930908, 'epoch': 3.0}
[INFO][01:22:03]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4743, 'train_samples_per_second': 153.366, 'train_steps_per_second': 1.216, 'train_loss': 1.4959235191345215, 'epoch': 3.0}
[INFO][01:22:04]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:22:05]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:22:05]: [Client #2] Model trained.
[INFO][01:22:05]: [Client #2] Inbound data has been processed.
[INFO][01:22:05]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:22:06]: [Client #1] Model trained.
[INFO][01:22:06]: [Client #1] Inbound data has been processed.
[INFO][01:22:06]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:22:11]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:22:12]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:22:12]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:22:13]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:22:13]: [Server #3350301] Selecting client #5 for training.
[INFO][01:22:13]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:22:16]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:22:16]: [Server #3350301] Selecting client #7 for training.
[INFO][01:22:16]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:22:20]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:22:20]: [Client #5] Selected by the server.
[INFO][01:22:20]: [Client #5] Loading its data source...
[INFO][01:22:20]: [Client #5] Dataset size: 2018
[INFO][01:22:20]: [Client #5] Sampler: iid
[INFO][01:22:20]: [Client #7] Selected by the server.
[INFO][01:22:20]: [Client #7] Loading its data source...
[INFO][01:22:20]: [Client #7] Dataset size: 2018
[INFO][01:22:20]: [Client #7] Sampler: iid
[INFO][01:22:22]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:22:22]: [Client #7] Start to process inbound data.
[INFO][01:22:22]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:22:22]: [Client #5] Start to process inbound data.
[INFO][01:22:22]: [93m[1m[Client #7] Started training in communication round #80.[0m
[INFO][01:22:22]: [93m[1m[Client #5] Started training in communication round #80.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  2%|â–         | 1/48 [00:04<03:31,  4.50s/it]  4%|â–         | 2/48 [00:05<01:43,  2.24s/it]  4%|â–         | 2/48 [00:05<01:45,  2.29s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.58s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:23:08]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.326, 'train_samples_per_second': 153.944, 'train_steps_per_second': 1.221, 'train_loss': 2.0960326194763184, 'epoch': 3.0}
[INFO][01:23:08]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.2481, 'train_samples_per_second': 154.25, 'train_steps_per_second': 1.223, 'train_loss': 1.6654138565063477, 'epoch': 3.0}
[INFO][01:23:09]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:23:09]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][01:23:09]: [Client #7] Model trained.
[INFO][01:23:09]: [Client #7] Inbound data has been processed.
[INFO][01:23:09]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:23:10]: [Client #5] Model trained.
[INFO][01:23:10]: [Client #5] Inbound data has been processed.
[INFO][01:23:10]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:23:16]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:23:16]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:23:17]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:23:18]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:23:18]: [Server #3350301] Selecting client #9 for training.
[INFO][01:23:18]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:23:22]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:23:22]: [Client #9] Selected by the server.
[INFO][01:23:22]: [Client #9] Loading its data source...
[INFO][01:23:22]: [Client #9] Dataset size: 2018
[INFO][01:23:22]: [Client #9] Sampler: iid
[INFO][01:23:23]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:23:23]: [Client #9] Start to process inbound data.
[INFO][01:23:23]: [93m[1m[Client #9] Started training in communication round #80.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:44,  1.00s/it] 10%|â–ˆ         | 5/48 [00:06<00:35,  1.22it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.41it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.69it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.86it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.91it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.95it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.98it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:12<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:23:56]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8563, 'train_samples_per_second': 225.422, 'train_steps_per_second': 1.787, 'train_loss': 1.7177211443583171, 'epoch': 3.0}
[INFO][01:23:57]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:23:58]: [Client #9] Model trained.
[INFO][01:23:58]: [Client #9] Inbound data has been processed.
[INFO][01:23:58]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:24:02]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:24:03]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:24:03]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:24:03]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:24:03]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][01:24:03]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][01:24:03]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:24:03]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:24:03]: [Server #3350301] Updated weights have been received.
[INFO][01:24:03]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:24:04]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:24:04]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.19it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.38it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.73it/s]
[INFO][01:24:15]: [93m[1m[Server #3350301] Global model perplexity: 60.20
[0m
[INFO][01:24:15]: [Server #3350301] All client reports have been processed.
[INFO][01:24:15]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_80.pth.
[INFO][01:24:16]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_80.pth.
[INFO][01:24:16]: [93m[1m
[Server #3350301] Starting round 81/100.[0m
[INFO][01:24:16]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][01:24:16]: [Server #3350301] Selecting client #4 for training.
[INFO][01:24:16]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][01:24:19]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][01:24:19]: [Server #3350301] Selecting client #1 for training.
[INFO][01:24:19]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:24:23]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:24:23]: [Client #4] Selected by the server.
[INFO][01:24:23]: [Client #4] Loading its data source...
[INFO][01:24:23]: [Client #4] Dataset size: 2018
[INFO][01:24:23]: [Client #4] Sampler: iid
[INFO][01:24:23]: [Client #1] Selected by the server.
[INFO][01:24:23]: [Client #1] Loading its data source...
[INFO][01:24:23]: [Client #1] Dataset size: 2018
[INFO][01:24:23]: [Client #1] Sampler: iid
[INFO][01:24:24]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:24:24]: [Client #4] Start to process inbound data.
[INFO][01:24:25]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:24:25]: [Client #1] Start to process inbound data.
[INFO][01:24:25]: [93m[1m[Client #4] Started training in communication round #81.[0m
[INFO][01:24:25]: [93m[1m[Client #1] Started training in communication round #81.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.02s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  4%|â–         | 2/48 [00:05<01:55,  2.52s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.75s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.14s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.40s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.05s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.23s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.01s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.04s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:36,  1.06it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:39,  1.01it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:35,  1.08it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:33,  1.09it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:32,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.10it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:30,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.09it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:26,  1.16it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:26,  1.12it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:26,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:25,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:24,  1.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:24,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:22,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:21,  1.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.13it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:20,  1.13it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.13it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:26<00:19,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.13it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:18,  1.13it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:30<00:15,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:31<00:15,  1.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.07it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:32<00:13,  1.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:33<00:12,  1.10it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:12,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:11,  1.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:10,  1.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:09,  1.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:08,  1.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:07,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:02,  1.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.04it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.02it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.34it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
[INFO][01:25:18]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 47.0219, 'train_samples_per_second': 128.749, 'train_steps_per_second': 1.021, 'train_loss': 2.6737677256266275, 'epoch': 3.0}
[INFO][01:25:19]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 47.3657, 'train_samples_per_second': 127.814, 'train_steps_per_second': 1.013, 'train_loss': 1.4644168217976887, 'epoch': 3.0}
[INFO][01:25:19]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][01:25:20]: [Client #4] Model trained.
[INFO][01:25:20]: [Client #4] Inbound data has been processed.
[INFO][01:25:20]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][01:25:20]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:25:21]: [Client #1] Model trained.
[INFO][01:25:21]: [Client #1] Inbound data has been processed.
[INFO][01:25:21]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:25:26]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:25:27]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:25:27]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][01:25:28]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:25:28]: [Server #3350301] Selecting client #8 for training.
[INFO][01:25:28]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][01:25:32]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][01:25:32]: [Server #3350301] Selecting client #3 for training.
[INFO][01:25:32]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:25:36]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:25:36]: [Client #8] Selected by the server.
[INFO][01:25:36]: [Client #8] Loading its data source...
[INFO][01:25:36]: [Client #3] Selected by the server.
[INFO][01:25:36]: [Client #8] Dataset size: 2018
[INFO][01:25:36]: [Client #3] Loading its data source...
[INFO][01:25:36]: [Client #8] Sampler: iid
[INFO][01:25:36]: [Client #3] Dataset size: 2018
[INFO][01:25:36]: [Client #3] Sampler: iid
[INFO][01:25:37]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:25:37]: [Client #3] Start to process inbound data.
[INFO][01:25:37]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:25:37]: [Client #8] Start to process inbound data.
[INFO][01:25:38]: [93m[1m[Client #3] Started training in communication round #81.[0m
[INFO][01:25:38]: [93m[1m[Client #8] Started training in communication round #81.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.15s/it]  2%|â–         | 1/48 [00:04<03:46,  4.82s/it]  4%|â–         | 2/48 [00:04<01:37,  2.13s/it]  4%|â–         | 2/48 [00:05<01:51,  2.42s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.29it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.30it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:26:24]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.0921, 'train_samples_per_second': 154.865, 'train_steps_per_second': 1.228, 'train_loss': 2.718709627787272, 'epoch': 3.0}
[INFO][01:26:24]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.5215, 'train_samples_per_second': 153.183, 'train_steps_per_second': 1.215, 'train_loss': 2.01003630956014, 'epoch': 3.0}
[INFO][01:26:25]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][01:26:25]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:26:26]: [Client #8] Model trained.
[INFO][01:26:26]: [Client #8] Inbound data has been processed.
[INFO][01:26:26]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][01:26:26]: [Client #3] Model trained.
[INFO][01:26:26]: [Client #3] Inbound data has been processed.
[INFO][01:26:26]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:26:32]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:26:32]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:26:33]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][01:26:34]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:26:34]: [Server #3350301] Selecting client #10 for training.
[INFO][01:26:34]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:26:38]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:26:38]: [Client #10] Selected by the server.
[INFO][01:26:38]: [Client #10] Loading its data source...
[INFO][01:26:38]: [Client #10] Dataset size: 2018
[INFO][01:26:38]: [Client #10] Sampler: iid
[INFO][01:26:39]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:26:39]: [Client #10] Start to process inbound data.
[INFO][01:26:40]: [93m[1m[Client #10] Started training in communication round #81.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.15it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:27:12]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.8629, 'train_samples_per_second': 225.367, 'train_steps_per_second': 1.787, 'train_loss': 2.3064988454182944, 'epoch': 3.0}
[INFO][01:27:13]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:27:14]: [Client #10] Model trained.
[INFO][01:27:14]: [Client #10] Inbound data has been processed.
[INFO][01:27:14]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:27:18]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:27:19]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:27:19]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:27:19]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:27:19]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:27:19]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:27:19]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][01:27:19]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:27:19]: [Server #3350301] Updated weights have been received.
[INFO][01:27:19]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:27:20]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:27:20]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.43it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.79it/s]
[INFO][01:27:31]: [93m[1m[Server #3350301] Global model perplexity: 62.41
[0m
[INFO][01:27:31]: [Server #3350301] All client reports have been processed.
[INFO][01:27:31]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_81.pth.
[INFO][01:27:32]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_81.pth.
[INFO][01:27:32]: [93m[1m
[Server #3350301] Starting round 82/100.[0m
[INFO][01:27:32]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][01:27:32]: [Server #3350301] Selecting client #2 for training.
[INFO][01:27:32]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:27:35]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:27:35]: [Server #3350301] Selecting client #5 for training.
[INFO][01:27:35]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:27:39]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:27:39]: [Client #2] Selected by the server.
[INFO][01:27:39]: [Client #2] Loading its data source...
[INFO][01:27:39]: [Client #2] Dataset size: 2018
[INFO][01:27:39]: [Client #2] Sampler: iid
[INFO][01:27:39]: [Client #5] Selected by the server.
[INFO][01:27:39]: [Client #5] Loading its data source...
[INFO][01:27:39]: [Client #5] Dataset size: 2018
[INFO][01:27:39]: [Client #5] Sampler: iid
[INFO][01:27:41]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:27:41]: [Client #2] Start to process inbound data.
[INFO][01:27:41]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:27:41]: [Client #5] Start to process inbound data.
[INFO][01:27:42]: [93m[1m[Client #2] Started training in communication round #82.[0m
[INFO][01:27:42]: [93m[1m[Client #5] Started training in communication round #82.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:12,  4.10s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.10s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.58s/it]  4%|â–         | 2/48 [00:05<01:56,  2.54s/it]  8%|â–Š         | 4/48 [00:06<00:58,  1.33s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.82s/it] 10%|â–ˆ         | 5/48 [00:07<00:52,  1.21s/it]  8%|â–Š         | 4/48 [00:07<01:05,  1.50s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.09s/it] 10%|â–ˆ         | 5/48 [00:08<00:54,  1.28s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:40,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:40,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:36,  1.10it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:33,  1.16it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:31,  1.22it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:29,  1.26it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:26,  1.30it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:22,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.40it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:33<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:36<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:39<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][01:28:27]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.7211, 'train_samples_per_second': 152.413, 'train_steps_per_second': 1.208, 'train_loss': 2.128872553507487, 'epoch': 3.0}
[INFO][01:28:28]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 40.285, 'train_samples_per_second': 150.279, 'train_steps_per_second': 1.192, 'train_loss': 1.6203099886576335, 'epoch': 3.0}
[INFO][01:28:29]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:28:29]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:28:29]: [Client #2] Model trained.
[INFO][01:28:29]: [Client #2] Inbound data has been processed.
[INFO][01:28:29]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:28:30]: [Client #5] Model trained.
[INFO][01:28:30]: [Client #5] Inbound data has been processed.
[INFO][01:28:30]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:28:35]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:28:36]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:28:36]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:28:37]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:28:37]: [Server #3350301] Selecting client #6 for training.
[INFO][01:28:37]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][01:28:41]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][01:28:41]: [Server #3350301] Selecting client #7 for training.
[INFO][01:28:41]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:28:45]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:28:45]: [Client #6] Selected by the server.
[INFO][01:28:45]: [Client #6] Loading its data source...
[INFO][01:28:45]: [Client #6] Dataset size: 2018
[INFO][01:28:45]: [Client #6] Sampler: iid
[INFO][01:28:45]: [Client #7] Selected by the server.
[INFO][01:28:45]: [Client #7] Loading its data source...
[INFO][01:28:45]: [Client #7] Dataset size: 2018
[INFO][01:28:45]: [Client #7] Sampler: iid
[INFO][01:28:46]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:28:46]: [Client #7] Start to process inbound data.
[INFO][01:28:46]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:28:46]: [Client #6] Start to process inbound data.
[INFO][01:28:47]: [93m[1m[Client #6] Started training in communication round #82.[0m
[INFO][01:28:47]: [93m[1m[Client #7] Started training in communication round #82.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  2%|â–         | 1/48 [00:04<03:31,  4.50s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:05<01:45,  2.30s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.59s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.25s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.07s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.33it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:29:33]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.3585, 'train_samples_per_second': 153.817, 'train_steps_per_second': 1.22, 'train_loss': 2.6853275299072266, 'epoch': 3.0}
[INFO][01:29:33]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.2708, 'train_samples_per_second': 154.16, 'train_steps_per_second': 1.222, 'train_loss': 2.045773188273112, 'epoch': 3.0}
[INFO][01:29:34]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:29:34]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:29:35]: [Client #6] Model trained.
[INFO][01:29:35]: [Client #6] Inbound data has been processed.
[INFO][01:29:35]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:29:35]: [Client #7] Model trained.
[INFO][01:29:35]: [Client #7] Inbound data has been processed.
[INFO][01:29:35]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:29:41]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:29:42]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:29:42]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:29:44]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:29:44]: [Server #3350301] Selecting client #9 for training.
[INFO][01:29:44]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:29:48]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:29:48]: [Client #9] Selected by the server.
[INFO][01:29:48]: [Client #9] Loading its data source...
[INFO][01:29:48]: [Client #9] Dataset size: 2018
[INFO][01:29:48]: [Client #9] Sampler: iid
[INFO][01:29:49]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:29:49]: [Client #9] Start to process inbound data.
[INFO][01:29:49]: [93m[1m[Client #9] Started training in communication round #82.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.21s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][01:30:22]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7346, 'train_samples_per_second': 226.448, 'train_steps_per_second': 1.795, 'train_loss': 1.665030797322591, 'epoch': 3.0}
[INFO][01:30:23]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:30:23]: [Client #9] Model trained.
[INFO][01:30:23]: [Client #9] Inbound data has been processed.
[INFO][01:30:23]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:30:27]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:30:28]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:30:28]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:30:28]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:30:28]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:30:28]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:30:28]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:30:28]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:30:28]: [Server #3350301] Updated weights have been received.
[INFO][01:30:29]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:30:29]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:30:29]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.66it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.54it/s]
[INFO][01:30:40]: [93m[1m[Server #3350301] Global model perplexity: 68.61
[0m
[INFO][01:30:40]: [Server #3350301] All client reports have been processed.
[INFO][01:30:41]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_82.pth.
[INFO][01:30:41]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_82.pth.
[INFO][01:30:41]: [93m[1m
[Server #3350301] Starting round 83/100.[0m
[INFO][01:30:41]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][01:30:41]: [Server #3350301] Selecting client #10 for training.
[INFO][01:30:41]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:30:45]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:30:45]: [Server #3350301] Selecting client #1 for training.
[INFO][01:30:45]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:30:49]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:30:49]: [Client #10] Selected by the server.
[INFO][01:30:49]: [Client #10] Loading its data source...
[INFO][01:30:49]: [Client #10] Dataset size: 2018
[INFO][01:30:49]: [Client #10] Sampler: iid
[INFO][01:30:49]: [Client #1] Selected by the server.
[INFO][01:30:49]: [Client #1] Loading its data source...
[INFO][01:30:49]: [Client #1] Dataset size: 2018
[INFO][01:30:49]: [Client #1] Sampler: iid
[INFO][01:30:50]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:30:50]: [Client #1] Start to process inbound data.
[INFO][01:30:50]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:30:50]: [Client #10] Start to process inbound data.
[INFO][01:30:51]: [93m[1m[Client #1] Started training in communication round #83.[0m
[INFO][01:30:51]: [93m[1m[Client #10] Started training in communication round #83.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:13,  4.11s/it]  2%|â–         | 1/48 [00:04<03:42,  4.74s/it]  4%|â–         | 2/48 [00:04<01:36,  2.10s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.49s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:31:37]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 38.8897, 'train_samples_per_second': 155.671, 'train_steps_per_second': 1.234, 'train_loss': 1.4531893730163574, 'epoch': 3.0}
[INFO][01:31:37]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.2593, 'train_samples_per_second': 154.205, 'train_steps_per_second': 1.223, 'train_loss': 2.283320903778076, 'epoch': 3.0}
[INFO][01:31:38]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:31:38]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:31:38]: [Client #10] Model trained.
[INFO][01:31:38]: [Client #10] Inbound data has been processed.
[INFO][01:31:38]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:31:39]: [Client #1] Model trained.
[INFO][01:31:39]: [Client #1] Inbound data has been processed.
[INFO][01:31:39]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:31:45]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:31:45]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:31:46]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:31:47]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:31:47]: [Server #3350301] Selecting client #3 for training.
[INFO][01:31:47]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:31:51]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:31:51]: [Server #3350301] Selecting client #5 for training.
[INFO][01:31:51]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:31:55]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:31:55]: [Client #3] Selected by the server.
[INFO][01:31:55]: [Client #5] Selected by the server.
[INFO][01:31:55]: [Client #3] Loading its data source...
[INFO][01:31:55]: [Client #5] Loading its data source...
[INFO][01:31:55]: [Client #3] Dataset size: 2018
[INFO][01:31:55]: [Client #5] Dataset size: 2018
[INFO][01:31:55]: [Client #3] Sampler: iid
[INFO][01:31:55]: [Client #5] Sampler: iid
[INFO][01:31:56]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:31:56]: [Client #5] Start to process inbound data.
[INFO][01:31:56]: [93m[1m[Client #5] Started training in communication round #83.[0m
[INFO][01:31:56]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:31:56]: [Client #3] Start to process inbound data.
[INFO][01:31:57]: [93m[1m[Client #3] Started training in communication round #83.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:36,  4.61s/it]  2%|â–         | 1/48 [00:04<03:35,  4.59s/it]  4%|â–         | 2/48 [00:05<01:46,  2.32s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.60s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.61s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:32:42]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.5525, 'train_samples_per_second': 153.063, 'train_steps_per_second': 1.214, 'train_loss': 1.6003891626993816, 'epoch': 3.0}
[INFO][01:32:43]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.3518, 'train_samples_per_second': 153.843, 'train_steps_per_second': 1.22, 'train_loss': 1.9771378835042317, 'epoch': 3.0}
[INFO][01:32:44]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:32:44]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][01:32:44]: [Client #5] Model trained.
[INFO][01:32:44]: [Client #5] Inbound data has been processed.
[INFO][01:32:44]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:32:44]: [Client #3] Model trained.
[INFO][01:32:44]: [Client #3] Inbound data has been processed.
[INFO][01:32:44]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:32:50]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:32:51]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:32:52]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:32:53]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:32:53]: [Server #3350301] Selecting client #9 for training.
[INFO][01:32:53]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:32:57]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:32:57]: [Client #9] Selected by the server.
[INFO][01:32:57]: [Client #9] Loading its data source...
[INFO][01:32:57]: [Client #9] Dataset size: 2018
[INFO][01:32:57]: [Client #9] Sampler: iid
[INFO][01:32:58]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:32:58]: [Client #9] Start to process inbound data.
[INFO][01:32:59]: [93m[1m[Client #9] Started training in communication round #83.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.99it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:17,  1.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  1.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.11it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:33:32]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8011, 'train_samples_per_second': 225.886, 'train_steps_per_second': 1.791, 'train_loss': 1.6377514203389485, 'epoch': 3.0}
[INFO][01:33:33]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:33:33]: [Client #9] Model trained.
[INFO][01:33:33]: [Client #9] Inbound data has been processed.
[INFO][01:33:33]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:33:37]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:33:38]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:33:38]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:33:38]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:33:38]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][01:33:38]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][01:33:38]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:33:38]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:33:38]: [Server #3350301] Updated weights have been received.
[INFO][01:33:39]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:33:39]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:33:39]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.68it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.38it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.59it/s]
[INFO][01:33:50]: [93m[1m[Server #3350301] Global model perplexity: 64.37
[0m
[INFO][01:33:50]: [Server #3350301] All client reports have been processed.
[INFO][01:33:50]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_83.pth.
[INFO][01:33:51]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_83.pth.
[INFO][01:33:51]: [93m[1m
[Server #3350301] Starting round 84/100.[0m
[INFO][01:33:51]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][01:33:51]: [Server #3350301] Selecting client #2 for training.
[INFO][01:33:51]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:33:55]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:33:55]: [Server #3350301] Selecting client #1 for training.
[INFO][01:33:55]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:33:59]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:33:59]: [Client #2] Selected by the server.
[INFO][01:33:59]: [Client #2] Loading its data source...
[INFO][01:33:59]: [Client #1] Selected by the server.
[INFO][01:33:59]: [Client #2] Dataset size: 2018
[INFO][01:33:59]: [Client #1] Loading its data source...
[INFO][01:33:59]: [Client #2] Sampler: iid
[INFO][01:33:59]: [Client #1] Dataset size: 2018
[INFO][01:33:59]: [Client #1] Sampler: iid
[INFO][01:34:00]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:34:00]: [Client #1] Start to process inbound data.
[INFO][01:34:00]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:34:00]: [Client #2] Start to process inbound data.
[INFO][01:34:01]: [93m[1m[Client #1] Started training in communication round #84.[0m
[INFO][01:34:01]: [93m[1m[Client #2] Started training in communication round #84.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:05<03:55,  5.00s/it]  2%|â–         | 1/48 [00:05<03:55,  5.02s/it]  4%|â–         | 2/48 [00:05<02:00,  2.63s/it]  4%|â–         | 2/48 [00:05<02:01,  2.64s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.84s/it]  6%|â–‹         | 3/48 [00:06<01:23,  1.85s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it]  8%|â–Š         | 4/48 [00:07<01:03,  1.44s/it] 10%|â–ˆ         | 5/48 [00:08<00:50,  1.17s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.20s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:42,  1.02s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:43,  1.04s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.08it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:38,  1.06it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.15it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:35,  1.14it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.20it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:17<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:23<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:26<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:32<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:35<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:38<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.19it/s]
[INFO][01:34:48]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 40.2881, 'train_samples_per_second': 150.268, 'train_steps_per_second': 1.191, 'train_loss': 2.1002840995788574, 'epoch': 3.0}
[INFO][01:34:48]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 40.2027, 'train_samples_per_second': 150.587, 'train_steps_per_second': 1.194, 'train_loss': 1.4173210461934407, 'epoch': 3.0}
[INFO][01:34:49]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:34:49]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:34:49]: [Client #2] Model trained.
[INFO][01:34:49]: [Client #2] Inbound data has been processed.
[INFO][01:34:49]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:34:50]: [Client #1] Model trained.
[INFO][01:34:50]: [Client #1] Inbound data has been processed.
[INFO][01:34:50]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:34:56]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:34:56]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:34:57]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:34:58]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:34:58]: [Server #3350301] Selecting client #4 for training.
[INFO][01:34:58]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][01:35:02]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][01:35:02]: [Server #3350301] Selecting client #7 for training.
[INFO][01:35:02]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:35:05]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:35:05]: [Client #4] Selected by the server.
[INFO][01:35:05]: [Client #4] Loading its data source...
[INFO][01:35:05]: [Client #4] Dataset size: 2018
[INFO][01:35:05]: [Client #4] Sampler: iid
[INFO][01:35:05]: [Client #7] Selected by the server.
[INFO][01:35:05]: [Client #7] Loading its data source...
[INFO][01:35:05]: [Client #7] Dataset size: 2018
[INFO][01:35:05]: [Client #7] Sampler: iid
[INFO][01:35:07]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:35:07]: [Client #4] Start to process inbound data.
[INFO][01:35:07]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:35:07]: [Client #7] Start to process inbound data.
[INFO][01:35:08]: [93m[1m[Client #4] Started training in communication round #84.[0m
[INFO][01:35:08]: [93m[1m[Client #7] Started training in communication round #84.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:27,  4.41s/it]  2%|â–         | 1/48 [00:04<03:29,  4.47s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.57s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.25s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:35:53]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.3326, 'train_samples_per_second': 153.918, 'train_steps_per_second': 1.22, 'train_loss': 2.0256710052490234, 'epoch': 3.0}
[INFO][01:35:53]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.3647, 'train_samples_per_second': 153.793, 'train_steps_per_second': 1.219, 'train_loss': 2.645435333251953, 'epoch': 3.0}
[INFO][01:35:54]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:35:55]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][01:35:55]: [Client #7] Model trained.
[INFO][01:35:55]: [Client #7] Inbound data has been processed.
[INFO][01:35:55]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:35:55]: [Client #4] Model trained.
[INFO][01:35:55]: [Client #4] Inbound data has been processed.
[INFO][01:35:55]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][01:36:02]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:36:02]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:36:03]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:36:04]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][01:36:04]: [Server #3350301] Selecting client #8 for training.
[INFO][01:36:04]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][01:36:08]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][01:36:08]: [Client #8] Selected by the server.
[INFO][01:36:08]: [Client #8] Loading its data source...
[INFO][01:36:08]: [Client #8] Dataset size: 2018
[INFO][01:36:08]: [Client #8] Sampler: iid
[INFO][01:36:09]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:36:09]: [Client #8] Start to process inbound data.
[INFO][01:36:10]: [93m[1m[Client #8] Started training in communication round #84.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.45it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.61it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.96it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][01:36:42]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.5539, 'train_samples_per_second': 227.989, 'train_steps_per_second': 1.808, 'train_loss': 2.6871363321940103, 'epoch': 3.0}
[INFO][01:36:43]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][01:36:44]: [Client #8] Model trained.
[INFO][01:36:44]: [Client #8] Inbound data has been processed.
[INFO][01:36:44]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][01:36:47]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:36:49]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][01:36:49]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:36:49]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:36:49]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:36:49]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:36:49]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][01:36:49]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:36:49]: [Server #3350301] Updated weights have been received.
[INFO][01:36:49]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:36:50]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:36:50]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.74it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.57it/s]
[INFO][01:37:01]: [93m[1m[Server #3350301] Global model perplexity: 64.45
[0m
[INFO][01:37:01]: [Server #3350301] All client reports have been processed.
[INFO][01:37:01]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_84.pth.
[INFO][01:37:01]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_84.pth.
[INFO][01:37:01]: [93m[1m
[Server #3350301] Starting round 85/100.[0m
[INFO][01:37:01]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][01:37:01]: [Server #3350301] Selecting client #6 for training.
[INFO][01:37:01]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][01:37:05]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][01:37:05]: [Server #3350301] Selecting client #3 for training.
[INFO][01:37:05]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:37:09]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:37:09]: [Client #6] Selected by the server.
[INFO][01:37:09]: [Client #6] Loading its data source...
[INFO][01:37:09]: [Client #6] Dataset size: 2018
[INFO][01:37:09]: [Client #6] Sampler: iid
[INFO][01:37:09]: [Client #3] Selected by the server.
[INFO][01:37:09]: [Client #3] Loading its data source...
[INFO][01:37:09]: [Client #3] Dataset size: 2018
[INFO][01:37:09]: [Client #3] Sampler: iid
[INFO][01:37:10]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:37:10]: [Client #6] Start to process inbound data.
[INFO][01:37:10]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:37:10]: [Client #3] Start to process inbound data.
[INFO][01:37:11]: [93m[1m[Client #6] Started training in communication round #85.[0m
[INFO][01:37:11]: [93m[1m[Client #3] Started training in communication round #85.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:30,  4.48s/it]  2%|â–         | 1/48 [00:05<03:57,  5.05s/it]  4%|â–         | 2/48 [00:05<01:44,  2.26s/it]  4%|â–         | 2/48 [00:05<01:56,  2.54s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.13s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:39,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.08it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
[INFO][01:37:57]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.3895, 'train_samples_per_second': 153.696, 'train_steps_per_second': 1.219, 'train_loss': 2.662705580393473, 'epoch': 3.0}
[INFO][01:37:57]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.849, 'train_samples_per_second': 151.923, 'train_steps_per_second': 1.205, 'train_loss': 1.9363789558410645, 'epoch': 3.0}
[INFO][01:37:58]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:37:58]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:37:58]: [Client #6] Model trained.
[INFO][01:37:58]: [Client #6] Inbound data has been processed.
[INFO][01:37:58]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:37:59]: [Client #3] Model trained.
[INFO][01:37:59]: [Client #3] Inbound data has been processed.
[INFO][01:37:59]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:38:05]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:38:06]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:38:06]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:38:07]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:38:07]: [Server #3350301] Selecting client #10 for training.
[INFO][01:38:07]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:38:10]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:38:10]: [Server #3350301] Selecting client #5 for training.
[INFO][01:38:10]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:38:14]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:38:14]: [Client #10] Selected by the server.
[INFO][01:38:14]: [Client #10] Loading its data source...
[INFO][01:38:14]: [Client #10] Dataset size: 2018
[INFO][01:38:14]: [Client #5] Selected by the server.
[INFO][01:38:14]: [Client #10] Sampler: iid
[INFO][01:38:14]: [Client #5] Loading its data source...
[INFO][01:38:14]: [Client #5] Dataset size: 2018
[INFO][01:38:14]: [Client #5] Sampler: iid
[INFO][01:38:15]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:38:15]: [Client #5] Start to process inbound data.
[INFO][01:38:15]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:38:15]: [Client #10] Start to process inbound data.
[INFO][01:38:16]: [93m[1m[Client #5] Started training in communication round #85.[0m
[INFO][01:38:16]: [93m[1m[Client #10] Started training in communication round #85.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  2%|â–         | 1/48 [00:04<03:45,  4.81s/it]  4%|â–         | 2/48 [00:04<01:39,  2.15s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.51s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.21s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:39:01]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.1781, 'train_samples_per_second': 154.525, 'train_steps_per_second': 1.225, 'train_loss': 1.5594333012898762, 'epoch': 3.0}
[INFO][01:39:02]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.558, 'train_samples_per_second': 153.041, 'train_steps_per_second': 1.213, 'train_loss': 2.235647360483805, 'epoch': 3.0}
[INFO][01:39:02]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:39:03]: [Client #5] Model trained.
[INFO][01:39:03]: [Client #5] Inbound data has been processed.
[INFO][01:39:03]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:39:03]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:39:04]: [Client #10] Model trained.
[INFO][01:39:04]: [Client #10] Inbound data has been processed.
[INFO][01:39:04]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:39:08]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:39:09]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:39:10]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:39:11]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:39:11]: [Server #3350301] Selecting client #9 for training.
[INFO][01:39:11]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:39:15]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:39:15]: [Client #9] Selected by the server.
[INFO][01:39:15]: [Client #9] Loading its data source...
[INFO][01:39:15]: [Client #9] Dataset size: 2018
[INFO][01:39:15]: [Client #9] Sampler: iid
[INFO][01:39:16]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:39:16]: [Client #9] Start to process inbound data.
[INFO][01:39:16]: [93m[1m[Client #9] Started training in communication round #85.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.69it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.79it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  1.99it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:39:49]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8252, 'train_samples_per_second': 225.684, 'train_steps_per_second': 1.789, 'train_loss': 1.5980245272318523, 'epoch': 3.0}
[INFO][01:39:50]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:39:51]: [Client #9] Model trained.
[INFO][01:39:51]: [Client #9] Inbound data has been processed.
[INFO][01:39:51]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:39:54]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:39:55]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:39:55]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:39:55]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:39:55]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:39:55]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:39:55]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:39:55]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:39:55]: [Server #3350301] Updated weights have been received.
[INFO][01:39:56]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:39:56]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:39:56]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.39it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]
[INFO][01:40:07]: [93m[1m[Server #3350301] Global model perplexity: 72.91
[0m
[INFO][01:40:07]: [Server #3350301] All client reports have been processed.
[INFO][01:40:07]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_85.pth.
[INFO][01:40:08]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_85.pth.
[INFO][01:40:08]: [93m[1m
[Server #3350301] Starting round 86/100.[0m
[INFO][01:40:08]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][01:40:08]: [Server #3350301] Selecting client #2 for training.
[INFO][01:40:08]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:40:12]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:40:12]: [Server #3350301] Selecting client #1 for training.
[INFO][01:40:12]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:40:16]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:40:16]: [Client #2] Selected by the server.
[INFO][01:40:16]: [Client #2] Loading its data source...
[INFO][01:40:16]: [Client #2] Dataset size: 2018
[INFO][01:40:16]: [Client #2] Sampler: iid
[INFO][01:40:16]: [Client #1] Selected by the server.
[INFO][01:40:16]: [Client #1] Loading its data source...
[INFO][01:40:16]: [Client #1] Dataset size: 2018
[INFO][01:40:16]: [Client #1] Sampler: iid
[INFO][01:40:17]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:40:17]: [Client #2] Start to process inbound data.
[INFO][01:40:17]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:40:17]: [Client #1] Start to process inbound data.
[INFO][01:40:18]: [93m[1m[Client #2] Started training in communication round #86.[0m
[INFO][01:40:18]: [93m[1m[Client #1] Started training in communication round #86.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:24,  4.34s/it]  2%|â–         | 1/48 [00:04<03:48,  4.85s/it]  4%|â–         | 2/48 [00:05<01:41,  2.20s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:41:03]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.149, 'train_samples_per_second': 154.64, 'train_steps_per_second': 1.226, 'train_loss': 2.105527877807617, 'epoch': 3.0}
[INFO][01:41:04]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.5091, 'train_samples_per_second': 153.231, 'train_steps_per_second': 1.215, 'train_loss': 1.3980690638224285, 'epoch': 3.0}
[INFO][01:41:04]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:41:05]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:41:05]: [Client #2] Model trained.
[INFO][01:41:05]: [Client #2] Inbound data has been processed.
[INFO][01:41:05]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:41:05]: [Client #1] Model trained.
[INFO][01:41:05]: [Client #1] Inbound data has been processed.
[INFO][01:41:05]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:41:11]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:41:12]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:41:12]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:41:13]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:41:13]: [Server #3350301] Selecting client #5 for training.
[INFO][01:41:13]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:41:17]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:41:17]: [Server #3350301] Selecting client #7 for training.
[INFO][01:41:17]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:41:21]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:41:21]: [Client #5] Selected by the server.
[INFO][01:41:21]: [Client #5] Loading its data source...
[INFO][01:41:21]: [Client #5] Dataset size: 2018
[INFO][01:41:21]: [Client #5] Sampler: iid
[INFO][01:41:21]: [Client #7] Selected by the server.
[INFO][01:41:21]: [Client #7] Loading its data source...
[INFO][01:41:21]: [Client #7] Dataset size: 2018
[INFO][01:41:21]: [Client #7] Sampler: iid
[INFO][01:41:22]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:41:22]: [Client #7] Start to process inbound data.
[INFO][01:41:22]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:41:22]: [Client #5] Start to process inbound data.
[INFO][01:41:23]: [93m[1m[Client #7] Started training in communication round #86.[0m
[INFO][01:41:23]: [93m[1m[Client #5] Started training in communication round #86.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.13s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:05<01:41,  2.21s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.25s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:42:08]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.1655, 'train_samples_per_second': 154.575, 'train_steps_per_second': 1.226, 'train_loss': 1.9963665008544922, 'epoch': 3.0}
[INFO][01:42:08]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.3583, 'train_samples_per_second': 153.818, 'train_steps_per_second': 1.22, 'train_loss': 1.554585615793864, 'epoch': 3.0}
[INFO][01:42:09]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:42:09]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][01:42:09]: [Client #7] Model trained.
[INFO][01:42:09]: [Client #7] Inbound data has been processed.
[INFO][01:42:09]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:42:10]: [Client #5] Model trained.
[INFO][01:42:10]: [Client #5] Inbound data has been processed.
[INFO][01:42:10]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:42:16]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:42:16]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:42:17]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:42:18]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:42:18]: [Server #3350301] Selecting client #9 for training.
[INFO][01:42:18]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:42:22]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:42:22]: [Client #9] Selected by the server.
[INFO][01:42:22]: [Client #9] Loading its data source...
[INFO][01:42:22]: [Client #9] Dataset size: 2018
[INFO][01:42:22]: [Client #9] Sampler: iid
[INFO][01:42:23]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:42:23]: [Client #9] Start to process inbound data.
[INFO][01:42:23]: [93m[1m[Client #9] Started training in communication round #86.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][01:42:56]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.6975, 'train_samples_per_second': 226.763, 'train_steps_per_second': 1.798, 'train_loss': 1.575422763824463, 'epoch': 3.0}
[INFO][01:42:57]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:42:58]: [Client #9] Model trained.
[INFO][01:42:58]: [Client #9] Inbound data has been processed.
[INFO][01:42:58]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:43:02]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:43:03]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:43:03]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:43:03]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:43:03]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][01:43:03]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][01:43:03]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:43:03]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:43:03]: [Server #3350301] Updated weights have been received.
[INFO][01:43:03]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:43:04]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:43:04]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.86it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.59it/s]
[INFO][01:43:15]: [93m[1m[Server #3350301] Global model perplexity: 66.52
[0m
[INFO][01:43:15]: [Server #3350301] All client reports have been processed.
[INFO][01:43:15]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_86.pth.
[INFO][01:43:15]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_86.pth.
[INFO][01:43:15]: [93m[1m
[Server #3350301] Starting round 87/100.[0m
[INFO][01:43:15]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][01:43:15]: [Server #3350301] Selecting client #4 for training.
[INFO][01:43:15]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][01:43:19]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][01:43:19]: [Server #3350301] Selecting client #1 for training.
[INFO][01:43:19]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:43:23]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:43:23]: [Client #4] Selected by the server.
[INFO][01:43:23]: [Client #4] Loading its data source...
[INFO][01:43:23]: [Client #4] Dataset size: 2018
[INFO][01:43:23]: [Client #4] Sampler: iid
[INFO][01:43:23]: [Client #1] Selected by the server.
[INFO][01:43:23]: [Client #1] Loading its data source...
[INFO][01:43:23]: [Client #1] Dataset size: 2018
[INFO][01:43:23]: [Client #1] Sampler: iid
[INFO][01:43:24]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:43:24]: [Client #1] Start to process inbound data.
[INFO][01:43:25]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:43:25]: [Client #4] Start to process inbound data.
[INFO][01:43:25]: [93m[1m[Client #1] Started training in communication round #87.[0m
[INFO][01:43:25]: [93m[1m[Client #4] Started training in communication round #87.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.06s/it]  2%|â–         | 1/48 [00:04<03:43,  4.75s/it]  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.48s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.19s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:44:10]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 38.887, 'train_samples_per_second': 155.682, 'train_steps_per_second': 1.234, 'train_loss': 1.3930288950602214, 'epoch': 3.0}
[INFO][01:44:10]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.348, 'train_samples_per_second': 153.858, 'train_steps_per_second': 1.22, 'train_loss': 2.6329847971598306, 'epoch': 3.0}
[INFO][01:44:11]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:44:11]: [Client #1] Model trained.
[INFO][01:44:11]: [Client #1] Inbound data has been processed.
[INFO][01:44:11]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:44:12]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][01:44:12]: [Client #4] Model trained.
[INFO][01:44:12]: [Client #4] Inbound data has been processed.
[INFO][01:44:12]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][01:44:18]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:44:19]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:44:19]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:44:20]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][01:44:20]: [Server #3350301] Selecting client #8 for training.
[INFO][01:44:20]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][01:44:24]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][01:44:24]: [Server #3350301] Selecting client #3 for training.
[INFO][01:44:24]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:44:28]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:44:28]: [Client #8] Selected by the server.
[INFO][01:44:28]: [Client #8] Loading its data source...
[INFO][01:44:28]: [Client #8] Dataset size: 2018
[INFO][01:44:28]: [Client #3] Selected by the server.
[INFO][01:44:28]: [Client #8] Sampler: iid
[INFO][01:44:28]: [Client #3] Loading its data source...
[INFO][01:44:28]: [Client #3] Dataset size: 2018
[INFO][01:44:28]: [Client #3] Sampler: iid
[INFO][01:44:29]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:44:29]: [Client #3] Start to process inbound data.
[INFO][01:44:29]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:44:29]: [Client #8] Start to process inbound data.
[INFO][01:44:30]: [93m[1m[Client #3] Started training in communication round #87.[0m
[INFO][01:44:30]: [93m[1m[Client #8] Started training in communication round #87.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.40s/it]  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  4%|â–         | 2/48 [00:05<01:49,  2.37s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it]  8%|â–Š         | 4/48 [00:07<01:01,  1.41s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.22s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.23s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.12s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.05s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:43,  1.06s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.02s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:40,  1.01s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:33,  1.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:33,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:32,  1.11it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:31,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:32,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:30,  1.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.12it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.14it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.12it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.12it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:16,  1.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.10it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:13,  1.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.08it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:13,  1.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:09,  1.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.19it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
[INFO][01:45:24]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 47.5301, 'train_samples_per_second': 127.372, 'train_steps_per_second': 1.01, 'train_loss': 1.9335568745930989, 'epoch': 3.0}
[INFO][01:45:24]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 47.3242, 'train_samples_per_second': 127.926, 'train_steps_per_second': 1.014, 'train_loss': 2.680186907450358, 'epoch': 3.0}
[INFO][01:45:25]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:45:25]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][01:45:25]: [Client #3] Model trained.
[INFO][01:45:25]: [Client #3] Inbound data has been processed.
[INFO][01:45:25]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:45:26]: [Client #8] Model trained.
[INFO][01:45:26]: [Client #8] Inbound data has been processed.
[INFO][01:45:26]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][01:45:31]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:45:32]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:45:32]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:45:34]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][01:45:34]: [Server #3350301] Selecting client #10 for training.
[INFO][01:45:34]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:45:37]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:45:37]: [Client #10] Selected by the server.
[INFO][01:45:37]: [Client #10] Loading its data source...
[INFO][01:45:37]: [Client #10] Dataset size: 2018
[INFO][01:45:37]: [Client #10] Sampler: iid
[INFO][01:45:39]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:45:39]: [Client #10] Start to process inbound data.
[INFO][01:45:39]: [93m[1m[Client #10] Started training in communication round #87.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.45it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.61it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.74it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.91it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.96it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  2.00it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][01:46:12]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.4982, 'train_samples_per_second': 228.468, 'train_steps_per_second': 1.811, 'train_loss': 2.209967295328776, 'epoch': 3.0}
[INFO][01:46:13]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:46:14]: [Client #10] Model trained.
[INFO][01:46:14]: [Client #10] Inbound data has been processed.
[INFO][01:46:14]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:46:18]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:46:19]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:46:19]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:46:19]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:46:19]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:46:19]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:46:19]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][01:46:19]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:46:19]: [Server #3350301] Updated weights have been received.
[INFO][01:46:19]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:46:20]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:46:20]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.13it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.64it/s]
[INFO][01:46:31]: [93m[1m[Server #3350301] Global model perplexity: 68.63
[0m
[INFO][01:46:31]: [Server #3350301] All client reports have been processed.
[INFO][01:46:31]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_87.pth.
[INFO][01:46:32]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_87.pth.
[INFO][01:46:32]: [93m[1m
[Server #3350301] Starting round 88/100.[0m
[INFO][01:46:32]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][01:46:32]: [Server #3350301] Selecting client #2 for training.
[INFO][01:46:32]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:46:36]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:46:36]: [Server #3350301] Selecting client #5 for training.
[INFO][01:46:36]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:46:39]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:46:39]: [Client #2] Selected by the server.
[INFO][01:46:39]: [Client #2] Loading its data source...
[INFO][01:46:39]: [Client #2] Dataset size: 2018
[INFO][01:46:39]: [Client #2] Sampler: iid
[INFO][01:46:39]: [Client #5] Selected by the server.
[INFO][01:46:39]: [Client #5] Loading its data source...
[INFO][01:46:39]: [Client #5] Dataset size: 2018
[INFO][01:46:39]: [Client #5] Sampler: iid
[INFO][01:46:41]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:46:41]: [Client #5] Start to process inbound data.
[INFO][01:46:41]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:46:41]: [Client #2] Start to process inbound data.
[INFO][01:46:42]: [93m[1m[Client #5] Started training in communication round #88.[0m
[INFO][01:46:42]: [93m[1m[Client #2] Started training in communication round #88.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:10,  4.05s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:49,  4.87s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.55s/it]  4%|â–         | 2/48 [00:05<02:01,  2.64s/it]  8%|â–Š         | 4/48 [00:06<01:00,  1.37s/it]  6%|â–‹         | 3/48 [00:07<01:26,  1.92s/it] 10%|â–ˆ         | 5/48 [00:07<00:54,  1.26s/it]  8%|â–Š         | 4/48 [00:07<01:08,  1.55s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:49,  1.17s/it] 10%|â–ˆ         | 5/48 [00:08<00:56,  1.32s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:44,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:48,  1.16s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:41,  1.03s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:44,  1.09s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:38,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.04it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:34,  1.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:32,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:32,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:30,  1.08it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:26,  1.15it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:28,  1.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:27,  1.10it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:26,  1.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:27,  1.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:25,  1.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:22,  1.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:22,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:19,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:20,  1.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:30<00:19,  1.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:31<00:17,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:17,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.08it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.09it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:12,  1.05it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:11,  1.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:09,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:08,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:41<00:07,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:42<00:06,  1.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:43<00:05,  1.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:44<00:04,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:45<00:03,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.07it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:47<00:01,  1.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.06it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.00it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:48<00:00,  1.00s/it]
[INFO][01:47:35]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 47.82, 'train_samples_per_second': 126.6, 'train_steps_per_second': 1.004, 'train_loss': 1.539278507232666, 'epoch': 3.0}
[INFO][01:47:36]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 48.1004, 'train_samples_per_second': 125.862, 'train_steps_per_second': 0.998, 'train_loss': 2.0370448430379233, 'epoch': 3.0}
[INFO][01:47:36]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:47:37]: [Client #5] Model trained.
[INFO][01:47:37]: [Client #5] Inbound data has been processed.
[INFO][01:47:37]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:47:37]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:47:38]: [Client #2] Model trained.
[INFO][01:47:38]: [Client #2] Inbound data has been processed.
[INFO][01:47:38]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:47:43]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:47:44]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:47:44]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:47:45]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:47:45]: [Server #3350301] Selecting client #6 for training.
[INFO][01:47:45]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][01:47:49]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][01:47:49]: [Server #3350301] Selecting client #7 for training.
[INFO][01:47:49]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:47:52]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:47:52]: [Client #6] Selected by the server.
[INFO][01:47:52]: [Client #6] Loading its data source...
[INFO][01:47:52]: [Client #7] Selected by the server.
[INFO][01:47:52]: [Client #6] Dataset size: 2018
[INFO][01:47:52]: [Client #7] Loading its data source...
[INFO][01:47:52]: [Client #6] Sampler: iid
[INFO][01:47:52]: [Client #7] Dataset size: 2018
[INFO][01:47:52]: [Client #7] Sampler: iid
[INFO][01:47:54]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:47:54]: [Client #6] Start to process inbound data.
[INFO][01:47:54]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:47:54]: [Client #7] Start to process inbound data.
[INFO][01:47:54]: [93m[1m[Client #6] Started training in communication round #88.[0m
[INFO][01:47:55]: [93m[1m[Client #7] Started training in communication round #88.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.69s/it]  2%|â–         | 1/48 [00:04<03:38,  4.65s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.27s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:48:40]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.5881, 'train_samples_per_second': 152.925, 'train_steps_per_second': 1.212, 'train_loss': 1.9550013542175293, 'epoch': 3.0}
[INFO][01:48:41]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.6136, 'train_samples_per_second': 152.826, 'train_steps_per_second': 1.212, 'train_loss': 2.6351119677225747, 'epoch': 3.0}
[INFO][01:48:42]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:48:42]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:48:42]: [Client #7] Model trained.
[INFO][01:48:42]: [Client #7] Inbound data has been processed.
[INFO][01:48:42]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:48:43]: [Client #6] Model trained.
[INFO][01:48:43]: [Client #6] Inbound data has been processed.
[INFO][01:48:43]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:48:49]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:48:49]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:48:50]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:48:51]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:48:51]: [Server #3350301] Selecting client #9 for training.
[INFO][01:48:51]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:48:54]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:48:54]: [Client #9] Selected by the server.
[INFO][01:48:54]: [Client #9] Loading its data source...
[INFO][01:48:54]: [Client #9] Dataset size: 2018
[INFO][01:48:54]: [Client #9] Sampler: iid
[INFO][01:48:56]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:48:56]: [Client #9] Start to process inbound data.
[INFO][01:48:56]: [93m[1m[Client #9] Started training in communication round #88.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:13,  2.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][01:49:29]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.9532, 'train_samples_per_second': 224.611, 'train_steps_per_second': 1.781, 'train_loss': 1.5370383262634277, 'epoch': 3.0}
[INFO][01:49:30]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:49:30]: [Client #9] Model trained.
[INFO][01:49:30]: [Client #9] Inbound data has been processed.
[INFO][01:49:30]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:49:34]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:49:35]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:49:35]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:49:35]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:49:35]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:49:35]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:49:35]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:49:35]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:49:35]: [Server #3350301] Updated weights have been received.
[INFO][01:49:36]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:49:36]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:49:36]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.39it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][01:49:47]: [93m[1m[Server #3350301] Global model perplexity: 74.99
[0m
[INFO][01:49:47]: [Server #3350301] All client reports have been processed.
[INFO][01:49:47]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_88.pth.
[INFO][01:49:48]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_88.pth.
[INFO][01:49:48]: [93m[1m
[Server #3350301] Starting round 89/100.[0m
[INFO][01:49:48]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][01:49:48]: [Server #3350301] Selecting client #10 for training.
[INFO][01:49:48]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:49:52]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:49:52]: [Server #3350301] Selecting client #1 for training.
[INFO][01:49:52]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:49:56]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:49:56]: [Client #10] Selected by the server.
[INFO][01:49:56]: [Client #10] Loading its data source...
[INFO][01:49:56]: [Client #10] Dataset size: 2018
[INFO][01:49:56]: [Client #10] Sampler: iid
[INFO][01:49:56]: [Client #1] Selected by the server.
[INFO][01:49:56]: [Client #1] Loading its data source...
[INFO][01:49:56]: [Client #1] Dataset size: 2018
[INFO][01:49:56]: [Client #1] Sampler: iid
[INFO][01:49:57]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:49:57]: [Client #1] Start to process inbound data.
[INFO][01:49:57]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:49:57]: [Client #10] Start to process inbound data.
[INFO][01:49:58]: [93m[1m[Client #10] Started training in communication round #89.[0m
[INFO][01:49:58]: [93m[1m[Client #1] Started training in communication round #89.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:03<03:07,  4.00s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.48s/it]  4%|â–         | 2/48 [00:05<01:54,  2.49s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.76s/it] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.12s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:44,  1.05s/it] 10%|â–ˆ         | 5/48 [00:08<00:52,  1.23s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.00s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.11s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.04s/it] 19%|â–ˆâ–‰        | 9/48 [00:10<00:36,  1.06it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:35,  1.06it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.00s/it] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:35,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:33,  1.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:32,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.06it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:32,  1.06it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:30,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:33,  1.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.06it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.15it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:18<00:25,  1.20it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:26,  1.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:19<00:23,  1.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:24,  1.22it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:20<00:21,  1.29it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:23,  1.25it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:21<00:20,  1.30it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:21,  1.28it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:21<00:19,  1.32it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:20,  1.30it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:22<00:18,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:22<00:19,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:23<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:23<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:24<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:24<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:24<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:25<00:17,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:25<00:15,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:25<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:26<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:26<00:16,  1.30it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:27<00:14,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:27<00:15,  1.29it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:27<00:13,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:28<00:14,  1.28it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:28<00:13,  1.29it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:28<00:13,  1.29it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:29<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:29<00:13,  1.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:30<00:11,  1.27it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:30<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:30<00:10,  1.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:31<00:11,  1.31it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:31<00:09,  1.31it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:32<00:10,  1.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:32<00:09,  1.30it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:32<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:33<00:08,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:33<00:09,  1.30it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:34<00:07,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:34<00:08,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:34<00:06,  1.31it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:35<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:35<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:35<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:36<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:36<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:37<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:37<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:37<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:38<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:38<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:38<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:39<00:02,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:39<00:03,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:40<00:01,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:40<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:40<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:41<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.16it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:41<00:00,  1.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.67it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:41<00:00,  1.14it/s]
[INFO][01:50:46]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 41.4943, 'train_samples_per_second': 145.9, 'train_steps_per_second': 1.157, 'train_loss': 1.3712104161580403, 'epoch': 3.0}
[INFO][01:50:46]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 41.9907, 'train_samples_per_second': 144.175, 'train_steps_per_second': 1.143, 'train_loss': 2.1818761825561523, 'epoch': 3.0}
[INFO][01:50:47]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:50:47]: [Client #1] Model trained.
[INFO][01:50:47]: [Client #1] Inbound data has been processed.
[INFO][01:50:47]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:50:48]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:50:48]: [Client #10] Model trained.
[INFO][01:50:48]: [Client #10] Inbound data has been processed.
[INFO][01:50:48]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:50:53]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:50:54]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:50:54]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:50:55]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:50:55]: [Server #3350301] Selecting client #3 for training.
[INFO][01:50:55]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:50:59]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:50:59]: [Server #3350301] Selecting client #5 for training.
[INFO][01:50:59]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:51:02]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:51:02]: [Client #5] Selected by the server.
[INFO][01:51:02]: [Client #3] Selected by the server.
[INFO][01:51:02]: [Client #5] Loading its data source...
[INFO][01:51:02]: [Client #3] Loading its data source...
[INFO][01:51:02]: [Client #5] Dataset size: 2018
[INFO][01:51:02]: [Client #5] Sampler: iid
[INFO][01:51:02]: [Client #3] Dataset size: 2018
[INFO][01:51:02]: [Client #3] Sampler: iid
[INFO][01:51:04]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:51:04]: [Client #3] Start to process inbound data.
[INFO][01:51:04]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:51:04]: [Client #5] Start to process inbound data.
[INFO][01:51:05]: [93m[1m[Client #3] Started training in communication round #89.[0m
[INFO][01:51:05]: [93m[1m[Client #5] Started training in communication round #89.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:35,  4.58s/it]  2%|â–         | 1/48 [00:04<03:40,  4.70s/it]  4%|â–         | 2/48 [00:05<01:46,  2.32s/it]  4%|â–         | 2/48 [00:05<01:48,  2.37s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.59s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.27s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.05it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.21it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.31it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:19,  1.31it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.31it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:51:51]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.7325, 'train_samples_per_second': 152.369, 'train_steps_per_second': 1.208, 'train_loss': 1.5005927085876465, 'epoch': 3.0}
[INFO][01:51:51]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.6341, 'train_samples_per_second': 152.747, 'train_steps_per_second': 1.211, 'train_loss': 1.8816286722819011, 'epoch': 3.0}
[INFO][01:51:52]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:51:52]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][01:51:52]: [Client #5] Model trained.
[INFO][01:51:52]: [Client #5] Inbound data has been processed.
[INFO][01:51:52]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:51:53]: [Client #3] Model trained.
[INFO][01:51:53]: [Client #3] Inbound data has been processed.
[INFO][01:51:53]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:51:58]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:51:59]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:52:00]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:52:01]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:52:01]: [Server #3350301] Selecting client #9 for training.
[INFO][01:52:01]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:52:05]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:52:05]: [Client #9] Selected by the server.
[INFO][01:52:05]: [Client #9] Loading its data source...
[INFO][01:52:05]: [Client #9] Dataset size: 2018
[INFO][01:52:05]: [Client #9] Sampler: iid
[INFO][01:52:06]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:52:06]: [Client #9] Start to process inbound data.
[INFO][01:52:06]: [93m[1m[Client #9] Started training in communication round #89.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:16,  4.19s/it]  4%|â–         | 2/48 [00:04<01:32,  2.00s/it]  6%|â–‹         | 3/48 [00:05<00:58,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:28,  1.45it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.61it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.74it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.84it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.91it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:08<00:18,  1.96it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:17,  2.00it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.03it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.18it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:17<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.20it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.13it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.10it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][01:52:39]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.4543, 'train_samples_per_second': 228.848, 'train_steps_per_second': 1.814, 'train_loss': 1.5237247149149578, 'epoch': 3.0}
[INFO][01:52:40]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:52:40]: [Client #9] Model trained.
[INFO][01:52:40]: [Client #9] Inbound data has been processed.
[INFO][01:52:40]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:52:44]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:52:45]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:52:45]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:52:45]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:52:45]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][01:52:45]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][01:52:45]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:52:45]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:52:45]: [Server #3350301] Updated weights have been received.
[INFO][01:52:45]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:52:46]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:52:46]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.20it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.39it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][01:52:57]: [93m[1m[Server #3350301] Global model perplexity: 70.53
[0m
[INFO][01:52:57]: [Server #3350301] All client reports have been processed.
[INFO][01:52:57]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_89.pth.
[INFO][01:52:57]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_89.pth.
[INFO][01:52:57]: [93m[1m
[Server #3350301] Starting round 90/100.[0m
[INFO][01:52:57]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][01:52:57]: [Server #3350301] Selecting client #2 for training.
[INFO][01:52:57]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:53:01]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:53:01]: [Server #3350301] Selecting client #1 for training.
[INFO][01:53:01]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:53:05]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:53:05]: [Client #2] Selected by the server.
[INFO][01:53:05]: [Client #2] Loading its data source...
[INFO][01:53:05]: [Client #2] Dataset size: 2018
[INFO][01:53:05]: [Client #2] Sampler: iid
[INFO][01:53:05]: [Client #1] Selected by the server.
[INFO][01:53:05]: [Client #1] Loading its data source...
[INFO][01:53:05]: [Client #1] Dataset size: 2018
[INFO][01:53:05]: [Client #1] Sampler: iid
[INFO][01:53:07]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:53:07]: [Client #2] Start to process inbound data.
[INFO][01:53:07]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:53:07]: [Client #1] Start to process inbound data.
[INFO][01:53:07]: [93m[1m[Client #2] Started training in communication round #90.[0m
[INFO][01:53:07]: [93m[1m[Client #1] Started training in communication round #90.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:32,  4.51s/it]  2%|â–         | 1/48 [00:04<03:35,  4.58s/it]  4%|â–         | 2/48 [00:05<01:43,  2.26s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.56s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:53:53]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.4332, 'train_samples_per_second': 153.525, 'train_steps_per_second': 1.217, 'train_loss': 1.3408308029174805, 'epoch': 3.0}
[INFO][01:53:53]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.3721, 'train_samples_per_second': 153.764, 'train_steps_per_second': 1.219, 'train_loss': 2.011018753051758, 'epoch': 3.0}
[INFO][01:53:54]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][01:53:54]: [Client #1] Model trained.
[INFO][01:53:54]: [Client #1] Inbound data has been processed.
[INFO][01:53:54]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][01:53:55]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][01:53:55]: [Client #2] Model trained.
[INFO][01:53:55]: [Client #2] Inbound data has been processed.
[INFO][01:53:55]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][01:54:00]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:54:01]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][01:54:01]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:54:02]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][01:54:02]: [Server #3350301] Selecting client #4 for training.
[INFO][01:54:02]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][01:54:06]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][01:54:06]: [Server #3350301] Selecting client #7 for training.
[INFO][01:54:06]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][01:54:10]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][01:54:10]: [Client #7] Selected by the server.
[INFO][01:54:10]: [Client #7] Loading its data source...
[INFO][01:54:10]: [Client #4] Selected by the server.
[INFO][01:54:10]: [Client #7] Dataset size: 2018
[INFO][01:54:10]: [Client #4] Loading its data source...
[INFO][01:54:10]: [Client #7] Sampler: iid
[INFO][01:54:10]: [Client #4] Dataset size: 2018
[INFO][01:54:10]: [Client #4] Sampler: iid
[INFO][01:54:11]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:54:11]: [Client #7] Start to process inbound data.
[INFO][01:54:11]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:54:11]: [Client #4] Start to process inbound data.
[INFO][01:54:12]: [93m[1m[Client #4] Started training in communication round #90.[0m
[INFO][01:54:12]: [93m[1m[Client #7] Started training in communication round #90.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:14,  4.15s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.11s/it]  2%|â–         | 1/48 [00:04<03:29,  4.45s/it]  6%|â–‹         | 3/48 [00:05<01:06,  1.48s/it]  4%|â–         | 2/48 [00:05<01:44,  2.28s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  6%|â–‹         | 3/48 [00:05<01:11,  1.59s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:23,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][01:54:57]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.0936, 'train_samples_per_second': 154.859, 'train_steps_per_second': 1.228, 'train_loss': 1.9347445170084636, 'epoch': 3.0}
[INFO][01:54:58]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.1903, 'train_samples_per_second': 154.477, 'train_steps_per_second': 1.225, 'train_loss': 2.5833212534586587, 'epoch': 3.0}
[INFO][01:54:58]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][01:54:59]: [Client #7] Model trained.
[INFO][01:54:59]: [Client #7] Inbound data has been processed.
[INFO][01:54:59]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][01:54:59]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][01:55:00]: [Client #4] Model trained.
[INFO][01:55:00]: [Client #4] Inbound data has been processed.
[INFO][01:55:00]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][01:55:05]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:55:06]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][01:55:06]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:55:07]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][01:55:07]: [Server #3350301] Selecting client #8 for training.
[INFO][01:55:07]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][01:55:11]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][01:55:11]: [Client #8] Selected by the server.
[INFO][01:55:11]: [Client #8] Loading its data source...
[INFO][01:55:11]: [Client #8] Dataset size: 2018
[INFO][01:55:11]: [Client #8] Sampler: iid
[INFO][01:55:12]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:55:12]: [Client #8] Start to process inbound data.
[INFO][01:55:12]: [93m[1m[Client #8] Started training in communication round #90.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:55:45]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.7529, 'train_samples_per_second': 226.293, 'train_steps_per_second': 1.794, 'train_loss': 2.6435701052347818, 'epoch': 3.0}
[INFO][01:55:46]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][01:55:46]: [Client #8] Model trained.
[INFO][01:55:46]: [Client #8] Inbound data has been processed.
[INFO][01:55:46]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][01:55:50]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:55:52]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][01:55:52]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:55:52]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:55:52]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][01:55:52]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][01:55:52]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][01:55:52]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:55:52]: [Server #3350301] Updated weights have been received.
[INFO][01:55:52]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:55:53]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:55:53]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.60it/s]
[INFO][01:56:04]: [93m[1m[Server #3350301] Global model perplexity: 70.88
[0m
[INFO][01:56:04]: [Server #3350301] All client reports have been processed.
[INFO][01:56:04]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_90.pth.
[INFO][01:56:04]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_90.pth.
[INFO][01:56:04]: [93m[1m
[Server #3350301] Starting round 91/100.[0m
[INFO][01:56:04]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][01:56:04]: [Server #3350301] Selecting client #6 for training.
[INFO][01:56:04]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][01:56:08]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][01:56:08]: [Server #3350301] Selecting client #3 for training.
[INFO][01:56:08]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][01:56:12]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][01:56:12]: [Client #6] Selected by the server.
[INFO][01:56:12]: [Client #6] Loading its data source...
[INFO][01:56:12]: [Client #6] Dataset size: 2018
[INFO][01:56:12]: [Client #6] Sampler: iid
[INFO][01:56:12]: [Client #3] Selected by the server.
[INFO][01:56:12]: [Client #3] Loading its data source...
[INFO][01:56:12]: [Client #3] Dataset size: 2018
[INFO][01:56:12]: [Client #3] Sampler: iid
[INFO][01:56:13]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:56:13]: [Client #3] Start to process inbound data.
[INFO][01:56:13]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:56:13]: [Client #6] Start to process inbound data.
[INFO][01:56:14]: [93m[1m[Client #3] Started training in communication round #91.[0m
[INFO][01:56:14]: [93m[1m[Client #6] Started training in communication round #91.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:50,  4.90s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  4%|â–         | 2/48 [00:05<01:53,  2.47s/it]  4%|â–         | 2/48 [00:05<01:54,  2.49s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.67s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.69s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.32s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.11s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.36it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:57:00]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.6616, 'train_samples_per_second': 152.641, 'train_steps_per_second': 1.21, 'train_loss': 2.6098845799764, 'epoch': 3.0}
[INFO][01:57:00]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.6237, 'train_samples_per_second': 152.787, 'train_steps_per_second': 1.211, 'train_loss': 1.839422384897868, 'epoch': 3.0}
[INFO][01:57:01]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][01:57:01]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][01:57:01]: [Client #6] Model trained.
[INFO][01:57:01]: [Client #6] Inbound data has been processed.
[INFO][01:57:01]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][01:57:02]: [Client #3] Model trained.
[INFO][01:57:02]: [Client #3] Inbound data has been processed.
[INFO][01:57:02]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][01:57:08]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:57:09]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:57:09]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][01:57:10]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][01:57:10]: [Server #3350301] Selecting client #10 for training.
[INFO][01:57:10]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][01:57:14]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][01:57:14]: [Server #3350301] Selecting client #5 for training.
[INFO][01:57:14]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][01:57:17]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][01:57:17]: [Client #10] Selected by the server.
[INFO][01:57:17]: [Client #10] Loading its data source...
[INFO][01:57:17]: [Client #10] Dataset size: 2018
[INFO][01:57:17]: [Client #10] Sampler: iid
[INFO][01:57:17]: [Client #5] Selected by the server.
[INFO][01:57:17]: [Client #5] Loading its data source...
[INFO][01:57:17]: [Client #5] Dataset size: 2018
[INFO][01:57:17]: [Client #5] Sampler: iid
[INFO][01:57:19]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:57:19]: [Client #5] Start to process inbound data.
[INFO][01:57:19]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:57:19]: [Client #10] Start to process inbound data.
[INFO][01:57:19]: [93m[1m[Client #10] Started training in communication round #91.[0m
[INFO][01:57:19]: [93m[1m[Client #5] Started training in communication round #91.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.68s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.27s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.24it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:29,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.30it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.31it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][01:58:06]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.8132, 'train_samples_per_second': 152.06, 'train_steps_per_second': 1.206, 'train_loss': 2.144816239674886, 'epoch': 3.0}
[INFO][01:58:06]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.7214, 'train_samples_per_second': 152.412, 'train_steps_per_second': 1.208, 'train_loss': 1.4646410942077637, 'epoch': 3.0}
[INFO][01:58:07]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][01:58:07]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][01:58:07]: [Client #10] Model trained.
[INFO][01:58:07]: [Client #10] Inbound data has been processed.
[INFO][01:58:07]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][01:58:07]: [Client #5] Model trained.
[INFO][01:58:07]: [Client #5] Inbound data has been processed.
[INFO][01:58:07]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][01:58:14]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:58:14]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:58:15]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][01:58:16]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][01:58:16]: [Server #3350301] Selecting client #9 for training.
[INFO][01:58:16]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][01:58:20]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][01:58:20]: [Client #9] Selected by the server.
[INFO][01:58:20]: [Client #9] Loading its data source...
[INFO][01:58:20]: [Client #9] Dataset size: 2018
[INFO][01:58:20]: [Client #9] Sampler: iid
[INFO][01:58:21]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:58:21]: [Client #9] Start to process inbound data.
[INFO][01:58:21]: [93m[1m[Client #9] Started training in communication round #91.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.42it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:26,  1.57it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.70it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.80it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.87it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][01:58:54]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.7703, 'train_samples_per_second': 226.146, 'train_steps_per_second': 1.793, 'train_loss': 1.486449400583903, 'epoch': 3.0}
[INFO][01:58:56]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][01:58:56]: [Client #9] Model trained.
[INFO][01:58:56]: [Client #9] Inbound data has been processed.
[INFO][01:58:56]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][01:59:00]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][01:59:02]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][01:59:02]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][01:59:02]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][01:59:02]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][01:59:02]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][01:59:02]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][01:59:02]: [Server #3350301] Aggregating 5 clients in total.
[INFO][01:59:02]: [Server #3350301] Updated weights have been received.
[INFO][01:59:02]: [Server #3350301] Aggregating model weight deltas.
[INFO][01:59:03]: [Server #3350301] Finished aggregating updated weights.
[INFO][01:59:03]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.95it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.41it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.75it/s]
[INFO][01:59:14]: [93m[1m[Server #3350301] Global model perplexity: 79.93
[0m
[INFO][01:59:14]: [Server #3350301] All client reports have been processed.
[INFO][01:59:14]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_91.pth.
[INFO][01:59:14]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_91.pth.
[INFO][01:59:14]: [93m[1m
[Server #3350301] Starting round 92/100.[0m
[INFO][01:59:14]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][01:59:14]: [Server #3350301] Selecting client #2 for training.
[INFO][01:59:14]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][01:59:18]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][01:59:18]: [Server #3350301] Selecting client #1 for training.
[INFO][01:59:18]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][01:59:22]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][01:59:22]: [Client #2] Selected by the server.
[INFO][01:59:22]: [Client #2] Loading its data source...
[INFO][01:59:22]: [Client #2] Dataset size: 2018
[INFO][01:59:22]: [Client #2] Sampler: iid
[INFO][01:59:22]: [Client #1] Selected by the server.
[INFO][01:59:22]: [Client #1] Loading its data source...
[INFO][01:59:22]: [Client #1] Dataset size: 2018
[INFO][01:59:22]: [Client #1] Sampler: iid
[INFO][01:59:23]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:59:23]: [Client #2] Start to process inbound data.
[INFO][01:59:23]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][01:59:23]: [Client #1] Start to process inbound data.
[INFO][01:59:24]: [93m[1m[Client #2] Started training in communication round #92.[0m
[INFO][01:59:24]: [93m[1m[Client #1] Started training in communication round #92.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  2%|â–         | 1/48 [00:04<03:47,  4.85s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.35it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:10,  1.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.30it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:00:09]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.1228, 'train_samples_per_second': 154.743, 'train_steps_per_second': 1.227, 'train_loss': 1.3374581336975098, 'epoch': 3.0}
[INFO][02:00:10]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.5629, 'train_samples_per_second': 153.022, 'train_steps_per_second': 1.213, 'train_loss': 1.9968454043070476, 'epoch': 3.0}
[INFO][02:00:11]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][02:00:11]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][02:00:11]: [Client #1] Model trained.
[INFO][02:00:11]: [Client #1] Inbound data has been processed.
[INFO][02:00:11]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][02:00:11]: [Client #2] Model trained.
[INFO][02:00:11]: [Client #2] Inbound data has been processed.
[INFO][02:00:11]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][02:00:18]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:00:18]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:00:19]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][02:00:20]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][02:00:20]: [Server #3350301] Selecting client #5 for training.
[INFO][02:00:20]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][02:00:24]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][02:00:24]: [Server #3350301] Selecting client #7 for training.
[INFO][02:00:24]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][02:00:27]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][02:00:27]: [Client #5] Selected by the server.
[INFO][02:00:27]: [Client #5] Loading its data source...
[INFO][02:00:27]: [Client #7] Selected by the server.
[INFO][02:00:27]: [Client #7] Loading its data source...
[INFO][02:00:27]: [Client #5] Dataset size: 2018
[INFO][02:00:27]: [Client #5] Sampler: iid
[INFO][02:00:27]: [Client #7] Dataset size: 2018
[INFO][02:00:27]: [Client #7] Sampler: iid
[INFO][02:00:28]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:00:28]: [Client #7] Start to process inbound data.
[INFO][02:00:29]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:00:29]: [Client #5] Start to process inbound data.
[INFO][02:00:29]: [93m[1m[Client #7] Started training in communication round #92.[0m
[INFO][02:00:29]: [93m[1m[Client #5] Started training in communication round #92.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:41,  4.71s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  4%|â–         | 2/48 [00:05<01:58,  2.58s/it]  6%|â–‹         | 3/48 [00:06<01:22,  1.82s/it]  6%|â–‹         | 3/48 [00:06<01:25,  1.90s/it]  8%|â–Š         | 4/48 [00:07<01:07,  1.53s/it]  8%|â–Š         | 4/48 [00:08<01:09,  1.58s/it] 10%|â–ˆ         | 5/48 [00:08<00:58,  1.36s/it] 10%|â–ˆ         | 5/48 [00:09<01:00,  1.40s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:52,  1.25s/it] 12%|â–ˆâ–Ž        | 6/48 [00:10<00:53,  1.28s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:47,  1.15s/it] 15%|â–ˆâ–        | 7/48 [00:11<00:48,  1.17s/it] 17%|â–ˆâ–‹        | 8/48 [00:11<00:43,  1.08s/it] 17%|â–ˆâ–‹        | 8/48 [00:12<00:43,  1.09s/it] 19%|â–ˆâ–‰        | 9/48 [00:12<00:38,  1.01it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:39,  1.02s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.05it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:37,  1.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:35,  1.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:14<00:36,  1.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:33,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:15<00:34,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:16<00:32,  1.08it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:31,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:17<00:31,  1.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:29,  1.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:18<00:31,  1.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:19<00:28,  1.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:27,  1.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:20<00:27,  1.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:26,  1.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:21<00:27,  1.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:26,  1.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:25<00:22,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:22,  1.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:26<00:21,  1.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:27<00:21,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:20,  1.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:28<00:20,  1.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:29<00:19,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:30<00:18,  1.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:31<00:17,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:32<00:16,  1.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:15,  1.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:33<00:16,  1.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:13,  1.16it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:14,  1.03it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.07it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:14,  1.00s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:35<00:13,  1.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:36<00:12,  1.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:37<00:11,  1.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:10,  1.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:38<00:09,  1.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:08,  1.12it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:39<00:08,  1.18it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:07,  1.17it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:40<00:07,  1.23it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:06,  1.21it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:06,  1.26it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:05,  1.25it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:05,  1.28it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:04,  1.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:04,  1.30it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:03,  1.26it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:03,  1.30it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.28it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.30it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.31it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.03it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:46<00:00,  1.03it/s]
[INFO][02:01:22]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 46.7458, 'train_samples_per_second': 129.509, 'train_steps_per_second': 1.027, 'train_loss': 1.8985268274943035, 'epoch': 3.0}
[INFO][02:01:22]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 46.729, 'train_samples_per_second': 129.556, 'train_steps_per_second': 1.027, 'train_loss': 1.4544893900553386, 'epoch': 3.0}
[INFO][02:01:23]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][02:01:23]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][02:01:23]: [Client #7] Model trained.
[INFO][02:01:23]: [Client #7] Inbound data has been processed.
[INFO][02:01:23]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][02:01:23]: [Client #5] Model trained.
[INFO][02:01:23]: [Client #5] Inbound data has been processed.
[INFO][02:01:23]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][02:01:30]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:01:30]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:01:31]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][02:01:32]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][02:01:32]: [Server #3350301] Selecting client #9 for training.
[INFO][02:01:32]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][02:01:36]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][02:01:36]: [Client #9] Selected by the server.
[INFO][02:01:36]: [Client #9] Loading its data source...
[INFO][02:01:36]: [Client #9] Dataset size: 2018
[INFO][02:01:36]: [Client #9] Sampler: iid
[INFO][02:01:37]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:01:37]: [Client #9] Start to process inbound data.
[INFO][02:01:37]: [93m[1m[Client #9] Started training in communication round #92.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.25s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.20it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][02:02:10]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.5644, 'train_samples_per_second': 227.899, 'train_steps_per_second': 1.807, 'train_loss': 1.477388858795166, 'epoch': 3.0}
[INFO][02:02:11]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][02:02:11]: [Client #9] Model trained.
[INFO][02:02:11]: [Client #9] Inbound data has been processed.
[INFO][02:02:11]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][02:02:15]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:02:17]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][02:02:17]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][02:02:17]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][02:02:17]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][02:02:17]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][02:02:17]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][02:02:17]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:02:17]: [Server #3350301] Updated weights have been received.
[INFO][02:02:17]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:02:18]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:02:18]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.54it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.50it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.70it/s]
[INFO][02:02:29]: [93m[1m[Server #3350301] Global model perplexity: 72.83
[0m
[INFO][02:02:29]: [Server #3350301] All client reports have been processed.
[INFO][02:02:29]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_92.pth.
[INFO][02:02:29]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_92.pth.
[INFO][02:02:29]: [93m[1m
[Server #3350301] Starting round 93/100.[0m
[INFO][02:02:29]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][02:02:29]: [Server #3350301] Selecting client #4 for training.
[INFO][02:02:29]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][02:02:33]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][02:02:33]: [Server #3350301] Selecting client #1 for training.
[INFO][02:02:33]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][02:02:37]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][02:02:37]: [Client #4] Selected by the server.
[INFO][02:02:37]: [Client #4] Loading its data source...
[INFO][02:02:37]: [Client #4] Dataset size: 2018
[INFO][02:02:37]: [Client #4] Sampler: iid
[INFO][02:02:37]: [Client #1] Selected by the server.
[INFO][02:02:37]: [Client #1] Loading its data source...
[INFO][02:02:37]: [Client #1] Dataset size: 2018
[INFO][02:02:37]: [Client #1] Sampler: iid
[INFO][02:02:38]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:02:38]: [Client #1] Start to process inbound data.
[INFO][02:02:38]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:02:38]: [Client #4] Start to process inbound data.
[INFO][02:02:39]: [93m[1m[Client #1] Started training in communication round #93.[0m
[INFO][02:02:39]: [93m[1m[Client #4] Started training in communication round #93.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:52,  4.95s/it]  2%|â–         | 1/48 [00:04<03:53,  4.96s/it]  4%|â–         | 2/48 [00:05<01:58,  2.57s/it]  4%|â–         | 2/48 [00:05<01:59,  2.60s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.73s/it]  6%|â–‹         | 3/48 [00:06<01:19,  1.77s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.33s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it] 10%|â–ˆ         | 5/48 [00:08<00:47,  1.12s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.14s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.00s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:42,  1.01s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.16it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.31it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:28<00:11,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.32it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.31it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.20it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:40<00:00,  1.20it/s]
[INFO][02:03:25]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 40.0716, 'train_samples_per_second': 151.079, 'train_steps_per_second': 1.198, 'train_loss': 2.562547047932943, 'epoch': 3.0}
[INFO][02:03:25]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.9759, 'train_samples_per_second': 151.441, 'train_steps_per_second': 1.201, 'train_loss': 1.371657371520996, 'epoch': 3.0}
[INFO][02:03:26]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][02:03:27]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][02:03:27]: [Client #4] Model trained.
[INFO][02:03:27]: [Client #4] Inbound data has been processed.
[INFO][02:03:27]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][02:03:27]: [Client #1] Model trained.
[INFO][02:03:27]: [Client #1] Inbound data has been processed.
[INFO][02:03:27]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][02:03:34]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:03:34]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:03:35]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][02:03:36]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][02:03:36]: [Server #3350301] Selecting client #8 for training.
[INFO][02:03:36]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][02:03:39]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][02:03:39]: [Server #3350301] Selecting client #3 for training.
[INFO][02:03:39]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][02:03:43]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][02:03:43]: [Client #8] Selected by the server.
[INFO][02:03:43]: [Client #8] Loading its data source...
[INFO][02:03:43]: [Client #8] Dataset size: 2018
[INFO][02:03:43]: [Client #3] Selected by the server.
[INFO][02:03:43]: [Client #8] Sampler: iid
[INFO][02:03:43]: [Client #3] Loading its data source...
[INFO][02:03:43]: [Client #3] Dataset size: 2018
[INFO][02:03:43]: [Client #3] Sampler: iid
[INFO][02:03:45]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:03:45]: [Client #8] Start to process inbound data.
[INFO][02:03:45]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:03:45]: [Client #3] Start to process inbound data.
[INFO][02:03:45]: [93m[1m[Client #8] Started training in communication round #93.[0m
[INFO][02:03:45]: [93m[1m[Client #3] Started training in communication round #93.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:37,  4.63s/it]  2%|â–         | 1/48 [00:04<03:42,  4.72s/it]  4%|â–         | 2/48 [00:05<01:47,  2.35s/it]  4%|â–         | 2/48 [00:05<01:48,  2.37s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][02:04:31]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.506, 'train_samples_per_second': 153.242, 'train_steps_per_second': 1.215, 'train_loss': 1.8241639137268066, 'epoch': 3.0}
[INFO][02:04:31]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.5096, 'train_samples_per_second': 153.229, 'train_steps_per_second': 1.215, 'train_loss': 2.623509089152018, 'epoch': 3.0}
[INFO][02:04:32]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][02:04:32]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][02:04:33]: [Client #3] Model trained.
[INFO][02:04:33]: [Client #3] Inbound data has been processed.
[INFO][02:04:33]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][02:04:33]: [Client #8] Model trained.
[INFO][02:04:33]: [Client #8] Inbound data has been processed.
[INFO][02:04:33]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][02:04:39]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:04:39]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:04:40]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][02:04:41]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][02:04:41]: [Server #3350301] Selecting client #10 for training.
[INFO][02:04:41]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][02:04:45]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][02:04:45]: [Client #10] Selected by the server.
[INFO][02:04:45]: [Client #10] Loading its data source...
[INFO][02:04:45]: [Client #10] Dataset size: 2018
[INFO][02:04:45]: [Client #10] Sampler: iid
[INFO][02:04:46]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:04:46]: [Client #10] Start to process inbound data.
[INFO][02:04:46]: [93m[1m[Client #10] Started training in communication round #93.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:20,  4.26s/it]  4%|â–         | 2/48 [00:04<01:33,  2.04s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:15,  2.13it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.18it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][02:05:19]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.7907, 'train_samples_per_second': 225.974, 'train_steps_per_second': 1.792, 'train_loss': 2.1174842516581216, 'epoch': 3.0}
[INFO][02:05:20]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][02:05:21]: [Client #10] Model trained.
[INFO][02:05:21]: [Client #10] Inbound data has been processed.
[INFO][02:05:21]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][02:05:25]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:05:26]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][02:05:26]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][02:05:26]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][02:05:26]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][02:05:26]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][02:05:26]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][02:05:26]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:05:26]: [Server #3350301] Updated weights have been received.
[INFO][02:05:26]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:05:27]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:05:27]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.21it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.57it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 12.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.81it/s]
[INFO][02:05:38]: [93m[1m[Server #3350301] Global model perplexity: 75.38
[0m
[INFO][02:05:38]: [Server #3350301] All client reports have been processed.
[INFO][02:05:38]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_93.pth.
[INFO][02:05:39]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_93.pth.
[INFO][02:05:39]: [93m[1m
[Server #3350301] Starting round 94/100.[0m
[INFO][02:05:39]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][02:05:39]: [Server #3350301] Selecting client #2 for training.
[INFO][02:05:39]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][02:05:43]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][02:05:43]: [Server #3350301] Selecting client #5 for training.
[INFO][02:05:43]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][02:05:46]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][02:05:46]: [Client #2] Selected by the server.
[INFO][02:05:46]: [Client #2] Loading its data source...
[INFO][02:05:46]: [Client #2] Dataset size: 2018
[INFO][02:05:46]: [Client #2] Sampler: iid
[INFO][02:05:46]: [Client #5] Selected by the server.
[INFO][02:05:46]: [Client #5] Loading its data source...
[INFO][02:05:46]: [Client #5] Dataset size: 2018
[INFO][02:05:46]: [Client #5] Sampler: iid
[INFO][02:05:48]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:05:48]: [Client #2] Start to process inbound data.
[INFO][02:05:48]: [93m[1m[Client #2] Started training in communication round #94.[0m
[INFO][02:05:48]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:05:48]: [Client #5] Start to process inbound data.
[INFO][02:05:48]: [93m[1m[Client #5] Started training in communication round #94.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:09,  4.03s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:34,  2.05s/it]  2%|â–         | 1/48 [00:04<03:33,  4.54s/it]  6%|â–‹         | 3/48 [00:05<01:05,  1.44s/it]  4%|â–         | 2/48 [00:05<01:46,  2.32s/it]  8%|â–Š         | 4/48 [00:06<00:51,  1.17s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.60s/it] 10%|â–ˆ         | 5/48 [00:06<00:43,  1.02s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.09it/s] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.16it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:31,  1.25it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:14<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:17<00:20,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.32it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:20<00:18,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.39it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:29<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.31it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:32<00:05,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][02:06:33]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 38.8877, 'train_samples_per_second': 155.679, 'train_steps_per_second': 1.234, 'train_loss': 1.9466867446899414, 'epoch': 3.0}
[INFO][02:06:33]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.24, 'train_samples_per_second': 154.281, 'train_steps_per_second': 1.223, 'train_loss': 1.416906197865804, 'epoch': 3.0}
[INFO][02:06:34]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][02:06:34]: [Client #2] Model trained.
[INFO][02:06:34]: [Client #2] Inbound data has been processed.
[INFO][02:06:34]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][02:06:35]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][02:06:35]: [Client #5] Model trained.
[INFO][02:06:35]: [Client #5] Inbound data has been processed.
[INFO][02:06:35]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][02:06:40]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:06:41]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][02:06:42]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:06:43]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][02:06:43]: [Server #3350301] Selecting client #6 for training.
[INFO][02:06:43]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][02:06:46]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][02:06:46]: [Server #3350301] Selecting client #7 for training.
[INFO][02:06:46]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][02:06:50]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][02:06:50]: [Client #6] Selected by the server.
[INFO][02:06:50]: [Client #6] Loading its data source...
[INFO][02:06:50]: [Client #6] Dataset size: 2018
[INFO][02:06:50]: [Client #6] Sampler: iid
[INFO][02:06:50]: [Client #7] Selected by the server.
[INFO][02:06:50]: [Client #7] Loading its data source...
[INFO][02:06:50]: [Client #7] Dataset size: 2018
[INFO][02:06:50]: [Client #7] Sampler: iid
[INFO][02:06:51]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:06:51]: [Client #7] Start to process inbound data.
[INFO][02:06:51]: [93m[1m[Client #7] Started training in communication round #94.[0m
[INFO][02:06:51]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:06:51]: [Client #6] Start to process inbound data.
[INFO][02:06:52]: [93m[1m[Client #6] Started training in communication round #94.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:11,  4.07s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:35,  2.07s/it]  2%|â–         | 1/48 [00:04<03:47,  4.83s/it]  6%|â–‹         | 3/48 [00:05<01:05,  1.47s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  8%|â–Š         | 4/48 [00:06<00:51,  1.17s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it] 10%|â–ˆ         | 5/48 [00:06<00:43,  1.02s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:38,  1.09it/s] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.16it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:32,  1.22it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 19%|â–ˆâ–‰        | 9/48 [00:09<00:31,  1.26it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.29it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:12<00:26,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:14<00:22,  1.41it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.33it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.31it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:26<00:11,  1.40it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:09,  1.33it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:38<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:07:36]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 38.9426, 'train_samples_per_second': 155.46, 'train_steps_per_second': 1.233, 'train_loss': 1.8686103820800781, 'epoch': 3.0}
[INFO][02:07:37]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.5555, 'train_samples_per_second': 153.051, 'train_steps_per_second': 1.213, 'train_loss': 2.5798540115356445, 'epoch': 3.0}
[INFO][02:07:38]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][02:07:38]: [Client #7] Model trained.
[INFO][02:07:38]: [Client #7] Inbound data has been processed.
[INFO][02:07:38]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][02:07:38]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][02:07:39]: [Client #6] Model trained.
[INFO][02:07:39]: [Client #6] Inbound data has been processed.
[INFO][02:07:39]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][02:07:44]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:07:45]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:07:45]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][02:07:46]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][02:07:46]: [Server #3350301] Selecting client #9 for training.
[INFO][02:07:46]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][02:07:50]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][02:07:50]: [Client #9] Selected by the server.
[INFO][02:07:50]: [Client #9] Loading its data source...
[INFO][02:07:50]: [Client #9] Dataset size: 2018
[INFO][02:07:50]: [Client #9] Sampler: iid
[INFO][02:07:52]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:07:52]: [Client #9] Start to process inbound data.
[INFO][02:07:52]: [93m[1m[Client #9] Started training in communication round #94.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:17,  4.20s/it]  4%|â–         | 2/48 [00:04<01:32,  2.01s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.13it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][02:08:25]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.8786, 'train_samples_per_second': 225.235, 'train_steps_per_second': 1.786, 'train_loss': 1.4276281992594402, 'epoch': 3.0}
[INFO][02:08:26]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][02:08:26]: [Client #9] Model trained.
[INFO][02:08:26]: [Client #9] Inbound data has been processed.
[INFO][02:08:26]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][02:08:30]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:08:31]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][02:08:31]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][02:08:31]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][02:08:31]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][02:08:31]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][02:08:31]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][02:08:31]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:08:31]: [Server #3350301] Updated weights have been received.
[INFO][02:08:32]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:08:32]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:08:32]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.78it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]
[INFO][02:08:43]: [93m[1m[Server #3350301] Global model perplexity: 82.36
[0m
[INFO][02:08:43]: [Server #3350301] All client reports have been processed.
[INFO][02:08:43]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_94.pth.
[INFO][02:08:44]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_94.pth.
[INFO][02:08:44]: [93m[1m
[Server #3350301] Starting round 95/100.[0m
[INFO][02:08:44]: [Server #3350301] Selected clients: [1, 3, 5, 9, 10]
[INFO][02:08:44]: [Server #3350301] Selecting client #10 for training.
[INFO][02:08:44]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][02:08:48]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][02:08:48]: [Server #3350301] Selecting client #1 for training.
[INFO][02:08:48]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][02:08:51]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][02:08:51]: [Client #1] Selected by the server.
[INFO][02:08:51]: [Client #10] Selected by the server.
[INFO][02:08:51]: [Client #1] Loading its data source...
[INFO][02:08:51]: [Client #10] Loading its data source...
[INFO][02:08:51]: [Client #1] Dataset size: 2018
[INFO][02:08:51]: [Client #10] Dataset size: 2018
[INFO][02:08:51]: [Client #1] Sampler: iid
[INFO][02:08:51]: [Client #10] Sampler: iid
[INFO][02:08:53]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:08:53]: [Client #10] Start to process inbound data.
[INFO][02:08:53]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:08:53]: [Client #1] Start to process inbound data.
[INFO][02:08:54]: [93m[1m[Client #10] Started training in communication round #95.[0m
[INFO][02:08:54]: [93m[1m[Client #1] Started training in communication round #95.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:36,  4.60s/it]  2%|â–         | 1/48 [00:04<03:41,  4.72s/it]  4%|â–         | 2/48 [00:05<01:47,  2.33s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.32it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.35it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.35it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.35it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][02:09:39]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.3781, 'train_samples_per_second': 153.74, 'train_steps_per_second': 1.219, 'train_loss': 1.295242468516032, 'epoch': 3.0}
[INFO][02:09:40]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.4031, 'train_samples_per_second': 153.643, 'train_steps_per_second': 1.218, 'train_loss': 2.1173073450724282, 'epoch': 3.0}
[INFO][02:09:40]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][02:09:41]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][02:09:41]: [Client #1] Model trained.
[INFO][02:09:41]: [Client #1] Inbound data has been processed.
[INFO][02:09:41]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][02:09:41]: [Client #10] Model trained.
[INFO][02:09:41]: [Client #10] Inbound data has been processed.
[INFO][02:09:41]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][02:09:48]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:09:48]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:09:49]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][02:09:50]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][02:09:50]: [Server #3350301] Selecting client #3 for training.
[INFO][02:09:50]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][02:09:53]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][02:09:53]: [Server #3350301] Selecting client #5 for training.
[INFO][02:09:53]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][02:09:57]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][02:09:57]: [Client #3] Selected by the server.
[INFO][02:09:57]: [Client #3] Loading its data source...
[INFO][02:09:57]: [Client #5] Selected by the server.
[INFO][02:09:57]: [Client #5] Loading its data source...
[INFO][02:09:57]: [Client #3] Dataset size: 2018
[INFO][02:09:57]: [Client #3] Sampler: iid
[INFO][02:09:57]: [Client #5] Dataset size: 2018
[INFO][02:09:57]: [Client #5] Sampler: iid
[INFO][02:09:58]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:09:58]: [Client #3] Start to process inbound data.
[INFO][02:09:58]: [93m[1m[Client #3] Started training in communication round #95.[0m
[INFO][02:09:58]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:09:58]: [Client #5] Start to process inbound data.
[INFO][02:09:59]: [93m[1m[Client #5] Started training in communication round #95.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:41,  4.70s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.60s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.26s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.35it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.35it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.35it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.31it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][02:10:44]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
{'train_runtime': 39.4768, 'train_samples_per_second': 153.356, 'train_steps_per_second': 1.216, 'train_loss': 1.804796536763509, 'epoch': 3.0}
[INFO][02:10:44]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.4641, 'train_samples_per_second': 153.405, 'train_steps_per_second': 1.216, 'train_loss': 1.4070380528767903, 'epoch': 3.0}
[INFO][02:10:46]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350395.pth.
[INFO][02:10:46]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][02:10:46]: [Client #5] Model trained.
[INFO][02:10:46]: [Client #5] Inbound data has been processed.
[INFO][02:10:46]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][02:10:47]: [Client #3] Model trained.
[INFO][02:10:47]: [Client #3] Inbound data has been processed.
[INFO][02:10:47]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][02:10:54]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:10:54]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:10:55]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][02:10:56]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][02:10:56]: [Server #3350301] Selecting client #9 for training.
[INFO][02:10:56]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][02:10:59]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][02:10:59]: [Client #9] Selected by the server.
[INFO][02:10:59]: [Client #9] Loading its data source...
[INFO][02:10:59]: [Client #9] Dataset size: 2018
[INFO][02:10:59]: [Client #9] Sampler: iid
[INFO][02:11:01]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:11:01]: [Client #9] Start to process inbound data.
[INFO][02:11:01]: [93m[1m[Client #9] Started training in communication round #95.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.23s/it]  4%|â–         | 2/48 [00:04<01:33,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:10,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][02:11:34]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.5323, 'train_samples_per_second': 228.174, 'train_steps_per_second': 1.809, 'train_loss': 1.405777136484782, 'epoch': 3.0}
[INFO][02:11:35]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][02:11:35]: [Client #9] Model trained.
[INFO][02:11:35]: [Client #9] Inbound data has been processed.
[INFO][02:11:35]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][02:11:39]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:11:40]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][02:11:40]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][02:11:40]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][02:11:40]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][02:11:40]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][02:11:40]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][02:11:40]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:11:40]: [Server #3350301] Updated weights have been received.
[INFO][02:11:41]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:11:41]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:11:41]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.69it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.13it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][02:11:52]: [93m[1m[Server #3350301] Global model perplexity: 76.78
[0m
[INFO][02:11:52]: [Server #3350301] All client reports have been processed.
[INFO][02:11:52]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_95.pth.
[INFO][02:11:53]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_95.pth.
[INFO][02:11:53]: [93m[1m
[Server #3350301] Starting round 96/100.[0m
[INFO][02:11:53]: [Server #3350301] Selected clients: [1, 2, 4, 7, 8]
[INFO][02:11:53]: [Server #3350301] Selecting client #2 for training.
[INFO][02:11:53]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][02:11:57]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][02:11:57]: [Server #3350301] Selecting client #1 for training.
[INFO][02:11:57]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][02:12:01]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][02:12:01]: [Client #2] Selected by the server.
[INFO][02:12:01]: [Client #2] Loading its data source...
[INFO][02:12:01]: [Client #2] Dataset size: 2018
[INFO][02:12:01]: [Client #2] Sampler: iid
[INFO][02:12:01]: [Client #1] Selected by the server.
[INFO][02:12:01]: [Client #1] Loading its data source...
[INFO][02:12:01]: [Client #1] Dataset size: 2018
[INFO][02:12:01]: [Client #1] Sampler: iid
[INFO][02:12:02]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:12:02]: [Client #2] Start to process inbound data.
[INFO][02:12:02]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:12:02]: [Client #1] Start to process inbound data.
[INFO][02:12:03]: [93m[1m[Client #2] Started training in communication round #96.[0m
[INFO][02:12:03]: [93m[1m[Client #1] Started training in communication round #96.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  2%|â–         | 1/48 [00:05<03:56,  5.04s/it]  4%|â–         | 2/48 [00:05<01:49,  2.38s/it]  4%|â–         | 2/48 [00:05<01:56,  2.54s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.27s/it]  8%|â–Š         | 4/48 [00:07<00:58,  1.34s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:08<00:48,  1.12s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.38it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:22,  1.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.38it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.31it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:31<00:09,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:37<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.34it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:12:49]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.6065, 'train_samples_per_second': 152.854, 'train_steps_per_second': 1.212, 'train_loss': 1.9239064852396648, 'epoch': 3.0}
[INFO][02:12:49]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.7559, 'train_samples_per_second': 152.279, 'train_steps_per_second': 1.207, 'train_loss': 1.265408992767334, 'epoch': 3.0}
[INFO][02:12:50]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][02:12:50]: [Client #2] Model trained.
[INFO][02:12:50]: [Client #2] Inbound data has been processed.
[INFO][02:12:50]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][02:12:50]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][02:12:51]: [Client #1] Model trained.
[INFO][02:12:51]: [Client #1] Inbound data has been processed.
[INFO][02:12:51]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][02:12:57]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:12:57]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:12:58]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][02:12:59]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][02:12:59]: [Server #3350301] Selecting client #4 for training.
[INFO][02:12:59]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][02:13:02]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][02:13:02]: [Server #3350301] Selecting client #7 for training.
[INFO][02:13:02]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][02:13:06]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][02:13:06]: [Client #4] Selected by the server.
[INFO][02:13:06]: [Client #4] Loading its data source...
[INFO][02:13:06]: [Client #4] Dataset size: 2018
[INFO][02:13:06]: [Client #4] Sampler: iid
[INFO][02:13:06]: [Client #7] Selected by the server.
[INFO][02:13:06]: [Client #7] Loading its data source...
[INFO][02:13:06]: [Client #7] Dataset size: 2018
[INFO][02:13:06]: [Client #7] Sampler: iid
[INFO][02:13:08]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:13:08]: [Client #7] Start to process inbound data.
[INFO][02:13:08]: [93m[1m[Client #7] Started training in communication round #96.[0m
[INFO][02:13:08]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:13:08]: [Client #4] Start to process inbound data.
[INFO][02:13:09]: [93m[1m[Client #4] Started training in communication round #96.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:30,  4.47s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:05<01:43,  2.25s/it]  2%|â–         | 1/48 [00:04<03:44,  4.78s/it]  6%|â–‹         | 3/48 [00:05<01:09,  1.54s/it]  4%|â–         | 2/48 [00:05<01:53,  2.46s/it]  8%|â–Š         | 4/48 [00:06<00:57,  1.31s/it]  6%|â–‹         | 3/48 [00:06<01:18,  1.74s/it] 10%|â–ˆ         | 5/48 [00:07<00:49,  1.16s/it]  8%|â–Š         | 4/48 [00:07<01:02,  1.42s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.07s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.01s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:46,  1.10s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:38,  1.05it/s] 15%|â–ˆâ–        | 7/48 [00:10<00:42,  1.03s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:35,  1.09it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:34,  1.10it/s] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:33,  1.09it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:36,  1.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:33,  1.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:35,  1.05it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:14<00:33,  1.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:15<00:31,  1.08it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:33,  1.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:16<00:30,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:33,  1.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:18<00:27,  1.13it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:29,  1.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:28,  1.07it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.08it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:27,  1.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:26,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:24,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:25,  1.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:23,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:23,  1.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:22,  1.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:23,  1.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:22,  1.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:27<00:19,  1.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:21,  1.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:28<00:18,  1.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:19,  1.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:18,  1.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:17,  1.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:16,  1.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:17,  1.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.05it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.15it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:13,  1.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:11,  1.21it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:12,  1.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:34<00:10,  1.25it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:11,  1.21it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:35<00:09,  1.27it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:10,  1.25it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:36<00:08,  1.29it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:09,  1.27it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:07,  1.30it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:08,  1.27it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:37<00:06,  1.30it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:37<00:07,  1.30it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:38<00:06,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:38<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:39<00:05,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:39<00:06,  1.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:40<00:04,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:05,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:40<00:03,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:40<00:04,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:41<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:41<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:42<00:02,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:42<00:03,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:43<00:01,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:43<00:02,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:43<00:00,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:43<00:01,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.08it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:44<00:00,  1.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.66it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:44<00:00,  1.07it/s]
[INFO][02:13:59]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 44.6019, 'train_samples_per_second': 135.734, 'train_steps_per_second': 1.076, 'train_loss': 1.8417690594991047, 'epoch': 3.0}
[INFO][02:13:59]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 44.7922, 'train_samples_per_second': 135.157, 'train_steps_per_second': 1.072, 'train_loss': 2.518035888671875, 'epoch': 3.0}
[INFO][02:14:00]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][02:14:00]: [Client #7] Model trained.
[INFO][02:14:00]: [Client #7] Inbound data has been processed.
[INFO][02:14:00]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][02:14:01]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][02:14:01]: [Client #4] Model trained.
[INFO][02:14:01]: [Client #4] Inbound data has been processed.
[INFO][02:14:01]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][02:14:06]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:14:07]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][02:14:07]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:14:08]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][02:14:08]: [Server #3350301] Selecting client #8 for training.
[INFO][02:14:08]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][02:14:12]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][02:14:12]: [Client #8] Selected by the server.
[INFO][02:14:12]: [Client #8] Loading its data source...
[INFO][02:14:12]: [Client #8] Dataset size: 2018
[INFO][02:14:12]: [Client #8] Sampler: iid
[INFO][02:14:13]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:14:13]: [Client #8] Start to process inbound data.
[INFO][02:14:14]: [93m[1m[Client #8] Started training in communication round #96.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  4%|â–         | 2/48 [00:04<01:33,  2.03s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.24it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.44it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.58it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.71it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.81it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.88it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.93it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.97it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.00it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.14it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.17it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.79it/s]
[INFO][02:14:47]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 26.7699, 'train_samples_per_second': 226.149, 'train_steps_per_second': 1.793, 'train_loss': 2.589552402496338, 'epoch': 3.0}
[INFO][02:14:48]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][02:14:48]: [Client #8] Model trained.
[INFO][02:14:48]: [Client #8] Inbound data has been processed.
[INFO][02:14:48]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][02:14:52]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:14:53]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][02:14:53]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][02:14:53]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][02:14:53]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][02:14:53]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][02:14:53]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][02:14:53]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:14:53]: [Server #3350301] Updated weights have been received.
[INFO][02:14:54]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:14:54]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:14:54]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.28it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.66it/s]
[INFO][02:15:05]: [93m[1m[Server #3350301] Global model perplexity: 77.63
[0m
[INFO][02:15:05]: [Server #3350301] All client reports have been processed.
[INFO][02:15:06]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_96.pth.
[INFO][02:15:06]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_96.pth.
[INFO][02:15:06]: [93m[1m
[Server #3350301] Starting round 97/100.[0m
[INFO][02:15:06]: [Server #3350301] Selected clients: [3, 5, 6, 9, 10]
[INFO][02:15:06]: [Server #3350301] Selecting client #6 for training.
[INFO][02:15:06]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][02:15:10]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][02:15:10]: [Server #3350301] Selecting client #3 for training.
[INFO][02:15:10]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][02:15:14]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][02:15:14]: [Client #6] Selected by the server.
[INFO][02:15:14]: [Client #6] Loading its data source...
[INFO][02:15:14]: [Client #6] Dataset size: 2018
[INFO][02:15:14]: [Client #6] Sampler: iid
[INFO][02:15:14]: [Client #3] Selected by the server.
[INFO][02:15:14]: [Client #3] Loading its data source...
[INFO][02:15:14]: [Client #3] Dataset size: 2018
[INFO][02:15:14]: [Client #3] Sampler: iid
[INFO][02:15:15]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:15:15]: [Client #6] Start to process inbound data.
[INFO][02:15:16]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:15:16]: [Client #3] Start to process inbound data.
[INFO][02:15:16]: [93m[1m[Client #6] Started training in communication round #97.[0m
[INFO][02:15:16]: [93m[1m[Client #3] Started training in communication round #97.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:47,  4.84s/it]  2%|â–         | 1/48 [00:04<03:46,  4.82s/it]  4%|â–         | 2/48 [00:05<01:52,  2.44s/it]  4%|â–         | 2/48 [00:05<01:52,  2.45s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.65s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.67s/it]  8%|â–Š         | 4/48 [00:07<00:56,  1.29s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.27it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.39it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.36it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.35it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.33it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:16:02]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 39.6163, 'train_samples_per_second': 152.816, 'train_steps_per_second': 1.212, 'train_loss': 2.5589962005615234, 'epoch': 3.0}
[INFO][02:16:02]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.595, 'train_samples_per_second': 152.898, 'train_steps_per_second': 1.212, 'train_loss': 1.7767545382181804, 'epoch': 3.0}
[INFO][02:16:03]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][02:16:03]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][02:16:04]: [Client #6] Model trained.
[INFO][02:16:04]: [Client #6] Inbound data has been processed.
[INFO][02:16:04]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][02:16:04]: [Client #3] Model trained.
[INFO][02:16:04]: [Client #3] Inbound data has been processed.
[INFO][02:16:04]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][02:16:10]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:16:11]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:16:11]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][02:16:12]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][02:16:12]: [Server #3350301] Selecting client #10 for training.
[INFO][02:16:12]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][02:16:16]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][02:16:16]: [Server #3350301] Selecting client #5 for training.
[INFO][02:16:16]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][02:16:20]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][02:16:20]: [Client #10] Selected by the server.
[INFO][02:16:20]: [Client #10] Loading its data source...
[INFO][02:16:20]: [Client #5] Selected by the server.
[INFO][02:16:20]: [Client #10] Dataset size: 2018
[INFO][02:16:20]: [Client #5] Loading its data source...
[INFO][02:16:20]: [Client #10] Sampler: iid
[INFO][02:16:20]: [Client #5] Dataset size: 2018
[INFO][02:16:20]: [Client #5] Sampler: iid
[INFO][02:16:21]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:16:21]: [Client #5] Start to process inbound data.
[INFO][02:16:21]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:16:21]: [Client #10] Start to process inbound data.
[INFO][02:16:22]: [93m[1m[Client #10] Started training in communication round #97.[0m
[INFO][02:16:22]: [93m[1m[Client #5] Started training in communication round #97.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:19,  4.24s/it]  2%|â–         | 1/48 [00:04<03:49,  4.89s/it]  4%|â–         | 2/48 [00:04<01:39,  2.17s/it]  4%|â–         | 2/48 [00:05<01:53,  2.48s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  6%|â–‹         | 3/48 [00:06<01:15,  1.68s/it]  8%|â–Š         | 4/48 [00:06<00:53,  1.22s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.31s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.05s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.31it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.31it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.36it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:15,  1.31it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.32it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.32it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.32it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.35it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.32it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:17:08]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.3002, 'train_samples_per_second': 154.045, 'train_steps_per_second': 1.221, 'train_loss': 1.3769747416178386, 'epoch': 3.0}
[INFO][02:17:08]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 39.6997, 'train_samples_per_second': 152.495, 'train_steps_per_second': 1.209, 'train_loss': 2.1022337277730307, 'epoch': 3.0}
[INFO][02:17:09]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][02:17:09]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][02:17:09]: [Client #5] Model trained.
[INFO][02:17:09]: [Client #5] Inbound data has been processed.
[INFO][02:17:09]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][02:17:10]: [Client #10] Model trained.
[INFO][02:17:10]: [Client #10] Inbound data has been processed.
[INFO][02:17:10]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][02:17:16]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:17:17]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:17:17]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][02:17:18]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][02:17:18]: [Server #3350301] Selecting client #9 for training.
[INFO][02:17:18]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][02:17:22]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][02:17:22]: [Client #9] Selected by the server.
[INFO][02:17:22]: [Client #9] Loading its data source...
[INFO][02:17:22]: [Client #9] Dataset size: 2018
[INFO][02:17:22]: [Client #9] Sampler: iid
[INFO][02:17:24]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:17:24]: [Client #9] Start to process inbound data.
[INFO][02:17:24]: [93m[1m[Client #9] Started training in communication round #97.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:21,  4.29s/it]  4%|â–         | 2/48 [00:04<01:34,  2.05s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.33s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.59it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.72it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.89it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:19,  1.94it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.98it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.01it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.15it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:12,  2.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.13it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:07,  2.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:20<00:06,  2.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:21<00:05,  2.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:22<00:04,  2.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:23<00:03,  2.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:24<00:02,  2.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:25<00:01,  2.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:26<00:00,  2.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.78it/s]
[INFO][02:17:57]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.9531, 'train_samples_per_second': 224.613, 'train_steps_per_second': 1.781, 'train_loss': 1.3792174657185872, 'epoch': 3.0}
[INFO][02:17:58]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][02:17:58]: [Client #9] Model trained.
[INFO][02:17:58]: [Client #9] Inbound data has been processed.
[INFO][02:17:58]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][02:18:02]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:18:03]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][02:18:03]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][02:18:03]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][02:18:03]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][02:18:03]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][02:18:03]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][02:18:03]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:18:03]: [Server #3350301] Updated weights have been received.
[INFO][02:18:04]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:18:04]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:18:04]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.87it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][02:18:15]: [93m[1m[Server #3350301] Global model perplexity: 88.17
[0m
[INFO][02:18:15]: [Server #3350301] All client reports have been processed.
[INFO][02:18:15]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_97.pth.
[INFO][02:18:16]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_97.pth.
[INFO][02:18:16]: [93m[1m
[Server #3350301] Starting round 98/100.[0m
[INFO][02:18:16]: [Server #3350301] Selected clients: [1, 2, 5, 7, 9]
[INFO][02:18:16]: [Server #3350301] Selecting client #2 for training.
[INFO][02:18:16]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][02:18:19]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][02:18:19]: [Server #3350301] Selecting client #1 for training.
[INFO][02:18:19]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][02:18:23]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][02:18:23]: [Client #2] Selected by the server.
[INFO][02:18:23]: [Client #2] Loading its data source...
[INFO][02:18:23]: [Client #2] Dataset size: 2018
[INFO][02:18:23]: [Client #2] Sampler: iid
[INFO][02:18:23]: [Client #1] Selected by the server.
[INFO][02:18:23]: [Client #1] Loading its data source...
[INFO][02:18:23]: [Client #1] Dataset size: 2018
[INFO][02:18:23]: [Client #1] Sampler: iid
[INFO][02:18:25]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:18:25]: [Client #1] Start to process inbound data.
[INFO][02:18:25]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:18:25]: [Client #2] Start to process inbound data.
[INFO][02:18:25]: [93m[1m[Client #1] Started training in communication round #98.[0m
[INFO][02:18:25]: [93m[1m[Client #2] Started training in communication round #98.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
***** Running training *****
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Num examples = 2018
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:12,  4.10s/it]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  4%|â–         | 2/48 [00:04<01:36,  2.09s/it]  2%|â–         | 1/48 [00:04<03:45,  4.80s/it]  6%|â–‹         | 3/48 [00:05<01:08,  1.53s/it]  4%|â–         | 2/48 [00:05<01:54,  2.50s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.23s/it]  6%|â–‹         | 3/48 [00:06<01:17,  1.72s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.04s/it]  8%|â–Š         | 4/48 [00:07<00:59,  1.35s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.07it/s] 10%|â–ˆ         | 5/48 [00:07<00:48,  1.13s/it] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.15it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.01it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.21it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:37,  1.10it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:34,  1.17it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:13<00:27,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:23,  1.35it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:16<00:23,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:23,  1.35it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.35it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.31it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:20,  1.34it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:19<00:21,  1.33it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:22<00:18,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.35it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.36it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:30<00:09,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.35it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.55it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:19:11]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.0167, 'train_samples_per_second': 155.164, 'train_steps_per_second': 1.23, 'train_loss': 1.9098216692606609, 'epoch': 3.0}
[INFO][02:19:11]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.5936, 'train_samples_per_second': 152.903, 'train_steps_per_second': 1.212, 'train_loss': 1.2453970909118652, 'epoch': 3.0}
[INFO][02:19:12]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][02:19:12]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][02:19:13]: [Client #2] Model trained.
[INFO][02:19:13]: [Client #2] Inbound data has been processed.
[INFO][02:19:13]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][02:19:14]: [Client #1] Model trained.
[INFO][02:19:14]: [Client #1] Inbound data has been processed.
[INFO][02:19:14]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][02:19:19]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:19:20]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:19:20]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][02:19:21]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][02:19:21]: [Server #3350301] Selecting client #5 for training.
[INFO][02:19:21]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][02:19:25]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][02:19:25]: [Server #3350301] Selecting client #7 for training.
[INFO][02:19:25]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][02:19:29]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][02:19:29]: [Client #5] Selected by the server.
[INFO][02:19:29]: [Client #5] Loading its data source...
[INFO][02:19:29]: [Client #7] Selected by the server.
[INFO][02:19:29]: [Client #5] Dataset size: 2018
[INFO][02:19:29]: [Client #7] Loading its data source...
[INFO][02:19:29]: [Client #5] Sampler: iid
[INFO][02:19:29]: [Client #7] Dataset size: 2018
[INFO][02:19:29]: [Client #7] Sampler: iid
[INFO][02:19:30]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:19:30]: [Client #7] Start to process inbound data.
[INFO][02:19:30]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:19:30]: [Client #5] Start to process inbound data.
[INFO][02:19:31]: [93m[1m[Client #7] Started training in communication round #98.[0m
[INFO][02:19:31]: [93m[1m[Client #5] Started training in communication round #98.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/48 [00:00<?, ?it/s]***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:26,  4.38s/it]  2%|â–         | 1/48 [00:04<03:32,  4.53s/it]  4%|â–         | 2/48 [00:05<01:43,  2.24s/it]  4%|â–         | 2/48 [00:05<01:45,  2.29s/it]  6%|â–‹         | 3/48 [00:05<01:10,  1.58s/it]  6%|â–‹         | 3/48 [00:06<01:11,  1.59s/it]  8%|â–Š         | 4/48 [00:06<00:54,  1.24s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.25s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.06s/it] 10%|â–ˆ         | 5/48 [00:07<00:45,  1.07s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.13it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.24it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:29,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:21,  1.33it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.32it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
[INFO][02:20:17]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 39.3577, 'train_samples_per_second': 153.82, 'train_steps_per_second': 1.22, 'train_loss': 1.8604402542114258, 'epoch': 3.0}
[INFO][02:20:17]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
{'train_runtime': 39.4472, 'train_samples_per_second': 153.471, 'train_steps_per_second': 1.217, 'train_loss': 1.3832236925760906, 'epoch': 3.0}
[INFO][02:20:18]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][02:20:18]: [Client #7] Model trained.
[INFO][02:20:18]: [Client #7] Inbound data has been processed.
[INFO][02:20:18]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][02:20:18]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350395.pth.
[INFO][02:20:19]: [Client #5] Model trained.
[INFO][02:20:19]: [Client #5] Inbound data has been processed.
[INFO][02:20:19]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][02:20:25]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:20:25]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:20:26]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][02:20:27]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][02:20:27]: [Server #3350301] Selecting client #9 for training.
[INFO][02:20:27]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][02:20:31]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][02:20:31]: [Client #9] Selected by the server.
[INFO][02:20:31]: [Client #9] Loading its data source...
[INFO][02:20:31]: [Client #9] Dataset size: 2018
[INFO][02:20:31]: [Client #9] Sampler: iid
[INFO][02:20:32]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:20:32]: [Client #9] Start to process inbound data.
[INFO][02:20:32]: [93m[1m[Client #9] Started training in communication round #98.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.22s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.32s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.01it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.45it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.61it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.74it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][02:21:05]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.5499, 'train_samples_per_second': 228.023, 'train_steps_per_second': 1.808, 'train_loss': 1.3908907572428386, 'epoch': 3.0}
[INFO][02:21:06]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][02:21:06]: [Client #9] Model trained.
[INFO][02:21:06]: [Client #9] Inbound data has been processed.
[INFO][02:21:06]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][02:21:10]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:21:12]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][02:21:12]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][02:21:12]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][02:21:12]: [Server #3350301] Adding client #8 to the list of clients for aggregation.
[INFO][02:21:12]: [Server #3350301] Adding client #4 to the list of clients for aggregation.
[INFO][02:21:12]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][02:21:12]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:21:12]: [Server #3350301] Updated weights have been received.
[INFO][02:21:12]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:21:13]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:21:13]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.79it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]
[INFO][02:21:24]: [93m[1m[Server #3350301] Global model perplexity: 79.52
[0m
[INFO][02:21:24]: [Server #3350301] All client reports have been processed.
[INFO][02:21:24]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_98.pth.
[INFO][02:21:24]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_98.pth.
[INFO][02:21:24]: [93m[1m
[Server #3350301] Starting round 99/100.[0m
[INFO][02:21:24]: [Server #3350301] Selected clients: [1, 3, 4, 8, 10]
[INFO][02:21:24]: [Server #3350301] Selecting client #4 for training.
[INFO][02:21:24]: [Server #3350301] Sending the current model to client #4 (simulated).
[INFO][02:21:28]: [Server #3350301] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][02:21:28]: [Server #3350301] Selecting client #1 for training.
[INFO][02:21:28]: [Server #3350301] Sending the current model to client #1 (simulated).
[INFO][02:21:32]: [Server #3350301] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][02:21:32]: [Client #4] Selected by the server.
[INFO][02:21:32]: [Client #4] Loading its data source...
[INFO][02:21:32]: [Client #4] Dataset size: 2018
[INFO][02:21:32]: [Client #4] Sampler: iid
[INFO][02:21:32]: [Client #1] Selected by the server.
[INFO][02:21:32]: [Client #1] Loading its data source...
[INFO][02:21:32]: [Client #1] Dataset size: 2018
[INFO][02:21:32]: [Client #1] Sampler: iid
[INFO][02:21:34]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:21:34]: [Client #4] Start to process inbound data.
[INFO][02:21:34]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:21:34]: [Client #1] Start to process inbound data.
[INFO][02:21:34]: [93m[1m[Client #4] Started training in communication round #99.[0m
[INFO][02:21:34]: [93m[1m[Client #1] Started training in communication round #99.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:15,  4.17s/it]  2%|â–         | 1/48 [00:04<03:43,  4.76s/it]  4%|â–         | 2/48 [00:04<01:38,  2.14s/it]  4%|â–         | 2/48 [00:05<01:49,  2.39s/it]  6%|â–‹         | 3/48 [00:05<01:07,  1.50s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  8%|â–Š         | 4/48 [00:06<00:52,  1.20s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.29s/it] 10%|â–ˆ         | 5/48 [00:07<00:44,  1.03s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:07<00:39,  1.06it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:08<00:35,  1.14it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.20it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.25it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:10<00:29,  1.28it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:11<00:28,  1.30it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.33it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:13<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:14<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:25,  1.32it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:23,  1.37it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:15<00:22,  1.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:16<00:22,  1.36it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:22,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.36it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:18<00:19,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.34it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:19<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.33it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.32it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:21<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.32it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:22<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:15,  1.32it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:24<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:25<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.37it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:27<00:11,  1.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:11,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:28<00:10,  1.35it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.34it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:30<00:08,  1.34it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:31<00:07,  1.34it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.31it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.32it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:33<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.32it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.31it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:33<00:05,  1.32it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:34<00:04,  1.32it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:36<00:02,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.30it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:37<00:01,  1.32it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.30it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:39<00:00,  1.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.34it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.23it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:22:20]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
{'train_runtime': 39.1799, 'train_samples_per_second': 154.518, 'train_steps_per_second': 1.225, 'train_loss': 2.5284969011942544, 'epoch': 3.0}
[INFO][02:22:20]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
{'train_runtime': 39.541, 'train_samples_per_second': 153.107, 'train_steps_per_second': 1.214, 'train_loss': 1.225481351216634, 'epoch': 3.0}
[INFO][02:22:21]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3350395.pth.
[INFO][02:22:21]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3350396.pth.
[INFO][02:22:21]: [Client #4] Model trained.
[INFO][02:22:21]: [Client #4] Inbound data has been processed.
[INFO][02:22:21]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][02:22:22]: [Client #1] Model trained.
[INFO][02:22:22]: [Client #1] Inbound data has been processed.
[INFO][02:22:22]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][02:22:28]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:22:28]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:22:29]: [Server #3350301] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][02:22:29]: [Server #3350301] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][02:22:29]: [Server #3350301] Selecting client #8 for training.
[INFO][02:22:29]: [Server #3350301] Sending the current model to client #8 (simulated).
[INFO][02:22:33]: [Server #3350301] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][02:22:33]: [Server #3350301] Selecting client #3 for training.
[INFO][02:22:33]: [Server #3350301] Sending the current model to client #3 (simulated).
[INFO][02:22:37]: [Server #3350301] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][02:22:37]: [Client #8] Selected by the server.
[INFO][02:22:37]: [Client #8] Loading its data source...
[INFO][02:22:37]: [Client #8] Dataset size: 2018
[INFO][02:22:37]: [Client #8] Sampler: iid
[INFO][02:22:37]: [Client #3] Selected by the server.
[INFO][02:22:37]: [Client #3] Loading its data source...
[INFO][02:22:37]: [Client #3] Dataset size: 2018
[INFO][02:22:37]: [Client #3] Sampler: iid
[INFO][02:22:38]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:22:38]: [Client #8] Start to process inbound data.
[INFO][02:22:38]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:22:38]: [Client #3] Start to process inbound data.
[INFO][02:22:39]: [93m[1m[Client #8] Started training in communication round #99.[0m
[INFO][02:22:39]: [93m[1m[Client #3] Started training in communication round #99.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:41,  4.72s/it]  2%|â–         | 1/48 [00:04<03:47,  4.83s/it]  4%|â–         | 2/48 [00:05<01:48,  2.36s/it]  4%|â–         | 2/48 [00:05<01:51,  2.43s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.63s/it]  6%|â–‹         | 3/48 [00:06<01:14,  1.66s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it]  8%|â–Š         | 4/48 [00:07<00:57,  1.30s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.08s/it] 10%|â–ˆ         | 5/48 [00:07<00:47,  1.10s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.04it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.02it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.19it/s] 17%|â–ˆâ–‹        | 8/48 [00:10<00:33,  1.18it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.23it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:29,  1.27it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.29it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.34it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.37it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.35it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.31it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:18,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.33it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.33it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.36it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.33it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.33it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:06,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.32it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.32it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:03,  1.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:23:25]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
{'train_runtime': 39.6173, 'train_samples_per_second': 152.812, 'train_steps_per_second': 1.212, 'train_loss': 1.7422467867533367, 'epoch': 3.0}
[INFO][02:23:25]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
{'train_runtime': 39.4839, 'train_samples_per_second': 153.328, 'train_steps_per_second': 1.216, 'train_loss': 2.5711437861124673, 'epoch': 3.0}
[INFO][02:23:26]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3350396.pth.
[INFO][02:23:26]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3350395.pth.
[INFO][02:23:27]: [Client #3] Model trained.
[INFO][02:23:27]: [Client #3] Inbound data has been processed.
[INFO][02:23:27]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][02:23:27]: [Client #8] Model trained.
[INFO][02:23:27]: [Client #8] Inbound data has been processed.
[INFO][02:23:27]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][02:23:34]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:23:34]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:23:35]: [Server #3350301] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][02:23:36]: [Server #3350301] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][02:23:36]: [Server #3350301] Selecting client #10 for training.
[INFO][02:23:36]: [Server #3350301] Sending the current model to client #10 (simulated).
[INFO][02:23:39]: [Server #3350301] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][02:23:39]: [Client #10] Selected by the server.
[INFO][02:23:39]: [Client #10] Loading its data source...
[INFO][02:23:39]: [Client #10] Dataset size: 2018
[INFO][02:23:39]: [Client #10] Sampler: iid
[INFO][02:23:41]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:23:41]: [Client #10] Start to process inbound data.
[INFO][02:23:41]: [93m[1m[Client #10] Started training in communication round #99.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:22,  4.31s/it]  4%|â–         | 2/48 [00:04<01:34,  2.06s/it]  6%|â–‹         | 3/48 [00:05<01:00,  1.34s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.00it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.23it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.43it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.60it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.82it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:20,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:10<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:11<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:19<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.80it/s]
[INFO][02:24:14]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
{'train_runtime': 26.6599, 'train_samples_per_second': 227.082, 'train_steps_per_second': 1.8, 'train_loss': 2.068251609802246, 'epoch': 3.0}
[INFO][02:24:15]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3350395.pth.
[INFO][02:24:15]: [Client #10] Model trained.
[INFO][02:24:15]: [Client #10] Inbound data has been processed.
[INFO][02:24:15]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][02:24:19]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:24:20]: [Server #3350301] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][02:24:20]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][02:24:20]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][02:24:20]: [Server #3350301] Adding client #2 to the list of clients for aggregation.
[INFO][02:24:20]: [Server #3350301] Adding client #7 to the list of clients for aggregation.
[INFO][02:24:20]: [Server #3350301] Adding client #6 to the list of clients for aggregation.
[INFO][02:24:20]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:24:20]: [Server #3350301] Updated weights have been received.
[INFO][02:24:20]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:24:21]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:24:21]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 18.83it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.58it/s]
[INFO][02:24:32]: [93m[1m[Server #3350301] Global model perplexity: 82.10
[0m
[INFO][02:24:32]: [Server #3350301] All client reports have been processed.
[INFO][02:24:32]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_99.pth.
[INFO][02:24:33]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_99.pth.
[INFO][02:24:33]: [93m[1m
[Server #3350301] Starting round 100/100.[0m
[INFO][02:24:33]: [Server #3350301] Selected clients: [2, 5, 6, 7, 9]
[INFO][02:24:33]: [Server #3350301] Selecting client #2 for training.
[INFO][02:24:33]: [Server #3350301] Sending the current model to client #2 (simulated).
[INFO][02:24:37]: [Server #3350301] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][02:24:37]: [Server #3350301] Selecting client #5 for training.
[INFO][02:24:37]: [Server #3350301] Sending the current model to client #5 (simulated).
[INFO][02:24:40]: [Server #3350301] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][02:24:40]: [Client #2] Selected by the server.
[INFO][02:24:40]: [Client #2] Loading its data source...
[INFO][02:24:40]: [Client #2] Dataset size: 2018
[INFO][02:24:40]: [Client #2] Sampler: iid
[INFO][02:24:40]: [Client #5] Selected by the server.
[INFO][02:24:40]: [Client #5] Loading its data source...
[INFO][02:24:40]: [Client #5] Dataset size: 2018
[INFO][02:24:40]: [Client #5] Sampler: iid
[INFO][02:24:42]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:24:42]: [Client #2] Start to process inbound data.
[INFO][02:24:42]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:24:42]: [Client #5] Start to process inbound data.
[INFO][02:24:42]: [93m[1m[Client #2] Started training in communication round #100.[0m
[INFO][02:24:42]: [93m[1m[Client #5] Started training in communication round #100.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:37,  4.63s/it]  2%|â–         | 1/48 [00:04<03:44,  4.77s/it]  4%|â–         | 2/48 [00:05<01:48,  2.35s/it]  4%|â–         | 2/48 [00:05<01:50,  2.40s/it]  6%|â–‹         | 3/48 [00:06<01:12,  1.62s/it]  6%|â–‹         | 3/48 [00:06<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<00:55,  1.27s/it]  8%|â–Š         | 4/48 [00:06<00:56,  1.28s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.07s/it] 10%|â–ˆ         | 5/48 [00:07<00:46,  1.09s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:41,  1.02it/s] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:40,  1.03it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.12it/s] 15%|â–ˆâ–        | 7/48 [00:09<00:36,  1.11it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:33,  1.18it/s] 17%|â–ˆâ–‹        | 8/48 [00:09<00:34,  1.17it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:31,  1.22it/s] 19%|â–ˆâ–‰        | 9/48 [00:10<00:32,  1.22it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.26it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:11<00:30,  1.25it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:28,  1.28it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:12<00:27,  1.29it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.31it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:13<00:26,  1.30it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.33it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:14<00:25,  1.32it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:15<00:24,  1.33it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:15<00:22,  1.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:16<00:22,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.38it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:17<00:21,  1.37it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:18<00:21,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:18<00:20,  1.36it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.33it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:19<00:20,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.35it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:20<00:19,  1.34it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:20<00:18,  1.35it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:21<00:18,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:21<00:17,  1.34it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.33it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:22<00:17,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:23<00:16,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:23<00:15,  1.34it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:24<00:15,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:24<00:14,  1.34it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.33it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:25<00:14,  1.34it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:26<00:13,  1.33it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:26<00:12,  1.34it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:27<00:12,  1.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:27<00:11,  1.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:28<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.38it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:29<00:10,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:29<00:09,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:30<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.36it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:31<00:08,  1.36it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:32<00:07,  1.35it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:32<00:06,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:33<00:05,  1.34it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:34<00:05,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.34it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:35<00:04,  1.33it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:35<00:03,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:36<00:02,  1.34it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.32it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:37<00:02,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:38<00:01,  1.33it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.31it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:38<00:00,  1.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.22it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:39<00:00,  1.21it/s]
[INFO][02:25:28]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
{'train_runtime': 39.5607, 'train_samples_per_second': 153.031, 'train_steps_per_second': 1.213, 'train_loss': 1.8749356269836426, 'epoch': 3.0}
[INFO][02:25:28]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
{'train_runtime': 39.467, 'train_samples_per_second': 153.394, 'train_steps_per_second': 1.216, 'train_loss': 1.3281581401824951, 'epoch': 3.0}
[INFO][02:25:29]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3350395.pth.
[INFO][02:25:29]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3350396.pth.
[INFO][02:25:30]: [Client #2] Model trained.
[INFO][02:25:30]: [Client #2] Inbound data has been processed.
[INFO][02:25:30]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][02:25:30]: [Client #5] Model trained.
[INFO][02:25:30]: [Client #5] Inbound data has been processed.
[INFO][02:25:30]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][02:25:37]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:25:37]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:25:38]: [Server #3350301] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][02:25:38]: [Server #3350301] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][02:25:38]: [Server #3350301] Selecting client #6 for training.
[INFO][02:25:39]: [Server #3350301] Sending the current model to client #6 (simulated).
[INFO][02:25:42]: [Server #3350301] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][02:25:42]: [Server #3350301] Selecting client #7 for training.
[INFO][02:25:42]: [Server #3350301] Sending the current model to client #7 (simulated).
[INFO][02:25:46]: [Server #3350301] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][02:25:46]: [Client #6] Selected by the server.
[INFO][02:25:46]: [Client #6] Loading its data source...
[INFO][02:25:46]: [Client #7] Selected by the server.
[INFO][02:25:46]: [Client #6] Dataset size: 2018
[INFO][02:25:46]: [Client #6] Sampler: iid
[INFO][02:25:46]: [Client #7] Loading its data source...
[INFO][02:25:46]: [Client #7] Dataset size: 2018
[INFO][02:25:46]: [Client #7] Sampler: iid
[INFO][02:25:48]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:25:48]: [Client #7] Start to process inbound data.
[INFO][02:25:48]: [93m[1m[Client #7] Started training in communication round #100.[0m
[INFO][02:25:48]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:25:48]: [Client #6] Start to process inbound data.
[INFO][02:25:48]: [93m[1m[Client #6] Started training in communication round #100.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:40,  4.68s/it]  2%|â–         | 1/48 [00:04<03:52,  4.95s/it]  4%|â–         | 2/48 [00:05<01:50,  2.41s/it]  4%|â–         | 2/48 [00:05<01:59,  2.59s/it]  6%|â–‹         | 3/48 [00:06<01:16,  1.70s/it]  6%|â–‹         | 3/48 [00:06<01:21,  1.81s/it]  8%|â–Š         | 4/48 [00:07<01:00,  1.37s/it]  8%|â–Š         | 4/48 [00:07<01:04,  1.45s/it] 10%|â–ˆ         | 5/48 [00:08<00:51,  1.20s/it] 10%|â–ˆ         | 5/48 [00:08<00:53,  1.24s/it] 12%|â–ˆâ–Ž        | 6/48 [00:08<00:45,  1.08s/it] 12%|â–ˆâ–Ž        | 6/48 [00:09<00:47,  1.12s/it] 15%|â–ˆâ–        | 7/48 [00:09<00:41,  1.01s/it] 15%|â–ˆâ–        | 7/48 [00:10<00:43,  1.05s/it] 17%|â–ˆâ–‹        | 8/48 [00:10<00:39,  1.02it/s] 17%|â–ˆâ–‹        | 8/48 [00:11<00:40,  1.00s/it] 19%|â–ˆâ–‰        | 9/48 [00:11<00:37,  1.05it/s] 19%|â–ˆâ–‰        | 9/48 [00:12<00:37,  1.04it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:12<00:35,  1.06it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:13<00:36,  1.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:13<00:34,  1.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:14<00:33,  1.07it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:31,  1.09it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:15<00:32,  1.09it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.11it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:16<00:30,  1.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:30,  1.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:17<00:31,  1.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:17<00:29,  1.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:18<00:27,  1.16it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:29,  1.05it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:19<00:28,  1.07it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:19<00:28,  1.06it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:20<00:28,  1.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:20<00:26,  1.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:21<00:27,  1.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:21<00:25,  1.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:22<00:25,  1.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:22<00:25,  1.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:23<00:24,  1.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:23<00:24,  1.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:24<00:23,  1.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:22,  1.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:24<00:23,  1.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:25<00:21,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:26<00:20,  1.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:27<00:20,  1.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.11it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:28<00:18,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:17,  1.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:29<00:18,  1.11it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:29<00:17,  1.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:30<00:17,  1.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:30<00:16,  1.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:31<00:16,  1.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:31<00:15,  1.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:32<00:16,  1.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:32<00:14,  1.10it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:33<00:14,  1.14it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:33<00:13,  1.10it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:34<00:13,  1.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:34<00:12,  1.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:35<00:11,  1.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:36<00:10,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:37<00:10,  1.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:38<00:09,  1.10it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:39<00:08,  1.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:40<00:07,  1.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:40<00:06,  1.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:41<00:06,  1.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:41<00:05,  1.10it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:42<00:05,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:42<00:04,  1.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:43<00:04,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:43<00:03,  1.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:44<00:03,  1.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:44<00:02,  1.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:45<00:02,  1.07it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:45<00:01,  1.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:46<00:01,  1.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:46<00:00,  1.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:47<00:00,  1.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:47<00:00,  1.01it/s]
[INFO][02:26:41]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
{'train_runtime': 47.7411, 'train_samples_per_second': 126.809, 'train_steps_per_second': 1.005, 'train_loss': 1.8028233846028645, 'epoch': 3.0}
[INFO][02:26:42]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
{'train_runtime': 47.492, 'train_samples_per_second': 127.474, 'train_steps_per_second': 1.011, 'train_loss': 2.531432628631592, 'epoch': 3.0}
[INFO][02:26:43]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3350395.pth.
[INFO][02:26:43]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3350396.pth.
[INFO][02:26:43]: [Client #6] Model trained.
[INFO][02:26:43]: [Client #6] Inbound data has been processed.
[INFO][02:26:43]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][02:26:43]: [Client #7] Model trained.
[INFO][02:26:43]: [Client #7] Inbound data has been processed.
[INFO][02:26:43]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][02:26:50]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:26:50]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:26:51]: [Server #3350301] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][02:26:53]: [Server #3350301] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][02:26:53]: [Server #3350301] Selecting client #9 for training.
[INFO][02:26:53]: [Server #3350301] Sending the current model to client #9 (simulated).
[INFO][02:26:57]: [Server #3350301] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][02:26:57]: [Client #9] Selected by the server.
[INFO][02:26:57]: [Client #9] Loading its data source...
[INFO][02:26:57]: [Client #9] Dataset size: 2018
[INFO][02:26:57]: [Client #9] Sampler: iid
[INFO][02:26:58]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][02:26:58]: [Client #9] Start to process inbound data.
[INFO][02:26:58]: [93m[1m[Client #9] Started training in communication round #100.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 48
  0%|          | 0/48 [00:00<?, ?it/s]/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  2%|â–         | 1/48 [00:04<03:18,  4.21s/it]  4%|â–         | 2/48 [00:04<01:32,  2.02s/it]  6%|â–‹         | 3/48 [00:05<00:59,  1.31s/it]  8%|â–Š         | 4/48 [00:05<00:43,  1.02it/s] 10%|â–ˆ         | 5/48 [00:06<00:34,  1.25it/s] 12%|â–ˆâ–Ž        | 6/48 [00:06<00:29,  1.45it/s] 15%|â–ˆâ–        | 7/48 [00:07<00:25,  1.61it/s] 17%|â–ˆâ–‹        | 8/48 [00:07<00:23,  1.73it/s] 19%|â–ˆâ–‰        | 9/48 [00:08<00:21,  1.83it/s] 21%|â–ˆâ–ˆ        | 10/48 [00:08<00:19,  1.90it/s] 23%|â–ˆâ–ˆâ–Ž       | 11/48 [00:09<00:18,  1.95it/s] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:09<00:18,  1.99it/s] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:09<00:17,  2.02it/s] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:10<00:16,  2.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:10<00:16,  2.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 16/48 [00:11<00:14,  2.17it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:11<00:14,  2.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:12<00:14,  2.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:12<00:13,  2.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:13<00:13,  2.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:13<00:12,  2.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:14<00:12,  2.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:14<00:11,  2.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:15<00:11,  2.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:15<00:11,  2.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:16<00:10,  2.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:16<00:10,  2.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:17<00:09,  2.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:17<00:09,  2.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 30/48 [00:18<00:08,  2.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:18<00:08,  2.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:18<00:07,  2.19it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:19<00:06,  2.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:19<00:06,  2.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 35/48 [00:20<00:06,  2.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:20<00:05,  2.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:21<00:05,  2.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [00:21<00:04,  2.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [00:22<00:04,  2.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 40/48 [00:22<00:03,  2.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [00:23<00:03,  2.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [00:23<00:02,  2.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [00:24<00:02,  2.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [00:24<00:01,  2.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [00:25<00:01,  2.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [00:25<00:00,  2.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [00:26<00:00,  2.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  2.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:26<00:00,  1.81it/s]
[INFO][02:27:31]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
{'train_runtime': 26.5474, 'train_samples_per_second': 228.045, 'train_steps_per_second': 1.808, 'train_loss': 1.351346492767334, 'epoch': 3.0}
[INFO][02:27:32]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3350395.pth.
[INFO][02:27:32]: [Client #9] Model trained.
[INFO][02:27:32]: [Client #9] Inbound data has been processed.
[INFO][02:27:32]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][02:27:36]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][02:27:37]: [Server #3350301] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][02:27:37]: [Server #3350301] Adding client #1 to the list of clients for aggregation.
[INFO][02:27:37]: [Server #3350301] Adding client #10 to the list of clients for aggregation.
[INFO][02:27:37]: [Server #3350301] Adding client #3 to the list of clients for aggregation.
[INFO][02:27:37]: [Server #3350301] Adding client #5 to the list of clients for aggregation.
[INFO][02:27:37]: [Server #3350301] Adding client #9 to the list of clients for aggregation.
[INFO][02:27:37]: [Server #3350301] Aggregating 5 clients in total.
[INFO][02:27:37]: [Server #3350301] Updated weights have been received.
[INFO][02:27:38]: [Server #3350301] Aggregating model weight deltas.
[INFO][02:27:38]: [Server #3350301] Finished aggregating updated weights.
[INFO][02:27:38]: [Server #3350301] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 16
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|          | 0/8 [00:00<?, ?it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:00<00:00, 19.25it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [00:00<00:00, 13.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:00<00:00, 11.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.76it/s]
[INFO][02:27:49]: [93m[1m[Server #3350301] Global model perplexity: 89.83
[0m
[INFO][02:27:49]: [Server #3350301] All client reports have been processed.
[INFO][02:27:49]: [Server #3350301] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_100.pth.
[INFO][02:27:50]: [Server #3350301] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_100.pth.
[INFO][02:27:50]: Target number of training rounds reached.
[INFO][02:27:50]: [Server #3350301] Training concluded.
[INFO][02:27:53]: [Server #3350301] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased.pth.
[INFO][02:27:53]: [Server #3350301] Closing the server.
[INFO][02:27:53]: Closing the connection to client #2.
[INFO][02:27:53]: Closing the connection to client #1.
[INFO][02:27:53]: [Client #2] The server disconnected the connection.
[INFO][02:27:53]: [Client #1] The server disconnected the connection.
/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 2 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
