The configuration filename is: ./oort_shakespeare_bert.yml
 
clients:
# Type
type: simple

# The total number of clients
total_clients: 200

# The number of clients selected in each round
per_round: 20

# Should the clients compute test accuracy locally?
do_test: false

speed_simulation: true
simulation_distribution:
distribution: zipf
s: 1.2

sleep_simulation: true
avg_training_time: 10
random_seed: 1

server:
address: 127.0.0.1
port: 1101
simulate_wall_time: true
# Should we operate in sychronous mode?
synchronous: false
# What is the minimum number of clients that need to report before aggregation begins?
minimum_clients_aggregated: 10

step_window: 2
penalty: 2
exploration_factor: 0.9
desired_duration: 50

# What is the staleness bound, beyond which the server should wait for stale clients?
staleness_bound: 10
checkpoint_path: checkpoints/huggingface/fedavg
model_path: models/huggingface/fedavg

data:
# The training and testing dataset
datasource: HuggingFace
dataset_name: tiny_shakespeare

# Number of samples in each partition
partition_size: 1009

# IID or non-IID?
sampler: iid

# The random seed for sampling data
random_seed: 3

trainer:
# The type of the trainer
type: HuggingFace

# The maximum number of training rounds
rounds: 50

# The maximum number of clients running concurrently
max_concurrency: 1

# The target perplexity
target_perplexity: 20

# The machine learning model
model_type: huggingface
model_name: bert-base-uncased

# Number of epoches for local training in each communication round
epochs: 5
batch_size: 32
optimizer: SGD

algorithm:
# Aggregation algorithm
type: fedavg

parameters:
optimizer:
lr: 0.01
momentum: 0.9
weight_decay: 0.0

results:
# Write the following parameter(s) into a CSV
types: round, elapsed_time, accuracy
result_path: /data/ykang/plato/results/oort/shakespeare/test
[INFO][04:06:53]: [93m[1m[3995185] Logging runtime results to: /data/ykang/plato/results/oort/shakespeare/test/3995185.csv.[0m
[INFO][04:06:53]: [Server #3995185] Started training on 200 clients with 20 per round.
[INFO][04:06:53]: [Server #3995185] Configuring the server...
[INFO][04:06:53]: Training: 50 rounds or perplexity below 20.0

If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO][04:06:55]: Algorithm: fedavg
[INFO][04:06:55]: Data source: HuggingFace
[INFO][04:06:55]: Dataset: tiny_shakespeare
[WARNING][04:06:56]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (258335 > 512). Running this sequence through the model will result in indexing errors
^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.
Running tokenizer on dataset:   0%|          | 0/1 [00:01<?, ?ba/s]
[WARNING][04:06:57]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][04:06:57]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][04:06:57]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[INFO][04:06:57]: Starting client #1's process.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[INFO][04:06:57]: Starting a server at address 127.0.0.1 and port 1101.
[INFO][04:07:00]: Starting a custom client #1
If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO][04:07:02]: Algorithm: fedavg
[INFO][04:07:07]: [Client #1] Contacting the server.
[INFO][04:07:07]: [Client #1] Connecting to the server at http://127.0.0.1:1101.
[INFO][04:07:07]: 127.0.0.1 [06/Feb/2023:09:07:07 +0000] "GET /socket.io/?transport=polling&EIO=4&t=1675674427.6193507 HTTP/1.1" 200 293 "-" "Python/3.9 aiohttp/3.8.3"
[INFO][04:07:07]: [Server #3995185] A new client just connected.
[INFO][04:07:07]: [Client #1] Connected to the server.
[INFO][04:07:07]: [Client #1] Waiting to be selected.
[INFO][04:07:07]: [Server #3995185] New client with id #1 arrived.
[INFO][04:07:07]: [Server #3995185] Starting training.
[INFO][04:07:07]: [93m[1m
[Server #3995185] Starting round 1/50.[0m
[INFO][04:07:07]: [Server #3995185] Selected clients: [166, 141, 19, 138, 55, 75, 145, 48, 15, 118, 192, 185, 187, 108, 136, 56, 161, 21, 171, 98]
[INFO][04:07:07]: [Server #3995185] Selecting client #166 for training.
[INFO][04:07:07]: [Server #3995185] Sending the current model to client #166 (simulated).
[INFO][04:07:11]: [Server #3995185] Sending 507.38 MB of payload data to client #166 (simulated).
[INFO][04:07:11]: [Client #166] Selected by the server.
[INFO][04:07:11]: [Client #166] Loading its data source...
[INFO][04:07:11]: Data source: HuggingFace
[INFO][04:07:11]: Dataset: tiny_shakespeare
[WARNING][04:07:12]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Token indices sequence length is longer than the specified maximum sequence length for this model (258335 > 512). Running this sequence through the model will result in indexing errors
^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.
Running tokenizer on dataset:   0%|          | 0/1 [00:01<?, ?ba/s]
[WARNING][04:07:13]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][04:07:13]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]
[WARNING][04:07:13]: num_proc must be <= 1. Reducing num_proc to 1 for dataset of size 1.
Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]Grouping texts in chunks of 512:   0%|          | 0/1 [00:00<?, ?ba/s]
[INFO][04:07:13]: [Client #166] Dataset size: 2018
[INFO][04:07:13]: [Client #166] Sampler: iid
[INFO][04:07:15]: [Client #166] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:07:15]: [Client #166] Start to process inbound data.
[INFO][04:07:15]: [93m[1m[Client #166] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.60s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.10it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.11it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.12it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.09it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.10it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.08it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.54it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.13it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.12it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.12it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.08it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.08it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.282235781351726,)
[INFO][04:07:53]: [Client #166] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_166_3995237.pth.
{'train_runtime': 32.1092, 'train_samples_per_second': 188.544, 'train_steps_per_second': 2.99, 'train_loss': 5.282235781351726, 'epoch': 3.0}
[INFO][04:07:54]: [Client #166] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_166_3995237.pth.
[INFO][04:07:54]: [Client #166] Model trained.
[INFO][04:07:54]: [Client #166] Inbound data has been processed.
[INFO][04:07:54]: [Client #166] Outbound data is ready to be sent after being processed.
[INFO][04:07:58]: [Client #166] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:08:00]: [Server #3995185] Received 507.38 MB of payload data from client #166 (simulated).
[INFO][04:08:00]: [Server #3995185] Selecting client #141 for training.
[INFO][04:08:00]: [Server #3995185] Sending the current model to client #141 (simulated).
[INFO][04:08:04]: [Server #3995185] Sending 507.38 MB of payload data to client #141 (simulated).
[INFO][04:08:04]: [Client #141] Selected by the server.
[INFO][04:08:04]: [Client #141] Loading its data source...
[INFO][04:08:04]: [Client #141] Dataset size: 2018
[INFO][04:08:04]: [Client #141] Sampler: iid
[INFO][04:08:06]: [Client #141] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:08:06]: [Client #141] Start to process inbound data.
[INFO][04:08:06]: [93m[1m[Client #141] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:57,  1.87s/it]  2%|â–         | 2/96 [00:02<01:31,  1.03it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.48it/s]  4%|â–         | 4/96 [00:02<00:49,  1.86it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.39it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.56it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.68it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.204050699869792,)
[INFO][04:08:46]: [Client #141] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_141_3995237.pth.
{'train_runtime': 33.0425, 'train_samples_per_second': 183.218, 'train_steps_per_second': 2.905, 'train_loss': 5.204050699869792, 'epoch': 3.0}
[INFO][04:08:47]: [Client #141] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_141_3995237.pth.
[INFO][04:08:48]: [Client #141] Model trained.
[INFO][04:08:48]: [Client #141] Inbound data has been processed.
[INFO][04:08:48]: [Client #141] Outbound data is ready to be sent after being processed.
[INFO][04:08:52]: [Client #141] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:08:54]: [Server #3995185] Received 507.38 MB of payload data from client #141 (simulated).
[INFO][04:08:54]: [Server #3995185] Selecting client #19 for training.
[INFO][04:08:54]: [Server #3995185] Sending the current model to client #19 (simulated).
[INFO][04:08:58]: [Server #3995185] Sending 507.38 MB of payload data to client #19 (simulated).
[INFO][04:08:58]: [Client #19] Selected by the server.
[INFO][04:08:58]: [Client #19] Loading its data source...
[INFO][04:08:58]: [Client #19] Dataset size: 2018
[INFO][04:08:58]: [Client #19] Sampler: iid
[INFO][04:09:00]: [Client #19] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:09:00]: [Client #19] Start to process inbound data.
[INFO][04:09:00]: [93m[1m[Client #19] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.158245086669922,)
[INFO][04:09:39]: [Client #19] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_19_3995237.pth.
{'train_runtime': 32.9507, 'train_samples_per_second': 183.729, 'train_steps_per_second': 2.913, 'train_loss': 5.158245086669922, 'epoch': 3.0}
[INFO][04:09:40]: [Client #19] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_19_3995237.pth.
[INFO][04:09:41]: [Client #19] Model trained.
[INFO][04:09:41]: [Client #19] Inbound data has been processed.
[INFO][04:09:41]: [Client #19] Outbound data is ready to be sent after being processed.
[INFO][04:09:44]: [Client #19] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:09:45]: [Server #3995185] Received 507.38 MB of payload data from client #19 (simulated).
[INFO][04:09:45]: [Server #3995185] Selecting client #138 for training.
[INFO][04:09:45]: [Server #3995185] Sending the current model to client #138 (simulated).
[INFO][04:09:49]: [Server #3995185] Sending 507.38 MB of payload data to client #138 (simulated).
[INFO][04:09:49]: [Client #138] Selected by the server.
[INFO][04:09:49]: [Client #138] Loading its data source...
[INFO][04:09:49]: [Client #138] Dataset size: 2018
[INFO][04:09:49]: [Client #138] Sampler: iid
[INFO][04:09:50]: [Client #138] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:09:50]: [Client #138] Start to process inbound data.
[INFO][04:09:50]: [93m[1m[Client #138] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.66it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  2.99it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.98it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.97it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.95it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.92it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.94it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.94it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.203667004903157,)
[INFO][04:10:29]: [Client #138] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_138_3995237.pth.
{'train_runtime': 32.9384, 'train_samples_per_second': 183.797, 'train_steps_per_second': 2.915, 'train_loss': 5.203667004903157, 'epoch': 3.0}
[INFO][04:10:30]: [Client #138] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_138_3995237.pth.
[INFO][04:10:31]: [Client #138] Model trained.
[INFO][04:10:31]: [Client #138] Inbound data has been processed.
[INFO][04:10:31]: [Client #138] Outbound data is ready to be sent after being processed.
[INFO][04:10:34]: [Client #138] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:10:36]: [Server #3995185] Received 507.38 MB of payload data from client #138 (simulated).
[INFO][04:10:36]: [Server #3995185] Selecting client #55 for training.
[INFO][04:10:36]: [Server #3995185] Sending the current model to client #55 (simulated).
[INFO][04:10:39]: [Server #3995185] Sending 507.38 MB of payload data to client #55 (simulated).
[INFO][04:10:39]: [Client #55] Selected by the server.
[INFO][04:10:39]: [Client #55] Loading its data source...
[INFO][04:10:39]: [Client #55] Dataset size: 2018
[INFO][04:10:39]: [Client #55] Sampler: iid
[INFO][04:10:41]: [Client #55] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:10:41]: [Client #55] Start to process inbound data.
[INFO][04:10:41]: [93m[1m[Client #55] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.54s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.196880340576172,)
[INFO][04:11:20]: [Client #55] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_55_3995237.pth.
{'train_runtime': 32.6063, 'train_samples_per_second': 185.669, 'train_steps_per_second': 2.944, 'train_loss': 5.196880340576172, 'epoch': 3.0}
[INFO][04:11:20]: [Client #55] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_55_3995237.pth.
[INFO][04:11:21]: [Client #55] Model trained.
[INFO][04:11:21]: [Client #55] Inbound data has been processed.
[INFO][04:11:21]: [Client #55] Outbound data is ready to be sent after being processed.
[INFO][04:11:25]: [Client #55] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:11:26]: [Server #3995185] Received 507.38 MB of payload data from client #55 (simulated).
[INFO][04:11:26]: [Server #3995185] Selecting client #75 for training.
[INFO][04:11:26]: [Server #3995185] Sending the current model to client #75 (simulated).
[INFO][04:11:30]: [Server #3995185] Sending 507.38 MB of payload data to client #75 (simulated).
[INFO][04:11:30]: [Client #75] Selected by the server.
[INFO][04:11:30]: [Client #75] Loading its data source...
[INFO][04:11:30]: [Client #75] Dataset size: 2018
[INFO][04:11:30]: [Client #75] Sampler: iid
[INFO][04:11:31]: [Client #75] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:11:31]: [Client #75] Start to process inbound data.
[INFO][04:11:31]: [93m[1m[Client #75] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:51,  1.80s/it]  2%|â–         | 2/96 [00:02<01:28,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.1705582936604815,)
[INFO][04:12:11]: [Client #75] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_75_3995237.pth.
{'train_runtime': 33.0449, 'train_samples_per_second': 183.205, 'train_steps_per_second': 2.905, 'train_loss': 5.1705582936604815, 'epoch': 3.0}
[INFO][04:12:12]: [Client #75] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_75_3995237.pth.
[INFO][04:12:13]: [Client #75] Model trained.
[INFO][04:12:13]: [Client #75] Inbound data has been processed.
[INFO][04:12:13]: [Client #75] Outbound data is ready to be sent after being processed.
[INFO][04:12:16]: [Client #75] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:12:17]: [Server #3995185] Received 507.38 MB of payload data from client #75 (simulated).
[INFO][04:12:17]: [Server #3995185] Selecting client #145 for training.
[INFO][04:12:17]: [Server #3995185] Sending the current model to client #145 (simulated).
[INFO][04:12:21]: [Server #3995185] Sending 507.38 MB of payload data to client #145 (simulated).
[INFO][04:12:21]: [Client #145] Selected by the server.
[INFO][04:12:21]: [Client #145] Loading its data source...
[INFO][04:12:21]: [Client #145] Dataset size: 2018
[INFO][04:12:21]: [Client #145] Sampler: iid
[INFO][04:12:23]: [Client #145] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:12:23]: [Client #145] Start to process inbound data.
[INFO][04:12:23]: [93m[1m[Client #145] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.99it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.98it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.96it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.93it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.192071596781413,)
[INFO][04:13:03]: [Client #145] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_145_3995237.pth.
{'train_runtime': 33.0484, 'train_samples_per_second': 183.186, 'train_steps_per_second': 2.905, 'train_loss': 5.192071596781413, 'epoch': 3.0}
[INFO][04:13:04]: [Client #145] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_145_3995237.pth.
[INFO][04:13:04]: [Client #145] Model trained.
[INFO][04:13:04]: [Client #145] Inbound data has been processed.
[INFO][04:13:04]: [Client #145] Outbound data is ready to be sent after being processed.
[INFO][04:13:08]: [Client #145] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:13:10]: [Server #3995185] Received 507.38 MB of payload data from client #145 (simulated).
[INFO][04:13:10]: [Server #3995185] Selecting client #48 for training.
[INFO][04:13:10]: [Server #3995185] Sending the current model to client #48 (simulated).
[INFO][04:13:14]: [Server #3995185] Sending 507.38 MB of payload data to client #48 (simulated).
[INFO][04:13:14]: [Client #48] Selected by the server.
[INFO][04:13:14]: [Client #48] Loading its data source...
[INFO][04:13:14]: [Client #48] Dataset size: 2018
[INFO][04:13:14]: [Client #48] Sampler: iid
[INFO][04:13:16]: [Client #48] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:13:16]: [Client #48] Start to process inbound data.
[INFO][04:13:16]: [93m[1m[Client #48] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:23,  1.51s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.155976295471191,)
[INFO][04:13:54]: [Client #48] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_48_3995237.pth.
{'train_runtime': 32.4837, 'train_samples_per_second': 186.37, 'train_steps_per_second': 2.955, 'train_loss': 5.155976295471191, 'epoch': 3.0}
[INFO][04:13:55]: [Client #48] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_48_3995237.pth.
[INFO][04:13:55]: [Client #48] Model trained.
[INFO][04:13:55]: [Client #48] Inbound data has been processed.
[INFO][04:13:55]: [Client #48] Outbound data is ready to be sent after being processed.
[INFO][04:14:00]: [Client #48] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:14:01]: [Server #3995185] Received 507.38 MB of payload data from client #48 (simulated).
[INFO][04:14:01]: [Server #3995185] Selecting client #15 for training.
[INFO][04:14:01]: [Server #3995185] Sending the current model to client #15 (simulated).
[INFO][04:14:06]: [Server #3995185] Sending 507.38 MB of payload data to client #15 (simulated).
[INFO][04:14:06]: [Client #15] Selected by the server.
[INFO][04:14:06]: [Client #15] Loading its data source...
[INFO][04:14:06]: [Client #15] Dataset size: 2018
[INFO][04:14:06]: [Client #15] Sampler: iid
[INFO][04:14:07]: [Client #15] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:14:07]: [Client #15] Start to process inbound data.
[INFO][04:14:07]: [93m[1m[Client #15] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:16,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.32it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.232015609741211,)
[INFO][04:14:46]: [Client #15] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_15_3995237.pth.
{'train_runtime': 32.4655, 'train_samples_per_second': 186.475, 'train_steps_per_second': 2.957, 'train_loss': 5.232015609741211, 'epoch': 3.0}
[INFO][04:14:47]: [Client #15] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_15_3995237.pth.
[INFO][04:14:47]: [Client #15] Model trained.
[INFO][04:14:47]: [Client #15] Inbound data has been processed.
[INFO][04:14:47]: [Client #15] Outbound data is ready to be sent after being processed.
[INFO][04:14:52]: [Client #15] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:14:53]: [Server #3995185] Received 507.38 MB of payload data from client #15 (simulated).
[INFO][04:14:53]: [Server #3995185] Selecting client #118 for training.
[INFO][04:14:53]: [Server #3995185] Sending the current model to client #118 (simulated).
[INFO][04:14:59]: [Server #3995185] Sending 507.38 MB of payload data to client #118 (simulated).
[INFO][04:14:59]: [Client #118] Selected by the server.
[INFO][04:14:59]: [Client #118] Loading its data source...
[INFO][04:14:59]: [Client #118] Dataset size: 2018
[INFO][04:14:59]: [Client #118] Sampler: iid
[INFO][04:15:00]: [Client #118] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:15:00]: [Client #118] Start to process inbound data.
[INFO][04:15:01]: [93m[1m[Client #118] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.10it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.17it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.09it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.06it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.07it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.1758473714192705,)
[INFO][04:15:39]: [Client #118] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_118_3995237.pth.
{'train_runtime': 32.0584, 'train_samples_per_second': 188.843, 'train_steps_per_second': 2.995, 'train_loss': 5.1758473714192705, 'epoch': 3.0}
[INFO][04:15:39]: [Client #118] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_118_3995237.pth.
[INFO][04:15:40]: [Client #118] Model trained.
[INFO][04:15:40]: [Client #118] Inbound data has been processed.
[INFO][04:15:40]: [Client #118] Outbound data is ready to be sent after being processed.
[INFO][04:15:44]: [Client #118] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:15:45]: [Server #3995185] Received 507.38 MB of payload data from client #118 (simulated).
[INFO][04:15:45]: [Server #3995185] Selecting client #192 for training.
[INFO][04:15:45]: [Server #3995185] Sending the current model to client #192 (simulated).
[INFO][04:15:51]: [Server #3995185] Sending 507.38 MB of payload data to client #192 (simulated).
[INFO][04:15:51]: [Client #192] Selected by the server.
[INFO][04:15:51]: [Client #192] Loading its data source...
[INFO][04:15:51]: [Client #192] Dataset size: 2018
[INFO][04:15:51]: [Client #192] Sampler: iid
[INFO][04:15:52]: [Client #192] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:15:52]: [Client #192] Start to process inbound data.
[INFO][04:15:52]: [93m[1m[Client #192] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.81s/it]  2%|â–         | 2/96 [00:02<01:28,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.94it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.94it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.94it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.93it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.202468554178874,)
[INFO][04:16:31]: [Client #192] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_192_3995237.pth.
{'train_runtime': 33.1238, 'train_samples_per_second': 182.769, 'train_steps_per_second': 2.898, 'train_loss': 5.202468554178874, 'epoch': 3.0}
[INFO][04:16:32]: [Client #192] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_192_3995237.pth.
[INFO][04:16:33]: [Client #192] Model trained.
[INFO][04:16:33]: [Client #192] Inbound data has been processed.
[INFO][04:16:33]: [Client #192] Outbound data is ready to be sent after being processed.
[INFO][04:16:37]: [Client #192] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:16:38]: [Server #3995185] Received 507.38 MB of payload data from client #192 (simulated).
[INFO][04:16:38]: [Server #3995185] Selecting client #185 for training.
[INFO][04:16:38]: [Server #3995185] Sending the current model to client #185 (simulated).
[INFO][04:16:47]: [Server #3995185] Sending 507.38 MB of payload data to client #185 (simulated).
[INFO][04:16:47]: [Client #185] Selected by the server.
[INFO][04:16:47]: [Client #185] Loading its data source...
[INFO][04:16:47]: [Client #185] Dataset size: 2018
[INFO][04:16:47]: [Client #185] Sampler: iid
[INFO][04:16:48]: [Client #185] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:16:48]: [Client #185] Start to process inbound data.
[INFO][04:16:48]: [93m[1m[Client #185] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<03:03,  1.93s/it]  2%|â–         | 2/96 [00:02<01:32,  1.02it/s]  3%|â–Ž         | 3/96 [00:02<01:03,  1.47it/s]  4%|â–         | 4/96 [00:02<00:50,  1.84it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.14it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.37it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.55it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  2.98it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.96it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.187307993570964,)
[INFO][04:17:28]: [Client #185] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_185_3995237.pth.
{'train_runtime': 33.335, 'train_samples_per_second': 181.611, 'train_steps_per_second': 2.88, 'train_loss': 5.187307993570964, 'epoch': 3.0}
[INFO][04:17:29]: [Client #185] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_185_3995237.pth.
[INFO][04:17:29]: [Client #185] Model trained.
[INFO][04:17:29]: [Client #185] Inbound data has been processed.
[INFO][04:17:29]: [Client #185] Outbound data is ready to be sent after being processed.
[INFO][04:17:37]: [Client #185] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:17:38]: [Server #3995185] Received 507.38 MB of payload data from client #185 (simulated).
[INFO][04:17:38]: [Server #3995185] Selecting client #187 for training.
[INFO][04:17:38]: [Server #3995185] Sending the current model to client #187 (simulated).
[INFO][04:17:46]: [Server #3995185] Sending 507.38 MB of payload data to client #187 (simulated).
[INFO][04:17:46]: [Client #187] Selected by the server.
[INFO][04:17:46]: [Client #187] Loading its data source...
[INFO][04:17:46]: [Client #187] Dataset size: 2018
[INFO][04:17:46]: [Client #187] Sampler: iid
[INFO][04:17:47]: [Client #187] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:17:47]: [Client #187] Start to process inbound data.
[INFO][04:17:47]: [93m[1m[Client #187] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.185433069864909,)
[INFO][04:18:27]: [Client #187] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_187_3995237.pth.
{'train_runtime': 32.9414, 'train_samples_per_second': 183.781, 'train_steps_per_second': 2.914, 'train_loss': 5.185433069864909, 'epoch': 3.0}
[INFO][04:18:28]: [Client #187] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_187_3995237.pth.
[INFO][04:18:28]: [Client #187] Model trained.
[INFO][04:18:28]: [Client #187] Inbound data has been processed.
[INFO][04:18:28]: [Client #187] Outbound data is ready to be sent after being processed.
[INFO][04:18:34]: [Client #187] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:18:36]: [Server #3995185] Received 507.38 MB of payload data from client #187 (simulated).
[INFO][04:18:36]: [Server #3995185] Selecting client #108 for training.
[INFO][04:18:36]: [Server #3995185] Sending the current model to client #108 (simulated).
[INFO][04:18:40]: [Server #3995185] Sending 507.38 MB of payload data to client #108 (simulated).
[INFO][04:18:40]: [Client #108] Selected by the server.
[INFO][04:18:40]: [Client #108] Loading its data source...
[INFO][04:18:40]: [Client #108] Dataset size: 2018
[INFO][04:18:40]: [Client #108] Sampler: iid
[INFO][04:18:41]: [Client #108] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:18:41]: [Client #108] Start to process inbound data.
[INFO][04:18:41]: [93m[1m[Client #108] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.63it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.192864418029785,)
[INFO][04:19:20]: [Client #108] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_108_3995237.pth.
{'train_runtime': 32.6924, 'train_samples_per_second': 185.18, 'train_steps_per_second': 2.936, 'train_loss': 5.192864418029785, 'epoch': 3.0}
[INFO][04:19:20]: [Client #108] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_108_3995237.pth.
[INFO][04:19:21]: [Client #108] Model trained.
[INFO][04:19:21]: [Client #108] Inbound data has been processed.
[INFO][04:19:21]: [Client #108] Outbound data is ready to be sent after being processed.
[INFO][04:19:29]: [Client #108] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:19:30]: [Server #3995185] Received 507.38 MB of payload data from client #108 (simulated).
[INFO][04:19:30]: [Server #3995185] Selecting client #136 for training.
[INFO][04:19:30]: [Server #3995185] Sending the current model to client #136 (simulated).
[INFO][04:19:34]: [Server #3995185] Sending 507.38 MB of payload data to client #136 (simulated).
[INFO][04:19:34]: [Client #136] Selected by the server.
[INFO][04:19:34]: [Client #136] Loading its data source...
[INFO][04:19:34]: [Client #136] Dataset size: 2018
[INFO][04:19:34]: [Client #136] Sampler: iid
[INFO][04:19:36]: [Client #136] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:19:36]: [Client #136] Start to process inbound data.
[INFO][04:19:37]: [93m[1m[Client #136] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.81s/it]  2%|â–         | 2/96 [00:02<01:28,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.96it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.97it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.97it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.97it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.163635889689128,)
[INFO][04:20:16]: [Client #136] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_136_3995237.pth.
{'train_runtime': 33.0389, 'train_samples_per_second': 183.238, 'train_steps_per_second': 2.906, 'train_loss': 5.163635889689128, 'epoch': 3.0}
[INFO][04:20:17]: [Client #136] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_136_3995237.pth.
[INFO][04:20:18]: [Client #136] Model trained.
[INFO][04:20:18]: [Client #136] Inbound data has been processed.
[INFO][04:20:18]: [Client #136] Outbound data is ready to be sent after being processed.
[INFO][04:20:22]: [Client #136] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:20:23]: [Server #3995185] Received 507.38 MB of payload data from client #136 (simulated).
[INFO][04:20:23]: [Server #3995185] Selecting client #56 for training.
[INFO][04:20:23]: [Server #3995185] Sending the current model to client #56 (simulated).
[INFO][04:20:28]: [Server #3995185] Sending 507.38 MB of payload data to client #56 (simulated).
[INFO][04:20:28]: [Client #56] Selected by the server.
[INFO][04:20:28]: [Client #56] Loading its data source...
[INFO][04:20:28]: [Client #56] Dataset size: 2018
[INFO][04:20:28]: [Client #56] Sampler: iid
[INFO][04:20:29]: [Client #56] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:20:29]: [Client #56] Start to process inbound data.
[INFO][04:20:30]: [93m[1m[Client #56] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.175515810648601,)
[INFO][04:21:09]: [Client #56] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_56_3995237.pth.
{'train_runtime': 32.6933, 'train_samples_per_second': 185.176, 'train_steps_per_second': 2.936, 'train_loss': 5.175515810648601, 'epoch': 3.0}
[INFO][04:21:10]: [Client #56] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_56_3995237.pth.
[INFO][04:21:10]: [Client #56] Model trained.
[INFO][04:21:10]: [Client #56] Inbound data has been processed.
[INFO][04:21:10]: [Client #56] Outbound data is ready to be sent after being processed.
[INFO][04:21:14]: [Client #56] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:21:16]: [Server #3995185] Received 507.38 MB of payload data from client #56 (simulated).
[INFO][04:21:16]: [Server #3995185] Selecting client #161 for training.
[INFO][04:21:16]: [Server #3995185] Sending the current model to client #161 (simulated).
[INFO][04:21:20]: [Server #3995185] Sending 507.38 MB of payload data to client #161 (simulated).
[INFO][04:21:20]: [Client #161] Selected by the server.
[INFO][04:21:20]: [Client #161] Loading its data source...
[INFO][04:21:20]: [Client #161] Dataset size: 2018
[INFO][04:21:20]: [Client #161] Sampler: iid
[INFO][04:21:21]: [Client #161] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:21:21]: [Client #161] Start to process inbound data.
[INFO][04:21:22]: [93m[1m[Client #161] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.76s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.219120343526204,)
[INFO][04:22:01]: [Client #161] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_161_3995237.pth.
{'train_runtime': 32.5599, 'train_samples_per_second': 185.934, 'train_steps_per_second': 2.948, 'train_loss': 5.219120343526204, 'epoch': 3.0}
[INFO][04:22:02]: [Client #161] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_161_3995237.pth.
[INFO][04:22:02]: [Client #161] Model trained.
[INFO][04:22:02]: [Client #161] Inbound data has been processed.
[INFO][04:22:02]: [Client #161] Outbound data is ready to be sent after being processed.
[INFO][04:22:07]: [Client #161] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:22:08]: [Server #3995185] Received 507.38 MB of payload data from client #161 (simulated).
[INFO][04:22:08]: [Server #3995185] Selecting client #21 for training.
[INFO][04:22:08]: [Server #3995185] Sending the current model to client #21 (simulated).
[INFO][04:22:12]: [Server #3995185] Sending 507.38 MB of payload data to client #21 (simulated).
[INFO][04:22:12]: [Client #21] Selected by the server.
[INFO][04:22:12]: [Client #21] Loading its data source...
[INFO][04:22:12]: [Client #21] Dataset size: 2018
[INFO][04:22:12]: [Client #21] Sampler: iid
[INFO][04:22:14]: [Client #21] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:22:14]: [Client #21] Start to process inbound data.
[INFO][04:22:14]: [93m[1m[Client #21] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.163098017374675,)
[INFO][04:22:53]: [Client #21] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_21_3995237.pth.
{'train_runtime': 32.8389, 'train_samples_per_second': 184.355, 'train_steps_per_second': 2.923, 'train_loss': 5.163098017374675, 'epoch': 3.0}
[INFO][04:22:54]: [Client #21] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_21_3995237.pth.
[INFO][04:22:55]: [Client #21] Model trained.
[INFO][04:22:55]: [Client #21] Inbound data has been processed.
[INFO][04:22:55]: [Client #21] Outbound data is ready to be sent after being processed.
[INFO][04:23:00]: [Client #21] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:23:01]: [Server #3995185] Received 507.38 MB of payload data from client #21 (simulated).
[INFO][04:23:01]: [Server #3995185] Selecting client #171 for training.
[INFO][04:23:01]: [Server #3995185] Sending the current model to client #171 (simulated).
[INFO][04:23:05]: [Server #3995185] Sending 507.38 MB of payload data to client #171 (simulated).
[INFO][04:23:05]: [Client #171] Selected by the server.
[INFO][04:23:05]: [Client #171] Loading its data source...
[INFO][04:23:05]: [Client #171] Dataset size: 2018
[INFO][04:23:05]: [Client #171] Sampler: iid
[INFO][04:23:07]: [Client #171] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:23:07]: [Client #171] Start to process inbound data.
[INFO][04:23:07]: [93m[1m[Client #171] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.187232971191406,)
[INFO][04:23:46]: [Client #171] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_171_3995237.pth.
{'train_runtime': 32.8376, 'train_samples_per_second': 184.362, 'train_steps_per_second': 2.923, 'train_loss': 5.187232971191406, 'epoch': 3.0}
[INFO][04:23:47]: [Client #171] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_171_3995237.pth.
[INFO][04:23:48]: [Client #171] Model trained.
[INFO][04:23:48]: [Client #171] Inbound data has been processed.
[INFO][04:23:48]: [Client #171] Outbound data is ready to be sent after being processed.
[INFO][04:23:52]: [Client #171] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:23:54]: [Server #3995185] Received 507.38 MB of payload data from client #171 (simulated).
[INFO][04:23:54]: [Server #3995185] Selecting client #98 for training.
[INFO][04:23:54]: [Server #3995185] Sending the current model to client #98 (simulated).
[INFO][04:23:58]: [Server #3995185] Sending 507.38 MB of payload data to client #98 (simulated).
[INFO][04:23:58]: [Client #98] Selected by the server.
[INFO][04:23:58]: [Client #98] Loading its data source...
[INFO][04:23:58]: [Client #98] Dataset size: 2018
[INFO][04:23:58]: [Client #98] Sampler: iid
[INFO][04:23:59]: [Client #98] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:23:59]: [Client #98] Start to process inbound data.
[INFO][04:23:59]: [93m[1m[Client #98] Started training in communication round #1.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:56,  1.85s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (5.1669260660807295,)
[INFO][04:24:39]: [Client #98] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_98_3995237.pth.
{'train_runtime': 32.7736, 'train_samples_per_second': 184.722, 'train_steps_per_second': 2.929, 'train_loss': 5.1669260660807295, 'epoch': 3.0}
[INFO][04:24:40]: [Client #98] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_98_3995237.pth.
[INFO][04:24:40]: [Client #98] Model trained.
[INFO][04:24:40]: [Client #98] Inbound data has been processed.
[INFO][04:24:40]: [Client #98] Outbound data is ready to be sent after being processed.
[INFO][04:24:44]: [Client #98] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:24:46]: [Server #3995185] Received 507.38 MB of payload data from client #98 (simulated).
[INFO][04:24:46]: [Server #3995185] Adding client #21 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #48 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #138 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #141 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #171 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #108 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #55 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #136 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #19 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Adding client #185 to the list of clients for aggregation.
[INFO][04:24:46]: [Server #3995185] Aggregating 10 clients in total.
[INFO][04:24:46]: [Server #3995185] Updated weights have been received.
[INFO][04:24:47]: [Server #3995185] Aggregating model weight deltas.
[INFO][04:24:48]: [Server #3995185] Finished aggregating updated weights.
[INFO][04:24:48]: [Server #3995185] Started model testing.
======== Running on http://127.0.0.1:1101 ========
(Press CTRL+C to quit)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.72it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.19it/s]
[INFO][04:24:56]: [93m[1m[Server #3995185] Global model perplexity: 91.09
[0m
[INFO][04:24:56]: [Server #3995185] All client reports have been processed.
[INFO][04:24:56]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_1.pth.
[INFO][04:24:59]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_1.pth.
[INFO][04:24:59]: [93m[1m
[Server #3995185] Starting round 2/50.[0m
[INFO][04:24:59]: [Server #3995185] Selected clients: [2, 134, 199, 193, 109, 89, 183, 83, 125, 71]
[INFO][04:24:59]: [Server #3995185] Selecting client #2 for training.
[INFO][04:24:59]: [Server #3995185] Sending the current model to client #2 (simulated).
[INFO][04:25:03]: [Server #3995185] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][04:25:03]: [Client #2] Selected by the server.
[INFO][04:25:03]: [Client #2] Loading its data source...
[INFO][04:25:03]: [Client #2] Dataset size: 2018
[INFO][04:25:03]: [Client #2] Sampler: iid
[INFO][04:25:05]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:25:05]: [Client #2] Start to process inbound data.
[INFO][04:25:05]: [93m[1m[Client #2] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.83s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:48,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.316171010335286,)
[INFO][04:25:44]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3995237.pth.
{'train_runtime': 32.7179, 'train_samples_per_second': 185.036, 'train_steps_per_second': 2.934, 'train_loss': 4.316171010335286, 'epoch': 3.0}
[INFO][04:25:45]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3995237.pth.
[INFO][04:25:46]: [Client #2] Model trained.
[INFO][04:25:46]: [Client #2] Inbound data has been processed.
[INFO][04:25:46]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][04:25:50]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:25:51]: [Server #3995185] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][04:25:51]: [Server #3995185] Selecting client #134 for training.
[INFO][04:25:51]: [Server #3995185] Sending the current model to client #134 (simulated).
[INFO][04:25:57]: [Server #3995185] Sending 507.38 MB of payload data to client #134 (simulated).
[INFO][04:25:57]: [Client #134] Selected by the server.
[INFO][04:25:57]: [Client #134] Loading its data source...
[INFO][04:25:57]: [Client #134] Dataset size: 2018
[INFO][04:25:57]: [Client #134] Sampler: iid
[INFO][04:25:59]: [Client #134] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:25:59]: [Client #134] Start to process inbound data.
[INFO][04:25:59]: [93m[1m[Client #134] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:29,  1.57s/it]  2%|â–         | 2/96 [00:01<01:19,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.333915710449219,)
[INFO][04:26:38]: [Client #134] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_134_3995237.pth.
{'train_runtime': 32.4739, 'train_samples_per_second': 186.426, 'train_steps_per_second': 2.956, 'train_loss': 4.333915710449219, 'epoch': 3.0}
[INFO][04:26:39]: [Client #134] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_134_3995237.pth.
[INFO][04:26:39]: [Client #134] Model trained.
[INFO][04:26:39]: [Client #134] Inbound data has been processed.
[INFO][04:26:39]: [Client #134] Outbound data is ready to be sent after being processed.
[INFO][04:26:43]: [Client #134] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:26:44]: [Server #3995185] Received 507.38 MB of payload data from client #134 (simulated).
[INFO][04:26:44]: [Server #3995185] Selecting client #199 for training.
[INFO][04:26:44]: [Server #3995185] Sending the current model to client #199 (simulated).
[INFO][04:26:48]: [Server #3995185] Sending 507.38 MB of payload data to client #199 (simulated).
[INFO][04:26:48]: [Client #199] Selected by the server.
[INFO][04:26:48]: [Client #199] Loading its data source...
[INFO][04:26:48]: [Client #199] Dataset size: 2018
[INFO][04:26:48]: [Client #199] Sampler: iid
[INFO][04:26:49]: [Client #199] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:26:49]: [Client #199] Start to process inbound data.
[INFO][04:26:50]: [93m[1m[Client #199] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.327909151713054,)
[INFO][04:27:29]: [Client #199] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_199_3995237.pth.
{'train_runtime': 32.7102, 'train_samples_per_second': 185.08, 'train_steps_per_second': 2.935, 'train_loss': 4.327909151713054, 'epoch': 3.0}
[INFO][04:27:30]: [Client #199] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_199_3995237.pth.
[INFO][04:27:30]: [Client #199] Model trained.
[INFO][04:27:30]: [Client #199] Inbound data has been processed.
[INFO][04:27:30]: [Client #199] Outbound data is ready to be sent after being processed.
[INFO][04:27:35]: [Client #199] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:27:36]: [Server #3995185] Received 507.38 MB of payload data from client #199 (simulated).
[INFO][04:27:36]: [Server #3995185] Selecting client #193 for training.
[INFO][04:27:36]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][04:27:39]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][04:27:39]: [Client #193] Selected by the server.
[INFO][04:27:39]: [Client #193] Loading its data source...
[INFO][04:27:39]: [Client #193] Dataset size: 2018
[INFO][04:27:39]: [Client #193] Sampler: iid
[INFO][04:27:41]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:27:41]: [Client #193] Start to process inbound data.
[INFO][04:27:41]: [93m[1m[Client #193] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.82s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.86it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.39it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.97it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.97it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.97it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.97it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.96it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.96it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.96it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.96it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.97it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.96it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.95it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.95it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.94it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.94it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.94it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.94it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.94it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.94it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.303831736246745,)
[INFO][04:28:21]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 33.3642, 'train_samples_per_second': 181.452, 'train_steps_per_second': 2.877, 'train_loss': 4.303831736246745, 'epoch': 3.0}
[INFO][04:28:22]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][04:28:23]: [Client #193] Model trained.
[INFO][04:28:23]: [Client #193] Inbound data has been processed.
[INFO][04:28:23]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][04:28:26]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:28:27]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][04:28:27]: [Server #3995185] Selecting client #109 for training.
[INFO][04:28:27]: [Server #3995185] Sending the current model to client #109 (simulated).
[INFO][04:28:30]: [Server #3995185] Sending 507.38 MB of payload data to client #109 (simulated).
[INFO][04:28:30]: [Client #109] Selected by the server.
[INFO][04:28:30]: [Client #109] Loading its data source...
[INFO][04:28:30]: [Client #109] Dataset size: 2018
[INFO][04:28:30]: [Client #109] Sampler: iid
[INFO][04:28:32]: [Client #109] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:28:32]: [Client #109] Start to process inbound data.
[INFO][04:28:32]: [93m[1m[Client #109] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:02<03:18,  2.09s/it]  2%|â–         | 2/96 [00:02<01:39,  1.06s/it]  3%|â–Ž         | 3/96 [00:02<01:07,  1.37it/s]  4%|â–         | 4/96 [00:03<00:52,  1.75it/s]  5%|â–Œ         | 5/96 [00:03<00:44,  2.06it/s]  6%|â–‹         | 6/96 [00:03<00:39,  2.30it/s]  7%|â–‹         | 7/96 [00:04<00:35,  2.49it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.63it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.74it/s] 10%|â–ˆ         | 10/96 [00:05<00:30,  2.82it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.87it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:06<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.96it/s] 17%|â–ˆâ–‹        | 16/96 [00:07<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.97it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.97it/s] 20%|â–ˆâ–‰        | 19/96 [00:08<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:09<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:10<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:11<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:12<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  2.99it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:20<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:21<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:22<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.312971750895183,)
[INFO][04:29:12]: [Client #109] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_109_3995237.pth.
{'train_runtime': 33.3843, 'train_samples_per_second': 181.343, 'train_steps_per_second': 2.876, 'train_loss': 4.312971750895183, 'epoch': 3.0}
[INFO][04:29:13]: [Client #109] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_109_3995237.pth.
[INFO][04:29:14]: [Client #109] Model trained.
[INFO][04:29:14]: [Client #109] Inbound data has been processed.
[INFO][04:29:14]: [Client #109] Outbound data is ready to be sent after being processed.
[INFO][04:29:18]: [Client #109] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:29:19]: [Server #3995185] Received 507.38 MB of payload data from client #109 (simulated).
[INFO][04:29:19]: [Server #3995185] Selecting client #89 for training.
[INFO][04:29:19]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][04:29:26]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][04:29:26]: [Client #89] Selected by the server.
[INFO][04:29:26]: [Client #89] Loading its data source...
[INFO][04:29:26]: [Client #89] Dataset size: 2018
[INFO][04:29:26]: [Client #89] Sampler: iid
[INFO][04:29:27]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:29:27]: [Client #89] Start to process inbound data.
[INFO][04:29:27]: [93m[1m[Client #89] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:02<03:13,  2.04s/it]  2%|â–         | 2/96 [00:02<01:37,  1.03s/it]  3%|â–Ž         | 3/96 [00:02<01:06,  1.40it/s]  4%|â–         | 4/96 [00:03<00:51,  1.78it/s]  5%|â–Œ         | 5/96 [00:03<00:43,  2.08it/s]  6%|â–‹         | 6/96 [00:03<00:38,  2.33it/s]  7%|â–‹         | 7/96 [00:04<00:35,  2.51it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.65it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.76it/s] 10%|â–ˆ         | 10/96 [00:05<00:30,  2.83it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:06<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.96it/s] 17%|â–ˆâ–‹        | 16/96 [00:07<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:08<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.98it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:09<00:24,  2.98it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:10<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:11<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:12<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.18it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.97it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.32777722676595,)
[INFO][04:30:08]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 33.2784, 'train_samples_per_second': 181.92, 'train_steps_per_second': 2.885, 'train_loss': 4.32777722676595, 'epoch': 3.0}
[INFO][04:30:09]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][04:30:09]: [Client #89] Model trained.
[INFO][04:30:09]: [Client #89] Inbound data has been processed.
[INFO][04:30:09]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][04:30:17]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:30:18]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][04:30:18]: [Server #3995185] Selecting client #183 for training.
[INFO][04:30:18]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][04:30:23]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][04:30:23]: [Client #183] Selected by the server.
[INFO][04:30:23]: [Client #183] Loading its data source...
[INFO][04:30:23]: [Client #183] Dataset size: 2018
[INFO][04:30:23]: [Client #183] Sampler: iid
[INFO][04:30:25]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:30:25]: [Client #183] Start to process inbound data.
[INFO][04:30:25]: [93m[1m[Client #183] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.54s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.22it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.11it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.10it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.10it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.09it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.09it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.08it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.06it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.323381106058757,)
[INFO][04:31:03]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.0229, 'train_samples_per_second': 189.052, 'train_steps_per_second': 2.998, 'train_loss': 4.323381106058757, 'epoch': 3.0}
[INFO][04:31:04]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][04:31:04]: [Client #183] Model trained.
[INFO][04:31:04]: [Client #183] Inbound data has been processed.
[INFO][04:31:04]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][04:31:10]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:31:11]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][04:31:11]: [Server #3995185] Selecting client #83 for training.
[INFO][04:31:11]: [Server #3995185] Sending the current model to client #83 (simulated).
[INFO][04:31:15]: [Server #3995185] Sending 507.38 MB of payload data to client #83 (simulated).
[INFO][04:31:15]: [Client #83] Selected by the server.
[INFO][04:31:15]: [Client #83] Loading its data source...
[INFO][04:31:15]: [Client #83] Dataset size: 2018
[INFO][04:31:15]: [Client #83] Sampler: iid
[INFO][04:31:16]: [Client #83] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:31:16]: [Client #83] Start to process inbound data.
[INFO][04:31:16]: [93m[1m[Client #83] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:50,  1.79s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:48,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.328707695007324,)
[INFO][04:31:56]: [Client #83] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_83_3995237.pth.
{'train_runtime': 33.1971, 'train_samples_per_second': 182.365, 'train_steps_per_second': 2.892, 'train_loss': 4.328707695007324, 'epoch': 3.0}
[INFO][04:31:57]: [Client #83] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_83_3995237.pth.
[INFO][04:31:58]: [Client #83] Model trained.
[INFO][04:31:58]: [Client #83] Inbound data has been processed.
[INFO][04:31:58]: [Client #83] Outbound data is ready to be sent after being processed.
[INFO][04:32:04]: [Client #83] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:32:04]: [Server #3995185] Received 507.38 MB of payload data from client #83 (simulated).
[INFO][04:32:04]: [Server #3995185] Selecting client #125 for training.
[INFO][04:32:04]: [Server #3995185] Sending the current model to client #125 (simulated).
[INFO][04:32:08]: [Server #3995185] Sending 507.38 MB of payload data to client #125 (simulated).
[INFO][04:32:08]: [Client #125] Selected by the server.
[INFO][04:32:08]: [Client #125] Loading its data source...
[INFO][04:32:08]: [Client #125] Dataset size: 2018
[INFO][04:32:08]: [Client #125] Sampler: iid
[INFO][04:32:09]: [Client #125] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:32:09]: [Client #125] Start to process inbound data.
[INFO][04:32:09]: [93m[1m[Client #125] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:41,  1.70s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.77it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.84it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.317898750305176,)
[INFO][04:32:49]: [Client #125] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_125_3995237.pth.
{'train_runtime': 33.0082, 'train_samples_per_second': 183.409, 'train_steps_per_second': 2.908, 'train_loss': 4.317898750305176, 'epoch': 3.0}
[INFO][04:32:50]: [Client #125] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_125_3995237.pth.
[INFO][04:32:50]: [Client #125] Model trained.
[INFO][04:32:50]: [Client #125] Inbound data has been processed.
[INFO][04:32:50]: [Client #125] Outbound data is ready to be sent after being processed.
[INFO][04:32:55]: [Client #125] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:32:55]: [Server #3995185] Received 507.38 MB of payload data from client #125 (simulated).
[INFO][04:32:55]: [Server #3995185] Selecting client #71 for training.
[INFO][04:32:55]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][04:32:59]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][04:32:59]: [Client #71] Selected by the server.
[INFO][04:32:59]: [Client #71] Loading its data source...
[INFO][04:32:59]: [Client #71] Dataset size: 2018
[INFO][04:32:59]: [Client #71] Sampler: iid
[INFO][04:33:00]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:33:00]: [Client #71] Start to process inbound data.
[INFO][04:33:01]: [93m[1m[Client #71] Started training in communication round #2.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:41,  1.70s/it]  2%|â–         | 2/96 [00:02<01:24,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.311909357706706,)
[INFO][04:33:40]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.9535, 'train_samples_per_second': 183.713, 'train_steps_per_second': 2.913, 'train_loss': 4.311909357706706, 'epoch': 3.0}
[INFO][04:33:41]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][04:33:41]: [Client #71] Model trained.
[INFO][04:33:41]: [Client #71] Inbound data has been processed.
[INFO][04:33:41]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][04:33:46]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:33:46]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][04:33:46]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #2 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #125 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #15 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #56 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #75 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Adding client #98 to the list of clients for aggregation.
[INFO][04:33:46]: [Server #3995185] Aggregating 10 clients in total.
[INFO][04:33:46]: [Server #3995185] Updated weights have been received.
[INFO][04:33:47]: [Server #3995185] Aggregating model weight deltas.
[INFO][04:33:49]: [Server #3995185] Finished aggregating updated weights.
[INFO][04:33:49]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.23it/s]
[INFO][04:33:57]: [93m[1m[Server #3995185] Global model perplexity: 66.34
[0m
[INFO][04:33:57]: [Server #3995185] All client reports have been processed.
[INFO][04:33:57]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_2.pth.
[INFO][04:34:00]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_2.pth.
[INFO][04:34:00]: [93m[1m
[Server #3995185] Starting round 3/50.[0m
[INFO][04:34:00]: [Server #3995185] Selected clients: [183, 127, 29, 69, 3, 53, 200, 6, 79, 111]
[INFO][04:34:00]: [Server #3995185] Selecting client #183 for training.
[INFO][04:34:00]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][04:34:04]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][04:34:04]: [Client #183] Selected by the server.
[INFO][04:34:04]: [Client #183] Loading its data source...
[INFO][04:34:04]: [Client #183] Dataset size: 2018
[INFO][04:34:04]: [Client #183] Sampler: iid
[INFO][04:34:06]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:34:06]: [Client #183] Start to process inbound data.
[INFO][04:34:06]: [93m[1m[Client #183] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.61it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.76it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.87it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.95it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.99it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.04it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.06it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.11it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.11it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.074061393737793,)
[INFO][04:34:44]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.1313, 'train_samples_per_second': 188.414, 'train_steps_per_second': 2.988, 'train_loss': 4.074061393737793, 'epoch': 3.0}
[INFO][04:34:45]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][04:34:45]: [Client #183] Model trained.
[INFO][04:34:45]: [Client #183] Inbound data has been processed.
[INFO][04:34:45]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][04:34:49]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:34:50]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][04:34:50]: [Server #3995185] Selecting client #127 for training.
[INFO][04:34:50]: [Server #3995185] Sending the current model to client #127 (simulated).
[INFO][04:34:54]: [Server #3995185] Sending 507.38 MB of payload data to client #127 (simulated).
[INFO][04:34:54]: [Client #127] Selected by the server.
[INFO][04:34:54]: [Client #127] Loading its data source...
[INFO][04:34:54]: [Client #127] Dataset size: 2018
[INFO][04:34:54]: [Client #127] Sampler: iid
[INFO][04:34:56]: [Client #127] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:34:56]: [Client #127] Start to process inbound data.
[INFO][04:34:56]: [93m[1m[Client #127] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.99it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.11559263865153,)
[INFO][04:35:35]: [Client #127] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_127_3995237.pth.
{'train_runtime': 32.912, 'train_samples_per_second': 183.945, 'train_steps_per_second': 2.917, 'train_loss': 4.11559263865153, 'epoch': 3.0}
[INFO][04:35:36]: [Client #127] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_127_3995237.pth.
[INFO][04:35:36]: [Client #127] Model trained.
[INFO][04:35:36]: [Client #127] Inbound data has been processed.
[INFO][04:35:36]: [Client #127] Outbound data is ready to be sent after being processed.
[INFO][04:35:41]: [Client #127] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:35:41]: [Server #3995185] Received 507.38 MB of payload data from client #127 (simulated).
[INFO][04:35:41]: [Server #3995185] Selecting client #29 for training.
[INFO][04:35:41]: [Server #3995185] Sending the current model to client #29 (simulated).
[INFO][04:35:45]: [Server #3995185] Sending 507.38 MB of payload data to client #29 (simulated).
[INFO][04:35:45]: [Client #29] Selected by the server.
[INFO][04:35:45]: [Client #29] Loading its data source...
[INFO][04:35:45]: [Client #29] Dataset size: 2018
[INFO][04:35:45]: [Client #29] Sampler: iid
[INFO][04:35:47]: [Client #29] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:35:47]: [Client #29] Start to process inbound data.
[INFO][04:35:47]: [93m[1m[Client #29] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.97it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.97it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.96it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.96it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.098260879516602,)
[INFO][04:36:26]: [Client #29] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_29_3995237.pth.
{'train_runtime': 32.9732, 'train_samples_per_second': 183.604, 'train_steps_per_second': 2.911, 'train_loss': 4.098260879516602, 'epoch': 3.0}
[INFO][04:36:28]: [Client #29] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_29_3995237.pth.
[INFO][04:36:28]: [Client #29] Model trained.
[INFO][04:36:28]: [Client #29] Inbound data has been processed.
[INFO][04:36:28]: [Client #29] Outbound data is ready to be sent after being processed.
[INFO][04:36:32]: [Client #29] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:36:33]: [Server #3995185] Received 507.38 MB of payload data from client #29 (simulated).
[INFO][04:36:33]: [Server #3995185] Selecting client #69 for training.
[INFO][04:36:33]: [Server #3995185] Sending the current model to client #69 (simulated).
[INFO][04:36:37]: [Server #3995185] Sending 507.38 MB of payload data to client #69 (simulated).
[INFO][04:36:37]: [Client #69] Selected by the server.
[INFO][04:36:37]: [Client #69] Loading its data source...
[INFO][04:36:37]: [Client #69] Dataset size: 2018
[INFO][04:36:37]: [Client #69] Sampler: iid
[INFO][04:36:38]: [Client #69] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:36:38]: [Client #69] Start to process inbound data.
[INFO][04:36:38]: [93m[1m[Client #69] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.1370086669921875,)
[INFO][04:37:18]: [Client #69] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3995237.pth.
{'train_runtime': 33.0161, 'train_samples_per_second': 183.365, 'train_steps_per_second': 2.908, 'train_loss': 4.1370086669921875, 'epoch': 3.0}
[INFO][04:37:19]: [Client #69] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3995237.pth.
[INFO][04:37:20]: [Client #69] Model trained.
[INFO][04:37:20]: [Client #69] Inbound data has been processed.
[INFO][04:37:20]: [Client #69] Outbound data is ready to be sent after being processed.
[INFO][04:37:24]: [Client #69] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:37:25]: [Server #3995185] Received 507.38 MB of payload data from client #69 (simulated).
[INFO][04:37:25]: [Server #3995185] Selecting client #3 for training.
[INFO][04:37:25]: [Server #3995185] Sending the current model to client #3 (simulated).
[INFO][04:37:28]: [Server #3995185] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][04:37:28]: [Client #3] Selected by the server.
[INFO][04:37:28]: [Client #3] Loading its data source...
[INFO][04:37:28]: [Client #3] Dataset size: 2018
[INFO][04:37:28]: [Client #3] Sampler: iid
[INFO][04:37:30]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:37:30]: [Client #3] Start to process inbound data.
[INFO][04:37:30]: [93m[1m[Client #3] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.97it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.97it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.97it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.97it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.96it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.41it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.117237726847331,)
[INFO][04:38:10]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3995237.pth.
{'train_runtime': 33.0264, 'train_samples_per_second': 183.308, 'train_steps_per_second': 2.907, 'train_loss': 4.117237726847331, 'epoch': 3.0}
[INFO][04:38:10]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3995237.pth.
[INFO][04:38:11]: [Client #3] Model trained.
[INFO][04:38:11]: [Client #3] Inbound data has been processed.
[INFO][04:38:11]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][04:38:15]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:38:16]: [Server #3995185] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][04:38:16]: [Server #3995185] Selecting client #53 for training.
[INFO][04:38:16]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][04:38:20]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][04:38:20]: [Client #53] Selected by the server.
[INFO][04:38:20]: [Client #53] Loading its data source...
[INFO][04:38:20]: [Client #53] Dataset size: 2018
[INFO][04:38:20]: [Client #53] Sampler: iid
[INFO][04:38:21]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:38:21]: [Client #53] Start to process inbound data.
[INFO][04:38:21]: [93m[1m[Client #53] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.140310605367024,)
[INFO][04:38:59]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 32.1979, 'train_samples_per_second': 188.025, 'train_steps_per_second': 2.982, 'train_loss': 4.140310605367024, 'epoch': 3.0}
[INFO][04:39:00]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][04:39:01]: [Client #53] Model trained.
[INFO][04:39:01]: [Client #53] Inbound data has been processed.
[INFO][04:39:01]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][04:39:05]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:39:05]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][04:39:05]: [Server #3995185] Selecting client #200 for training.
[INFO][04:39:05]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][04:39:09]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][04:39:09]: [Client #200] Selected by the server.
[INFO][04:39:09]: [Client #200] Loading its data source...
[INFO][04:39:09]: [Client #200] Dataset size: 2018
[INFO][04:39:09]: [Client #200] Sampler: iid
[INFO][04:39:10]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:39:10]: [Client #200] Start to process inbound data.
[INFO][04:39:10]: [93m[1m[Client #200] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.72s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.153511683146159,)
[INFO][04:39:50]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 32.8966, 'train_samples_per_second': 184.031, 'train_steps_per_second': 2.918, 'train_loss': 4.153511683146159, 'epoch': 3.0}
[INFO][04:39:51]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][04:39:51]: [Client #200] Model trained.
[INFO][04:39:51]: [Client #200] Inbound data has been processed.
[INFO][04:39:51]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][04:39:56]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:39:57]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][04:39:57]: [Server #3995185] Selecting client #6 for training.
[INFO][04:39:57]: [Server #3995185] Sending the current model to client #6 (simulated).
[INFO][04:40:00]: [Server #3995185] Sending 507.38 MB of payload data to client #6 (simulated).
[INFO][04:40:00]: [Client #6] Selected by the server.
[INFO][04:40:00]: [Client #6] Loading its data source...
[INFO][04:40:00]: [Client #6] Dataset size: 2018
[INFO][04:40:00]: [Client #6] Sampler: iid
[INFO][04:40:02]: [Client #6] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:40:02]: [Client #6] Start to process inbound data.
[INFO][04:40:03]: [93m[1m[Client #6] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:42,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.61it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.149330457051595,)
[INFO][04:40:41]: [Client #6] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3995237.pth.
{'train_runtime': 32.1753, 'train_samples_per_second': 188.157, 'train_steps_per_second': 2.984, 'train_loss': 4.149330457051595, 'epoch': 3.0}
[INFO][04:40:42]: [Client #6] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_6_3995237.pth.
[INFO][04:40:43]: [Client #6] Model trained.
[INFO][04:40:43]: [Client #6] Inbound data has been processed.
[INFO][04:40:43]: [Client #6] Outbound data is ready to be sent after being processed.
[INFO][04:40:48]: [Client #6] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:40:49]: [Server #3995185] Received 507.38 MB of payload data from client #6 (simulated).
[INFO][04:40:49]: [Server #3995185] Selecting client #79 for training.
[INFO][04:40:49]: [Server #3995185] Sending the current model to client #79 (simulated).
[INFO][04:40:52]: [Server #3995185] Sending 507.38 MB of payload data to client #79 (simulated).
[INFO][04:40:52]: [Client #79] Selected by the server.
[INFO][04:40:52]: [Client #79] Loading its data source...
[INFO][04:40:53]: [Client #79] Dataset size: 2018
[INFO][04:40:53]: [Client #79] Sampler: iid
[INFO][04:40:54]: [Client #79] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:40:54]: [Client #79] Start to process inbound data.
[INFO][04:40:55]: [93m[1m[Client #79] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.72s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.53it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.121446291605632,)
[INFO][04:41:34]: [Client #79] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_79_3995237.pth.
{'train_runtime': 32.6435, 'train_samples_per_second': 185.458, 'train_steps_per_second': 2.941, 'train_loss': 4.121446291605632, 'epoch': 3.0}
[INFO][04:41:34]: [Client #79] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_79_3995237.pth.
[INFO][04:41:35]: [Client #79] Model trained.
[INFO][04:41:35]: [Client #79] Inbound data has been processed.
[INFO][04:41:35]: [Client #79] Outbound data is ready to be sent after being processed.
[INFO][04:41:39]: [Client #79] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:41:40]: [Server #3995185] Received 507.38 MB of payload data from client #79 (simulated).
[INFO][04:41:40]: [Server #3995185] Selecting client #111 for training.
[INFO][04:41:40]: [Server #3995185] Sending the current model to client #111 (simulated).
[INFO][04:41:45]: [Server #3995185] Sending 507.38 MB of payload data to client #111 (simulated).
[INFO][04:41:45]: [Client #111] Selected by the server.
[INFO][04:41:45]: [Client #111] Loading its data source...
[INFO][04:41:45]: [Client #111] Dataset size: 2018
[INFO][04:41:45]: [Client #111] Sampler: iid
[INFO][04:41:46]: [Client #111] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:41:46]: [Client #111] Start to process inbound data.
[INFO][04:41:47]: [93m[1m[Client #111] Started training in communication round #3.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:56,  1.86s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.48it/s]  4%|â–         | 4/96 [00:02<00:49,  1.85it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.14it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.39it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.56it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.68it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.84it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.93it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.134888966878255,)
[INFO][04:42:27]: [Client #111] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_111_3995237.pth.
{'train_runtime': 33.1079, 'train_samples_per_second': 182.857, 'train_steps_per_second': 2.9, 'train_loss': 4.134888966878255, 'epoch': 3.0}
[INFO][04:42:28]: [Client #111] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_111_3995237.pth.
[INFO][04:42:28]: [Client #111] Model trained.
[INFO][04:42:28]: [Client #111] Inbound data has been processed.
[INFO][04:42:28]: [Client #111] Outbound data is ready to be sent after being processed.
[INFO][04:42:33]: [Client #111] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:42:34]: [Server #3995185] Received 507.38 MB of payload data from client #111 (simulated).
[INFO][04:42:34]: [Server #3995185] Adding client #118 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #145 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #161 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #166 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #187 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #192 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #134 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #53 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][04:42:34]: [Server #3995185] Aggregating 10 clients in total.
[INFO][04:42:34]: [Server #3995185] Updated weights have been received.
[INFO][04:42:35]: [Server #3995185] Aggregating model weight deltas.
[INFO][04:42:36]: [Server #3995185] Finished aggregating updated weights.
[INFO][04:42:36]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:00<00:00, 49.48it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:00<00:00, 41.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 38.93it/s]
[INFO][04:42:46]: [93m[1m[Server #3995185] Global model perplexity: 70.38
[0m
[INFO][04:42:46]: [Server #3995185] All client reports have been processed.
[INFO][04:42:46]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_3.pth.
[INFO][04:42:49]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_3.pth.
[INFO][04:42:50]: [93m[1m
[Server #3995185] Starting round 4/50.[0m
[INFO][04:42:50]: [Server #3995185] Selected clients: [89, 198, 46, 13, 182, 45, 148, 153, 97, 102]
[INFO][04:42:50]: [Server #3995185] Selecting client #89 for training.
[INFO][04:42:50]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][04:42:54]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][04:42:54]: [Client #89] Selected by the server.
[INFO][04:42:54]: [Client #89] Loading its data source...
[INFO][04:42:54]: [Client #89] Dataset size: 2018
[INFO][04:42:54]: [Client #89] Sampler: iid
[INFO][04:42:56]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:42:56]: [Client #89] Start to process inbound data.
[INFO][04:42:56]: [93m[1m[Client #89] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.128890673319499,)
[INFO][04:43:36]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 33.1856, 'train_samples_per_second': 182.429, 'train_steps_per_second': 2.893, 'train_loss': 4.128890673319499, 'epoch': 3.0}
[INFO][04:43:37]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][04:43:37]: [Client #89] Model trained.
[INFO][04:43:37]: [Client #89] Inbound data has been processed.
[INFO][04:43:37]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][04:43:42]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:43:43]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][04:43:43]: [Server #3995185] Selecting client #198 for training.
[INFO][04:43:43]: [Server #3995185] Sending the current model to client #198 (simulated).
[INFO][04:43:51]: [Server #3995185] Sending 507.38 MB of payload data to client #198 (simulated).
[INFO][04:43:51]: [Client #198] Selected by the server.
[INFO][04:43:51]: [Client #198] Loading its data source...
[INFO][04:43:51]: [Client #198] Dataset size: 2018
[INFO][04:43:51]: [Client #198] Sampler: iid
[INFO][04:43:53]: [Client #198] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:43:53]: [Client #198] Start to process inbound data.
[INFO][04:43:53]: [93m[1m[Client #198] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.11it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.13165283203125,)
[INFO][04:44:31]: [Client #198] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_198_3995237.pth.
{'train_runtime': 32.0377, 'train_samples_per_second': 188.965, 'train_steps_per_second': 2.996, 'train_loss': 4.13165283203125, 'epoch': 3.0}
[INFO][04:44:32]: [Client #198] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_198_3995237.pth.
[INFO][04:44:33]: [Client #198] Model trained.
[INFO][04:44:33]: [Client #198] Inbound data has been processed.
[INFO][04:44:33]: [Client #198] Outbound data is ready to be sent after being processed.
[INFO][04:44:37]: [Client #198] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:44:38]: [Server #3995185] Received 507.38 MB of payload data from client #198 (simulated).
[INFO][04:44:38]: [Server #3995185] Selecting client #46 for training.
[INFO][04:44:38]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][04:44:44]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][04:44:44]: [Client #46] Selected by the server.
[INFO][04:44:44]: [Client #46] Loading its data source...
[INFO][04:44:44]: [Client #46] Dataset size: 2018
[INFO][04:44:44]: [Client #46] Sampler: iid
[INFO][04:44:45]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:44:45]: [Client #46] Start to process inbound data.
[INFO][04:44:45]: [93m[1m[Client #46] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.72s/it]  2%|â–         | 2/96 [00:02<01:25,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.151822090148926,)
[INFO][04:45:24]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.8261, 'train_samples_per_second': 184.427, 'train_steps_per_second': 2.925, 'train_loss': 4.151822090148926, 'epoch': 3.0}
[INFO][04:45:25]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][04:45:26]: [Client #46] Model trained.
[INFO][04:45:26]: [Client #46] Inbound data has been processed.
[INFO][04:45:26]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][04:45:34]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:45:35]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][04:45:35]: [Server #3995185] Selecting client #13 for training.
[INFO][04:45:35]: [Server #3995185] Sending the current model to client #13 (simulated).
[INFO][04:45:43]: [Server #3995185] Sending 507.38 MB of payload data to client #13 (simulated).
[INFO][04:45:43]: [Client #13] Selected by the server.
[INFO][04:45:43]: [Client #13] Loading its data source...
[INFO][04:45:43]: [Client #13] Dataset size: 2018
[INFO][04:45:43]: [Client #13] Sampler: iid
[INFO][04:45:44]: [Client #13] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:45:44]: [Client #13] Start to process inbound data.
[INFO][04:45:45]: [93m[1m[Client #13] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.133688926696777,)
[INFO][04:46:23]: [Client #13] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
{'train_runtime': 32.1289, 'train_samples_per_second': 188.429, 'train_steps_per_second': 2.988, 'train_loss': 4.133688926696777, 'epoch': 3.0}
[INFO][04:46:24]: [Client #13] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
[INFO][04:46:24]: [Client #13] Model trained.
[INFO][04:46:24]: [Client #13] Inbound data has been processed.
[INFO][04:46:24]: [Client #13] Outbound data is ready to be sent after being processed.
[INFO][04:46:31]: [Client #13] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:46:32]: [Server #3995185] Received 507.38 MB of payload data from client #13 (simulated).
[INFO][04:46:32]: [Server #3995185] Selecting client #182 for training.
[INFO][04:46:32]: [Server #3995185] Sending the current model to client #182 (simulated).
[INFO][04:46:36]: [Server #3995185] Sending 507.38 MB of payload data to client #182 (simulated).
[INFO][04:46:36]: [Client #182] Selected by the server.
[INFO][04:46:36]: [Client #182] Loading its data source...
[INFO][04:46:36]: [Client #182] Dataset size: 2018
[INFO][04:46:36]: [Client #182] Sampler: iid
[INFO][04:46:38]: [Client #182] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:46:38]: [Client #182] Start to process inbound data.
[INFO][04:46:38]: [93m[1m[Client #182] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.147591908772786,)
[INFO][04:47:16]: [Client #182] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_182_3995237.pth.
{'train_runtime': 32.1322, 'train_samples_per_second': 188.409, 'train_steps_per_second': 2.988, 'train_loss': 4.147591908772786, 'epoch': 3.0}
[INFO][04:47:16]: [Client #182] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_182_3995237.pth.
[INFO][04:47:17]: [Client #182] Model trained.
[INFO][04:47:17]: [Client #182] Inbound data has been processed.
[INFO][04:47:17]: [Client #182] Outbound data is ready to be sent after being processed.
[INFO][04:47:22]: [Client #182] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:47:23]: [Server #3995185] Received 507.38 MB of payload data from client #182 (simulated).
[INFO][04:47:23]: [Server #3995185] Selecting client #45 for training.
[INFO][04:47:23]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][04:47:27]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][04:47:27]: [Client #45] Selected by the server.
[INFO][04:47:27]: [Client #45] Loading its data source...
[INFO][04:47:27]: [Client #45] Dataset size: 2018
[INFO][04:47:27]: [Client #45] Sampler: iid
[INFO][04:47:28]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:47:28]: [Client #45] Start to process inbound data.
[INFO][04:47:28]: [93m[1m[Client #45] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.141097704569499,)
[INFO][04:48:08]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.8111, 'train_samples_per_second': 184.511, 'train_steps_per_second': 2.926, 'train_loss': 4.141097704569499, 'epoch': 3.0}
[INFO][04:48:09]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][04:48:09]: [Client #45] Model trained.
[INFO][04:48:09]: [Client #45] Inbound data has been processed.
[INFO][04:48:09]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][04:48:16]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:48:17]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][04:48:17]: [Server #3995185] Selecting client #148 for training.
[INFO][04:48:17]: [Server #3995185] Sending the current model to client #148 (simulated).
[INFO][04:48:22]: [Server #3995185] Sending 507.38 MB of payload data to client #148 (simulated).
[INFO][04:48:22]: [Client #148] Selected by the server.
[INFO][04:48:22]: [Client #148] Loading its data source...
[INFO][04:48:22]: [Client #148] Dataset size: 2018
[INFO][04:48:22]: [Client #148] Sampler: iid
[INFO][04:48:23]: [Client #148] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:48:23]: [Client #148] Start to process inbound data.
[INFO][04:48:24]: [93m[1m[Client #148] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.15393861134847,)
[INFO][04:49:02]: [Client #148] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_148_3995237.pth.
{'train_runtime': 32.5724, 'train_samples_per_second': 185.863, 'train_steps_per_second': 2.947, 'train_loss': 4.15393861134847, 'epoch': 3.0}
[INFO][04:49:03]: [Client #148] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_148_3995237.pth.
[INFO][04:49:04]: [Client #148] Model trained.
[INFO][04:49:04]: [Client #148] Inbound data has been processed.
[INFO][04:49:04]: [Client #148] Outbound data is ready to be sent after being processed.
[INFO][04:49:09]: [Client #148] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:49:10]: [Server #3995185] Received 507.38 MB of payload data from client #148 (simulated).
[INFO][04:49:10]: [Server #3995185] Selecting client #153 for training.
[INFO][04:49:10]: [Server #3995185] Sending the current model to client #153 (simulated).
[INFO][04:49:14]: [Server #3995185] Sending 507.38 MB of payload data to client #153 (simulated).
[INFO][04:49:14]: [Client #153] Selected by the server.
[INFO][04:49:14]: [Client #153] Loading its data source...
[INFO][04:49:14]: [Client #153] Dataset size: 2018
[INFO][04:49:14]: [Client #153] Sampler: iid
[INFO][04:49:15]: [Client #153] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:49:15]: [Client #153] Start to process inbound data.
[INFO][04:49:16]: [93m[1m[Client #153] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<03:02,  1.92s/it]  2%|â–         | 2/96 [00:02<01:33,  1.01it/s]  3%|â–Ž         | 3/96 [00:02<01:04,  1.44it/s]  4%|â–         | 4/96 [00:02<00:50,  1.81it/s]  5%|â–Œ         | 5/96 [00:03<00:43,  2.11it/s]  6%|â–‹         | 6/96 [00:03<00:38,  2.35it/s]  7%|â–‹         | 7/96 [00:03<00:35,  2.53it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.66it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.76it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.82it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.87it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.92it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.94it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.96it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.142332712809245,)
[INFO][04:49:56]: [Client #153] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_153_3995237.pth.
{'train_runtime': 33.183, 'train_samples_per_second': 182.443, 'train_steps_per_second': 2.893, 'train_loss': 4.142332712809245, 'epoch': 3.0}
[INFO][04:49:57]: [Client #153] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_153_3995237.pth.
[INFO][04:49:58]: [Client #153] Model trained.
[INFO][04:49:58]: [Client #153] Inbound data has been processed.
[INFO][04:49:58]: [Client #153] Outbound data is ready to be sent after being processed.
[INFO][04:50:02]: [Client #153] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:50:03]: [Server #3995185] Received 507.38 MB of payload data from client #153 (simulated).
[INFO][04:50:03]: [Server #3995185] Selecting client #97 for training.
[INFO][04:50:03]: [Server #3995185] Sending the current model to client #97 (simulated).
[INFO][04:50:07]: [Server #3995185] Sending 507.38 MB of payload data to client #97 (simulated).
[INFO][04:50:07]: [Client #97] Selected by the server.
[INFO][04:50:07]: [Client #97] Loading its data source...
[INFO][04:50:07]: [Client #97] Dataset size: 2018
[INFO][04:50:07]: [Client #97] Sampler: iid
[INFO][04:50:09]: [Client #97] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:50:09]: [Client #97] Start to process inbound data.
[INFO][04:50:09]: [93m[1m[Client #97] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.42it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.61it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.87it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.94it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.05it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.07it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.17it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.129200299580892,)
[INFO][04:50:47]: [Client #97] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_97_3995237.pth.
{'train_runtime': 32.0848, 'train_samples_per_second': 188.688, 'train_steps_per_second': 2.992, 'train_loss': 4.129200299580892, 'epoch': 3.0}
[INFO][04:50:48]: [Client #97] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_97_3995237.pth.
[INFO][04:50:49]: [Client #97] Model trained.
[INFO][04:50:49]: [Client #97] Inbound data has been processed.
[INFO][04:50:49]: [Client #97] Outbound data is ready to be sent after being processed.
[INFO][04:50:53]: [Client #97] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:50:55]: [Server #3995185] Received 507.38 MB of payload data from client #97 (simulated).
[INFO][04:50:55]: [Server #3995185] Selecting client #102 for training.
[INFO][04:50:55]: [Server #3995185] Sending the current model to client #102 (simulated).
[INFO][04:50:59]: [Server #3995185] Sending 507.38 MB of payload data to client #102 (simulated).
[INFO][04:50:59]: [Client #102] Selected by the server.
[INFO][04:50:59]: [Client #102] Loading its data source...
[INFO][04:50:59]: [Client #102] Dataset size: 2018
[INFO][04:50:59]: [Client #102] Sampler: iid
[INFO][04:51:00]: [Client #102] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:51:00]: [Client #102] Start to process inbound data.
[INFO][04:51:01]: [93m[1m[Client #102] Started training in communication round #4.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.54s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (4.154141743977864,)
[INFO][04:51:39]: [Client #102] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_102_3995237.pth.
{'train_runtime': 32.5825, 'train_samples_per_second': 185.805, 'train_steps_per_second': 2.946, 'train_loss': 4.154141743977864, 'epoch': 3.0}
[INFO][04:51:40]: [Client #102] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_102_3995237.pth.
[INFO][04:51:41]: [Client #102] Model trained.
[INFO][04:51:41]: [Client #102] Inbound data has been processed.
[INFO][04:51:41]: [Client #102] Outbound data is ready to be sent after being processed.
[INFO][04:51:47]: [Client #102] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:51:48]: [Server #3995185] Received 507.38 MB of payload data from client #102 (simulated).
[INFO][04:51:48]: [Server #3995185] Adding client #3 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #69 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #111 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #13 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #148 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #6 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Adding client #97 to the list of clients for aggregation.
[INFO][04:51:48]: [Server #3995185] Aggregating 10 clients in total.
[INFO][04:51:48]: [Server #3995185] Updated weights have been received.
[INFO][04:51:52]: [Server #3995185] Aggregating model weight deltas.
[INFO][04:51:52]: [Server #3995185] Finished aggregating updated weights.
[INFO][04:51:52]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:00<00:00, 49.88it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:00<00:00, 41.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.15it/s]
[INFO][04:52:01]: [93m[1m[Server #3995185] Global model perplexity: 47.52
[0m
[INFO][04:52:01]: [Server #3995185] All client reports have been processed.
[INFO][04:52:02]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_4.pth.
[INFO][04:52:05]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_4.pth.
[INFO][04:52:05]: [93m[1m
[Server #3995185] Starting round 5/50.[0m
[INFO][04:52:05]: [Server #3995185] Selected clients: [71, 35, 33, 82, 101, 39, 189, 8, 152, 147]
[INFO][04:52:05]: [Server #3995185] Selecting client #71 for training.
[INFO][04:52:05]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][04:52:09]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][04:52:09]: [Client #71] Selected by the server.
[INFO][04:52:09]: [Client #71] Loading its data source...
[INFO][04:52:09]: [Client #71] Dataset size: 2018
[INFO][04:52:09]: [Client #71] Sampler: iid
[INFO][04:52:10]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:52:10]: [Client #71] Start to process inbound data.
[INFO][04:52:10]: [93m[1m[Client #71] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.844766616821289,)
[INFO][04:52:49]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.3589, 'train_samples_per_second': 187.089, 'train_steps_per_second': 2.967, 'train_loss': 3.844766616821289, 'epoch': 3.0}
[INFO][04:52:50]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][04:52:50]: [Client #71] Model trained.
[INFO][04:52:50]: [Client #71] Inbound data has been processed.
[INFO][04:52:50]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][04:52:54]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:52:55]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][04:52:55]: [Server #3995185] Selecting client #35 for training.
[INFO][04:52:55]: [Server #3995185] Sending the current model to client #35 (simulated).
[INFO][04:53:00]: [Server #3995185] Sending 507.38 MB of payload data to client #35 (simulated).
[INFO][04:53:00]: [Client #35] Selected by the server.
[INFO][04:53:00]: [Client #35] Loading its data source...
[INFO][04:53:00]: [Client #35] Dataset size: 2018
[INFO][04:53:00]: [Client #35] Sampler: iid
[INFO][04:53:02]: [Client #35] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:53:02]: [Client #35] Start to process inbound data.
[INFO][04:53:03]: [93m[1m[Client #35] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8571227391560874,)
[INFO][04:53:41]: [Client #35] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_35_3995237.pth.
{'train_runtime': 32.5834, 'train_samples_per_second': 185.8, 'train_steps_per_second': 2.946, 'train_loss': 3.8571227391560874, 'epoch': 3.0}
[INFO][04:53:42]: [Client #35] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_35_3995237.pth.
[INFO][04:53:43]: [Client #35] Model trained.
[INFO][04:53:43]: [Client #35] Inbound data has been processed.
[INFO][04:53:43]: [Client #35] Outbound data is ready to be sent after being processed.
[INFO][04:53:48]: [Client #35] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:53:49]: [Server #3995185] Received 507.38 MB of payload data from client #35 (simulated).
[INFO][04:53:49]: [Server #3995185] Selecting client #33 for training.
[INFO][04:53:49]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][04:53:53]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][04:53:53]: [Client #33] Selected by the server.
[INFO][04:53:53]: [Client #33] Loading its data source...
[INFO][04:53:53]: [Client #33] Dataset size: 2018
[INFO][04:53:53]: [Client #33] Sampler: iid
[INFO][04:53:55]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:53:55]: [Client #33] Start to process inbound data.
[INFO][04:53:55]: [93m[1m[Client #33] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:48,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.97it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.96it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.96it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.96it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.95it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.95it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.95it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.95it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.95it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.40it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.24it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8734315236409507,)
[INFO][04:54:35]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 33.142, 'train_samples_per_second': 182.668, 'train_steps_per_second': 2.897, 'train_loss': 3.8734315236409507, 'epoch': 3.0}
[INFO][04:54:36]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][04:54:37]: [Client #33] Model trained.
[INFO][04:54:37]: [Client #33] Inbound data has been processed.
[INFO][04:54:37]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][04:54:42]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:54:43]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][04:54:43]: [Server #3995185] Selecting client #82 for training.
[INFO][04:54:43]: [Server #3995185] Sending the current model to client #82 (simulated).
[INFO][04:54:47]: [Server #3995185] Sending 507.38 MB of payload data to client #82 (simulated).
[INFO][04:54:47]: [Client #82] Selected by the server.
[INFO][04:54:47]: [Client #82] Loading its data source...
[INFO][04:54:47]: [Client #82] Dataset size: 2018
[INFO][04:54:47]: [Client #82] Sampler: iid
[INFO][04:54:48]: [Client #82] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:54:48]: [Client #82] Start to process inbound data.
[INFO][04:54:49]: [93m[1m[Client #82] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:33,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.99it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.878955523173014,)
[INFO][04:55:28]: [Client #82] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_82_3995237.pth.
{'train_runtime': 32.7308, 'train_samples_per_second': 184.963, 'train_steps_per_second': 2.933, 'train_loss': 3.878955523173014, 'epoch': 3.0}
[INFO][04:55:29]: [Client #82] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_82_3995237.pth.
[INFO][04:55:29]: [Client #82] Model trained.
[INFO][04:55:29]: [Client #82] Inbound data has been processed.
[INFO][04:55:29]: [Client #82] Outbound data is ready to be sent after being processed.
[INFO][04:55:33]: [Client #82] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:55:34]: [Server #3995185] Received 507.38 MB of payload data from client #82 (simulated).
[INFO][04:55:34]: [Server #3995185] Selecting client #101 for training.
[INFO][04:55:34]: [Server #3995185] Sending the current model to client #101 (simulated).
[INFO][04:55:39]: [Server #3995185] Sending 507.38 MB of payload data to client #101 (simulated).
[INFO][04:55:39]: [Client #101] Selected by the server.
[INFO][04:55:39]: [Client #101] Loading its data source...
[INFO][04:55:39]: [Client #101] Dataset size: 2018
[INFO][04:55:39]: [Client #101] Sampler: iid
[INFO][04:55:40]: [Client #101] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:55:40]: [Client #101] Start to process inbound data.
[INFO][04:55:40]: [93m[1m[Client #101] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8659890492757163,)
[INFO][04:56:19]: [Client #101] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_101_3995237.pth.
{'train_runtime': 32.7691, 'train_samples_per_second': 184.747, 'train_steps_per_second': 2.93, 'train_loss': 3.8659890492757163, 'epoch': 3.0}
[INFO][04:56:20]: [Client #101] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_101_3995237.pth.
[INFO][04:56:20]: [Client #101] Model trained.
[INFO][04:56:20]: [Client #101] Inbound data has been processed.
[INFO][04:56:20]: [Client #101] Outbound data is ready to be sent after being processed.
[INFO][04:56:25]: [Client #101] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:56:26]: [Server #3995185] Received 507.38 MB of payload data from client #101 (simulated).
[INFO][04:56:26]: [Server #3995185] Selecting client #39 for training.
[INFO][04:56:26]: [Server #3995185] Sending the current model to client #39 (simulated).
[INFO][04:56:30]: [Server #3995185] Sending 507.38 MB of payload data to client #39 (simulated).
[INFO][04:56:30]: [Client #39] Selected by the server.
[INFO][04:56:30]: [Client #39] Loading its data source...
[INFO][04:56:30]: [Client #39] Dataset size: 2018
[INFO][04:56:30]: [Client #39] Sampler: iid
[INFO][04:56:32]: [Client #39] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:56:32]: [Client #39] Start to process inbound data.
[INFO][04:56:32]: [93m[1m[Client #39] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.82s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.50it/s]  4%|â–         | 4/96 [00:02<00:48,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8967857360839844,)
[INFO][04:57:11]: [Client #39] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_39_3995237.pth.
{'train_runtime': 32.9345, 'train_samples_per_second': 183.82, 'train_steps_per_second': 2.915, 'train_loss': 3.8967857360839844, 'epoch': 3.0}
[INFO][04:57:12]: [Client #39] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_39_3995237.pth.
[INFO][04:57:13]: [Client #39] Model trained.
[INFO][04:57:13]: [Client #39] Inbound data has been processed.
[INFO][04:57:13]: [Client #39] Outbound data is ready to be sent after being processed.
[INFO][04:57:17]: [Client #39] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:57:18]: [Server #3995185] Received 507.38 MB of payload data from client #39 (simulated).
[INFO][04:57:18]: [Server #3995185] Selecting client #189 for training.
[INFO][04:57:18]: [Server #3995185] Sending the current model to client #189 (simulated).
[INFO][04:57:23]: [Server #3995185] Sending 507.38 MB of payload data to client #189 (simulated).
[INFO][04:57:23]: [Client #189] Selected by the server.
[INFO][04:57:23]: [Client #189] Loading its data source...
[INFO][04:57:23]: [Client #189] Dataset size: 2018
[INFO][04:57:23]: [Client #189] Sampler: iid
[INFO][04:57:25]: [Client #189] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:57:25]: [Client #189] Start to process inbound data.
[INFO][04:57:25]: [93m[1m[Client #189] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:40,  1.69s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.98it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.98it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.97it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.97it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.97it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.97it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.97it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.42it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:19,  3.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.99it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.98it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.94it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.94it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.93it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8839747111002603,)
[INFO][04:58:05]: [Client #189] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_189_3995237.pth.
{'train_runtime': 33.1938, 'train_samples_per_second': 182.383, 'train_steps_per_second': 2.892, 'train_loss': 3.8839747111002603, 'epoch': 3.0}
[INFO][04:58:05]: [Client #189] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_189_3995237.pth.
[INFO][04:58:06]: [Client #189] Model trained.
[INFO][04:58:06]: [Client #189] Inbound data has been processed.
[INFO][04:58:06]: [Client #189] Outbound data is ready to be sent after being processed.
[INFO][04:58:10]: [Client #189] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:58:12]: [Server #3995185] Received 507.38 MB of payload data from client #189 (simulated).
[INFO][04:58:12]: [Server #3995185] Selecting client #8 for training.
[INFO][04:58:12]: [Server #3995185] Sending the current model to client #8 (simulated).
[INFO][04:58:18]: [Server #3995185] Sending 507.38 MB of payload data to client #8 (simulated).
[INFO][04:58:18]: [Client #8] Selected by the server.
[INFO][04:58:18]: [Client #8] Loading its data source...
[INFO][04:58:18]: [Client #8] Dataset size: 2018
[INFO][04:58:18]: [Client #8] Sampler: iid
[INFO][04:58:19]: [Client #8] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:58:19]: [Client #8] Start to process inbound data.
[INFO][04:58:20]: [93m[1m[Client #8] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:02<03:14,  2.05s/it]  2%|â–         | 2/96 [00:02<01:37,  1.04s/it]  3%|â–Ž         | 3/96 [00:02<01:06,  1.40it/s]  4%|â–         | 4/96 [00:03<00:51,  1.78it/s]  5%|â–Œ         | 5/96 [00:03<00:43,  2.08it/s]  6%|â–‹         | 6/96 [00:03<00:38,  2.32it/s]  7%|â–‹         | 7/96 [00:04<00:35,  2.51it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.64it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.74it/s] 10%|â–ˆ         | 10/96 [00:05<00:30,  2.82it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:06<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.96it/s] 17%|â–ˆâ–‹        | 16/96 [00:07<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:08<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:09<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:10<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:11<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:12<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.87it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8953444163004556,)
[INFO][04:59:00]: [Client #8] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3995237.pth.
{'train_runtime': 33.4511, 'train_samples_per_second': 180.981, 'train_steps_per_second': 2.87, 'train_loss': 3.8953444163004556, 'epoch': 3.0}
[INFO][04:59:00]: [Client #8] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_8_3995237.pth.
[INFO][04:59:01]: [Client #8] Model trained.
[INFO][04:59:01]: [Client #8] Inbound data has been processed.
[INFO][04:59:01]: [Client #8] Outbound data is ready to be sent after being processed.
[INFO][04:59:06]: [Client #8] Sent 507.38 MB of payload data to the server (simulated).
[INFO][04:59:08]: [Server #3995185] Received 507.38 MB of payload data from client #8 (simulated).
[INFO][04:59:08]: [Server #3995185] Selecting client #152 for training.
[INFO][04:59:08]: [Server #3995185] Sending the current model to client #152 (simulated).
[INFO][04:59:12]: [Server #3995185] Sending 507.38 MB of payload data to client #152 (simulated).
[INFO][04:59:12]: [Client #152] Selected by the server.
[INFO][04:59:12]: [Client #152] Loading its data source...
[INFO][04:59:12]: [Client #152] Dataset size: 2018
[INFO][04:59:12]: [Client #152] Sampler: iid
[INFO][04:59:14]: [Client #152] Received 507.38 MB of payload data from the server (simulated).
[INFO][04:59:14]: [Client #152] Start to process inbound data.
[INFO][04:59:14]: [93m[1m[Client #152] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.97it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.97it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.18it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.02it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.00it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8861262003580728,)
[INFO][04:59:54]: [Client #152] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_152_3995237.pth.
{'train_runtime': 32.8713, 'train_samples_per_second': 184.173, 'train_steps_per_second': 2.92, 'train_loss': 3.8861262003580728, 'epoch': 3.0}
[INFO][04:59:55]: [Client #152] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_152_3995237.pth.
[INFO][04:59:56]: [Client #152] Model trained.
[INFO][04:59:56]: [Client #152] Inbound data has been processed.
[INFO][04:59:56]: [Client #152] Outbound data is ready to be sent after being processed.
[INFO][05:00:01]: [Client #152] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:00:02]: [Server #3995185] Received 507.38 MB of payload data from client #152 (simulated).
[INFO][05:00:02]: [Server #3995185] Selecting client #147 for training.
[INFO][05:00:02]: [Server #3995185] Sending the current model to client #147 (simulated).
[INFO][05:00:06]: [Server #3995185] Sending 507.38 MB of payload data to client #147 (simulated).
[INFO][05:00:06]: [Client #147] Selected by the server.
[INFO][05:00:06]: [Client #147] Loading its data source...
[INFO][05:00:06]: [Client #147] Dataset size: 2018
[INFO][05:00:06]: [Client #147] Sampler: iid
[INFO][05:00:07]: [Client #147] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:00:07]: [Client #147] Start to process inbound data.
[INFO][05:00:07]: [93m[1m[Client #147] Started training in communication round #5.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:55,  1.85s/it]  2%|â–         | 2/96 [00:02<01:29,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.86it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8940114974975586,)
[INFO][05:00:46]: [Client #147] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_147_3995237.pth.
{'train_runtime': 32.9449, 'train_samples_per_second': 183.761, 'train_steps_per_second': 2.914, 'train_loss': 3.8940114974975586, 'epoch': 3.0}
[INFO][05:00:47]: [Client #147] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_147_3995237.pth.
[INFO][05:00:48]: [Client #147] Model trained.
[INFO][05:00:48]: [Client #147] Inbound data has been processed.
[INFO][05:00:48]: [Client #147] Outbound data is ready to be sent after being processed.
[INFO][05:00:53]: [Client #147] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:00:54]: [Server #3995185] Received 507.38 MB of payload data from client #147 (simulated).
[INFO][05:00:54]: [Server #3995185] Adding client #198 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #8 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #101 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #153 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #35 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #83 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #109 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Adding client #199 to the list of clients for aggregation.
[INFO][05:00:54]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:00:54]: [Server #3995185] Updated weights have been received.
[INFO][05:00:56]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:00:57]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:00:57]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.99it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.69it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.36it/s]
[INFO][05:01:05]: [93m[1m[Server #3995185] Global model perplexity: 44.93
[0m
[INFO][05:01:05]: [Server #3995185] All client reports have been processed.
[INFO][05:01:05]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_5.pth.
[INFO][05:01:08]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_5.pth.
[INFO][05:01:08]: [93m[1m
[Server #3995185] Starting round 6/50.[0m
[INFO][05:01:08]: [Server #3995185] Selected clients: [183, 144, 72, 95, 104, 57, 40, 167, 7, 32]
[INFO][05:01:08]: [Server #3995185] Selecting client #183 for training.
[INFO][05:01:08]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][05:01:13]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][05:01:13]: [Client #183] Selected by the server.
[INFO][05:01:13]: [Client #183] Loading its data source...
[INFO][05:01:13]: [Client #183] Dataset size: 2018
[INFO][05:01:13]: [Client #183] Sampler: iid
[INFO][05:01:14]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:01:14]: [Client #183] Start to process inbound data.
[INFO][05:01:14]: [93m[1m[Client #183] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.71s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.11it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.11it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.09it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.54it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.06it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7787148157755532,)
[INFO][05:01:52]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.2684, 'train_samples_per_second': 187.614, 'train_steps_per_second': 2.975, 'train_loss': 3.7787148157755532, 'epoch': 3.0}
[INFO][05:01:53]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][05:01:53]: [Client #183] Model trained.
[INFO][05:01:53]: [Client #183] Inbound data has been processed.
[INFO][05:01:53]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][05:01:58]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:02:00]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][05:02:00]: [Server #3995185] Selecting client #144 for training.
[INFO][05:02:00]: [Server #3995185] Sending the current model to client #144 (simulated).
[INFO][05:02:03]: [Server #3995185] Sending 507.38 MB of payload data to client #144 (simulated).
[INFO][05:02:03]: [Client #144] Selected by the server.
[INFO][05:02:03]: [Client #144] Loading its data source...
[INFO][05:02:03]: [Client #144] Dataset size: 2018
[INFO][05:02:03]: [Client #144] Sampler: iid
[INFO][05:02:05]: [Client #144] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:02:05]: [Client #144] Start to process inbound data.
[INFO][05:02:05]: [93m[1m[Client #144] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8461087544759116,)
[INFO][05:02:44]: [Client #144] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
{'train_runtime': 32.6892, 'train_samples_per_second': 185.199, 'train_steps_per_second': 2.937, 'train_loss': 3.8461087544759116, 'epoch': 3.0}
[INFO][05:02:45]: [Client #144] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
[INFO][05:02:46]: [Client #144] Model trained.
[INFO][05:02:46]: [Client #144] Inbound data has been processed.
[INFO][05:02:46]: [Client #144] Outbound data is ready to be sent after being processed.
[INFO][05:02:50]: [Client #144] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:02:51]: [Server #3995185] Received 507.38 MB of payload data from client #144 (simulated).
[INFO][05:02:51]: [Server #3995185] Selecting client #72 for training.
[INFO][05:02:51]: [Server #3995185] Sending the current model to client #72 (simulated).
[INFO][05:02:55]: [Server #3995185] Sending 507.38 MB of payload data to client #72 (simulated).
[INFO][05:02:55]: [Client #72] Selected by the server.
[INFO][05:02:55]: [Client #72] Loading its data source...
[INFO][05:02:55]: [Client #72] Dataset size: 2018
[INFO][05:02:55]: [Client #72] Sampler: iid
[INFO][05:02:57]: [Client #72] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:02:57]: [Client #72] Start to process inbound data.
[INFO][05:02:57]: [93m[1m[Client #72] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.60s/it]  2%|â–         | 2/96 [00:01<01:20,  1.16it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8566741943359375,)
[INFO][05:03:36]: [Client #72] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_72_3995237.pth.
{'train_runtime': 32.6279, 'train_samples_per_second': 185.547, 'train_steps_per_second': 2.942, 'train_loss': 3.8566741943359375, 'epoch': 3.0}
[INFO][05:03:37]: [Client #72] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_72_3995237.pth.
[INFO][05:03:37]: [Client #72] Model trained.
[INFO][05:03:37]: [Client #72] Inbound data has been processed.
[INFO][05:03:37]: [Client #72] Outbound data is ready to be sent after being processed.
[INFO][05:03:42]: [Client #72] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:03:43]: [Server #3995185] Received 507.38 MB of payload data from client #72 (simulated).
[INFO][05:03:43]: [Server #3995185] Selecting client #95 for training.
[INFO][05:03:43]: [Server #3995185] Sending the current model to client #95 (simulated).
[INFO][05:03:47]: [Server #3995185] Sending 507.38 MB of payload data to client #95 (simulated).
[INFO][05:03:47]: [Client #95] Selected by the server.
[INFO][05:03:47]: [Client #95] Loading its data source...
[INFO][05:03:47]: [Client #95] Dataset size: 2018
[INFO][05:03:47]: [Client #95] Sampler: iid
[INFO][05:03:49]: [Client #95] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:03:49]: [Client #95] Start to process inbound data.
[INFO][05:03:49]: [93m[1m[Client #95] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:28,  1.57s/it]  2%|â–         | 2/96 [00:01<01:18,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.09it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.07it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.07it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.815452257792155,)
[INFO][05:04:27]: [Client #95] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_95_3995237.pth.
{'train_runtime': 32.2895, 'train_samples_per_second': 187.491, 'train_steps_per_second': 2.973, 'train_loss': 3.815452257792155, 'epoch': 3.0}
[INFO][05:04:28]: [Client #95] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_95_3995237.pth.
[INFO][05:04:28]: [Client #95] Model trained.
[INFO][05:04:28]: [Client #95] Inbound data has been processed.
[INFO][05:04:28]: [Client #95] Outbound data is ready to be sent after being processed.
[INFO][05:04:33]: [Client #95] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:04:34]: [Server #3995185] Received 507.38 MB of payload data from client #95 (simulated).
[INFO][05:04:34]: [Server #3995185] Selecting client #104 for training.
[INFO][05:04:34]: [Server #3995185] Sending the current model to client #104 (simulated).
[INFO][05:04:38]: [Server #3995185] Sending 507.38 MB of payload data to client #104 (simulated).
[INFO][05:04:38]: [Client #104] Selected by the server.
[INFO][05:04:38]: [Client #104] Loading its data source...
[INFO][05:04:38]: [Client #104] Dataset size: 2018
[INFO][05:04:38]: [Client #104] Sampler: iid
[INFO][05:04:39]: [Client #104] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:04:39]: [Client #104] Start to process inbound data.
[INFO][05:04:40]: [93m[1m[Client #104] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.93it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.844395637512207,)
[INFO][05:05:19]: [Client #104] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_104_3995237.pth.
{'train_runtime': 32.7335, 'train_samples_per_second': 184.948, 'train_steps_per_second': 2.933, 'train_loss': 3.844395637512207, 'epoch': 3.0}
[INFO][05:05:20]: [Client #104] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_104_3995237.pth.
[INFO][05:05:21]: [Client #104] Model trained.
[INFO][05:05:21]: [Client #104] Inbound data has been processed.
[INFO][05:05:21]: [Client #104] Outbound data is ready to be sent after being processed.
[INFO][05:05:25]: [Client #104] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:05:26]: [Server #3995185] Received 507.38 MB of payload data from client #104 (simulated).
[INFO][05:05:26]: [Server #3995185] Selecting client #57 for training.
[INFO][05:05:26]: [Server #3995185] Sending the current model to client #57 (simulated).
[INFO][05:05:31]: [Server #3995185] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][05:05:31]: [Client #57] Selected by the server.
[INFO][05:05:31]: [Client #57] Loading its data source...
[INFO][05:05:31]: [Client #57] Dataset size: 2018
[INFO][05:05:31]: [Client #57] Sampler: iid
[INFO][05:05:32]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:05:32]: [Client #57] Start to process inbound data.
[INFO][05:05:33]: [93m[1m[Client #57] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.59s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8255958557128906,)
[INFO][05:06:11]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
{'train_runtime': 32.3865, 'train_samples_per_second': 186.93, 'train_steps_per_second': 2.964, 'train_loss': 3.8255958557128906, 'epoch': 3.0}
[INFO][05:06:12]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
[INFO][05:06:13]: [Client #57] Model trained.
[INFO][05:06:13]: [Client #57] Inbound data has been processed.
[INFO][05:06:13]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][05:06:17]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:06:18]: [Server #3995185] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][05:06:18]: [Server #3995185] Selecting client #40 for training.
[INFO][05:06:18]: [Server #3995185] Sending the current model to client #40 (simulated).
[INFO][05:06:22]: [Server #3995185] Sending 507.38 MB of payload data to client #40 (simulated).
[INFO][05:06:22]: [Client #40] Selected by the server.
[INFO][05:06:22]: [Client #40] Loading its data source...
[INFO][05:06:22]: [Client #40] Dataset size: 2018
[INFO][05:06:22]: [Client #40] Sampler: iid
[INFO][05:06:24]: [Client #40] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:06:24]: [Client #40] Start to process inbound data.
[INFO][05:06:24]: [93m[1m[Client #40] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.87254269917806,)
[INFO][05:07:03]: [Client #40] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_40_3995237.pth.
{'train_runtime': 32.5503, 'train_samples_per_second': 185.989, 'train_steps_per_second': 2.949, 'train_loss': 3.87254269917806, 'epoch': 3.0}
[INFO][05:07:04]: [Client #40] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_40_3995237.pth.
[INFO][05:07:04]: [Client #40] Model trained.
[INFO][05:07:04]: [Client #40] Inbound data has been processed.
[INFO][05:07:04]: [Client #40] Outbound data is ready to be sent after being processed.
[INFO][05:07:08]: [Client #40] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:07:09]: [Server #3995185] Received 507.38 MB of payload data from client #40 (simulated).
[INFO][05:07:09]: [Server #3995185] Selecting client #167 for training.
[INFO][05:07:09]: [Server #3995185] Sending the current model to client #167 (simulated).
[INFO][05:07:13]: [Server #3995185] Sending 507.38 MB of payload data to client #167 (simulated).
[INFO][05:07:13]: [Client #167] Selected by the server.
[INFO][05:07:13]: [Client #167] Loading its data source...
[INFO][05:07:13]: [Client #167] Dataset size: 2018
[INFO][05:07:13]: [Client #167] Sampler: iid
[INFO][05:07:14]: [Client #167] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:07:14]: [Client #167] Start to process inbound data.
[INFO][05:07:14]: [93m[1m[Client #167] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.71s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.855227470397949,)
[INFO][05:07:53]: [Client #167] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_167_3995237.pth.
{'train_runtime': 32.5648, 'train_samples_per_second': 185.906, 'train_steps_per_second': 2.948, 'train_loss': 3.855227470397949, 'epoch': 3.0}
[INFO][05:07:54]: [Client #167] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_167_3995237.pth.
[INFO][05:07:54]: [Client #167] Model trained.
[INFO][05:07:54]: [Client #167] Inbound data has been processed.
[INFO][05:07:54]: [Client #167] Outbound data is ready to be sent after being processed.
[INFO][05:07:58]: [Client #167] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:07:59]: [Server #3995185] Received 507.38 MB of payload data from client #167 (simulated).
[INFO][05:07:59]: [Server #3995185] Selecting client #7 for training.
[INFO][05:07:59]: [Server #3995185] Sending the current model to client #7 (simulated).
[INFO][05:08:03]: [Server #3995185] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][05:08:03]: [Client #7] Selected by the server.
[INFO][05:08:03]: [Client #7] Loading its data source...
[INFO][05:08:03]: [Client #7] Dataset size: 2018
[INFO][05:08:03]: [Client #7] Sampler: iid
[INFO][05:08:05]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:08:05]: [Client #7] Start to process inbound data.
[INFO][05:08:05]: [93m[1m[Client #7] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:30,  1.58s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8128528594970703,)
[INFO][05:08:44]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3995237.pth.
{'train_runtime': 32.5904, 'train_samples_per_second': 185.76, 'train_steps_per_second': 2.946, 'train_loss': 3.8128528594970703, 'epoch': 3.0}
[INFO][05:08:45]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3995237.pth.
[INFO][05:08:45]: [Client #7] Model trained.
[INFO][05:08:45]: [Client #7] Inbound data has been processed.
[INFO][05:08:45]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][05:08:51]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:08:52]: [Server #3995185] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][05:08:52]: [Server #3995185] Selecting client #32 for training.
[INFO][05:08:52]: [Server #3995185] Sending the current model to client #32 (simulated).
[INFO][05:08:56]: [Server #3995185] Sending 507.38 MB of payload data to client #32 (simulated).
[INFO][05:08:56]: [Client #32] Selected by the server.
[INFO][05:08:56]: [Client #32] Loading its data source...
[INFO][05:08:56]: [Client #32] Dataset size: 2018
[INFO][05:08:56]: [Client #32] Sampler: iid
[INFO][05:08:57]: [Client #32] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:08:57]: [Client #32] Start to process inbound data.
[INFO][05:08:58]: [93m[1m[Client #32] Started training in communication round #6.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.8579416275024414,)
[INFO][05:09:37]: [Client #32] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_32_3995237.pth.
{'train_runtime': 32.5938, 'train_samples_per_second': 185.741, 'train_steps_per_second': 2.945, 'train_loss': 3.8579416275024414, 'epoch': 3.0}
[INFO][05:09:38]: [Client #32] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_32_3995237.pth.
[INFO][05:09:39]: [Client #32] Model trained.
[INFO][05:09:39]: [Client #32] Inbound data has been processed.
[INFO][05:09:39]: [Client #32] Outbound data is ready to be sent after being processed.
[INFO][05:09:43]: [Client #32] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:09:44]: [Server #3995185] Received 507.38 MB of payload data from client #32 (simulated).
[INFO][05:09:44]: [Server #3995185] Adding client #152 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #189 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #82 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #57 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #144 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #7 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #104 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #29 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Adding client #79 to the list of clients for aggregation.
[INFO][05:09:44]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:09:44]: [Server #3995185] Updated weights have been received.
[INFO][05:09:45]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:09:46]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:09:46]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:00<00:00, 49.44it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:00<00:00, 41.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 38.84it/s]
[INFO][05:09:54]: [93m[1m[Server #3995185] Global model perplexity: 39.92
[0m
[INFO][05:09:54]: [Server #3995185] All client reports have been processed.
[INFO][05:09:55]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_6.pth.
[INFO][05:09:58]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_6.pth.
[INFO][05:09:58]: [93m[1m
[Server #3995185] Starting round 7/50.[0m
[INFO][05:09:58]: [Server #3995185] Selected clients: [53, 17, 116, 122, 25, 175, 119, 131, 110, 150]
[INFO][05:09:58]: [Server #3995185] Selecting client #53 for training.
[INFO][05:09:58]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][05:10:02]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][05:10:02]: [Client #53] Selected by the server.
[INFO][05:10:02]: [Client #53] Loading its data source...
[INFO][05:10:02]: [Client #53] Dataset size: 2018
[INFO][05:10:02]: [Client #53] Sampler: iid
[INFO][05:10:03]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:10:03]: [Client #53] Start to process inbound data.
[INFO][05:10:03]: [93m[1m[Client #53] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.60s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.717278798421224,)
[INFO][05:10:42]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 32.4275, 'train_samples_per_second': 186.693, 'train_steps_per_second': 2.96, 'train_loss': 3.717278798421224, 'epoch': 3.0}
[INFO][05:10:43]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][05:10:43]: [Client #53] Model trained.
[INFO][05:10:43]: [Client #53] Inbound data has been processed.
[INFO][05:10:43]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][05:10:48]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:10:49]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][05:10:49]: [Server #3995185] Selecting client #17 for training.
[INFO][05:10:49]: [Server #3995185] Sending the current model to client #17 (simulated).
[INFO][05:10:54]: [Server #3995185] Sending 507.38 MB of payload data to client #17 (simulated).
[INFO][05:10:54]: [Client #17] Selected by the server.
[INFO][05:10:54]: [Client #17] Loading its data source...
[INFO][05:10:54]: [Client #17] Dataset size: 2018
[INFO][05:10:54]: [Client #17] Sampler: iid
[INFO][05:10:55]: [Client #17] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:10:55]: [Client #17] Start to process inbound data.
[INFO][05:10:55]: [93m[1m[Client #17] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.81s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.15it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.98it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.97it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.96it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.714854876200358,)
[INFO][05:11:35]: [Client #17] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3995237.pth.
{'train_runtime': 33.3012, 'train_samples_per_second': 181.795, 'train_steps_per_second': 2.883, 'train_loss': 3.714854876200358, 'epoch': 3.0}
[INFO][05:11:36]: [Client #17] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3995237.pth.
[INFO][05:11:36]: [Client #17] Model trained.
[INFO][05:11:36]: [Client #17] Inbound data has been processed.
[INFO][05:11:36]: [Client #17] Outbound data is ready to be sent after being processed.
[INFO][05:11:41]: [Client #17] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:11:42]: [Server #3995185] Received 507.38 MB of payload data from client #17 (simulated).
[INFO][05:11:42]: [Server #3995185] Selecting client #116 for training.
[INFO][05:11:42]: [Server #3995185] Sending the current model to client #116 (simulated).
[INFO][05:11:46]: [Server #3995185] Sending 507.38 MB of payload data to client #116 (simulated).
[INFO][05:11:46]: [Client #116] Selected by the server.
[INFO][05:11:46]: [Client #116] Loading its data source...
[INFO][05:11:46]: [Client #116] Dataset size: 2018
[INFO][05:11:46]: [Client #116] Sampler: iid
[INFO][05:11:47]: [Client #116] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:11:47]: [Client #116] Start to process inbound data.
[INFO][05:11:48]: [93m[1m[Client #116] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:41,  1.70s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.764965057373047,)
[INFO][05:12:27]: [Client #116] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_116_3995237.pth.
{'train_runtime': 32.8162, 'train_samples_per_second': 184.482, 'train_steps_per_second': 2.925, 'train_loss': 3.764965057373047, 'epoch': 3.0}
[INFO][05:12:28]: [Client #116] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_116_3995237.pth.
[INFO][05:12:28]: [Client #116] Model trained.
[INFO][05:12:28]: [Client #116] Inbound data has been processed.
[INFO][05:12:28]: [Client #116] Outbound data is ready to be sent after being processed.
[INFO][05:12:32]: [Client #116] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:12:33]: [Server #3995185] Received 507.38 MB of payload data from client #116 (simulated).
[INFO][05:12:33]: [Server #3995185] Selecting client #122 for training.
[INFO][05:12:33]: [Server #3995185] Sending the current model to client #122 (simulated).
[INFO][05:12:37]: [Server #3995185] Sending 507.38 MB of payload data to client #122 (simulated).
[INFO][05:12:37]: [Client #122] Selected by the server.
[INFO][05:12:37]: [Client #122] Loading its data source...
[INFO][05:12:37]: [Client #122] Dataset size: 2018
[INFO][05:12:37]: [Client #122] Sampler: iid
[INFO][05:12:38]: [Client #122] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:12:38]: [Client #122] Start to process inbound data.
[INFO][05:12:38]: [93m[1m[Client #122] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:39,  1.68s/it]  2%|â–         | 2/96 [00:02<01:23,  1.13it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7555923461914062,)
[INFO][05:13:16]: [Client #122] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_122_3995237.pth.
{'train_runtime': 32.5323, 'train_samples_per_second': 186.092, 'train_steps_per_second': 2.951, 'train_loss': 3.7555923461914062, 'epoch': 3.0}
[INFO][05:13:17]: [Client #122] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_122_3995237.pth.
[INFO][05:13:18]: [Client #122] Model trained.
[INFO][05:13:18]: [Client #122] Inbound data has been processed.
[INFO][05:13:18]: [Client #122] Outbound data is ready to be sent after being processed.
[INFO][05:13:22]: [Client #122] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:13:23]: [Server #3995185] Received 507.38 MB of payload data from client #122 (simulated).
[INFO][05:13:23]: [Server #3995185] Selecting client #25 for training.
[INFO][05:13:23]: [Server #3995185] Sending the current model to client #25 (simulated).
[INFO][05:13:27]: [Server #3995185] Sending 507.38 MB of payload data to client #25 (simulated).
[INFO][05:13:27]: [Client #25] Selected by the server.
[INFO][05:13:27]: [Client #25] Loading its data source...
[INFO][05:13:27]: [Client #25] Dataset size: 2018
[INFO][05:13:27]: [Client #25] Sampler: iid
[INFO][05:13:29]: [Client #25] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:13:29]: [Client #25] Start to process inbound data.
[INFO][05:13:29]: [93m[1m[Client #25] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:55,  1.84s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.86it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.39it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.56it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7422959009806314,)
[INFO][05:14:08]: [Client #25] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_25_3995237.pth.
{'train_runtime': 33.049, 'train_samples_per_second': 183.183, 'train_steps_per_second': 2.905, 'train_loss': 3.7422959009806314, 'epoch': 3.0}
[INFO][05:14:09]: [Client #25] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_25_3995237.pth.
[INFO][05:14:09]: [Client #25] Model trained.
[INFO][05:14:09]: [Client #25] Inbound data has been processed.
[INFO][05:14:09]: [Client #25] Outbound data is ready to be sent after being processed.
[INFO][05:14:14]: [Client #25] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:14:15]: [Server #3995185] Received 507.38 MB of payload data from client #25 (simulated).
[INFO][05:14:15]: [Server #3995185] Selecting client #175 for training.
[INFO][05:14:15]: [Server #3995185] Sending the current model to client #175 (simulated).
[INFO][05:14:19]: [Server #3995185] Sending 507.38 MB of payload data to client #175 (simulated).
[INFO][05:14:19]: [Client #175] Selected by the server.
[INFO][05:14:19]: [Client #175] Loading its data source...
[INFO][05:14:19]: [Client #175] Dataset size: 2018
[INFO][05:14:19]: [Client #175] Sampler: iid
[INFO][05:14:20]: [Client #175] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:14:20]: [Client #175] Start to process inbound data.
[INFO][05:14:20]: [93m[1m[Client #175] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:50,  1.79s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.97it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.97it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.42it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.06it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.01it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.00it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  2.98it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  2.98it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.97it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7294225692749023,)
[INFO][05:15:01]: [Client #175] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_175_3995237.pth.
{'train_runtime': 33.2198, 'train_samples_per_second': 182.24, 'train_steps_per_second': 2.89, 'train_loss': 3.7294225692749023, 'epoch': 3.0}
[INFO][05:15:02]: [Client #175] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_175_3995237.pth.
[INFO][05:15:02]: [Client #175] Model trained.
[INFO][05:15:02]: [Client #175] Inbound data has been processed.
[INFO][05:15:02]: [Client #175] Outbound data is ready to be sent after being processed.
[INFO][05:15:06]: [Client #175] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:15:07]: [Server #3995185] Received 507.38 MB of payload data from client #175 (simulated).
[INFO][05:15:07]: [Server #3995185] Selecting client #119 for training.
[INFO][05:15:07]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][05:15:14]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][05:15:14]: [Client #119] Selected by the server.
[INFO][05:15:14]: [Client #119] Loading its data source...
[INFO][05:15:14]: [Client #119] Dataset size: 2018
[INFO][05:15:14]: [Client #119] Sampler: iid
[INFO][05:15:16]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:15:16]: [Client #119] Start to process inbound data.
[INFO][05:15:16]: [93m[1m[Client #119] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:02<03:12,  2.03s/it]  2%|â–         | 2/96 [00:02<01:36,  1.03s/it]  3%|â–Ž         | 3/96 [00:02<01:06,  1.40it/s]  4%|â–         | 4/96 [00:03<00:51,  1.78it/s]  5%|â–Œ         | 5/96 [00:03<00:43,  2.09it/s]  6%|â–‹         | 6/96 [00:03<00:38,  2.33it/s]  7%|â–‹         | 7/96 [00:04<00:35,  2.52it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.65it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.76it/s] 10%|â–ˆ         | 10/96 [00:05<00:30,  2.83it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:06<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:07<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:08<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:09<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:10<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:11<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.87it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.703179677327474,)
[INFO][05:15:56]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 33.4257, 'train_samples_per_second': 181.118, 'train_steps_per_second': 2.872, 'train_loss': 3.703179677327474, 'epoch': 3.0}
[INFO][05:15:57]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][05:15:57]: [Client #119] Model trained.
[INFO][05:15:57]: [Client #119] Inbound data has been processed.
[INFO][05:15:57]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][05:16:03]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:16:04]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][05:16:04]: [Server #3995185] Selecting client #131 for training.
[INFO][05:16:04]: [Server #3995185] Sending the current model to client #131 (simulated).
[INFO][05:16:11]: [Server #3995185] Sending 507.38 MB of payload data to client #131 (simulated).
[INFO][05:16:11]: [Client #131] Selected by the server.
[INFO][05:16:11]: [Client #131] Loading its data source...
[INFO][05:16:11]: [Client #131] Dataset size: 2018
[INFO][05:16:11]: [Client #131] Sampler: iid
[INFO][05:16:12]: [Client #131] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:16:12]: [Client #131] Start to process inbound data.
[INFO][05:16:12]: [93m[1m[Client #131] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.720895449320475,)
[INFO][05:16:52]: [Client #131] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_131_3995237.pth.
{'train_runtime': 32.8668, 'train_samples_per_second': 184.198, 'train_steps_per_second': 2.921, 'train_loss': 3.720895449320475, 'epoch': 3.0}
[INFO][05:16:53]: [Client #131] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_131_3995237.pth.
[INFO][05:16:53]: [Client #131] Model trained.
[INFO][05:16:53]: [Client #131] Inbound data has been processed.
[INFO][05:16:53]: [Client #131] Outbound data is ready to be sent after being processed.
[INFO][05:16:58]: [Client #131] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:16:59]: [Server #3995185] Received 507.38 MB of payload data from client #131 (simulated).
[INFO][05:16:59]: [Server #3995185] Selecting client #110 for training.
[INFO][05:16:59]: [Server #3995185] Sending the current model to client #110 (simulated).
[INFO][05:17:03]: [Server #3995185] Sending 507.38 MB of payload data to client #110 (simulated).
[INFO][05:17:03]: [Client #110] Selected by the server.
[INFO][05:17:03]: [Client #110] Loading its data source...
[INFO][05:17:03]: [Client #110] Dataset size: 2018
[INFO][05:17:03]: [Client #110] Sampler: iid
[INFO][05:17:05]: [Client #110] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:17:05]: [Client #110] Start to process inbound data.
[INFO][05:17:05]: [93m[1m[Client #110] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:29,  1.57s/it]  2%|â–         | 2/96 [00:01<01:18,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.66it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.771583875020345,)
[INFO][05:17:43]: [Client #110] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_110_3995237.pth.
{'train_runtime': 32.878, 'train_samples_per_second': 184.135, 'train_steps_per_second': 2.92, 'train_loss': 3.771583875020345, 'epoch': 3.0}
[INFO][05:17:44]: [Client #110] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_110_3995237.pth.
[INFO][05:17:45]: [Client #110] Model trained.
[INFO][05:17:45]: [Client #110] Inbound data has been processed.
[INFO][05:17:45]: [Client #110] Outbound data is ready to be sent after being processed.
[INFO][05:17:49]: [Client #110] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:17:51]: [Server #3995185] Received 507.38 MB of payload data from client #110 (simulated).
[INFO][05:17:51]: [Server #3995185] Selecting client #150 for training.
[INFO][05:17:51]: [Server #3995185] Sending the current model to client #150 (simulated).
[INFO][05:17:55]: [Server #3995185] Sending 507.38 MB of payload data to client #150 (simulated).
[INFO][05:17:55]: [Client #150] Selected by the server.
[INFO][05:17:55]: [Client #150] Loading its data source...
[INFO][05:17:55]: [Client #150] Dataset size: 2018
[INFO][05:17:55]: [Client #150] Sampler: iid
[INFO][05:17:56]: [Client #150] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:17:56]: [Client #150] Start to process inbound data.
[INFO][05:17:56]: [93m[1m[Client #150] Started training in communication round #7.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.743443489074707,)
[INFO][05:18:35]: [Client #150] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_150_3995237.pth.
{'train_runtime': 32.6204, 'train_samples_per_second': 185.589, 'train_steps_per_second': 2.943, 'train_loss': 3.743443489074707, 'epoch': 3.0}
[INFO][05:18:36]: [Client #150] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_150_3995237.pth.
[INFO][05:18:36]: [Client #150] Model trained.
[INFO][05:18:36]: [Client #150] Inbound data has been processed.
[INFO][05:18:36]: [Client #150] Outbound data is ready to be sent after being processed.
[INFO][05:18:41]: [Client #150] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:18:42]: [Server #3995185] Received 507.38 MB of payload data from client #150 (simulated).
[INFO][05:18:42]: [Server #3995185] Adding client #127 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #95 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #17 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #53 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #102 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #119 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #182 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #131 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #116 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Adding client #122 to the list of clients for aggregation.
[INFO][05:18:42]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:18:42]: [Server #3995185] Updated weights have been received.
[INFO][05:18:43]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:18:44]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:18:44]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.97it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.26it/s]
[INFO][05:18:53]: [93m[1m[Server #3995185] Global model perplexity: 38.46
[0m
[INFO][05:18:53]: [Server #3995185] All client reports have been processed.
[INFO][05:18:54]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_7.pth.
[INFO][05:18:58]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_7.pth.
[INFO][05:18:58]: [93m[1m
[Server #3995185] Starting round 8/50.[0m
[INFO][05:18:58]: [Server #3995185] Selected clients: [46, 196, 180, 117, 10, 106, 179, 93, 120, 47]
[INFO][05:18:58]: [Server #3995185] Selecting client #46 for training.
[INFO][05:18:58]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][05:19:03]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][05:19:03]: [Client #46] Selected by the server.
[INFO][05:19:03]: [Client #46] Loading its data source...
[INFO][05:19:03]: [Client #46] Dataset size: 2018
[INFO][05:19:03]: [Client #46] Sampler: iid
[INFO][05:19:04]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:19:04]: [Client #46] Start to process inbound data.
[INFO][05:19:04]: [93m[1m[Client #46] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.04it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.704998016357422,)
[INFO][05:19:44]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 33.0841, 'train_samples_per_second': 182.988, 'train_steps_per_second': 2.902, 'train_loss': 3.704998016357422, 'epoch': 3.0}
[INFO][05:19:45]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][05:19:45]: [Client #46] Model trained.
[INFO][05:19:45]: [Client #46] Inbound data has been processed.
[INFO][05:19:45]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][05:19:49]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:19:50]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][05:19:50]: [Server #3995185] Selecting client #196 for training.
[INFO][05:19:50]: [Server #3995185] Sending the current model to client #196 (simulated).
[INFO][05:19:55]: [Server #3995185] Sending 507.38 MB of payload data to client #196 (simulated).
[INFO][05:19:55]: [Client #196] Selected by the server.
[INFO][05:19:55]: [Client #196] Loading its data source...
[INFO][05:19:55]: [Client #196] Dataset size: 2018
[INFO][05:19:55]: [Client #196] Sampler: iid
[INFO][05:19:56]: [Client #196] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:19:56]: [Client #196] Start to process inbound data.
[INFO][05:19:56]: [93m[1m[Client #196] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.43it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  2.99it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.99it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.98it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.97it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.97it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.97it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.97it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.96it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.96it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.96it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.96it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.95it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.688052177429199,)
[INFO][05:20:35]: [Client #196] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_196_3995237.pth.
{'train_runtime': 33.1819, 'train_samples_per_second': 182.449, 'train_steps_per_second': 2.893, 'train_loss': 3.688052177429199, 'epoch': 3.0}
[INFO][05:20:36]: [Client #196] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_196_3995237.pth.
[INFO][05:20:37]: [Client #196] Model trained.
[INFO][05:20:37]: [Client #196] Inbound data has been processed.
[INFO][05:20:37]: [Client #196] Outbound data is ready to be sent after being processed.
[INFO][05:20:41]: [Client #196] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:20:42]: [Server #3995185] Received 507.38 MB of payload data from client #196 (simulated).
[INFO][05:20:42]: [Server #3995185] Selecting client #180 for training.
[INFO][05:20:42]: [Server #3995185] Sending the current model to client #180 (simulated).
[INFO][05:20:46]: [Server #3995185] Sending 507.38 MB of payload data to client #180 (simulated).
[INFO][05:20:46]: [Client #180] Selected by the server.
[INFO][05:20:46]: [Client #180] Loading its data source...
[INFO][05:20:46]: [Client #180] Dataset size: 2018
[INFO][05:20:46]: [Client #180] Sampler: iid
[INFO][05:20:48]: [Client #180] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:20:48]: [Client #180] Start to process inbound data.
[INFO][05:20:48]: [93m[1m[Client #180] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:35,  1.64s/it]  2%|â–         | 2/96 [00:01<01:21,  1.15it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.61it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7052084604899087,)
[INFO][05:21:27]: [Client #180] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_180_3995237.pth.
{'train_runtime': 32.7758, 'train_samples_per_second': 184.71, 'train_steps_per_second': 2.929, 'train_loss': 3.7052084604899087, 'epoch': 3.0}
[INFO][05:21:28]: [Client #180] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_180_3995237.pth.
[INFO][05:21:29]: [Client #180] Model trained.
[INFO][05:21:29]: [Client #180] Inbound data has been processed.
[INFO][05:21:29]: [Client #180] Outbound data is ready to be sent after being processed.
[INFO][05:21:33]: [Client #180] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:21:34]: [Server #3995185] Received 507.38 MB of payload data from client #180 (simulated).
[INFO][05:21:34]: [Server #3995185] Selecting client #117 for training.
[INFO][05:21:34]: [Server #3995185] Sending the current model to client #117 (simulated).
[INFO][05:21:38]: [Server #3995185] Sending 507.38 MB of payload data to client #117 (simulated).
[INFO][05:21:38]: [Client #117] Selected by the server.
[INFO][05:21:38]: [Client #117] Loading its data source...
[INFO][05:21:38]: [Client #117] Dataset size: 2018
[INFO][05:21:38]: [Client #117] Sampler: iid
[INFO][05:21:40]: [Client #117] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:21:40]: [Client #117] Start to process inbound data.
[INFO][05:21:40]: [93m[1m[Client #117] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:37,  1.65s/it]  2%|â–         | 2/96 [00:01<01:22,  1.14it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.59it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.682953198750814,)
[INFO][05:22:20]: [Client #117] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_117_3995237.pth.
{'train_runtime': 32.8636, 'train_samples_per_second': 184.216, 'train_steps_per_second': 2.921, 'train_loss': 3.682953198750814, 'epoch': 3.0}
[INFO][05:22:21]: [Client #117] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_117_3995237.pth.
[INFO][05:22:21]: [Client #117] Model trained.
[INFO][05:22:21]: [Client #117] Inbound data has been processed.
[INFO][05:22:21]: [Client #117] Outbound data is ready to be sent after being processed.
[INFO][05:22:25]: [Client #117] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:22:26]: [Server #3995185] Received 507.38 MB of payload data from client #117 (simulated).
[INFO][05:22:26]: [Server #3995185] Selecting client #10 for training.
[INFO][05:22:26]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][05:22:31]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][05:22:31]: [Client #10] Selected by the server.
[INFO][05:22:31]: [Client #10] Loading its data source...
[INFO][05:22:31]: [Client #10] Dataset size: 2018
[INFO][05:22:31]: [Client #10] Sampler: iid
[INFO][05:22:32]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:22:32]: [Client #10] Start to process inbound data.
[INFO][05:22:32]: [93m[1m[Client #10] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7019694646199546,)
[INFO][05:23:12]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.7505, 'train_samples_per_second': 184.852, 'train_steps_per_second': 2.931, 'train_loss': 3.7019694646199546, 'epoch': 3.0}
[INFO][05:23:12]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][05:23:13]: [Client #10] Model trained.
[INFO][05:23:13]: [Client #10] Inbound data has been processed.
[INFO][05:23:13]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][05:23:17]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:23:18]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][05:23:18]: [Server #3995185] Selecting client #106 for training.
[INFO][05:23:18]: [Server #3995185] Sending the current model to client #106 (simulated).
[INFO][05:23:22]: [Server #3995185] Sending 507.38 MB of payload data to client #106 (simulated).
[INFO][05:23:22]: [Client #106] Selected by the server.
[INFO][05:23:22]: [Client #106] Loading its data source...
[INFO][05:23:22]: [Client #106] Dataset size: 2018
[INFO][05:23:22]: [Client #106] Sampler: iid
[INFO][05:23:23]: [Client #106] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:23:23]: [Client #106] Start to process inbound data.
[INFO][05:23:23]: [93m[1m[Client #106] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:37,  1.66s/it]  2%|â–         | 2/96 [00:01<01:22,  1.14it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.60it/s]  4%|â–         | 4/96 [00:02<00:46,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.68447208404541,)
[INFO][05:24:02]: [Client #106] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_106_3995237.pth.
{'train_runtime': 32.8648, 'train_samples_per_second': 184.209, 'train_steps_per_second': 2.921, 'train_loss': 3.68447208404541, 'epoch': 3.0}
[INFO][05:24:03]: [Client #106] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_106_3995237.pth.
[INFO][05:24:03]: [Client #106] Model trained.
[INFO][05:24:03]: [Client #106] Inbound data has been processed.
[INFO][05:24:03]: [Client #106] Outbound data is ready to be sent after being processed.
[INFO][05:24:07]: [Client #106] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:24:08]: [Server #3995185] Received 507.38 MB of payload data from client #106 (simulated).
[INFO][05:24:08]: [Server #3995185] Selecting client #179 for training.
[INFO][05:24:08]: [Server #3995185] Sending the current model to client #179 (simulated).
[INFO][05:24:12]: [Server #3995185] Sending 507.38 MB of payload data to client #179 (simulated).
[INFO][05:24:12]: [Client #179] Selected by the server.
[INFO][05:24:12]: [Client #179] Loading its data source...
[INFO][05:24:12]: [Client #179] Dataset size: 2018
[INFO][05:24:12]: [Client #179] Sampler: iid
[INFO][05:24:14]: [Client #179] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:24:14]: [Client #179] Start to process inbound data.
[INFO][05:24:14]: [93m[1m[Client #179] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  2.99it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.92it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6692221959431968,)
[INFO][05:24:52]: [Client #179] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_179_3995237.pth.
{'train_runtime': 32.8699, 'train_samples_per_second': 184.18, 'train_steps_per_second': 2.921, 'train_loss': 3.6692221959431968, 'epoch': 3.0}
[INFO][05:24:53]: [Client #179] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_179_3995237.pth.
[INFO][05:24:54]: [Client #179] Model trained.
[INFO][05:24:54]: [Client #179] Inbound data has been processed.
[INFO][05:24:54]: [Client #179] Outbound data is ready to be sent after being processed.
[INFO][05:24:58]: [Client #179] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:24:59]: [Server #3995185] Received 507.38 MB of payload data from client #179 (simulated).
[INFO][05:24:59]: [Server #3995185] Selecting client #93 for training.
[INFO][05:24:59]: [Server #3995185] Sending the current model to client #93 (simulated).
[INFO][05:25:03]: [Server #3995185] Sending 507.38 MB of payload data to client #93 (simulated).
[INFO][05:25:03]: [Client #93] Selected by the server.
[INFO][05:25:03]: [Client #93] Loading its data source...
[INFO][05:25:03]: [Client #93] Dataset size: 2018
[INFO][05:25:03]: [Client #93] Sampler: iid
[INFO][05:25:04]: [Client #93] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:25:04]: [Client #93] Start to process inbound data.
[INFO][05:25:05]: [93m[1m[Client #93] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:56,  1.86s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6702804565429688,)
[INFO][05:25:44]: [Client #93] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_93_3995237.pth.
{'train_runtime': 32.7615, 'train_samples_per_second': 184.79, 'train_steps_per_second': 2.93, 'train_loss': 3.6702804565429688, 'epoch': 3.0}
[INFO][05:25:45]: [Client #93] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_93_3995237.pth.
[INFO][05:25:46]: [Client #93] Model trained.
[INFO][05:25:46]: [Client #93] Inbound data has been processed.
[INFO][05:25:46]: [Client #93] Outbound data is ready to be sent after being processed.
[INFO][05:25:50]: [Client #93] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:25:51]: [Server #3995185] Received 507.38 MB of payload data from client #93 (simulated).
[INFO][05:25:51]: [Server #3995185] Selecting client #120 for training.
[INFO][05:25:51]: [Server #3995185] Sending the current model to client #120 (simulated).
[INFO][05:25:55]: [Server #3995185] Sending 507.38 MB of payload data to client #120 (simulated).
[INFO][05:25:55]: [Client #120] Selected by the server.
[INFO][05:25:55]: [Client #120] Loading its data source...
[INFO][05:25:55]: [Client #120] Dataset size: 2018
[INFO][05:25:55]: [Client #120] Sampler: iid
[INFO][05:25:56]: [Client #120] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:25:56]: [Client #120] Start to process inbound data.
[INFO][05:25:57]: [93m[1m[Client #120] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:50,  1.80s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.7178732554117837,)
[INFO][05:26:36]: [Client #120] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_120_3995237.pth.
{'train_runtime': 32.813, 'train_samples_per_second': 184.5, 'train_steps_per_second': 2.926, 'train_loss': 3.7178732554117837, 'epoch': 3.0}
[INFO][05:26:37]: [Client #120] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_120_3995237.pth.
[INFO][05:26:38]: [Client #120] Model trained.
[INFO][05:26:38]: [Client #120] Inbound data has been processed.
[INFO][05:26:38]: [Client #120] Outbound data is ready to be sent after being processed.
[INFO][05:26:42]: [Client #120] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:26:43]: [Server #3995185] Received 507.38 MB of payload data from client #120 (simulated).
[INFO][05:26:43]: [Server #3995185] Selecting client #47 for training.
[INFO][05:26:43]: [Server #3995185] Sending the current model to client #47 (simulated).
[INFO][05:26:47]: [Server #3995185] Sending 507.38 MB of payload data to client #47 (simulated).
[INFO][05:26:47]: [Client #47] Selected by the server.
[INFO][05:26:47]: [Client #47] Loading its data source...
[INFO][05:26:47]: [Client #47] Dataset size: 2018
[INFO][05:26:47]: [Client #47] Sampler: iid
[INFO][05:26:48]: [Client #47] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:26:48]: [Client #47] Start to process inbound data.
[INFO][05:26:48]: [93m[1m[Client #47] Started training in communication round #8.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.98it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.98it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.97it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.97it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.97it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.97it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6739123662312827,)
[INFO][05:27:28]: [Client #47] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_47_3995237.pth.
{'train_runtime': 33.0842, 'train_samples_per_second': 182.987, 'train_steps_per_second': 2.902, 'train_loss': 3.6739123662312827, 'epoch': 3.0}
[INFO][05:27:29]: [Client #47] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_47_3995237.pth.
[INFO][05:27:31]: [Client #47] Model trained.
[INFO][05:27:31]: [Client #47] Inbound data has been processed.
[INFO][05:27:31]: [Client #47] Outbound data is ready to be sent after being processed.
[INFO][05:27:35]: [Client #47] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:27:36]: [Server #3995185] Received 507.38 MB of payload data from client #47 (simulated).
[INFO][05:27:36]: [Server #3995185] Adding client #39 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #110 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #147 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #175 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #150 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #167 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #32 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Adding client #40 to the list of clients for aggregation.
[INFO][05:27:36]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:27:36]: [Server #3995185] Updated weights have been received.
[INFO][05:27:38]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:27:39]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:27:39]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.87it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.27it/s]
[INFO][05:27:48]: [93m[1m[Server #3995185] Global model perplexity: 36.52
[0m
[INFO][05:27:48]: [Server #3995185] All client reports have been processed.
[INFO][05:27:49]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_8.pth.
[INFO][05:27:52]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_8.pth.
[INFO][05:27:52]: [93m[1m
[Server #3995185] Starting round 9/50.[0m
[INFO][05:27:52]: [Server #3995185] Selected clients: [193, 44, 181, 149, 86, 22, 65, 195, 124, 12]
[INFO][05:27:52]: [Server #3995185] Selecting client #193 for training.
[INFO][05:27:52]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][05:27:56]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][05:27:56]: [Client #193] Selected by the server.
[INFO][05:27:56]: [Client #193] Loading its data source...
[INFO][05:27:56]: [Client #193] Dataset size: 2018
[INFO][05:27:56]: [Client #193] Sampler: iid
[INFO][05:27:58]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:27:58]: [Client #193] Start to process inbound data.
[INFO][05:27:58]: [93m[1m[Client #193] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.76it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.94it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.99it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.05it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.11it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.12it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.11it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.12it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.12it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.11it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.11it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.11it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.11it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.17it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.15it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.15it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.14it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.14it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.14it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:15,  3.14it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.14it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.15it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:14,  3.15it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.15it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.14it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.14it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:17<00:13,  3.14it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.14it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.15it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:18<00:12,  3.15it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.15it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.15it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:19<00:11,  3.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.14it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.14it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.14it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.59it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.44it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:21<00:08,  3.34it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.27it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.23it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:22<00:08,  3.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.17it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.16it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:23<00:07,  3.15it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.14it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.13it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:24<00:06,  3.13it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.13it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.13it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.13it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.13it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.13it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.13it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.12it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:29<00:01,  3.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.13it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.12it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:30<00:00,  3.13it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.05it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6078904469807944,)
[INFO][05:28:36]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 31.4461, 'train_samples_per_second': 192.52, 'train_steps_per_second': 3.053, 'train_loss': 3.6078904469807944, 'epoch': 3.0}
[INFO][05:28:37]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][05:28:37]: [Client #193] Model trained.
[INFO][05:28:37]: [Client #193] Inbound data has been processed.
[INFO][05:28:37]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][05:28:41]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:28:42]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][05:28:42]: [Server #3995185] Selecting client #44 for training.
[INFO][05:28:42]: [Server #3995185] Sending the current model to client #44 (simulated).
[INFO][05:28:47]: [Server #3995185] Sending 507.38 MB of payload data to client #44 (simulated).
[INFO][05:28:47]: [Client #44] Selected by the server.
[INFO][05:28:47]: [Client #44] Loading its data source...
[INFO][05:28:47]: [Client #44] Dataset size: 2018
[INFO][05:28:47]: [Client #44] Sampler: iid
[INFO][05:28:48]: [Client #44] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:28:48]: [Client #44] Start to process inbound data.
[INFO][05:28:48]: [93m[1m[Client #44] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.634122848510742,)
[INFO][05:29:27]: [Client #44] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_44_3995237.pth.
{'train_runtime': 32.4269, 'train_samples_per_second': 186.697, 'train_steps_per_second': 2.961, 'train_loss': 3.634122848510742, 'epoch': 3.0}
[INFO][05:29:28]: [Client #44] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_44_3995237.pth.
[INFO][05:29:28]: [Client #44] Model trained.
[INFO][05:29:28]: [Client #44] Inbound data has been processed.
[INFO][05:29:28]: [Client #44] Outbound data is ready to be sent after being processed.
[INFO][05:29:32]: [Client #44] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:29:34]: [Server #3995185] Received 507.38 MB of payload data from client #44 (simulated).
[INFO][05:29:34]: [Server #3995185] Selecting client #181 for training.
[INFO][05:29:34]: [Server #3995185] Sending the current model to client #181 (simulated).
[INFO][05:29:38]: [Server #3995185] Sending 507.38 MB of payload data to client #181 (simulated).
[INFO][05:29:38]: [Client #181] Selected by the server.
[INFO][05:29:38]: [Client #181] Loading its data source...
[INFO][05:29:38]: [Client #181] Dataset size: 2018
[INFO][05:29:38]: [Client #181] Sampler: iid
[INFO][05:29:39]: [Client #181] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:29:39]: [Client #181] Start to process inbound data.
[INFO][05:29:39]: [93m[1m[Client #181] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6284255981445312,)
[INFO][05:30:18]: [Client #181] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_181_3995237.pth.
{'train_runtime': 32.7453, 'train_samples_per_second': 184.882, 'train_steps_per_second': 2.932, 'train_loss': 3.6284255981445312, 'epoch': 3.0}
[INFO][05:30:19]: [Client #181] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_181_3995237.pth.
[INFO][05:30:20]: [Client #181] Model trained.
[INFO][05:30:20]: [Client #181] Inbound data has been processed.
[INFO][05:30:20]: [Client #181] Outbound data is ready to be sent after being processed.
[INFO][05:30:24]: [Client #181] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:30:25]: [Server #3995185] Received 507.38 MB of payload data from client #181 (simulated).
[INFO][05:30:25]: [Server #3995185] Selecting client #149 for training.
[INFO][05:30:25]: [Server #3995185] Sending the current model to client #149 (simulated).
[INFO][05:30:29]: [Server #3995185] Sending 507.38 MB of payload data to client #149 (simulated).
[INFO][05:30:29]: [Client #149] Selected by the server.
[INFO][05:30:29]: [Client #149] Loading its data source...
[INFO][05:30:29]: [Client #149] Dataset size: 2018
[INFO][05:30:29]: [Client #149] Sampler: iid
[INFO][05:30:31]: [Client #149] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:30:31]: [Client #149] Start to process inbound data.
[INFO][05:30:31]: [93m[1m[Client #149] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:51,  1.80s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.96it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.97it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.97it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.97it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.97it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.96it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.96it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.41it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.09it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.06it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.02it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.01it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:19,  2.99it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  2.98it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  2.97it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.98it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.97it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.97it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.96it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.96it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.96it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.96it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.96it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.96it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.96it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.96it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.96it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.629710833231608,)
[INFO][05:31:10]: [Client #149] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
{'train_runtime': 33.2275, 'train_samples_per_second': 182.199, 'train_steps_per_second': 2.889, 'train_loss': 3.629710833231608, 'epoch': 3.0}
[INFO][05:31:11]: [Client #149] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
[INFO][05:31:11]: [Client #149] Model trained.
[INFO][05:31:11]: [Client #149] Inbound data has been processed.
[INFO][05:31:11]: [Client #149] Outbound data is ready to be sent after being processed.
[INFO][05:31:16]: [Client #149] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:31:17]: [Server #3995185] Received 507.38 MB of payload data from client #149 (simulated).
[INFO][05:31:17]: [Server #3995185] Selecting client #86 for training.
[INFO][05:31:17]: [Server #3995185] Sending the current model to client #86 (simulated).
[INFO][05:31:21]: [Server #3995185] Sending 507.38 MB of payload data to client #86 (simulated).
[INFO][05:31:21]: [Client #86] Selected by the server.
[INFO][05:31:21]: [Client #86] Loading its data source...
[INFO][05:31:21]: [Client #86] Dataset size: 2018
[INFO][05:31:21]: [Client #86] Sampler: iid
[INFO][05:31:22]: [Client #86] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:31:22]: [Client #86] Start to process inbound data.
[INFO][05:31:22]: [93m[1m[Client #86] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.78s/it]  2%|â–         | 2/96 [00:02<01:27,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.97it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.42it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.18it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6421289443969727,)
[INFO][05:32:02]: [Client #86] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_86_3995237.pth.
{'train_runtime': 33.1108, 'train_samples_per_second': 182.841, 'train_steps_per_second': 2.899, 'train_loss': 3.6421289443969727, 'epoch': 3.0}
[INFO][05:32:03]: [Client #86] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_86_3995237.pth.
[INFO][05:32:03]: [Client #86] Model trained.
[INFO][05:32:03]: [Client #86] Inbound data has been processed.
[INFO][05:32:03]: [Client #86] Outbound data is ready to be sent after being processed.
[INFO][05:32:07]: [Client #86] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:32:08]: [Server #3995185] Received 507.38 MB of payload data from client #86 (simulated).
[INFO][05:32:08]: [Server #3995185] Selecting client #22 for training.
[INFO][05:32:08]: [Server #3995185] Sending the current model to client #22 (simulated).
[INFO][05:32:15]: [Server #3995185] Sending 507.38 MB of payload data to client #22 (simulated).
[INFO][05:32:15]: [Client #22] Selected by the server.
[INFO][05:32:15]: [Client #22] Loading its data source...
[INFO][05:32:15]: [Client #22] Dataset size: 2018
[INFO][05:32:15]: [Client #22] Sampler: iid
[INFO][05:32:16]: [Client #22] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:32:16]: [Client #22] Start to process inbound data.
[INFO][05:32:16]: [93m[1m[Client #22] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:36,  1.64s/it]  2%|â–         | 2/96 [00:01<01:21,  1.15it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.60it/s]  4%|â–         | 4/96 [00:02<00:46,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6578098932902017,)
[INFO][05:32:56]: [Client #22] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_22_3995237.pth.
{'train_runtime': 33.0411, 'train_samples_per_second': 183.226, 'train_steps_per_second': 2.905, 'train_loss': 3.6578098932902017, 'epoch': 3.0}
[INFO][05:32:56]: [Client #22] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_22_3995237.pth.
[INFO][05:32:57]: [Client #22] Model trained.
[INFO][05:32:57]: [Client #22] Inbound data has been processed.
[INFO][05:32:57]: [Client #22] Outbound data is ready to be sent after being processed.
[INFO][05:33:01]: [Client #22] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:33:02]: [Server #3995185] Received 507.38 MB of payload data from client #22 (simulated).
[INFO][05:33:02]: [Server #3995185] Selecting client #65 for training.
[INFO][05:33:02]: [Server #3995185] Sending the current model to client #65 (simulated).
[INFO][05:33:08]: [Server #3995185] Sending 507.38 MB of payload data to client #65 (simulated).
[INFO][05:33:08]: [Client #65] Selected by the server.
[INFO][05:33:08]: [Client #65] Loading its data source...
[INFO][05:33:08]: [Client #65] Dataset size: 2018
[INFO][05:33:08]: [Client #65] Sampler: iid
[INFO][05:33:09]: [Client #65] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:33:09]: [Client #65] Start to process inbound data.
[INFO][05:33:09]: [93m[1m[Client #65] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.624378522237142,)
[INFO][05:33:49]: [Client #65] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_65_3995237.pth.
{'train_runtime': 32.8484, 'train_samples_per_second': 184.301, 'train_steps_per_second': 2.923, 'train_loss': 3.624378522237142, 'epoch': 3.0}
[INFO][05:33:50]: [Client #65] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_65_3995237.pth.
[INFO][05:33:50]: [Client #65] Model trained.
[INFO][05:33:50]: [Client #65] Inbound data has been processed.
[INFO][05:33:50]: [Client #65] Outbound data is ready to be sent after being processed.
[INFO][05:33:57]: [Client #65] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:33:58]: [Server #3995185] Received 507.38 MB of payload data from client #65 (simulated).
[INFO][05:33:58]: [Server #3995185] Selecting client #195 for training.
[INFO][05:33:58]: [Server #3995185] Sending the current model to client #195 (simulated).
[INFO][05:34:03]: [Server #3995185] Sending 507.38 MB of payload data to client #195 (simulated).
[INFO][05:34:03]: [Client #195] Selected by the server.
[INFO][05:34:03]: [Client #195] Loading its data source...
[INFO][05:34:03]: [Client #195] Dataset size: 2018
[INFO][05:34:03]: [Client #195] Sampler: iid
[INFO][05:34:04]: [Client #195] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:34:04]: [Client #195] Start to process inbound data.
[INFO][05:34:04]: [93m[1m[Client #195] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.641194979349772,)
[INFO][05:34:43]: [Client #195] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_195_3995237.pth.
{'train_runtime': 32.4559, 'train_samples_per_second': 186.53, 'train_steps_per_second': 2.958, 'train_loss': 3.641194979349772, 'epoch': 3.0}
[INFO][05:34:44]: [Client #195] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_195_3995237.pth.
[INFO][05:34:45]: [Client #195] Model trained.
[INFO][05:34:45]: [Client #195] Inbound data has been processed.
[INFO][05:34:45]: [Client #195] Outbound data is ready to be sent after being processed.
[INFO][05:34:49]: [Client #195] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:34:50]: [Server #3995185] Received 507.38 MB of payload data from client #195 (simulated).
[INFO][05:34:50]: [Server #3995185] Selecting client #124 for training.
[INFO][05:34:50]: [Server #3995185] Sending the current model to client #124 (simulated).
[INFO][05:34:54]: [Server #3995185] Sending 507.38 MB of payload data to client #124 (simulated).
[INFO][05:34:54]: [Client #124] Selected by the server.
[INFO][05:34:54]: [Client #124] Loading its data source...
[INFO][05:34:54]: [Client #124] Dataset size: 2018
[INFO][05:34:54]: [Client #124] Sampler: iid
[INFO][05:34:56]: [Client #124] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:34:56]: [Client #124] Start to process inbound data.
[INFO][05:34:56]: [93m[1m[Client #124] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.44s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.633983612060547,)
[INFO][05:35:34]: [Client #124] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_124_3995237.pth.
{'train_runtime': 32.1076, 'train_samples_per_second': 188.553, 'train_steps_per_second': 2.99, 'train_loss': 3.633983612060547, 'epoch': 3.0}
[INFO][05:35:35]: [Client #124] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_124_3995237.pth.
[INFO][05:35:35]: [Client #124] Model trained.
[INFO][05:35:35]: [Client #124] Inbound data has been processed.
[INFO][05:35:35]: [Client #124] Outbound data is ready to be sent after being processed.
[INFO][05:35:39]: [Client #124] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:35:40]: [Server #3995185] Received 507.38 MB of payload data from client #124 (simulated).
[INFO][05:35:40]: [Server #3995185] Selecting client #12 for training.
[INFO][05:35:40]: [Server #3995185] Sending the current model to client #12 (simulated).
[INFO][05:35:44]: [Server #3995185] Sending 507.38 MB of payload data to client #12 (simulated).
[INFO][05:35:44]: [Client #12] Selected by the server.
[INFO][05:35:44]: [Client #12] Loading its data source...
[INFO][05:35:44]: [Client #12] Dataset size: 2018
[INFO][05:35:44]: [Client #12] Sampler: iid
[INFO][05:35:45]: [Client #12] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:35:45]: [Client #12] Start to process inbound data.
[INFO][05:35:45]: [93m[1m[Client #12] Started training in communication round #9.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6751317977905273,)
[INFO][05:36:25]: [Client #12] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_12_3995237.pth.
{'train_runtime': 32.9045, 'train_samples_per_second': 183.987, 'train_steps_per_second': 2.918, 'train_loss': 3.6751317977905273, 'epoch': 3.0}
[INFO][05:36:26]: [Client #12] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_12_3995237.pth.
[INFO][05:36:26]: [Client #12] Model trained.
[INFO][05:36:26]: [Client #12] Inbound data has been processed.
[INFO][05:36:26]: [Client #12] Outbound data is ready to be sent after being processed.
[INFO][05:36:30]: [Client #12] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:36:32]: [Server #3995185] Received 507.38 MB of payload data from client #12 (simulated).
[INFO][05:36:32]: [Server #3995185] Adding client #72 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #149 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #195 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #25 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #47 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #93 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #106 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #117 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Adding client #120 to the list of clients for aggregation.
[INFO][05:36:32]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:36:32]: [Server #3995185] Updated weights have been received.
[INFO][05:36:33]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:36:34]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:36:34]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.51it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 38.73it/s]
[INFO][05:36:43]: [93m[1m[Server #3995185] Global model perplexity: 34.67
[0m
[INFO][05:36:43]: [Server #3995185] All client reports have been processed.
[INFO][05:36:44]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_9.pth.
[INFO][05:36:49]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_9.pth.
[INFO][05:36:49]: [93m[1m
[Server #3995185] Starting round 10/50.[0m
[INFO][05:36:49]: [Server #3995185] Selected clients: [200, 66, 105, 113, 162, 155, 59, 130, 146, 51]
[INFO][05:36:49]: [Server #3995185] Selecting client #200 for training.
[INFO][05:36:49]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][05:36:53]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][05:36:53]: [Client #200] Selected by the server.
[INFO][05:36:53]: [Client #200] Loading its data source...
[INFO][05:36:53]: [Client #200] Dataset size: 2018
[INFO][05:36:53]: [Client #200] Sampler: iid
[INFO][05:36:55]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:36:55]: [Client #200] Start to process inbound data.
[INFO][05:36:55]: [93m[1m[Client #200] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6035683949788413,)
[INFO][05:37:34]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 33.0448, 'train_samples_per_second': 183.206, 'train_steps_per_second': 2.905, 'train_loss': 3.6035683949788413, 'epoch': 3.0}
[INFO][05:37:35]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][05:37:35]: [Client #200] Model trained.
[INFO][05:37:35]: [Client #200] Inbound data has been processed.
[INFO][05:37:35]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][05:37:42]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:37:43]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][05:37:43]: [Server #3995185] Selecting client #66 for training.
[INFO][05:37:43]: [Server #3995185] Sending the current model to client #66 (simulated).
[INFO][05:37:47]: [Server #3995185] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][05:37:47]: [Client #66] Selected by the server.
[INFO][05:37:47]: [Client #66] Loading its data source...
[INFO][05:37:47]: [Client #66] Dataset size: 2018
[INFO][05:37:47]: [Client #66] Sampler: iid
[INFO][05:37:49]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:37:49]: [Client #66] Start to process inbound data.
[INFO][05:37:49]: [93m[1m[Client #66] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.09it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.61150328318278,)
[INFO][05:38:27]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
{'train_runtime': 32.0706, 'train_samples_per_second': 188.771, 'train_steps_per_second': 2.993, 'train_loss': 3.61150328318278, 'epoch': 3.0}
[INFO][05:38:28]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
[INFO][05:38:29]: [Client #66] Model trained.
[INFO][05:38:29]: [Client #66] Inbound data has been processed.
[INFO][05:38:29]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][05:38:35]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:38:36]: [Server #3995185] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][05:38:36]: [Server #3995185] Selecting client #105 for training.
[INFO][05:38:36]: [Server #3995185] Sending the current model to client #105 (simulated).
[INFO][05:38:40]: [Server #3995185] Sending 507.38 MB of payload data to client #105 (simulated).
[INFO][05:38:40]: [Client #105] Selected by the server.
[INFO][05:38:40]: [Client #105] Loading its data source...
[INFO][05:38:40]: [Client #105] Dataset size: 2018
[INFO][05:38:40]: [Client #105] Sampler: iid
[INFO][05:38:42]: [Client #105] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:38:42]: [Client #105] Start to process inbound data.
[INFO][05:38:42]: [93m[1m[Client #105] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.519888242085775,)
[INFO][05:39:22]: [Client #105] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_105_3995237.pth.
{'train_runtime': 32.9654, 'train_samples_per_second': 183.647, 'train_steps_per_second': 2.912, 'train_loss': 3.519888242085775, 'epoch': 3.0}
[INFO][05:39:22]: [Client #105] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_105_3995237.pth.
[INFO][05:39:23]: [Client #105] Model trained.
[INFO][05:39:23]: [Client #105] Inbound data has been processed.
[INFO][05:39:23]: [Client #105] Outbound data is ready to be sent after being processed.
[INFO][05:39:27]: [Client #105] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:39:28]: [Server #3995185] Received 507.38 MB of payload data from client #105 (simulated).
[INFO][05:39:28]: [Server #3995185] Selecting client #113 for training.
[INFO][05:39:28]: [Server #3995185] Sending the current model to client #113 (simulated).
[INFO][05:39:32]: [Server #3995185] Sending 507.38 MB of payload data to client #113 (simulated).
[INFO][05:39:32]: [Client #113] Selected by the server.
[INFO][05:39:32]: [Client #113] Loading its data source...
[INFO][05:39:32]: [Client #113] Dataset size: 2018
[INFO][05:39:32]: [Client #113] Sampler: iid
[INFO][05:39:33]: [Client #113] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:39:33]: [Client #113] Start to process inbound data.
[INFO][05:39:33]: [93m[1m[Client #113] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:57,  1.87s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.48it/s]  4%|â–         | 4/96 [00:02<00:49,  1.85it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.15it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.38it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.56it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.68it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.84it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.98it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5688374837239585,)
[INFO][05:40:13]: [Client #113] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_113_3995237.pth.
{'train_runtime': 33.1672, 'train_samples_per_second': 182.53, 'train_steps_per_second': 2.894, 'train_loss': 3.5688374837239585, 'epoch': 3.0}
[INFO][05:40:14]: [Client #113] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_113_3995237.pth.
[INFO][05:40:14]: [Client #113] Model trained.
[INFO][05:40:14]: [Client #113] Inbound data has been processed.
[INFO][05:40:14]: [Client #113] Outbound data is ready to be sent after being processed.
[INFO][05:40:18]: [Client #113] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:40:19]: [Server #3995185] Received 507.38 MB of payload data from client #113 (simulated).
[INFO][05:40:19]: [Server #3995185] Selecting client #162 for training.
[INFO][05:40:19]: [Server #3995185] Sending the current model to client #162 (simulated).
[INFO][05:40:23]: [Server #3995185] Sending 507.38 MB of payload data to client #162 (simulated).
[INFO][05:40:23]: [Client #162] Selected by the server.
[INFO][05:40:23]: [Client #162] Loading its data source...
[INFO][05:40:23]: [Client #162] Dataset size: 2018
[INFO][05:40:23]: [Client #162] Sampler: iid
[INFO][05:40:24]: [Client #162] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:40:24]: [Client #162] Start to process inbound data.
[INFO][05:40:25]: [93m[1m[Client #162] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.83s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.6117073694864907,)
[INFO][05:41:05]: [Client #162] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_162_3995237.pth.
{'train_runtime': 32.9773, 'train_samples_per_second': 183.581, 'train_steps_per_second': 2.911, 'train_loss': 3.6117073694864907, 'epoch': 3.0}
[INFO][05:41:05]: [Client #162] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_162_3995237.pth.
[INFO][05:41:06]: [Client #162] Model trained.
[INFO][05:41:06]: [Client #162] Inbound data has been processed.
[INFO][05:41:06]: [Client #162] Outbound data is ready to be sent after being processed.
[INFO][05:41:10]: [Client #162] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:41:11]: [Server #3995185] Received 507.38 MB of payload data from client #162 (simulated).
[INFO][05:41:11]: [Server #3995185] Selecting client #155 for training.
[INFO][05:41:11]: [Server #3995185] Sending the current model to client #155 (simulated).
[INFO][05:41:15]: [Server #3995185] Sending 507.38 MB of payload data to client #155 (simulated).
[INFO][05:41:15]: [Client #155] Selected by the server.
[INFO][05:41:15]: [Client #155] Loading its data source...
[INFO][05:41:15]: [Client #155] Dataset size: 2018
[INFO][05:41:15]: [Client #155] Sampler: iid
[INFO][05:41:16]: [Client #155] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:41:16]: [Client #155] Start to process inbound data.
[INFO][05:41:16]: [93m[1m[Client #155] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5459553400675454,)
[INFO][05:41:55]: [Client #155] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_155_3995237.pth.
{'train_runtime': 32.4696, 'train_samples_per_second': 186.451, 'train_steps_per_second': 2.957, 'train_loss': 3.5459553400675454, 'epoch': 3.0}
[INFO][05:41:56]: [Client #155] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_155_3995237.pth.
[INFO][05:41:56]: [Client #155] Model trained.
[INFO][05:41:56]: [Client #155] Inbound data has been processed.
[INFO][05:41:56]: [Client #155] Outbound data is ready to be sent after being processed.
[INFO][05:42:00]: [Client #155] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:42:01]: [Server #3995185] Received 507.38 MB of payload data from client #155 (simulated).
[INFO][05:42:01]: [Server #3995185] Selecting client #59 for training.
[INFO][05:42:01]: [Server #3995185] Sending the current model to client #59 (simulated).
[INFO][05:42:05]: [Server #3995185] Sending 507.38 MB of payload data to client #59 (simulated).
[INFO][05:42:05]: [Client #59] Selected by the server.
[INFO][05:42:05]: [Client #59] Loading its data source...
[INFO][05:42:05]: [Client #59] Dataset size: 2018
[INFO][05:42:05]: [Client #59] Sampler: iid
[INFO][05:42:06]: [Client #59] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:42:06]: [Client #59] Start to process inbound data.
[INFO][05:42:06]: [93m[1m[Client #59] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:56,  1.85s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.48it/s]  4%|â–         | 4/96 [00:02<00:49,  1.85it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.15it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.38it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.55it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.67it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.77it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.83it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.97it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.97it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.43it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.96it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.96it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.96it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.95it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.95it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.94it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.95it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.95it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.541581471761068,)
[INFO][05:42:46]: [Client #59] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_59_3995237.pth.
{'train_runtime': 33.2948, 'train_samples_per_second': 181.83, 'train_steps_per_second': 2.883, 'train_loss': 3.541581471761068, 'epoch': 3.0}
[INFO][05:42:47]: [Client #59] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_59_3995237.pth.
[INFO][05:42:48]: [Client #59] Model trained.
[INFO][05:42:48]: [Client #59] Inbound data has been processed.
[INFO][05:42:48]: [Client #59] Outbound data is ready to be sent after being processed.
[INFO][05:42:53]: [Client #59] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:42:54]: [Server #3995185] Received 507.38 MB of payload data from client #59 (simulated).
[INFO][05:42:54]: [Server #3995185] Selecting client #130 for training.
[INFO][05:42:54]: [Server #3995185] Sending the current model to client #130 (simulated).
[INFO][05:42:58]: [Server #3995185] Sending 507.38 MB of payload data to client #130 (simulated).
[INFO][05:42:58]: [Client #130] Selected by the server.
[INFO][05:42:58]: [Client #130] Loading its data source...
[INFO][05:42:58]: [Client #130] Dataset size: 2018
[INFO][05:42:58]: [Client #130] Sampler: iid
[INFO][05:42:59]: [Client #130] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:42:59]: [Client #130] Start to process inbound data.
[INFO][05:43:00]: [93m[1m[Client #130] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5761807759602866,)
[INFO][05:43:39]: [Client #130] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_130_3995237.pth.
{'train_runtime': 32.8309, 'train_samples_per_second': 184.4, 'train_steps_per_second': 2.924, 'train_loss': 3.5761807759602866, 'epoch': 3.0}
[INFO][05:43:40]: [Client #130] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_130_3995237.pth.
[INFO][05:43:41]: [Client #130] Model trained.
[INFO][05:43:41]: [Client #130] Inbound data has been processed.
[INFO][05:43:41]: [Client #130] Outbound data is ready to be sent after being processed.
[INFO][05:43:45]: [Client #130] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:43:46]: [Server #3995185] Received 507.38 MB of payload data from client #130 (simulated).
[INFO][05:43:46]: [Server #3995185] Selecting client #146 for training.
[INFO][05:43:46]: [Server #3995185] Sending the current model to client #146 (simulated).
[INFO][05:43:50]: [Server #3995185] Sending 507.38 MB of payload data to client #146 (simulated).
[INFO][05:43:50]: [Client #146] Selected by the server.
[INFO][05:43:50]: [Client #146] Loading its data source...
[INFO][05:43:50]: [Client #146] Dataset size: 2018
[INFO][05:43:50]: [Client #146] Sampler: iid
[INFO][05:43:52]: [Client #146] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:43:52]: [Client #146] Start to process inbound data.
[INFO][05:43:52]: [93m[1m[Client #146] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:24,  1.52s/it]  2%|â–         | 2/96 [00:01<01:17,  1.22it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.98it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.97it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5905577341715493,)
[INFO][05:44:31]: [Client #146] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_146_3995237.pth.
{'train_runtime': 32.9699, 'train_samples_per_second': 183.622, 'train_steps_per_second': 2.912, 'train_loss': 3.5905577341715493, 'epoch': 3.0}
[INFO][05:44:32]: [Client #146] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_146_3995237.pth.
[INFO][05:44:32]: [Client #146] Model trained.
[INFO][05:44:32]: [Client #146] Inbound data has been processed.
[INFO][05:44:32]: [Client #146] Outbound data is ready to be sent after being processed.
[INFO][05:44:37]: [Client #146] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:44:38]: [Server #3995185] Received 507.38 MB of payload data from client #146 (simulated).
[INFO][05:44:38]: [Server #3995185] Selecting client #51 for training.
[INFO][05:44:38]: [Server #3995185] Sending the current model to client #51 (simulated).
[INFO][05:44:42]: [Server #3995185] Sending 507.38 MB of payload data to client #51 (simulated).
[INFO][05:44:42]: [Client #51] Selected by the server.
[INFO][05:44:42]: [Client #51] Loading its data source...
[INFO][05:44:42]: [Client #51] Dataset size: 2018
[INFO][05:44:42]: [Client #51] Sampler: iid
[INFO][05:44:43]: [Client #51] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:44:43]: [Client #51] Start to process inbound data.
[INFO][05:44:44]: [93m[1m[Client #51] Started training in communication round #10.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.94it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5625432332356772,)
[INFO][05:45:23]: [Client #51] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_51_3995237.pth.
{'train_runtime': 32.9338, 'train_samples_per_second': 183.823, 'train_steps_per_second': 2.915, 'train_loss': 3.5625432332356772, 'epoch': 3.0}
[INFO][05:45:24]: [Client #51] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_51_3995237.pth.
[INFO][05:45:25]: [Client #51] Model trained.
[INFO][05:45:25]: [Client #51] Inbound data has been processed.
[INFO][05:45:25]: [Client #51] Outbound data is ready to be sent after being processed.
[INFO][05:45:29]: [Client #51] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:45:30]: [Server #3995185] Received 507.38 MB of payload data from client #51 (simulated).
[INFO][05:45:30]: [Server #3995185] Adding client #179 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #180 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #196 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #66 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #59 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #113 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #162 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #105 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Adding client #130 to the list of clients for aggregation.
[INFO][05:45:30]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:45:30]: [Server #3995185] Updated weights have been received.
[INFO][05:45:32]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:45:33]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:45:33]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.03it/s]
[INFO][05:45:42]: [93m[1m[Server #3995185] Global model perplexity: 32.25
[0m
[INFO][05:45:42]: [Server #3995185] All client reports have been processed.
[INFO][05:45:42]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_10.pth.
[INFO][05:45:45]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_10.pth.
[INFO][05:45:45]: [93m[1m
[Server #3995185] Starting round 11/50.[0m
[INFO][05:45:45]: [Server #3995185] Selected clients: [33, 5, 24, 178, 137, 70, 135, 68, 169, 191]
[INFO][05:45:45]: [Server #3995185] Selecting client #33 for training.
[INFO][05:45:45]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][05:45:49]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][05:45:49]: [Client #33] Selected by the server.
[INFO][05:45:49]: [Client #33] Loading its data source...
[INFO][05:45:49]: [Client #33] Dataset size: 2018
[INFO][05:45:49]: [Client #33] Sampler: iid
[INFO][05:45:51]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:45:51]: [Client #33] Start to process inbound data.
[INFO][05:45:51]: [93m[1m[Client #33] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4745006561279297,)
[INFO][05:46:30]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 32.808, 'train_samples_per_second': 184.528, 'train_steps_per_second': 2.926, 'train_loss': 3.4745006561279297, 'epoch': 3.0}
[INFO][05:46:31]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][05:46:31]: [Client #33] Model trained.
[INFO][05:46:31]: [Client #33] Inbound data has been processed.
[INFO][05:46:31]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][05:46:35]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:46:37]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][05:46:37]: [Server #3995185] Selecting client #5 for training.
[INFO][05:46:37]: [Server #3995185] Sending the current model to client #5 (simulated).
[INFO][05:46:40]: [Server #3995185] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][05:46:40]: [Client #5] Selected by the server.
[INFO][05:46:40]: [Client #5] Loading its data source...
[INFO][05:46:40]: [Client #5] Dataset size: 2018
[INFO][05:46:40]: [Client #5] Sampler: iid
[INFO][05:46:42]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:46:42]: [Client #5] Start to process inbound data.
[INFO][05:46:42]: [93m[1m[Client #5] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:29,  1.57s/it]  2%|â–         | 2/96 [00:01<01:18,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4844792683919272,)
[INFO][05:47:20]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
{'train_runtime': 32.5608, 'train_samples_per_second': 185.929, 'train_steps_per_second': 2.948, 'train_loss': 3.4844792683919272, 'epoch': 3.0}
[INFO][05:47:21]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
[INFO][05:47:21]: [Client #5] Model trained.
[INFO][05:47:21]: [Client #5] Inbound data has been processed.
[INFO][05:47:21]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][05:47:26]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:47:27]: [Server #3995185] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][05:47:27]: [Server #3995185] Selecting client #24 for training.
[INFO][05:47:27]: [Server #3995185] Sending the current model to client #24 (simulated).
[INFO][05:47:32]: [Server #3995185] Sending 507.38 MB of payload data to client #24 (simulated).
[INFO][05:47:32]: [Client #24] Selected by the server.
[INFO][05:47:32]: [Client #24] Loading its data source...
[INFO][05:47:32]: [Client #24] Dataset size: 2018
[INFO][05:47:32]: [Client #24] Sampler: iid
[INFO][05:47:33]: [Client #24] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:47:33]: [Client #24] Start to process inbound data.
[INFO][05:47:33]: [93m[1m[Client #24] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:54,  1.83s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.85it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.15it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.38it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.97it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.97it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.97it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.42it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.513703982035319,)
[INFO][05:48:13]: [Client #24] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_24_3995237.pth.
{'train_runtime': 33.1064, 'train_samples_per_second': 182.865, 'train_steps_per_second': 2.9, 'train_loss': 3.513703982035319, 'epoch': 3.0}
[INFO][05:48:14]: [Client #24] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_24_3995237.pth.
[INFO][05:48:14]: [Client #24] Model trained.
[INFO][05:48:14]: [Client #24] Inbound data has been processed.
[INFO][05:48:14]: [Client #24] Outbound data is ready to be sent after being processed.
[INFO][05:48:19]: [Client #24] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:48:20]: [Server #3995185] Received 507.38 MB of payload data from client #24 (simulated).
[INFO][05:48:20]: [Server #3995185] Selecting client #178 for training.
[INFO][05:48:20]: [Server #3995185] Sending the current model to client #178 (simulated).
[INFO][05:48:24]: [Server #3995185] Sending 507.38 MB of payload data to client #178 (simulated).
[INFO][05:48:24]: [Client #178] Selected by the server.
[INFO][05:48:24]: [Client #178] Loading its data source...
[INFO][05:48:24]: [Client #178] Dataset size: 2018
[INFO][05:48:24]: [Client #178] Sampler: iid
[INFO][05:48:26]: [Client #178] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:48:26]: [Client #178] Start to process inbound data.
[INFO][05:48:26]: [93m[1m[Client #178] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:41,  1.70s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.94it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.94it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.94it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5408862431844077,)
[INFO][05:49:05]: [Client #178] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_178_3995237.pth.
{'train_runtime': 33.0472, 'train_samples_per_second': 183.193, 'train_steps_per_second': 2.905, 'train_loss': 3.5408862431844077, 'epoch': 3.0}
[INFO][05:49:06]: [Client #178] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_178_3995237.pth.
[INFO][05:49:06]: [Client #178] Model trained.
[INFO][05:49:06]: [Client #178] Inbound data has been processed.
[INFO][05:49:06]: [Client #178] Outbound data is ready to be sent after being processed.
[INFO][05:49:11]: [Client #178] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:49:12]: [Server #3995185] Received 507.38 MB of payload data from client #178 (simulated).
[INFO][05:49:12]: [Server #3995185] Selecting client #137 for training.
[INFO][05:49:12]: [Server #3995185] Sending the current model to client #137 (simulated).
[INFO][05:49:15]: [Server #3995185] Sending 507.38 MB of payload data to client #137 (simulated).
[INFO][05:49:15]: [Client #137] Selected by the server.
[INFO][05:49:15]: [Client #137] Loading its data source...
[INFO][05:49:15]: [Client #137] Dataset size: 2018
[INFO][05:49:15]: [Client #137] Sampler: iid
[INFO][05:49:17]: [Client #137] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:49:17]: [Client #137] Start to process inbound data.
[INFO][05:49:17]: [93m[1m[Client #137] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:25,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.97it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.96it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.485409418741862,)
[INFO][05:49:56]: [Client #137] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_137_3995237.pth.
{'train_runtime': 33.0305, 'train_samples_per_second': 183.285, 'train_steps_per_second': 2.906, 'train_loss': 3.485409418741862, 'epoch': 3.0}
[INFO][05:49:57]: [Client #137] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_137_3995237.pth.
[INFO][05:49:57]: [Client #137] Model trained.
[INFO][05:49:57]: [Client #137] Inbound data has been processed.
[INFO][05:49:57]: [Client #137] Outbound data is ready to be sent after being processed.
[INFO][05:50:01]: [Client #137] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:50:02]: [Server #3995185] Received 507.38 MB of payload data from client #137 (simulated).
[INFO][05:50:02]: [Server #3995185] Selecting client #70 for training.
[INFO][05:50:02]: [Server #3995185] Sending the current model to client #70 (simulated).
[INFO][05:50:06]: [Server #3995185] Sending 507.38 MB of payload data to client #70 (simulated).
[INFO][05:50:06]: [Client #70] Selected by the server.
[INFO][05:50:06]: [Client #70] Loading its data source...
[INFO][05:50:06]: [Client #70] Dataset size: 2018
[INFO][05:50:06]: [Client #70] Sampler: iid
[INFO][05:50:08]: [Client #70] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:50:08]: [Client #70] Start to process inbound data.
[INFO][05:50:08]: [93m[1m[Client #70] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:57,  1.86s/it]  2%|â–         | 2/96 [00:02<01:29,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.86it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.51108455657959,)
[INFO][05:50:48]: [Client #70] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_70_3995237.pth.
{'train_runtime': 33.1282, 'train_samples_per_second': 182.745, 'train_steps_per_second': 2.898, 'train_loss': 3.51108455657959, 'epoch': 3.0}
[INFO][05:50:49]: [Client #70] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_70_3995237.pth.
[INFO][05:50:50]: [Client #70] Model trained.
[INFO][05:50:50]: [Client #70] Inbound data has been processed.
[INFO][05:50:50]: [Client #70] Outbound data is ready to be sent after being processed.
[INFO][05:50:54]: [Client #70] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:50:55]: [Server #3995185] Received 507.38 MB of payload data from client #70 (simulated).
[INFO][05:50:55]: [Server #3995185] Selecting client #135 for training.
[INFO][05:50:55]: [Server #3995185] Sending the current model to client #135 (simulated).
[INFO][05:51:03]: [Server #3995185] Sending 507.38 MB of payload data to client #135 (simulated).
[INFO][05:51:03]: [Client #135] Selected by the server.
[INFO][05:51:03]: [Client #135] Loading its data source...
[INFO][05:51:03]: [Client #135] Dataset size: 2018
[INFO][05:51:03]: [Client #135] Sampler: iid
[INFO][05:51:04]: [Client #135] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:51:04]: [Client #135] Start to process inbound data.
[INFO][05:51:04]: [93m[1m[Client #135] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:29,  1.57s/it]  2%|â–         | 2/96 [00:01<01:18,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.07it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.06it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4772974650065103,)
[INFO][05:51:43]: [Client #135] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_135_3995237.pth.
{'train_runtime': 32.2342, 'train_samples_per_second': 187.813, 'train_steps_per_second': 2.978, 'train_loss': 3.4772974650065103, 'epoch': 3.0}
[INFO][05:51:44]: [Client #135] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_135_3995237.pth.
[INFO][05:51:44]: [Client #135] Model trained.
[INFO][05:51:44]: [Client #135] Inbound data has been processed.
[INFO][05:51:44]: [Client #135] Outbound data is ready to be sent after being processed.
[INFO][05:51:49]: [Client #135] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:51:50]: [Server #3995185] Received 507.38 MB of payload data from client #135 (simulated).
[INFO][05:51:50]: [Server #3995185] Selecting client #68 for training.
[INFO][05:51:50]: [Server #3995185] Sending the current model to client #68 (simulated).
[INFO][05:51:54]: [Server #3995185] Sending 507.38 MB of payload data to client #68 (simulated).
[INFO][05:51:54]: [Client #68] Selected by the server.
[INFO][05:51:54]: [Client #68] Loading its data source...
[INFO][05:51:54]: [Client #68] Dataset size: 2018
[INFO][05:51:54]: [Client #68] Sampler: iid
[INFO][05:51:56]: [Client #68] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:51:56]: [Client #68] Start to process inbound data.
[INFO][05:51:56]: [93m[1m[Client #68] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.32it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5422681172688804,)
[INFO][05:52:35]: [Client #68] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_68_3995237.pth.
{'train_runtime': 32.4357, 'train_samples_per_second': 186.646, 'train_steps_per_second': 2.96, 'train_loss': 3.5422681172688804, 'epoch': 3.0}
[INFO][05:52:35]: [Client #68] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_68_3995237.pth.
[INFO][05:52:36]: [Client #68] Model trained.
[INFO][05:52:36]: [Client #68] Inbound data has been processed.
[INFO][05:52:36]: [Client #68] Outbound data is ready to be sent after being processed.
[INFO][05:52:40]: [Client #68] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:52:41]: [Server #3995185] Received 507.38 MB of payload data from client #68 (simulated).
[INFO][05:52:41]: [Server #3995185] Selecting client #169 for training.
[INFO][05:52:41]: [Server #3995185] Sending the current model to client #169 (simulated).
[INFO][05:52:45]: [Server #3995185] Sending 507.38 MB of payload data to client #169 (simulated).
[INFO][05:52:45]: [Client #169] Selected by the server.
[INFO][05:52:45]: [Client #169] Loading its data source...
[INFO][05:52:45]: [Client #169] Dataset size: 2018
[INFO][05:52:45]: [Client #169] Sampler: iid
[INFO][05:52:46]: [Client #169] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:52:46]: [Client #169] Start to process inbound data.
[INFO][05:52:47]: [93m[1m[Client #169] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.03it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.01it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.96it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4792709350585938,)
[INFO][05:53:26]: [Client #169] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_169_3995237.pth.
{'train_runtime': 33.0041, 'train_samples_per_second': 183.432, 'train_steps_per_second': 2.909, 'train_loss': 3.4792709350585938, 'epoch': 3.0}
[INFO][05:53:27]: [Client #169] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_169_3995237.pth.
[INFO][05:53:28]: [Client #169] Model trained.
[INFO][05:53:28]: [Client #169] Inbound data has been processed.
[INFO][05:53:28]: [Client #169] Outbound data is ready to be sent after being processed.
[INFO][05:53:32]: [Client #169] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:53:33]: [Server #3995185] Received 507.38 MB of payload data from client #169 (simulated).
[INFO][05:53:33]: [Server #3995185] Selecting client #191 for training.
[INFO][05:53:33]: [Server #3995185] Sending the current model to client #191 (simulated).
[INFO][05:53:38]: [Server #3995185] Sending 507.38 MB of payload data to client #191 (simulated).
[INFO][05:53:38]: [Client #191] Selected by the server.
[INFO][05:53:38]: [Client #191] Loading its data source...
[INFO][05:53:38]: [Client #191] Dataset size: 2018
[INFO][05:53:38]: [Client #191] Sampler: iid
[INFO][05:53:39]: [Client #191] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:53:39]: [Client #191] Start to process inbound data.
[INFO][05:53:39]: [93m[1m[Client #191] Started training in communication round #11.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.32it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.11it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.11it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.11it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.11it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.12it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.12it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.16it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.15it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.14it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.13it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.13it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.12it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.11it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.11it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.11it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.11it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.11it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.10it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.10it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.09it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.10it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.10it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:10,  3.09it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.10it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.54it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.29it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.23it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.14it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.11it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.11it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.11it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.10it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.09it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.09it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.09it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.08it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.08it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.08it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.08it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.08it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.08it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.08it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.08it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.07it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.01it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4933818181355796,)
[INFO][05:54:18]: [Client #191] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_191_3995237.pth.
{'train_runtime': 31.8874, 'train_samples_per_second': 189.856, 'train_steps_per_second': 3.011, 'train_loss': 3.4933818181355796, 'epoch': 3.0}
[INFO][05:54:19]: [Client #191] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_191_3995237.pth.
[INFO][05:54:20]: [Client #191] Model trained.
[INFO][05:54:20]: [Client #191] Inbound data has been processed.
[INFO][05:54:20]: [Client #191] Outbound data is ready to be sent after being processed.
[INFO][05:54:24]: [Client #191] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:54:25]: [Server #3995185] Received 507.38 MB of payload data from client #191 (simulated).
[INFO][05:54:25]: [Server #3995185] Adding client #5 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #70 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #12 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #22 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #44 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #65 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #86 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #124 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Adding client #181 to the list of clients for aggregation.
[INFO][05:54:25]: [Server #3995185] Aggregating 10 clients in total.
[INFO][05:54:25]: [Server #3995185] Updated weights have been received.
[INFO][05:54:26]: [Server #3995185] Aggregating model weight deltas.
[INFO][05:54:27]: [Server #3995185] Finished aggregating updated weights.
[INFO][05:54:27]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.07it/s]
[INFO][05:54:36]: [93m[1m[Server #3995185] Global model perplexity: 32.12
[0m
[INFO][05:54:36]: [Server #3995185] All client reports have been processed.
[INFO][05:54:36]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_11.pth.
[INFO][05:54:40]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_11.pth.
[INFO][05:54:40]: [93m[1m
[Server #3995185] Starting round 12/50.[0m
[INFO][05:54:40]: [Server #3995185] Selected clients: [89, 85, 41, 49, 94, 67, 174, 43, 28, 159]
[INFO][05:54:40]: [Server #3995185] Selecting client #89 for training.
[INFO][05:54:40]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][05:54:46]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][05:54:46]: [Client #89] Selected by the server.
[INFO][05:54:46]: [Client #89] Loading its data source...
[INFO][05:54:46]: [Client #89] Dataset size: 2018
[INFO][05:54:46]: [Client #89] Sampler: iid
[INFO][05:54:48]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:54:48]: [Client #89] Start to process inbound data.
[INFO][05:54:48]: [93m[1m[Client #89] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.61it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.76it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.87it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.09it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.11it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.11it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.29it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.15it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.457489331563314,)
[INFO][05:55:26]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 31.9862, 'train_samples_per_second': 189.269, 'train_steps_per_second': 3.001, 'train_loss': 3.457489331563314, 'epoch': 3.0}
[INFO][05:55:27]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][05:55:27]: [Client #89] Model trained.
[INFO][05:55:27]: [Client #89] Inbound data has been processed.
[INFO][05:55:27]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][05:55:34]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:55:36]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][05:55:36]: [Server #3995185] Selecting client #85 for training.
[INFO][05:55:36]: [Server #3995185] Sending the current model to client #85 (simulated).
[INFO][05:55:40]: [Server #3995185] Sending 507.38 MB of payload data to client #85 (simulated).
[INFO][05:55:40]: [Client #85] Selected by the server.
[INFO][05:55:40]: [Client #85] Loading its data source...
[INFO][05:55:40]: [Client #85] Dataset size: 2018
[INFO][05:55:40]: [Client #85] Sampler: iid
[INFO][05:55:42]: [Client #85] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:55:42]: [Client #85] Start to process inbound data.
[INFO][05:55:42]: [93m[1m[Client #85] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.68it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.77it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.83it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.96it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.98it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.98it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.97it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.97it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5009711583455405,)
[INFO][05:56:22]: [Client #85] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
{'train_runtime': 33.2037, 'train_samples_per_second': 182.329, 'train_steps_per_second': 2.891, 'train_loss': 3.5009711583455405, 'epoch': 3.0}
[INFO][05:56:23]: [Client #85] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
[INFO][05:56:23]: [Client #85] Model trained.
[INFO][05:56:23]: [Client #85] Inbound data has been processed.
[INFO][05:56:23]: [Client #85] Outbound data is ready to be sent after being processed.
[INFO][05:56:30]: [Client #85] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:56:31]: [Server #3995185] Received 507.38 MB of payload data from client #85 (simulated).
[INFO][05:56:31]: [Server #3995185] Selecting client #41 for training.
[INFO][05:56:31]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][05:56:35]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][05:56:35]: [Client #41] Selected by the server.
[INFO][05:56:35]: [Client #41] Loading its data source...
[INFO][05:56:35]: [Client #41] Dataset size: 2018
[INFO][05:56:35]: [Client #41] Sampler: iid
[INFO][05:56:36]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:56:36]: [Client #41] Start to process inbound data.
[INFO][05:56:36]: [93m[1m[Client #41] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:56,  1.86s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5000009536743164,)
[INFO][05:57:16]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 33.0197, 'train_samples_per_second': 183.345, 'train_steps_per_second': 2.907, 'train_loss': 3.5000009536743164, 'epoch': 3.0}
[INFO][05:57:17]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][05:57:17]: [Client #41] Model trained.
[INFO][05:57:17]: [Client #41] Inbound data has been processed.
[INFO][05:57:17]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][05:57:21]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:57:22]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][05:57:22]: [Server #3995185] Selecting client #49 for training.
[INFO][05:57:22]: [Server #3995185] Sending the current model to client #49 (simulated).
[INFO][05:57:26]: [Server #3995185] Sending 507.38 MB of payload data to client #49 (simulated).
[INFO][05:57:26]: [Client #49] Selected by the server.
[INFO][05:57:26]: [Client #49] Loading its data source...
[INFO][05:57:26]: [Client #49] Dataset size: 2018
[INFO][05:57:26]: [Client #49] Sampler: iid
[INFO][05:57:27]: [Client #49] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:57:27]: [Client #49] Start to process inbound data.
[INFO][05:57:27]: [93m[1m[Client #49] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:54,  1.83s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5084718068440757,)
[INFO][05:58:07]: [Client #49] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_49_3995237.pth.
{'train_runtime': 32.8507, 'train_samples_per_second': 184.288, 'train_steps_per_second': 2.922, 'train_loss': 3.5084718068440757, 'epoch': 3.0}
[INFO][05:58:08]: [Client #49] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_49_3995237.pth.
[INFO][05:58:08]: [Client #49] Model trained.
[INFO][05:58:08]: [Client #49] Inbound data has been processed.
[INFO][05:58:08]: [Client #49] Outbound data is ready to be sent after being processed.
[INFO][05:58:12]: [Client #49] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:58:13]: [Server #3995185] Received 507.38 MB of payload data from client #49 (simulated).
[INFO][05:58:13]: [Server #3995185] Selecting client #94 for training.
[INFO][05:58:13]: [Server #3995185] Sending the current model to client #94 (simulated).
[INFO][05:58:18]: [Server #3995185] Sending 507.38 MB of payload data to client #94 (simulated).
[INFO][05:58:18]: [Client #94] Selected by the server.
[INFO][05:58:18]: [Client #94] Loading its data source...
[INFO][05:58:18]: [Client #94] Dataset size: 2018
[INFO][05:58:18]: [Client #94] Sampler: iid
[INFO][05:58:19]: [Client #94] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:58:19]: [Client #94] Start to process inbound data.
[INFO][05:58:19]: [93m[1m[Client #94] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.93it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.93it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.38it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.497494379679362,)
[INFO][05:58:58]: [Client #94] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_94_3995237.pth.
{'train_runtime': 32.4693, 'train_samples_per_second': 186.453, 'train_steps_per_second': 2.957, 'train_loss': 3.497494379679362, 'epoch': 3.0}
[INFO][05:58:59]: [Client #94] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_94_3995237.pth.
[INFO][05:58:59]: [Client #94] Model trained.
[INFO][05:58:59]: [Client #94] Inbound data has been processed.
[INFO][05:58:59]: [Client #94] Outbound data is ready to be sent after being processed.
[INFO][05:59:03]: [Client #94] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:59:04]: [Server #3995185] Received 507.38 MB of payload data from client #94 (simulated).
[INFO][05:59:04]: [Server #3995185] Selecting client #67 for training.
[INFO][05:59:04]: [Server #3995185] Sending the current model to client #67 (simulated).
[INFO][05:59:08]: [Server #3995185] Sending 507.38 MB of payload data to client #67 (simulated).
[INFO][05:59:08]: [Client #67] Selected by the server.
[INFO][05:59:08]: [Client #67] Loading its data source...
[INFO][05:59:08]: [Client #67] Dataset size: 2018
[INFO][05:59:08]: [Client #67] Sampler: iid
[INFO][05:59:10]: [Client #67] Received 507.38 MB of payload data from the server (simulated).
[INFO][05:59:10]: [Client #67] Start to process inbound data.
[INFO][05:59:10]: [93m[1m[Client #67] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.83s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4834934870402017,)
[INFO][05:59:49]: [Client #67] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_67_3995237.pth.
{'train_runtime': 32.9463, 'train_samples_per_second': 183.754, 'train_steps_per_second': 2.914, 'train_loss': 3.4834934870402017, 'epoch': 3.0}
[INFO][05:59:50]: [Client #67] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_67_3995237.pth.
[INFO][05:59:50]: [Client #67] Model trained.
[INFO][05:59:50]: [Client #67] Inbound data has been processed.
[INFO][05:59:50]: [Client #67] Outbound data is ready to be sent after being processed.
[INFO][05:59:56]: [Client #67] Sent 507.38 MB of payload data to the server (simulated).
[INFO][05:59:57]: [Server #3995185] Received 507.38 MB of payload data from client #67 (simulated).
[INFO][05:59:57]: [Server #3995185] Selecting client #174 for training.
[INFO][05:59:57]: [Server #3995185] Sending the current model to client #174 (simulated).
[INFO][06:00:03]: [Server #3995185] Sending 507.38 MB of payload data to client #174 (simulated).
[INFO][06:00:03]: [Client #174] Selected by the server.
[INFO][06:00:03]: [Client #174] Loading its data source...
[INFO][06:00:03]: [Client #174] Dataset size: 2018
[INFO][06:00:03]: [Client #174] Sampler: iid
[INFO][06:00:05]: [Client #174] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:00:05]: [Client #174] Start to process inbound data.
[INFO][06:00:05]: [93m[1m[Client #174] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.94it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:25,  2.96it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.97it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.97it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.97it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.97it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.42it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.10it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.06it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  2.99it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.98it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.98it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.96it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.97it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.491395950317383,)
[INFO][06:00:45]: [Client #174] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_174_3995237.pth.
{'train_runtime': 33.2388, 'train_samples_per_second': 182.136, 'train_steps_per_second': 2.888, 'train_loss': 3.491395950317383, 'epoch': 3.0}
[INFO][06:00:46]: [Client #174] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_174_3995237.pth.
[INFO][06:00:46]: [Client #174] Model trained.
[INFO][06:00:46]: [Client #174] Inbound data has been processed.
[INFO][06:00:46]: [Client #174] Outbound data is ready to be sent after being processed.
[INFO][06:00:53]: [Client #174] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:00:55]: [Server #3995185] Received 507.38 MB of payload data from client #174 (simulated).
[INFO][06:00:55]: [Server #3995185] Selecting client #43 for training.
[INFO][06:00:55]: [Server #3995185] Sending the current model to client #43 (simulated).
[INFO][06:00:59]: [Server #3995185] Sending 507.38 MB of payload data to client #43 (simulated).
[INFO][06:00:59]: [Client #43] Selected by the server.
[INFO][06:00:59]: [Client #43] Loading its data source...
[INFO][06:00:59]: [Client #43] Dataset size: 2018
[INFO][06:00:59]: [Client #43] Sampler: iid
[INFO][06:01:01]: [Client #43] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:01:01]: [Client #43] Start to process inbound data.
[INFO][06:01:01]: [93m[1m[Client #43] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.78s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.67it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.77it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5178772608439126,)
[INFO][06:01:40]: [Client #43] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
{'train_runtime': 32.8527, 'train_samples_per_second': 184.277, 'train_steps_per_second': 2.922, 'train_loss': 3.5178772608439126, 'epoch': 3.0}
[INFO][06:01:41]: [Client #43] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
[INFO][06:01:41]: [Client #43] Model trained.
[INFO][06:01:41]: [Client #43] Inbound data has been processed.
[INFO][06:01:41]: [Client #43] Outbound data is ready to be sent after being processed.
[INFO][06:01:46]: [Client #43] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:01:47]: [Server #3995185] Received 507.38 MB of payload data from client #43 (simulated).
[INFO][06:01:47]: [Server #3995185] Selecting client #28 for training.
[INFO][06:01:47]: [Server #3995185] Sending the current model to client #28 (simulated).
[INFO][06:01:52]: [Server #3995185] Sending 507.38 MB of payload data to client #28 (simulated).
[INFO][06:01:52]: [Client #28] Selected by the server.
[INFO][06:01:52]: [Client #28] Loading its data source...
[INFO][06:01:52]: [Client #28] Dataset size: 2018
[INFO][06:01:52]: [Client #28] Sampler: iid
[INFO][06:01:53]: [Client #28] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:01:53]: [Client #28] Start to process inbound data.
[INFO][06:01:53]: [93m[1m[Client #28] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:55,  1.85s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.95it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.94it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.94it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.495544115702311,)
[INFO][06:02:33]: [Client #28] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_28_3995237.pth.
{'train_runtime': 33.0815, 'train_samples_per_second': 183.003, 'train_steps_per_second': 2.902, 'train_loss': 3.495544115702311, 'epoch': 3.0}
[INFO][06:02:34]: [Client #28] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_28_3995237.pth.
[INFO][06:02:34]: [Client #28] Model trained.
[INFO][06:02:34]: [Client #28] Inbound data has been processed.
[INFO][06:02:34]: [Client #28] Outbound data is ready to be sent after being processed.
[INFO][06:02:39]: [Client #28] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:02:40]: [Server #3995185] Received 507.38 MB of payload data from client #28 (simulated).
[INFO][06:02:40]: [Server #3995185] Selecting client #159 for training.
[INFO][06:02:40]: [Server #3995185] Sending the current model to client #159 (simulated).
[INFO][06:02:45]: [Server #3995185] Sending 507.38 MB of payload data to client #159 (simulated).
[INFO][06:02:45]: [Client #159] Selected by the server.
[INFO][06:02:45]: [Client #159] Loading its data source...
[INFO][06:02:45]: [Client #159] Dataset size: 2018
[INFO][06:02:45]: [Client #159] Sampler: iid
[INFO][06:02:47]: [Client #159] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:02:47]: [Client #159] Start to process inbound data.
[INFO][06:02:47]: [93m[1m[Client #159] Started training in communication round #12.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:35,  1.64s/it]  2%|â–         | 2/96 [00:01<01:21,  1.15it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.5153605143229165,)
[INFO][06:03:27]: [Client #159] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_159_3995237.pth.
{'train_runtime': 32.6687, 'train_samples_per_second': 185.315, 'train_steps_per_second': 2.939, 'train_loss': 3.5153605143229165, 'epoch': 3.0}
[INFO][06:03:28]: [Client #159] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_159_3995237.pth.
[INFO][06:03:29]: [Client #159] Model trained.
[INFO][06:03:29]: [Client #159] Inbound data has been processed.
[INFO][06:03:29]: [Client #159] Outbound data is ready to be sent after being processed.
[INFO][06:03:33]: [Client #159] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:03:35]: [Server #3995185] Received 507.38 MB of payload data from client #159 (simulated).
[INFO][06:03:35]: [Server #3995185] Adding client #178 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #43 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #85 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #159 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #169 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #94 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #28 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Adding client #51 to the list of clients for aggregation.
[INFO][06:03:35]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:03:35]: [Server #3995185] Updated weights have been received.
[INFO][06:03:36]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:03:37]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:03:37]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.31it/s]
[INFO][06:03:46]: [93m[1m[Server #3995185] Global model perplexity: 30.30
[0m
[INFO][06:03:46]: [Server #3995185] All client reports have been processed.
[INFO][06:03:46]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_12.pth.
[INFO][06:03:49]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_12.pth.
[INFO][06:03:49]: [93m[1m
[Server #3995185] Starting round 13/50.[0m
[INFO][06:03:49]: [Server #3995185] Selected clients: [45, 140, 96, 88, 168, 80, 73, 60, 61, 100]
[INFO][06:03:49]: [Server #3995185] Selecting client #45 for training.
[INFO][06:03:49]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][06:03:52]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][06:03:53]: [Client #45] Selected by the server.
[INFO][06:03:53]: [Client #45] Loading its data source...
[INFO][06:03:53]: [Client #45] Dataset size: 2018
[INFO][06:03:53]: [Client #45] Sampler: iid
[INFO][06:03:54]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:03:54]: [Client #45] Start to process inbound data.
[INFO][06:03:54]: [93m[1m[Client #45] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.79s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3806724548339844,)
[INFO][06:04:33]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.5167, 'train_samples_per_second': 186.181, 'train_steps_per_second': 2.952, 'train_loss': 3.3806724548339844, 'epoch': 3.0}
[INFO][06:04:34]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][06:04:34]: [Client #45] Model trained.
[INFO][06:04:34]: [Client #45] Inbound data has been processed.
[INFO][06:04:34]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][06:04:39]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:04:40]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][06:04:40]: [Server #3995185] Selecting client #140 for training.
[INFO][06:04:40]: [Server #3995185] Sending the current model to client #140 (simulated).
[INFO][06:04:44]: [Server #3995185] Sending 507.38 MB of payload data to client #140 (simulated).
[INFO][06:04:44]: [Client #140] Selected by the server.
[INFO][06:04:44]: [Client #140] Loading its data source...
[INFO][06:04:44]: [Client #140] Dataset size: 2018
[INFO][06:04:44]: [Client #140] Sampler: iid
[INFO][06:04:46]: [Client #140] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:04:46]: [Client #140] Start to process inbound data.
[INFO][06:04:47]: [93m[1m[Client #140] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.82s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:49,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.97it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.97it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.98it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.96it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.43it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.27it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.17it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.01it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.97it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.96it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.93it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.95it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.94it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.94it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.94it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.94it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.89it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.440256118774414,)
[INFO][06:05:27]: [Client #140] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_140_3995237.pth.
{'train_runtime': 33.2606, 'train_samples_per_second': 182.017, 'train_steps_per_second': 2.886, 'train_loss': 3.440256118774414, 'epoch': 3.0}
[INFO][06:05:28]: [Client #140] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_140_3995237.pth.
[INFO][06:05:29]: [Client #140] Model trained.
[INFO][06:05:29]: [Client #140] Inbound data has been processed.
[INFO][06:05:29]: [Client #140] Outbound data is ready to be sent after being processed.
[INFO][06:05:34]: [Client #140] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:05:35]: [Server #3995185] Received 507.38 MB of payload data from client #140 (simulated).
[INFO][06:05:35]: [Server #3995185] Selecting client #96 for training.
[INFO][06:05:35]: [Server #3995185] Sending the current model to client #96 (simulated).
[INFO][06:05:39]: [Server #3995185] Sending 507.38 MB of payload data to client #96 (simulated).
[INFO][06:05:39]: [Client #96] Selected by the server.
[INFO][06:05:39]: [Client #96] Loading its data source...
[INFO][06:05:39]: [Client #96] Dataset size: 2018
[INFO][06:05:39]: [Client #96] Sampler: iid
[INFO][06:05:40]: [Client #96] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:05:40]: [Client #96] Start to process inbound data.
[INFO][06:05:41]: [93m[1m[Client #96] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<03:05,  1.95s/it]  2%|â–         | 2/96 [00:02<01:33,  1.01it/s]  3%|â–Ž         | 3/96 [00:02<01:03,  1.45it/s]  4%|â–         | 4/96 [00:02<00:50,  1.82it/s]  5%|â–Œ         | 5/96 [00:03<00:43,  2.11it/s]  6%|â–‹         | 6/96 [00:03<00:38,  2.36it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.54it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.434593836466471,)
[INFO][06:06:20]: [Client #96] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_96_3995237.pth.
{'train_runtime': 32.9867, 'train_samples_per_second': 183.528, 'train_steps_per_second': 2.91, 'train_loss': 3.434593836466471, 'epoch': 3.0}
[INFO][06:06:21]: [Client #96] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_96_3995237.pth.
[INFO][06:06:22]: [Client #96] Model trained.
[INFO][06:06:22]: [Client #96] Inbound data has been processed.
[INFO][06:06:22]: [Client #96] Outbound data is ready to be sent after being processed.
[INFO][06:06:27]: [Client #96] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:06:28]: [Server #3995185] Received 507.38 MB of payload data from client #96 (simulated).
[INFO][06:06:28]: [Server #3995185] Selecting client #88 for training.
[INFO][06:06:28]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][06:06:32]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][06:06:32]: [Client #88] Selected by the server.
[INFO][06:06:32]: [Client #88] Loading its data source...
[INFO][06:06:32]: [Client #88] Dataset size: 2018
[INFO][06:06:32]: [Client #88] Sampler: iid
[INFO][06:06:34]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:06:34]: [Client #88] Start to process inbound data.
[INFO][06:06:35]: [93m[1m[Client #88] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:51,  1.81s/it]  2%|â–         | 2/96 [00:02<01:28,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:49,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.96it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.96it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.96it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4401369094848633,)
[INFO][06:07:15]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 33.0835, 'train_samples_per_second': 182.992, 'train_steps_per_second': 2.902, 'train_loss': 3.4401369094848633, 'epoch': 3.0}
[INFO][06:07:16]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][06:07:16]: [Client #88] Model trained.
[INFO][06:07:16]: [Client #88] Inbound data has been processed.
[INFO][06:07:16]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][06:07:21]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:07:22]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][06:07:22]: [Server #3995185] Selecting client #168 for training.
[INFO][06:07:22]: [Server #3995185] Sending the current model to client #168 (simulated).
[INFO][06:07:29]: [Server #3995185] Sending 507.38 MB of payload data to client #168 (simulated).
[INFO][06:07:29]: [Client #168] Selected by the server.
[INFO][06:07:29]: [Client #168] Loading its data source...
[INFO][06:07:29]: [Client #168] Dataset size: 2018
[INFO][06:07:29]: [Client #168] Sampler: iid
[INFO][06:07:31]: [Client #168] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:07:31]: [Client #168] Start to process inbound data.
[INFO][06:07:31]: [93m[1m[Client #168] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.06it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.05it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4299885431925454,)
[INFO][06:08:09]: [Client #168] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_168_3995237.pth.
{'train_runtime': 32.1699, 'train_samples_per_second': 188.188, 'train_steps_per_second': 2.984, 'train_loss': 3.4299885431925454, 'epoch': 3.0}
[INFO][06:08:10]: [Client #168] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_168_3995237.pth.
[INFO][06:08:10]: [Client #168] Model trained.
[INFO][06:08:10]: [Client #168] Inbound data has been processed.
[INFO][06:08:10]: [Client #168] Outbound data is ready to be sent after being processed.
[INFO][06:08:15]: [Client #168] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:08:16]: [Server #3995185] Received 507.38 MB of payload data from client #168 (simulated).
[INFO][06:08:16]: [Server #3995185] Selecting client #80 for training.
[INFO][06:08:16]: [Server #3995185] Sending the current model to client #80 (simulated).
[INFO][06:08:22]: [Server #3995185] Sending 507.38 MB of payload data to client #80 (simulated).
[INFO][06:08:22]: [Client #80] Selected by the server.
[INFO][06:08:22]: [Client #80] Loading its data source...
[INFO][06:08:22]: [Client #80] Dataset size: 2018
[INFO][06:08:22]: [Client #80] Sampler: iid
[INFO][06:08:24]: [Client #80] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:08:24]: [Client #80] Start to process inbound data.
[INFO][06:08:24]: [93m[1m[Client #80] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.444406509399414,)
[INFO][06:09:04]: [Client #80] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_80_3995237.pth.
{'train_runtime': 32.9005, 'train_samples_per_second': 184.009, 'train_steps_per_second': 2.918, 'train_loss': 3.444406509399414, 'epoch': 3.0}
[INFO][06:09:05]: [Client #80] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_80_3995237.pth.
[INFO][06:09:05]: [Client #80] Model trained.
[INFO][06:09:05]: [Client #80] Inbound data has been processed.
[INFO][06:09:05]: [Client #80] Outbound data is ready to be sent after being processed.
[INFO][06:09:10]: [Client #80] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:09:11]: [Server #3995185] Received 507.38 MB of payload data from client #80 (simulated).
[INFO][06:09:11]: [Server #3995185] Selecting client #73 for training.
[INFO][06:09:11]: [Server #3995185] Sending the current model to client #73 (simulated).
[INFO][06:09:17]: [Server #3995185] Sending 507.38 MB of payload data to client #73 (simulated).
[INFO][06:09:17]: [Client #73] Selected by the server.
[INFO][06:09:17]: [Client #73] Loading its data source...
[INFO][06:09:17]: [Client #73] Dataset size: 2018
[INFO][06:09:17]: [Client #73] Sampler: iid
[INFO][06:09:18]: [Client #73] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:09:18]: [Client #73] Start to process inbound data.
[INFO][06:09:19]: [93m[1m[Client #73] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.79s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.417440096537272,)
[INFO][06:09:58]: [Client #73] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_73_3995237.pth.
{'train_runtime': 32.5609, 'train_samples_per_second': 185.929, 'train_steps_per_second': 2.948, 'train_loss': 3.417440096537272, 'epoch': 3.0}
[INFO][06:09:59]: [Client #73] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_73_3995237.pth.
[INFO][06:10:00]: [Client #73] Model trained.
[INFO][06:10:00]: [Client #73] Inbound data has been processed.
[INFO][06:10:00]: [Client #73] Outbound data is ready to be sent after being processed.
[INFO][06:10:04]: [Client #73] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:10:06]: [Server #3995185] Received 507.38 MB of payload data from client #73 (simulated).
[INFO][06:10:06]: [Server #3995185] Selecting client #60 for training.
[INFO][06:10:06]: [Server #3995185] Sending the current model to client #60 (simulated).
[INFO][06:10:11]: [Server #3995185] Sending 507.38 MB of payload data to client #60 (simulated).
[INFO][06:10:11]: [Client #60] Selected by the server.
[INFO][06:10:11]: [Client #60] Loading its data source...
[INFO][06:10:11]: [Client #60] Dataset size: 2018
[INFO][06:10:11]: [Client #60] Sampler: iid
[INFO][06:10:13]: [Client #60] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:10:13]: [Client #60] Start to process inbound data.
[INFO][06:10:13]: [93m[1m[Client #60] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:02<03:21,  2.12s/it]  2%|â–         | 2/96 [00:02<01:40,  1.07s/it]  3%|â–Ž         | 3/96 [00:02<01:08,  1.37it/s]  4%|â–         | 4/96 [00:03<00:52,  1.74it/s]  5%|â–Œ         | 5/96 [00:03<00:44,  2.05it/s]  6%|â–‹         | 6/96 [00:03<00:39,  2.30it/s]  7%|â–‹         | 7/96 [00:04<00:35,  2.49it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.64it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.74it/s] 10%|â–ˆ         | 10/96 [00:05<00:30,  2.82it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.92it/s] 14%|â–ˆâ–Ž        | 13/96 [00:06<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:07<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:08<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:09<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:10<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:11<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:12<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.87it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4234015146891275,)
[INFO][06:10:53]: [Client #60] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_60_3995237.pth.
{'train_runtime': 33.4958, 'train_samples_per_second': 180.739, 'train_steps_per_second': 2.866, 'train_loss': 3.4234015146891275, 'epoch': 3.0}
[INFO][06:10:54]: [Client #60] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_60_3995237.pth.
[INFO][06:10:54]: [Client #60] Model trained.
[INFO][06:10:54]: [Client #60] Inbound data has been processed.
[INFO][06:10:54]: [Client #60] Outbound data is ready to be sent after being processed.
[INFO][06:10:59]: [Client #60] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:11:00]: [Server #3995185] Received 507.38 MB of payload data from client #60 (simulated).
[INFO][06:11:00]: [Server #3995185] Selecting client #61 for training.
[INFO][06:11:00]: [Server #3995185] Sending the current model to client #61 (simulated).
[INFO][06:11:07]: [Server #3995185] Sending 507.38 MB of payload data to client #61 (simulated).
[INFO][06:11:07]: [Client #61] Selected by the server.
[INFO][06:11:07]: [Client #61] Loading its data source...
[INFO][06:11:07]: [Client #61] Dataset size: 2018
[INFO][06:11:07]: [Client #61] Sampler: iid
[INFO][06:11:09]: [Client #61] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:11:09]: [Client #61] Start to process inbound data.
[INFO][06:11:09]: [93m[1m[Client #61] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:39,  1.68s/it]  2%|â–         | 2/96 [00:02<01:23,  1.13it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.59it/s]  4%|â–         | 4/96 [00:02<00:46,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.32it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.17it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.16it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.10it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.10it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.10it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.10it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.414519945780436,)
[INFO][06:11:48]: [Client #61] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_61_3995237.pth.
{'train_runtime': 32.4079, 'train_samples_per_second': 186.806, 'train_steps_per_second': 2.962, 'train_loss': 3.414519945780436, 'epoch': 3.0}
[INFO][06:11:49]: [Client #61] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_61_3995237.pth.
[INFO][06:11:49]: [Client #61] Model trained.
[INFO][06:11:49]: [Client #61] Inbound data has been processed.
[INFO][06:11:49]: [Client #61] Outbound data is ready to be sent after being processed.
[INFO][06:11:55]: [Client #61] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:11:56]: [Server #3995185] Received 507.38 MB of payload data from client #61 (simulated).
[INFO][06:11:56]: [Server #3995185] Selecting client #100 for training.
[INFO][06:11:56]: [Server #3995185] Sending the current model to client #100 (simulated).
[INFO][06:12:03]: [Server #3995185] Sending 507.38 MB of payload data to client #100 (simulated).
[INFO][06:12:03]: [Client #100] Selected by the server.
[INFO][06:12:03]: [Client #100] Loading its data source...
[INFO][06:12:03]: [Client #100] Dataset size: 2018
[INFO][06:12:03]: [Client #100] Sampler: iid
[INFO][06:12:04]: [Client #100] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:12:04]: [Client #100] Start to process inbound data.
[INFO][06:12:05]: [93m[1m[Client #100] Started training in communication round #13.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4361184438069663,)
[INFO][06:12:44]: [Client #100] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_100_3995237.pth.
{'train_runtime': 32.5493, 'train_samples_per_second': 185.995, 'train_steps_per_second': 2.949, 'train_loss': 3.4361184438069663, 'epoch': 3.0}
[INFO][06:12:45]: [Client #100] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_100_3995237.pth.
[INFO][06:12:45]: [Client #100] Model trained.
[INFO][06:12:45]: [Client #100] Inbound data has been processed.
[INFO][06:12:45]: [Client #100] Outbound data is ready to be sent after being processed.
[INFO][06:12:53]: [Client #100] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:12:54]: [Server #3995185] Received 507.38 MB of payload data from client #100 (simulated).
[INFO][06:12:54]: [Server #3995185] Adding client #146 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #155 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #88 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #61 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #80 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #60 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #100 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #24 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Adding client #68 to the list of clients for aggregation.
[INFO][06:12:54]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:12:54]: [Server #3995185] Updated weights have been received.
[INFO][06:12:55]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:12:57]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:12:57]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.68it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.39it/s]
[INFO][06:13:06]: [93m[1m[Server #3995185] Global model perplexity: 29.28
[0m
[INFO][06:13:06]: [Server #3995185] All client reports have been processed.
[INFO][06:13:06]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_13.pth.
[INFO][06:13:09]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_13.pth.
[INFO][06:13:09]: [93m[1m
[Server #3995185] Starting round 14/50.[0m
[INFO][06:13:09]: [Server #3995185] Selected clients: [71, 38, 63, 165, 30, 123, 103, 163, 92, 172]
[INFO][06:13:09]: [Server #3995185] Selecting client #71 for training.
[INFO][06:13:09]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][06:13:13]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][06:13:13]: [Client #71] Selected by the server.
[INFO][06:13:13]: [Client #71] Loading its data source...
[INFO][06:13:13]: [Client #71] Dataset size: 2018
[INFO][06:13:13]: [Client #71] Sampler: iid
[INFO][06:13:14]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:13:14]: [Client #71] Start to process inbound data.
[INFO][06:13:15]: [93m[1m[Client #71] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:50,  1.79s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.12it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:16,  3.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.12it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.12it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.12it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.12it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.12it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.12it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.12it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.09it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.33833916982015,)
[INFO][06:13:55]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.6216, 'train_samples_per_second': 185.583, 'train_steps_per_second': 2.943, 'train_loss': 3.33833916982015, 'epoch': 3.0}
[INFO][06:13:56]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][06:13:56]: [Client #71] Model trained.
[INFO][06:13:56]: [Client #71] Inbound data has been processed.
[INFO][06:13:56]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][06:14:00]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:14:01]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][06:14:01]: [Server #3995185] Selecting client #38 for training.
[INFO][06:14:02]: [Server #3995185] Sending the current model to client #38 (simulated).
[INFO][06:14:06]: [Server #3995185] Sending 507.38 MB of payload data to client #38 (simulated).
[INFO][06:14:06]: [Client #38] Selected by the server.
[INFO][06:14:06]: [Client #38] Loading its data source...
[INFO][06:14:06]: [Client #38] Dataset size: 2018
[INFO][06:14:06]: [Client #38] Sampler: iid
[INFO][06:14:07]: [Client #38] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:14:07]: [Client #38] Start to process inbound data.
[INFO][06:14:07]: [93m[1m[Client #38] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.97it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.382666905721029,)
[INFO][06:14:47]: [Client #38] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_38_3995237.pth.
{'train_runtime': 33.031, 'train_samples_per_second': 183.282, 'train_steps_per_second': 2.906, 'train_loss': 3.382666905721029, 'epoch': 3.0}
[INFO][06:14:48]: [Client #38] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_38_3995237.pth.
[INFO][06:14:49]: [Client #38] Model trained.
[INFO][06:14:49]: [Client #38] Inbound data has been processed.
[INFO][06:14:49]: [Client #38] Outbound data is ready to be sent after being processed.
[INFO][06:14:53]: [Client #38] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:14:55]: [Server #3995185] Received 507.38 MB of payload data from client #38 (simulated).
[INFO][06:14:55]: [Server #3995185] Selecting client #63 for training.
[INFO][06:14:55]: [Server #3995185] Sending the current model to client #63 (simulated).
[INFO][06:14:59]: [Server #3995185] Sending 507.38 MB of payload data to client #63 (simulated).
[INFO][06:14:59]: [Client #63] Selected by the server.
[INFO][06:14:59]: [Client #63] Loading its data source...
[INFO][06:14:59]: [Client #63] Dataset size: 2018
[INFO][06:14:59]: [Client #63] Sampler: iid
[INFO][06:15:00]: [Client #63] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:15:00]: [Client #63] Start to process inbound data.
[INFO][06:15:01]: [93m[1m[Client #63] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:27,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.11it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.11it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.11it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.13it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.13it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.10it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3860610326131186,)
[INFO][06:15:39]: [Client #63] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_63_3995237.pth.
{'train_runtime': 32.2823, 'train_samples_per_second': 187.533, 'train_steps_per_second': 2.974, 'train_loss': 3.3860610326131186, 'epoch': 3.0}
[INFO][06:15:40]: [Client #63] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_63_3995237.pth.
[INFO][06:15:40]: [Client #63] Model trained.
[INFO][06:15:40]: [Client #63] Inbound data has been processed.
[INFO][06:15:40]: [Client #63] Outbound data is ready to be sent after being processed.
[INFO][06:15:45]: [Client #63] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:15:46]: [Server #3995185] Received 507.38 MB of payload data from client #63 (simulated).
[INFO][06:15:46]: [Server #3995185] Selecting client #165 for training.
[INFO][06:15:46]: [Server #3995185] Sending the current model to client #165 (simulated).
[INFO][06:15:50]: [Server #3995185] Sending 507.38 MB of payload data to client #165 (simulated).
[INFO][06:15:50]: [Client #165] Selected by the server.
[INFO][06:15:50]: [Client #165] Loading its data source...
[INFO][06:15:50]: [Client #165] Dataset size: 2018
[INFO][06:15:50]: [Client #165] Sampler: iid
[INFO][06:15:52]: [Client #165] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:15:52]: [Client #165] Start to process inbound data.
[INFO][06:15:52]: [93m[1m[Client #165] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:41,  1.70s/it]  2%|â–         | 2/96 [00:02<01:24,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.383525848388672,)
[INFO][06:16:31]: [Client #165] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_165_3995237.pth.
{'train_runtime': 32.8037, 'train_samples_per_second': 184.552, 'train_steps_per_second': 2.927, 'train_loss': 3.383525848388672, 'epoch': 3.0}
[INFO][06:16:32]: [Client #165] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_165_3995237.pth.
[INFO][06:16:32]: [Client #165] Model trained.
[INFO][06:16:32]: [Client #165] Inbound data has been processed.
[INFO][06:16:32]: [Client #165] Outbound data is ready to be sent after being processed.
[INFO][06:16:36]: [Client #165] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:16:38]: [Server #3995185] Received 507.38 MB of payload data from client #165 (simulated).
[INFO][06:16:38]: [Server #3995185] Selecting client #30 for training.
[INFO][06:16:38]: [Server #3995185] Sending the current model to client #30 (simulated).
[INFO][06:16:42]: [Server #3995185] Sending 507.38 MB of payload data to client #30 (simulated).
[INFO][06:16:42]: [Client #30] Selected by the server.
[INFO][06:16:42]: [Client #30] Loading its data source...
[INFO][06:16:42]: [Client #30] Dataset size: 2018
[INFO][06:16:42]: [Client #30] Sampler: iid
[INFO][06:16:44]: [Client #30] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:16:44]: [Client #30] Start to process inbound data.
[INFO][06:16:44]: [93m[1m[Client #30] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3910512924194336,)
[INFO][06:17:23]: [Client #30] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_30_3995237.pth.
{'train_runtime': 33.0308, 'train_samples_per_second': 183.284, 'train_steps_per_second': 2.906, 'train_loss': 3.3910512924194336, 'epoch': 3.0}
[INFO][06:17:24]: [Client #30] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_30_3995237.pth.
[INFO][06:17:25]: [Client #30] Model trained.
[INFO][06:17:25]: [Client #30] Inbound data has been processed.
[INFO][06:17:25]: [Client #30] Outbound data is ready to be sent after being processed.
[INFO][06:17:29]: [Client #30] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:17:31]: [Server #3995185] Received 507.38 MB of payload data from client #30 (simulated).
[INFO][06:17:31]: [Server #3995185] Selecting client #123 for training.
[INFO][06:17:31]: [Server #3995185] Sending the current model to client #123 (simulated).
[INFO][06:17:35]: [Server #3995185] Sending 507.38 MB of payload data to client #123 (simulated).
[INFO][06:17:35]: [Client #123] Selected by the server.
[INFO][06:17:35]: [Client #123] Loading its data source...
[INFO][06:17:35]: [Client #123] Dataset size: 2018
[INFO][06:17:35]: [Client #123] Sampler: iid
[INFO][06:17:36]: [Client #123] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:17:36]: [Client #123] Start to process inbound data.
[INFO][06:17:36]: [93m[1m[Client #123] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3866395950317383,)
[INFO][06:18:15]: [Client #123] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_123_3995237.pth.
{'train_runtime': 32.6747, 'train_samples_per_second': 185.281, 'train_steps_per_second': 2.938, 'train_loss': 3.3866395950317383, 'epoch': 3.0}
[INFO][06:18:16]: [Client #123] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_123_3995237.pth.
[INFO][06:18:16]: [Client #123] Model trained.
[INFO][06:18:16]: [Client #123] Inbound data has been processed.
[INFO][06:18:16]: [Client #123] Outbound data is ready to be sent after being processed.
[INFO][06:18:21]: [Client #123] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:18:22]: [Server #3995185] Received 507.38 MB of payload data from client #123 (simulated).
[INFO][06:18:22]: [Server #3995185] Selecting client #103 for training.
[INFO][06:18:22]: [Server #3995185] Sending the current model to client #103 (simulated).
[INFO][06:18:27]: [Server #3995185] Sending 507.38 MB of payload data to client #103 (simulated).
[INFO][06:18:27]: [Client #103] Selected by the server.
[INFO][06:18:27]: [Client #103] Loading its data source...
[INFO][06:18:27]: [Client #103] Dataset size: 2018
[INFO][06:18:27]: [Client #103] Sampler: iid
[INFO][06:18:28]: [Client #103] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:18:28]: [Client #103] Start to process inbound data.
[INFO][06:18:28]: [93m[1m[Client #103] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.381906509399414,)
[INFO][06:19:07]: [Client #103] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_103_3995237.pth.
{'train_runtime': 32.3587, 'train_samples_per_second': 187.09, 'train_steps_per_second': 2.967, 'train_loss': 3.381906509399414, 'epoch': 3.0}
[INFO][06:19:07]: [Client #103] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_103_3995237.pth.
[INFO][06:19:08]: [Client #103] Model trained.
[INFO][06:19:08]: [Client #103] Inbound data has been processed.
[INFO][06:19:08]: [Client #103] Outbound data is ready to be sent after being processed.
[INFO][06:19:13]: [Client #103] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:19:14]: [Server #3995185] Received 507.38 MB of payload data from client #103 (simulated).
[INFO][06:19:14]: [Server #3995185] Selecting client #163 for training.
[INFO][06:19:14]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][06:19:19]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][06:19:19]: [Client #163] Selected by the server.
[INFO][06:19:19]: [Client #163] Loading its data source...
[INFO][06:19:19]: [Client #163] Dataset size: 2018
[INFO][06:19:19]: [Client #163] Sampler: iid
[INFO][06:19:21]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:19:21]: [Client #163] Start to process inbound data.
[INFO][06:19:21]: [93m[1m[Client #163] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.72s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.07it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.08it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.08it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.08it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.09it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.52it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3675381342569985,)
[INFO][06:20:01]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.7737, 'train_samples_per_second': 184.721, 'train_steps_per_second': 2.929, 'train_loss': 3.3675381342569985, 'epoch': 3.0}
[INFO][06:20:02]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][06:20:03]: [Client #163] Model trained.
[INFO][06:20:03]: [Client #163] Inbound data has been processed.
[INFO][06:20:03]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][06:20:08]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:20:10]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][06:20:10]: [Server #3995185] Selecting client #92 for training.
[INFO][06:20:10]: [Server #3995185] Sending the current model to client #92 (simulated).
[INFO][06:20:14]: [Server #3995185] Sending 507.38 MB of payload data to client #92 (simulated).
[INFO][06:20:14]: [Client #92] Selected by the server.
[INFO][06:20:14]: [Client #92] Loading its data source...
[INFO][06:20:14]: [Client #92] Dataset size: 2018
[INFO][06:20:14]: [Client #92] Sampler: iid
[INFO][06:20:16]: [Client #92] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:20:16]: [Client #92] Start to process inbound data.
[INFO][06:20:16]: [93m[1m[Client #92] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.18it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.07it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.96it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.95it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.95it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.40it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.25it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3741563161214194,)
[INFO][06:20:56]: [Client #92] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_92_3995237.pth.
{'train_runtime': 33.1537, 'train_samples_per_second': 182.604, 'train_steps_per_second': 2.896, 'train_loss': 3.3741563161214194, 'epoch': 3.0}
[INFO][06:20:57]: [Client #92] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_92_3995237.pth.
[INFO][06:20:57]: [Client #92] Model trained.
[INFO][06:20:57]: [Client #92] Inbound data has been processed.
[INFO][06:20:57]: [Client #92] Outbound data is ready to be sent after being processed.
[INFO][06:21:02]: [Client #92] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:21:03]: [Server #3995185] Received 507.38 MB of payload data from client #92 (simulated).
[INFO][06:21:03]: [Server #3995185] Selecting client #172 for training.
[INFO][06:21:03]: [Server #3995185] Sending the current model to client #172 (simulated).
[INFO][06:21:07]: [Server #3995185] Sending 507.38 MB of payload data to client #172 (simulated).
[INFO][06:21:07]: [Client #172] Selected by the server.
[INFO][06:21:07]: [Client #172] Loading its data source...
[INFO][06:21:07]: [Client #172] Dataset size: 2018
[INFO][06:21:07]: [Client #172] Sampler: iid
[INFO][06:21:09]: [Client #172] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:21:09]: [Client #172] Start to process inbound data.
[INFO][06:21:09]: [93m[1m[Client #172] Started training in communication round #14.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3878453572591147,)
[INFO][06:21:48]: [Client #172] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_172_3995237.pth.
{'train_runtime': 32.6708, 'train_samples_per_second': 185.303, 'train_steps_per_second': 2.938, 'train_loss': 3.3878453572591147, 'epoch': 3.0}
[INFO][06:21:49]: [Client #172] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_172_3995237.pth.
[INFO][06:21:50]: [Client #172] Model trained.
[INFO][06:21:50]: [Client #172] Inbound data has been processed.
[INFO][06:21:50]: [Client #172] Outbound data is ready to be sent after being processed.
[INFO][06:21:54]: [Client #172] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:21:56]: [Server #3995185] Received 507.38 MB of payload data from client #172 (simulated).
[INFO][06:21:56]: [Server #3995185] Adding client #135 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #137 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #191 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #49 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #67 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #174 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #38 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Adding client #140 to the list of clients for aggregation.
[INFO][06:21:56]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:21:56]: [Server #3995185] Updated weights have been received.
[INFO][06:22:02]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:22:02]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:22:02]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.61it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.41it/s]
[INFO][06:22:11]: [93m[1m[Server #3995185] Global model perplexity: 29.34
[0m
[INFO][06:22:11]: [Server #3995185] All client reports have been processed.
[INFO][06:22:12]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_14.pth.
[INFO][06:22:14]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_14.pth.
[INFO][06:22:14]: [93m[1m
[Server #3995185] Starting round 15/50.[0m
[INFO][06:22:14]: [Server #3995185] Selected clients: [13, 154, 142, 156, 23, 114, 20, 36, 176, 129]
[INFO][06:22:14]: [Server #3995185] Selecting client #13 for training.
[INFO][06:22:14]: [Server #3995185] Sending the current model to client #13 (simulated).
[INFO][06:22:19]: [Server #3995185] Sending 507.38 MB of payload data to client #13 (simulated).
[INFO][06:22:19]: [Client #13] Selected by the server.
[INFO][06:22:19]: [Client #13] Loading its data source...
[INFO][06:22:19]: [Client #13] Dataset size: 2018
[INFO][06:22:19]: [Client #13] Sampler: iid
[INFO][06:22:20]: [Client #13] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:22:20]: [Client #13] Start to process inbound data.
[INFO][06:22:21]: [93m[1m[Client #13] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.83s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.50it/s]  4%|â–         | 4/96 [00:02<00:48,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.339196523030599,)
[INFO][06:23:01]: [Client #13] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
{'train_runtime': 32.5774, 'train_samples_per_second': 185.835, 'train_steps_per_second': 2.947, 'train_loss': 3.339196523030599, 'epoch': 3.0}
[INFO][06:23:02]: [Client #13] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
[INFO][06:23:02]: [Client #13] Model trained.
[INFO][06:23:02]: [Client #13] Inbound data has been processed.
[INFO][06:23:02]: [Client #13] Outbound data is ready to be sent after being processed.
[INFO][06:23:07]: [Client #13] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:23:08]: [Server #3995185] Received 507.38 MB of payload data from client #13 (simulated).
[INFO][06:23:08]: [Server #3995185] Selecting client #154 for training.
[INFO][06:23:08]: [Server #3995185] Sending the current model to client #154 (simulated).
[INFO][06:23:13]: [Server #3995185] Sending 507.38 MB of payload data to client #154 (simulated).
[INFO][06:23:13]: [Client #154] Selected by the server.
[INFO][06:23:13]: [Client #154] Loading its data source...
[INFO][06:23:13]: [Client #154] Dataset size: 2018
[INFO][06:23:13]: [Client #154] Sampler: iid
[INFO][06:23:14]: [Client #154] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:23:14]: [Client #154] Start to process inbound data.
[INFO][06:23:14]: [93m[1m[Client #154] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.77s/it]  2%|â–         | 2/96 [00:02<01:27,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.405445098876953,)
[INFO][06:23:54]: [Client #154] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_154_3995237.pth.
{'train_runtime': 32.7434, 'train_samples_per_second': 184.892, 'train_steps_per_second': 2.932, 'train_loss': 3.405445098876953, 'epoch': 3.0}
[INFO][06:23:55]: [Client #154] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_154_3995237.pth.
[INFO][06:23:55]: [Client #154] Model trained.
[INFO][06:23:55]: [Client #154] Inbound data has been processed.
[INFO][06:23:55]: [Client #154] Outbound data is ready to be sent after being processed.
[INFO][06:24:00]: [Client #154] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:24:01]: [Server #3995185] Received 507.38 MB of payload data from client #154 (simulated).
[INFO][06:24:01]: [Server #3995185] Selecting client #142 for training.
[INFO][06:24:01]: [Server #3995185] Sending the current model to client #142 (simulated).
[INFO][06:24:06]: [Server #3995185] Sending 507.38 MB of payload data to client #142 (simulated).
[INFO][06:24:06]: [Client #142] Selected by the server.
[INFO][06:24:06]: [Client #142] Loading its data source...
[INFO][06:24:06]: [Client #142] Dataset size: 2018
[INFO][06:24:06]: [Client #142] Sampler: iid
[INFO][06:24:07]: [Client #142] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:24:07]: [Client #142] Start to process inbound data.
[INFO][06:24:07]: [93m[1m[Client #142] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:30,  1.58s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.404358228047689,)
[INFO][06:24:47]: [Client #142] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_142_3995237.pth.
{'train_runtime': 32.7908, 'train_samples_per_second': 184.625, 'train_steps_per_second': 2.928, 'train_loss': 3.404358228047689, 'epoch': 3.0}
[INFO][06:24:48]: [Client #142] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_142_3995237.pth.
[INFO][06:24:48]: [Client #142] Model trained.
[INFO][06:24:48]: [Client #142] Inbound data has been processed.
[INFO][06:24:48]: [Client #142] Outbound data is ready to be sent after being processed.
[INFO][06:24:53]: [Client #142] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:24:54]: [Server #3995185] Received 507.38 MB of payload data from client #142 (simulated).
[INFO][06:24:54]: [Server #3995185] Selecting client #156 for training.
[INFO][06:24:54]: [Server #3995185] Sending the current model to client #156 (simulated).
[INFO][06:24:59]: [Server #3995185] Sending 507.38 MB of payload data to client #156 (simulated).
[INFO][06:24:59]: [Client #156] Selected by the server.
[INFO][06:24:59]: [Client #156] Loading its data source...
[INFO][06:24:59]: [Client #156] Dataset size: 2018
[INFO][06:24:59]: [Client #156] Sampler: iid
[INFO][06:25:00]: [Client #156] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:25:00]: [Client #156] Start to process inbound data.
[INFO][06:25:00]: [93m[1m[Client #156] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:02<03:11,  2.02s/it]  2%|â–         | 2/96 [00:02<01:36,  1.03s/it]  3%|â–Ž         | 3/96 [00:02<01:06,  1.40it/s]  4%|â–         | 4/96 [00:03<00:51,  1.77it/s]  5%|â–Œ         | 5/96 [00:03<00:43,  2.08it/s]  6%|â–‹         | 6/96 [00:03<00:38,  2.32it/s]  7%|â–‹         | 7/96 [00:04<00:35,  2.51it/s]  8%|â–Š         | 8/96 [00:04<00:33,  2.65it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.75it/s] 10%|â–ˆ         | 10/96 [00:05<00:30,  2.83it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.88it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.91it/s] 14%|â–ˆâ–Ž        | 13/96 [00:06<00:28,  2.93it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.95it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:07<00:26,  2.97it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:08<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:09<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:10<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:11<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:12<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:23<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:24<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:25<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:26<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:27<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:28<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:29<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:30<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:31<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:32<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:33<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.88it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.415196736653646,)
[INFO][06:25:40]: [Client #156] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_156_3995237.pth.
{'train_runtime': 33.3842, 'train_samples_per_second': 181.343, 'train_steps_per_second': 2.876, 'train_loss': 3.415196736653646, 'epoch': 3.0}
[INFO][06:25:41]: [Client #156] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_156_3995237.pth.
[INFO][06:25:41]: [Client #156] Model trained.
[INFO][06:25:41]: [Client #156] Inbound data has been processed.
[INFO][06:25:41]: [Client #156] Outbound data is ready to be sent after being processed.
[INFO][06:25:49]: [Client #156] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:25:50]: [Server #3995185] Received 507.38 MB of payload data from client #156 (simulated).
[INFO][06:25:50]: [Server #3995185] Selecting client #23 for training.
[INFO][06:25:50]: [Server #3995185] Sending the current model to client #23 (simulated).
[INFO][06:25:54]: [Server #3995185] Sending 507.38 MB of payload data to client #23 (simulated).
[INFO][06:25:54]: [Client #23] Selected by the server.
[INFO][06:25:54]: [Client #23] Loading its data source...
[INFO][06:25:54]: [Client #23] Dataset size: 2018
[INFO][06:25:54]: [Client #23] Sampler: iid
[INFO][06:25:56]: [Client #23] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:25:56]: [Client #23] Start to process inbound data.
[INFO][06:25:56]: [93m[1m[Client #23] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  2.99it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.98it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.97it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.96it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.95it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.95it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.95it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.373514175415039,)
[INFO][06:26:36]: [Client #23] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
{'train_runtime': 32.9612, 'train_samples_per_second': 183.67, 'train_steps_per_second': 2.913, 'train_loss': 3.373514175415039, 'epoch': 3.0}
[INFO][06:26:37]: [Client #23] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
[INFO][06:26:37]: [Client #23] Model trained.
[INFO][06:26:37]: [Client #23] Inbound data has been processed.
[INFO][06:26:37]: [Client #23] Outbound data is ready to be sent after being processed.
[INFO][06:26:41]: [Client #23] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:26:43]: [Server #3995185] Received 507.38 MB of payload data from client #23 (simulated).
[INFO][06:26:43]: [Server #3995185] Selecting client #114 for training.
[INFO][06:26:43]: [Server #3995185] Sending the current model to client #114 (simulated).
[INFO][06:26:47]: [Server #3995185] Sending 507.38 MB of payload data to client #114 (simulated).
[INFO][06:26:47]: [Client #114] Selected by the server.
[INFO][06:26:47]: [Client #114] Loading its data source...
[INFO][06:26:47]: [Client #114] Dataset size: 2018
[INFO][06:26:47]: [Client #114] Sampler: iid
[INFO][06:26:49]: [Client #114] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:26:49]: [Client #114] Start to process inbound data.
[INFO][06:26:49]: [93m[1m[Client #114] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:39,  1.68s/it]  2%|â–         | 2/96 [00:02<01:22,  1.14it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.59it/s]  4%|â–         | 4/96 [00:02<00:47,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3929246266682944,)
[INFO][06:27:27]: [Client #114] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_114_3995237.pth.
{'train_runtime': 32.4816, 'train_samples_per_second': 186.383, 'train_steps_per_second': 2.956, 'train_loss': 3.3929246266682944, 'epoch': 3.0}
[INFO][06:27:28]: [Client #114] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_114_3995237.pth.
[INFO][06:27:29]: [Client #114] Model trained.
[INFO][06:27:29]: [Client #114] Inbound data has been processed.
[INFO][06:27:29]: [Client #114] Outbound data is ready to be sent after being processed.
[INFO][06:27:33]: [Client #114] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:27:34]: [Server #3995185] Received 507.38 MB of payload data from client #114 (simulated).
[INFO][06:27:34]: [Server #3995185] Selecting client #20 for training.
[INFO][06:27:34]: [Server #3995185] Sending the current model to client #20 (simulated).
[INFO][06:27:39]: [Server #3995185] Sending 507.38 MB of payload data to client #20 (simulated).
[INFO][06:27:39]: [Client #20] Selected by the server.
[INFO][06:27:39]: [Client #20] Loading its data source...
[INFO][06:27:39]: [Client #20] Dataset size: 2018
[INFO][06:27:39]: [Client #20] Sampler: iid
[INFO][06:27:40]: [Client #20] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:27:40]: [Client #20] Start to process inbound data.
[INFO][06:27:40]: [93m[1m[Client #20] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4161437352498374,)
[INFO][06:28:20]: [Client #20] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_20_3995237.pth.
{'train_runtime': 32.9435, 'train_samples_per_second': 183.769, 'train_steps_per_second': 2.914, 'train_loss': 3.4161437352498374, 'epoch': 3.0}
[INFO][06:28:21]: [Client #20] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_20_3995237.pth.
[INFO][06:28:22]: [Client #20] Model trained.
[INFO][06:28:22]: [Client #20] Inbound data has been processed.
[INFO][06:28:22]: [Client #20] Outbound data is ready to be sent after being processed.
[INFO][06:28:26]: [Client #20] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:28:28]: [Server #3995185] Received 507.38 MB of payload data from client #20 (simulated).
[INFO][06:28:28]: [Server #3995185] Selecting client #36 for training.
[INFO][06:28:28]: [Server #3995185] Sending the current model to client #36 (simulated).
[INFO][06:28:32]: [Server #3995185] Sending 507.38 MB of payload data to client #36 (simulated).
[INFO][06:28:32]: [Client #36] Selected by the server.
[INFO][06:28:32]: [Client #36] Loading its data source...
[INFO][06:28:32]: [Client #36] Dataset size: 2018
[INFO][06:28:32]: [Client #36] Sampler: iid
[INFO][06:28:34]: [Client #36] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:28:34]: [Client #36] Start to process inbound data.
[INFO][06:28:34]: [93m[1m[Client #36] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:40,  1.69s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.98it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4172150293986,)
[INFO][06:29:13]: [Client #36] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_36_3995237.pth.
{'train_runtime': 32.6959, 'train_samples_per_second': 185.161, 'train_steps_per_second': 2.936, 'train_loss': 3.4172150293986, 'epoch': 3.0}
[INFO][06:29:14]: [Client #36] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_36_3995237.pth.
[INFO][06:29:15]: [Client #36] Model trained.
[INFO][06:29:15]: [Client #36] Inbound data has been processed.
[INFO][06:29:15]: [Client #36] Outbound data is ready to be sent after being processed.
[INFO][06:29:19]: [Client #36] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:29:20]: [Server #3995185] Received 507.38 MB of payload data from client #36 (simulated).
[INFO][06:29:20]: [Server #3995185] Selecting client #176 for training.
[INFO][06:29:20]: [Server #3995185] Sending the current model to client #176 (simulated).
[INFO][06:29:24]: [Server #3995185] Sending 507.38 MB of payload data to client #176 (simulated).
[INFO][06:29:24]: [Client #176] Selected by the server.
[INFO][06:29:24]: [Client #176] Loading its data source...
[INFO][06:29:24]: [Client #176] Dataset size: 2018
[INFO][06:29:24]: [Client #176] Sampler: iid
[INFO][06:29:26]: [Client #176] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:29:26]: [Client #176] Start to process inbound data.
[INFO][06:29:26]: [93m[1m[Client #176] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.59s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.63it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.4029057820638022,)
[INFO][06:30:05]: [Client #176] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_176_3995237.pth.
{'train_runtime': 32.6011, 'train_samples_per_second': 185.699, 'train_steps_per_second': 2.945, 'train_loss': 3.4029057820638022, 'epoch': 3.0}
[INFO][06:30:06]: [Client #176] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_176_3995237.pth.
[INFO][06:30:07]: [Client #176] Model trained.
[INFO][06:30:07]: [Client #176] Inbound data has been processed.
[INFO][06:30:07]: [Client #176] Outbound data is ready to be sent after being processed.
[INFO][06:30:11]: [Client #176] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:30:12]: [Server #3995185] Received 507.38 MB of payload data from client #176 (simulated).
[INFO][06:30:12]: [Server #3995185] Selecting client #129 for training.
[INFO][06:30:12]: [Server #3995185] Sending the current model to client #129 (simulated).
[INFO][06:30:17]: [Server #3995185] Sending 507.38 MB of payload data to client #129 (simulated).
[INFO][06:30:17]: [Client #129] Selected by the server.
[INFO][06:30:17]: [Client #129] Loading its data source...
[INFO][06:30:17]: [Client #129] Dataset size: 2018
[INFO][06:30:17]: [Client #129] Sampler: iid
[INFO][06:30:18]: [Client #129] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:30:18]: [Client #129] Start to process inbound data.
[INFO][06:30:18]: [93m[1m[Client #129] Started training in communication round #15.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:39,  1.68s/it]  2%|â–         | 2/96 [00:02<01:23,  1.13it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.95it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3973843256632485,)
[INFO][06:30:58]: [Client #129] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_129_3995237.pth.
{'train_runtime': 32.8025, 'train_samples_per_second': 184.559, 'train_steps_per_second': 2.927, 'train_loss': 3.3973843256632485, 'epoch': 3.0}
[INFO][06:30:59]: [Client #129] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_129_3995237.pth.
[INFO][06:30:59]: [Client #129] Model trained.
[INFO][06:30:59]: [Client #129] Inbound data has been processed.
[INFO][06:30:59]: [Client #129] Outbound data is ready to be sent after being processed.
[INFO][06:31:03]: [Client #129] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:31:04]: [Server #3995185] Received 507.38 MB of payload data from client #129 (simulated).
[INFO][06:31:04]: [Server #3995185] Adding client #172 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #13 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #23 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #142 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #73 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #96 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #168 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #30 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #63 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Adding client #92 to the list of clients for aggregation.
[INFO][06:31:04]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:31:04]: [Server #3995185] Updated weights have been received.
[INFO][06:31:05]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:31:06]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:31:06]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.76it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.23it/s]
[INFO][06:31:15]: [93m[1m[Server #3995185] Global model perplexity: 27.89
[0m
[INFO][06:31:15]: [Server #3995185] All client reports have been processed.
[INFO][06:31:16]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_15.pth.
[INFO][06:31:18]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_15.pth.
[INFO][06:31:18]: [93m[1m
[Server #3995185] Starting round 16/50.[0m
[INFO][06:31:18]: [Server #3995185] Selected clients: [57, 197, 170, 186, 132, 126, 128, 76, 158, 9]
[INFO][06:31:18]: [Server #3995185] Selecting client #57 for training.
[INFO][06:31:18]: [Server #3995185] Sending the current model to client #57 (simulated).
[INFO][06:31:23]: [Server #3995185] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][06:31:23]: [Client #57] Selected by the server.
[INFO][06:31:23]: [Client #57] Loading its data source...
[INFO][06:31:23]: [Client #57] Dataset size: 2018
[INFO][06:31:23]: [Client #57] Sampler: iid
[INFO][06:31:24]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:31:24]: [Client #57] Start to process inbound data.
[INFO][06:31:25]: [93m[1m[Client #57] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.72s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3102661768595376,)
[INFO][06:32:04]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
{'train_runtime': 32.8736, 'train_samples_per_second': 184.16, 'train_steps_per_second': 2.92, 'train_loss': 3.3102661768595376, 'epoch': 3.0}
[INFO][06:32:05]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
[INFO][06:32:06]: [Client #57] Model trained.
[INFO][06:32:06]: [Client #57] Inbound data has been processed.
[INFO][06:32:06]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][06:32:11]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:32:12]: [Server #3995185] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][06:32:12]: [Server #3995185] Selecting client #197 for training.
[INFO][06:32:12]: [Server #3995185] Sending the current model to client #197 (simulated).
[INFO][06:32:17]: [Server #3995185] Sending 507.38 MB of payload data to client #197 (simulated).
[INFO][06:32:17]: [Client #197] Selected by the server.
[INFO][06:32:17]: [Client #197] Loading its data source...
[INFO][06:32:17]: [Client #197] Dataset size: 2018
[INFO][06:32:17]: [Client #197] Sampler: iid
[INFO][06:32:18]: [Client #197] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:32:18]: [Client #197] Start to process inbound data.
[INFO][06:32:18]: [93m[1m[Client #197] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3168443044026694,)
[INFO][06:32:56]: [Client #197] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_197_3995237.pth.
{'train_runtime': 32.3619, 'train_samples_per_second': 187.072, 'train_steps_per_second': 2.966, 'train_loss': 3.3168443044026694, 'epoch': 3.0}
[INFO][06:32:57]: [Client #197] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_197_3995237.pth.
[INFO][06:32:58]: [Client #197] Model trained.
[INFO][06:32:58]: [Client #197] Inbound data has been processed.
[INFO][06:32:58]: [Client #197] Outbound data is ready to be sent after being processed.
[INFO][06:33:02]: [Client #197] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:33:03]: [Server #3995185] Received 507.38 MB of payload data from client #197 (simulated).
[INFO][06:33:03]: [Server #3995185] Selecting client #170 for training.
[INFO][06:33:03]: [Server #3995185] Sending the current model to client #170 (simulated).
[INFO][06:33:07]: [Server #3995185] Sending 507.38 MB of payload data to client #170 (simulated).
[INFO][06:33:07]: [Client #170] Selected by the server.
[INFO][06:33:07]: [Client #170] Loading its data source...
[INFO][06:33:07]: [Client #170] Dataset size: 2018
[INFO][06:33:07]: [Client #170] Sampler: iid
[INFO][06:33:08]: [Client #170] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:33:08]: [Client #170] Start to process inbound data.
[INFO][06:33:08]: [93m[1m[Client #170] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3450746536254883,)
[INFO][06:33:47]: [Client #170] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_170_3995237.pth.
{'train_runtime': 32.6089, 'train_samples_per_second': 185.655, 'train_steps_per_second': 2.944, 'train_loss': 3.3450746536254883, 'epoch': 3.0}
[INFO][06:33:47]: [Client #170] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_170_3995237.pth.
[INFO][06:33:48]: [Client #170] Model trained.
[INFO][06:33:48]: [Client #170] Inbound data has been processed.
[INFO][06:33:48]: [Client #170] Outbound data is ready to be sent after being processed.
[INFO][06:33:52]: [Client #170] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:33:54]: [Server #3995185] Received 507.38 MB of payload data from client #170 (simulated).
[INFO][06:33:54]: [Server #3995185] Selecting client #186 for training.
[INFO][06:33:54]: [Server #3995185] Sending the current model to client #186 (simulated).
[INFO][06:33:58]: [Server #3995185] Sending 507.38 MB of payload data to client #186 (simulated).
[INFO][06:33:58]: [Client #186] Selected by the server.
[INFO][06:33:58]: [Client #186] Loading its data source...
[INFO][06:33:58]: [Client #186] Dataset size: 2018
[INFO][06:33:58]: [Client #186] Sampler: iid
[INFO][06:34:00]: [Client #186] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:34:00]: [Client #186] Start to process inbound data.
[INFO][06:34:00]: [93m[1m[Client #186] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:16,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.69it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.94it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  3.00it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:27,  3.04it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.07it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3176453908284507,)
[INFO][06:34:38]: [Client #186] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_186_3995237.pth.
{'train_runtime': 32.5476, 'train_samples_per_second': 186.005, 'train_steps_per_second': 2.95, 'train_loss': 3.3176453908284507, 'epoch': 3.0}
[INFO][06:34:39]: [Client #186] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_186_3995237.pth.
[INFO][06:34:39]: [Client #186] Model trained.
[INFO][06:34:39]: [Client #186] Inbound data has been processed.
[INFO][06:34:39]: [Client #186] Outbound data is ready to be sent after being processed.
[INFO][06:34:44]: [Client #186] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:34:45]: [Server #3995185] Received 507.38 MB of payload data from client #186 (simulated).
[INFO][06:34:45]: [Server #3995185] Selecting client #132 for training.
[INFO][06:34:45]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][06:34:50]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][06:34:50]: [Client #132] Selected by the server.
[INFO][06:34:50]: [Client #132] Loading its data source...
[INFO][06:34:50]: [Client #132] Dataset size: 2018
[INFO][06:34:50]: [Client #132] Sampler: iid
[INFO][06:34:51]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:34:51]: [Client #132] Start to process inbound data.
[INFO][06:34:51]: [93m[1m[Client #132] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.11it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:10,  3.11it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.10it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.55it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.31it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.25it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.20it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.17it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.15it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.14it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.13it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.12it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.12it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.12it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.12it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.12it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.12it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.12it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.12it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.11it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.01it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3366098403930664,)
[INFO][06:35:29]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 31.879, 'train_samples_per_second': 189.906, 'train_steps_per_second': 3.011, 'train_loss': 3.3366098403930664, 'epoch': 3.0}
[INFO][06:35:30]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][06:35:31]: [Client #132] Model trained.
[INFO][06:35:31]: [Client #132] Inbound data has been processed.
[INFO][06:35:31]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][06:35:34]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:35:36]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][06:35:36]: [Server #3995185] Selecting client #126 for training.
[INFO][06:35:36]: [Server #3995185] Sending the current model to client #126 (simulated).
[INFO][06:35:42]: [Server #3995185] Sending 507.38 MB of payload data to client #126 (simulated).
[INFO][06:35:42]: [Client #126] Selected by the server.
[INFO][06:35:42]: [Client #126] Loading its data source...
[INFO][06:35:42]: [Client #126] Dataset size: 2018
[INFO][06:35:42]: [Client #126] Sampler: iid
[INFO][06:35:43]: [Client #126] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:35:43]: [Client #126] Start to process inbound data.
[INFO][06:35:43]: [93m[1m[Client #126] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3379764556884766,)
[INFO][06:36:21]: [Client #126] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_126_3995237.pth.
{'train_runtime': 32.2994, 'train_samples_per_second': 187.434, 'train_steps_per_second': 2.972, 'train_loss': 3.3379764556884766, 'epoch': 3.0}
[INFO][06:36:22]: [Client #126] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_126_3995237.pth.
[INFO][06:36:22]: [Client #126] Model trained.
[INFO][06:36:22]: [Client #126] Inbound data has been processed.
[INFO][06:36:22]: [Client #126] Outbound data is ready to be sent after being processed.
[INFO][06:36:28]: [Client #126] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:36:29]: [Server #3995185] Received 507.38 MB of payload data from client #126 (simulated).
[INFO][06:36:29]: [Server #3995185] Selecting client #128 for training.
[INFO][06:36:29]: [Server #3995185] Sending the current model to client #128 (simulated).
[INFO][06:36:33]: [Server #3995185] Sending 507.38 MB of payload data to client #128 (simulated).
[INFO][06:36:33]: [Client #128] Selected by the server.
[INFO][06:36:33]: [Client #128] Loading its data source...
[INFO][06:36:33]: [Client #128] Dataset size: 2018
[INFO][06:36:33]: [Client #128] Sampler: iid
[INFO][06:36:34]: [Client #128] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:36:34]: [Client #128] Start to process inbound data.
[INFO][06:36:35]: [93m[1m[Client #128] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.10it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.11it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.11it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.12it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.12it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.12it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.12it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.12it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.11it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.11it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.11it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:10,  3.11it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.11it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.56it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.32it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.26it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.22it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.17it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.15it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.14it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.12it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.11it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.11it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.11it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.11it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.11it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.11it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.12it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.11it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.11it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.01it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3173580169677734,)
[INFO][06:37:13]: [Client #128] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_128_3995237.pth.
{'train_runtime': 31.9013, 'train_samples_per_second': 189.773, 'train_steps_per_second': 3.009, 'train_loss': 3.3173580169677734, 'epoch': 3.0}
[INFO][06:37:13]: [Client #128] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_128_3995237.pth.
[INFO][06:37:14]: [Client #128] Model trained.
[INFO][06:37:14]: [Client #128] Inbound data has been processed.
[INFO][06:37:14]: [Client #128] Outbound data is ready to be sent after being processed.
[INFO][06:37:21]: [Client #128] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:37:22]: [Server #3995185] Received 507.38 MB of payload data from client #128 (simulated).
[INFO][06:37:22]: [Server #3995185] Selecting client #76 for training.
[INFO][06:37:22]: [Server #3995185] Sending the current model to client #76 (simulated).
[INFO][06:37:26]: [Server #3995185] Sending 507.38 MB of payload data to client #76 (simulated).
[INFO][06:37:26]: [Client #76] Selected by the server.
[INFO][06:37:26]: [Client #76] Loading its data source...
[INFO][06:37:26]: [Client #76] Dataset size: 2018
[INFO][06:37:26]: [Client #76] Sampler: iid
[INFO][06:37:28]: [Client #76] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:37:28]: [Client #76] Start to process inbound data.
[INFO][06:37:28]: [93m[1m[Client #76] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:53,  1.82s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.39it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.56it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.99it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.98it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.97it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.97it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:22<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.41it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3186658223470054,)
[INFO][06:38:07]: [Client #76] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_76_3995237.pth.
{'train_runtime': 33.0482, 'train_samples_per_second': 183.187, 'train_steps_per_second': 2.905, 'train_loss': 3.3186658223470054, 'epoch': 3.0}
[INFO][06:38:08]: [Client #76] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_76_3995237.pth.
[INFO][06:38:09]: [Client #76] Model trained.
[INFO][06:38:09]: [Client #76] Inbound data has been processed.
[INFO][06:38:09]: [Client #76] Outbound data is ready to be sent after being processed.
[INFO][06:38:14]: [Client #76] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:38:15]: [Server #3995185] Received 507.38 MB of payload data from client #76 (simulated).
[INFO][06:38:15]: [Server #3995185] Selecting client #158 for training.
[INFO][06:38:15]: [Server #3995185] Sending the current model to client #158 (simulated).
[INFO][06:38:20]: [Server #3995185] Sending 507.38 MB of payload data to client #158 (simulated).
[INFO][06:38:20]: [Client #158] Selected by the server.
[INFO][06:38:20]: [Client #158] Loading its data source...
[INFO][06:38:20]: [Client #158] Dataset size: 2018
[INFO][06:38:20]: [Client #158] Sampler: iid
[INFO][06:38:21]: [Client #158] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:38:21]: [Client #158] Start to process inbound data.
[INFO][06:38:21]: [93m[1m[Client #158] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.3570340474446616,)
[INFO][06:39:00]: [Client #158] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_158_3995237.pth.
{'train_runtime': 32.368, 'train_samples_per_second': 187.037, 'train_steps_per_second': 2.966, 'train_loss': 3.3570340474446616, 'epoch': 3.0}
[INFO][06:39:01]: [Client #158] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_158_3995237.pth.
[INFO][06:39:01]: [Client #158] Model trained.
[INFO][06:39:01]: [Client #158] Inbound data has been processed.
[INFO][06:39:01]: [Client #158] Outbound data is ready to be sent after being processed.
[INFO][06:39:07]: [Client #158] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:39:08]: [Server #3995185] Received 507.38 MB of payload data from client #158 (simulated).
[INFO][06:39:08]: [Server #3995185] Selecting client #9 for training.
[INFO][06:39:08]: [Server #3995185] Sending the current model to client #9 (simulated).
[INFO][06:39:13]: [Server #3995185] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][06:39:13]: [Client #9] Selected by the server.
[INFO][06:39:13]: [Client #9] Loading its data source...
[INFO][06:39:13]: [Client #9] Dataset size: 2018
[INFO][06:39:13]: [Client #9] Sampler: iid
[INFO][06:39:14]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:39:14]: [Client #9] Start to process inbound data.
[INFO][06:39:15]: [93m[1m[Client #9] Started training in communication round #16.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:51,  1.80s/it]  2%|â–         | 2/96 [00:02<01:28,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.11it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.297983487447103,)
[INFO][06:39:55]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
{'train_runtime': 32.9157, 'train_samples_per_second': 183.925, 'train_steps_per_second': 2.917, 'train_loss': 3.297983487447103, 'epoch': 3.0}
[INFO][06:39:56]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
[INFO][06:39:57]: [Client #9] Model trained.
[INFO][06:39:57]: [Client #9] Inbound data has been processed.
[INFO][06:39:57]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][06:40:01]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:40:03]: [Server #3995185] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][06:40:03]: [Server #3995185] Adding client #103 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #123 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #165 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #129 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #9 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #57 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #132 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #76 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #114 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Adding client #20 to the list of clients for aggregation.
[INFO][06:40:03]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:40:03]: [Server #3995185] Updated weights have been received.
[INFO][06:40:04]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:40:05]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:40:05]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.44it/s]
[INFO][06:40:14]: [93m[1m[Server #3995185] Global model perplexity: 27.16
[0m
[INFO][06:40:14]: [Server #3995185] All client reports have been processed.
[INFO][06:40:14]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_16.pth.
[INFO][06:40:17]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_16.pth.
[INFO][06:40:17]: [93m[1m
[Server #3995185] Starting round 17/50.[0m
[INFO][06:40:17]: [Server #3995185] Selected clients: [17, 139, 107, 77, 31, 62, 190, 91, 74, 121]
[INFO][06:40:17]: [Server #3995185] Selecting client #17 for training.
[INFO][06:40:17]: [Server #3995185] Sending the current model to client #17 (simulated).
[INFO][06:40:21]: [Server #3995185] Sending 507.38 MB of payload data to client #17 (simulated).
[INFO][06:40:21]: [Client #17] Selected by the server.
[INFO][06:40:21]: [Client #17] Loading its data source...
[INFO][06:40:21]: [Client #17] Dataset size: 2018
[INFO][06:40:21]: [Client #17] Sampler: iid
[INFO][06:40:23]: [Client #17] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:40:23]: [Client #17] Start to process inbound data.
[INFO][06:40:23]: [93m[1m[Client #17] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.15it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.14it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2582216262817383,)
[INFO][06:41:01]: [Client #17] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3995237.pth.
{'train_runtime': 32.004, 'train_samples_per_second': 189.164, 'train_steps_per_second': 3.0, 'train_loss': 3.2582216262817383, 'epoch': 3.0}
[INFO][06:41:01]: [Client #17] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3995237.pth.
[INFO][06:41:02]: [Client #17] Model trained.
[INFO][06:41:02]: [Client #17] Inbound data has been processed.
[INFO][06:41:02]: [Client #17] Outbound data is ready to be sent after being processed.
[INFO][06:41:06]: [Client #17] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:41:08]: [Server #3995185] Received 507.38 MB of payload data from client #17 (simulated).
[INFO][06:41:08]: [Server #3995185] Selecting client #139 for training.
[INFO][06:41:08]: [Server #3995185] Sending the current model to client #139 (simulated).
[INFO][06:41:12]: [Server #3995185] Sending 507.38 MB of payload data to client #139 (simulated).
[INFO][06:41:12]: [Client #139] Selected by the server.
[INFO][06:41:12]: [Client #139] Loading its data source...
[INFO][06:41:12]: [Client #139] Dataset size: 2018
[INFO][06:41:12]: [Client #139] Sampler: iid
[INFO][06:41:13]: [Client #139] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:41:13]: [Client #139] Start to process inbound data.
[INFO][06:41:13]: [93m[1m[Client #139] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.87it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.267913818359375,)
[INFO][06:41:51]: [Client #139] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_139_3995237.pth.
{'train_runtime': 32.0902, 'train_samples_per_second': 188.656, 'train_steps_per_second': 2.992, 'train_loss': 3.267913818359375, 'epoch': 3.0}
[INFO][06:41:52]: [Client #139] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_139_3995237.pth.
[INFO][06:41:52]: [Client #139] Model trained.
[INFO][06:41:52]: [Client #139] Inbound data has been processed.
[INFO][06:41:52]: [Client #139] Outbound data is ready to be sent after being processed.
[INFO][06:41:57]: [Client #139] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:41:58]: [Server #3995185] Received 507.38 MB of payload data from client #139 (simulated).
[INFO][06:41:58]: [Server #3995185] Selecting client #107 for training.
[INFO][06:41:58]: [Server #3995185] Sending the current model to client #107 (simulated).
[INFO][06:42:03]: [Server #3995185] Sending 507.38 MB of payload data to client #107 (simulated).
[INFO][06:42:03]: [Client #107] Selected by the server.
[INFO][06:42:03]: [Client #107] Loading its data source...
[INFO][06:42:03]: [Client #107] Dataset size: 2018
[INFO][06:42:03]: [Client #107] Sampler: iid
[INFO][06:42:04]: [Client #107] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:42:04]: [Client #107] Start to process inbound data.
[INFO][06:42:04]: [93m[1m[Client #107] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.93it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2695795694986978,)
[INFO][06:42:42]: [Client #107] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_107_3995237.pth.
{'train_runtime': 32.3052, 'train_samples_per_second': 187.4, 'train_steps_per_second': 2.972, 'train_loss': 3.2695795694986978, 'epoch': 3.0}
[INFO][06:42:42]: [Client #107] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_107_3995237.pth.
[INFO][06:42:43]: [Client #107] Model trained.
[INFO][06:42:43]: [Client #107] Inbound data has been processed.
[INFO][06:42:43]: [Client #107] Outbound data is ready to be sent after being processed.
[INFO][06:42:47]: [Client #107] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:42:49]: [Server #3995185] Received 507.38 MB of payload data from client #107 (simulated).
[INFO][06:42:49]: [Server #3995185] Selecting client #77 for training.
[INFO][06:42:49]: [Server #3995185] Sending the current model to client #77 (simulated).
[INFO][06:42:56]: [Server #3995185] Sending 507.38 MB of payload data to client #77 (simulated).
[INFO][06:42:56]: [Client #77] Selected by the server.
[INFO][06:42:56]: [Client #77] Loading its data source...
[INFO][06:42:56]: [Client #77] Dataset size: 2018
[INFO][06:42:56]: [Client #77] Sampler: iid
[INFO][06:42:57]: [Client #77] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:42:57]: [Client #77] Start to process inbound data.
[INFO][06:42:57]: [93m[1m[Client #77] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.280125300089518,)
[INFO][06:43:35]: [Client #77] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_77_3995237.pth.
{'train_runtime': 32.272, 'train_samples_per_second': 187.593, 'train_steps_per_second': 2.975, 'train_loss': 3.280125300089518, 'epoch': 3.0}
[INFO][06:43:36]: [Client #77] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_77_3995237.pth.
[INFO][06:43:36]: [Client #77] Model trained.
[INFO][06:43:36]: [Client #77] Inbound data has been processed.
[INFO][06:43:36]: [Client #77] Outbound data is ready to be sent after being processed.
[INFO][06:43:41]: [Client #77] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:43:42]: [Server #3995185] Received 507.38 MB of payload data from client #77 (simulated).
[INFO][06:43:42]: [Server #3995185] Selecting client #31 for training.
[INFO][06:43:42]: [Server #3995185] Sending the current model to client #31 (simulated).
[INFO][06:43:50]: [Server #3995185] Sending 507.38 MB of payload data to client #31 (simulated).
[INFO][06:43:50]: [Client #31] Selected by the server.
[INFO][06:43:50]: [Client #31] Loading its data source...
[INFO][06:43:50]: [Client #31] Dataset size: 2018
[INFO][06:43:50]: [Client #31] Sampler: iid
[INFO][06:43:51]: [Client #31] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:43:51]: [Client #31] Start to process inbound data.
[INFO][06:43:52]: [93m[1m[Client #31] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:37,  1.66s/it]  2%|â–         | 2/96 [00:01<01:22,  1.14it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.61it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.11it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.11it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.11it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.11it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.10it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.13it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.10it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.09it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.08it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2851832707722983,)
[INFO][06:44:30]: [Client #31] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_31_3995237.pth.
{'train_runtime': 32.1798, 'train_samples_per_second': 188.131, 'train_steps_per_second': 2.983, 'train_loss': 3.2851832707722983, 'epoch': 3.0}
[INFO][06:44:31]: [Client #31] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_31_3995237.pth.
[INFO][06:44:32]: [Client #31] Model trained.
[INFO][06:44:32]: [Client #31] Inbound data has been processed.
[INFO][06:44:32]: [Client #31] Outbound data is ready to be sent after being processed.
[INFO][06:44:37]: [Client #31] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:44:38]: [Server #3995185] Received 507.38 MB of payload data from client #31 (simulated).
[INFO][06:44:38]: [Server #3995185] Selecting client #62 for training.
[INFO][06:44:38]: [Server #3995185] Sending the current model to client #62 (simulated).
[INFO][06:44:44]: [Server #3995185] Sending 507.38 MB of payload data to client #62 (simulated).
[INFO][06:44:44]: [Client #62] Selected by the server.
[INFO][06:44:44]: [Client #62] Loading its data source...
[INFO][06:44:44]: [Client #62] Dataset size: 2018
[INFO][06:44:44]: [Client #62] Sampler: iid
[INFO][06:44:46]: [Client #62] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:44:46]: [Client #62] Start to process inbound data.
[INFO][06:44:47]: [93m[1m[Client #62] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:40,  1.69s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.11it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.10it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.11it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.09it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.30609130859375,)
[INFO][06:45:25]: [Client #62] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
{'train_runtime': 32.4352, 'train_samples_per_second': 186.649, 'train_steps_per_second': 2.96, 'train_loss': 3.30609130859375, 'epoch': 3.0}
[INFO][06:45:26]: [Client #62] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
[INFO][06:45:27]: [Client #62] Model trained.
[INFO][06:45:27]: [Client #62] Inbound data has been processed.
[INFO][06:45:27]: [Client #62] Outbound data is ready to be sent after being processed.
[INFO][06:45:33]: [Client #62] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:45:34]: [Server #3995185] Received 507.38 MB of payload data from client #62 (simulated).
[INFO][06:45:34]: [Server #3995185] Selecting client #190 for training.
[INFO][06:45:34]: [Server #3995185] Sending the current model to client #190 (simulated).
[INFO][06:45:41]: [Server #3995185] Sending 507.38 MB of payload data to client #190 (simulated).
[INFO][06:45:41]: [Client #190] Selected by the server.
[INFO][06:45:41]: [Client #190] Loading its data source...
[INFO][06:45:41]: [Client #190] Dataset size: 2018
[INFO][06:45:41]: [Client #190] Sampler: iid
[INFO][06:45:42]: [Client #190] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:45:42]: [Client #190] Start to process inbound data.
[INFO][06:45:43]: [93m[1m[Client #190] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.11it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.317173639933268,)
[INFO][06:46:21]: [Client #190] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_190_3995237.pth.
{'train_runtime': 31.9813, 'train_samples_per_second': 189.298, 'train_steps_per_second': 3.002, 'train_loss': 3.317173639933268, 'epoch': 3.0}
[INFO][06:46:22]: [Client #190] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_190_3995237.pth.
[INFO][06:46:22]: [Client #190] Model trained.
[INFO][06:46:22]: [Client #190] Inbound data has been processed.
[INFO][06:46:22]: [Client #190] Outbound data is ready to be sent after being processed.
[INFO][06:46:29]: [Client #190] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:46:30]: [Server #3995185] Received 507.38 MB of payload data from client #190 (simulated).
[INFO][06:46:30]: [Server #3995185] Selecting client #91 for training.
[INFO][06:46:30]: [Server #3995185] Sending the current model to client #91 (simulated).
[INFO][06:46:38]: [Server #3995185] Sending 507.38 MB of payload data to client #91 (simulated).
[INFO][06:46:38]: [Client #91] Selected by the server.
[INFO][06:46:38]: [Client #91] Loading its data source...
[INFO][06:46:38]: [Client #91] Dataset size: 2018
[INFO][06:46:38]: [Client #91] Sampler: iid
[INFO][06:46:39]: [Client #91] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:46:39]: [Client #91] Start to process inbound data.
[INFO][06:46:40]: [93m[1m[Client #91] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.275390307108561,)
[INFO][06:47:20]: [Client #91] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_91_3995237.pth.
{'train_runtime': 32.8042, 'train_samples_per_second': 184.55, 'train_steps_per_second': 2.926, 'train_loss': 3.275390307108561, 'epoch': 3.0}
[INFO][06:47:21]: [Client #91] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_91_3995237.pth.
[INFO][06:47:22]: [Client #91] Model trained.
[INFO][06:47:22]: [Client #91] Inbound data has been processed.
[INFO][06:47:22]: [Client #91] Outbound data is ready to be sent after being processed.
[INFO][06:47:27]: [Client #91] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:47:28]: [Server #3995185] Received 507.38 MB of payload data from client #91 (simulated).
[INFO][06:47:28]: [Server #3995185] Selecting client #74 for training.
[INFO][06:47:28]: [Server #3995185] Sending the current model to client #74 (simulated).
[INFO][06:47:34]: [Server #3995185] Sending 507.38 MB of payload data to client #74 (simulated).
[INFO][06:47:34]: [Client #74] Selected by the server.
[INFO][06:47:34]: [Client #74] Loading its data source...
[INFO][06:47:34]: [Client #74] Dataset size: 2018
[INFO][06:47:34]: [Client #74] Sampler: iid
[INFO][06:47:35]: [Client #74] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:47:35]: [Client #74] Start to process inbound data.
[INFO][06:47:35]: [93m[1m[Client #74] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.321409543355306,)
[INFO][06:48:13]: [Client #74] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_74_3995237.pth.
{'train_runtime': 32.2481, 'train_samples_per_second': 187.732, 'train_steps_per_second': 2.977, 'train_loss': 3.321409543355306, 'epoch': 3.0}
[INFO][06:48:14]: [Client #74] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_74_3995237.pth.
[INFO][06:48:15]: [Client #74] Model trained.
[INFO][06:48:15]: [Client #74] Inbound data has been processed.
[INFO][06:48:15]: [Client #74] Outbound data is ready to be sent after being processed.
[INFO][06:48:22]: [Client #74] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:48:23]: [Server #3995185] Received 507.38 MB of payload data from client #74 (simulated).
[INFO][06:48:23]: [Server #3995185] Selecting client #121 for training.
[INFO][06:48:23]: [Server #3995185] Sending the current model to client #121 (simulated).
[INFO][06:48:27]: [Server #3995185] Sending 507.38 MB of payload data to client #121 (simulated).
[INFO][06:48:27]: [Client #121] Selected by the server.
[INFO][06:48:27]: [Client #121] Loading its data source...
[INFO][06:48:27]: [Client #121] Dataset size: 2018
[INFO][06:48:27]: [Client #121] Sampler: iid
[INFO][06:48:29]: [Client #121] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:48:29]: [Client #121] Start to process inbound data.
[INFO][06:48:29]: [93m[1m[Client #121] Started training in communication round #17.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.08it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2917019526163735,)
[INFO][06:49:07]: [Client #121] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_121_3995237.pth.
{'train_runtime': 32.0488, 'train_samples_per_second': 188.9, 'train_steps_per_second': 2.995, 'train_loss': 3.2917019526163735, 'epoch': 3.0}
[INFO][06:49:08]: [Client #121] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_121_3995237.pth.
[INFO][06:49:08]: [Client #121] Model trained.
[INFO][06:49:08]: [Client #121] Inbound data has been processed.
[INFO][06:49:08]: [Client #121] Outbound data is ready to be sent after being processed.
[INFO][06:49:15]: [Client #121] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:49:16]: [Server #3995185] Received 507.38 MB of payload data from client #121 (simulated).
[INFO][06:49:16]: [Server #3995185] Adding client #36 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #154 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #156 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #176 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #17 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #62 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #77 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #107 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #91 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Adding client #139 to the list of clients for aggregation.
[INFO][06:49:16]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:49:16]: [Server #3995185] Updated weights have been received.
[INFO][06:49:18]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:49:19]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:49:19]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.78it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.28it/s]
[INFO][06:49:28]: [93m[1m[Server #3995185] Global model perplexity: 26.73
[0m
[INFO][06:49:28]: [Server #3995185] All client reports have been processed.
[INFO][06:49:29]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_17.pth.
[INFO][06:49:32]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_17.pth.
[INFO][06:49:32]: [93m[1m
[Server #3995185] Starting round 18/50.[0m
[INFO][06:49:32]: [Server #3995185] Selected clients: [119, 11, 115, 34, 177, 2, 26, 164, 50, 160]
[INFO][06:49:32]: [Server #3995185] Selecting client #119 for training.
[INFO][06:49:32]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][06:49:37]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][06:49:37]: [Client #119] Selected by the server.
[INFO][06:49:37]: [Client #119] Loading its data source...
[INFO][06:49:37]: [Client #119] Dataset size: 2018
[INFO][06:49:37]: [Client #119] Sampler: iid
[INFO][06:49:38]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:49:38]: [Client #119] Start to process inbound data.
[INFO][06:49:39]: [93m[1m[Client #119] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.94it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.99it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.04it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.06it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.07it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.211895306905111,)
[INFO][06:50:17]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 32.2062, 'train_samples_per_second': 187.976, 'train_steps_per_second': 2.981, 'train_loss': 3.211895306905111, 'epoch': 3.0}
[INFO][06:50:17]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][06:50:18]: [Client #119] Model trained.
[INFO][06:50:18]: [Client #119] Inbound data has been processed.
[INFO][06:50:18]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][06:50:23]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:50:24]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][06:50:24]: [Server #3995185] Selecting client #11 for training.
[INFO][06:50:24]: [Server #3995185] Sending the current model to client #11 (simulated).
[INFO][06:50:28]: [Server #3995185] Sending 507.38 MB of payload data to client #11 (simulated).
[INFO][06:50:28]: [Client #11] Selected by the server.
[INFO][06:50:28]: [Client #11] Loading its data source...
[INFO][06:50:28]: [Client #11] Dataset size: 2018
[INFO][06:50:28]: [Client #11] Sampler: iid
[INFO][06:50:30]: [Client #11] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:50:30]: [Client #11] Start to process inbound data.
[INFO][06:50:30]: [93m[1m[Client #11] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.97it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.97it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2495737075805664,)
[INFO][06:51:10]: [Client #11] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_11_3995237.pth.
{'train_runtime': 32.8663, 'train_samples_per_second': 184.201, 'train_steps_per_second': 2.921, 'train_loss': 3.2495737075805664, 'epoch': 3.0}
[INFO][06:51:10]: [Client #11] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_11_3995237.pth.
[INFO][06:51:11]: [Client #11] Model trained.
[INFO][06:51:11]: [Client #11] Inbound data has been processed.
[INFO][06:51:11]: [Client #11] Outbound data is ready to be sent after being processed.
[INFO][06:51:16]: [Client #11] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:51:17]: [Server #3995185] Received 507.38 MB of payload data from client #11 (simulated).
[INFO][06:51:17]: [Server #3995185] Selecting client #115 for training.
[INFO][06:51:17]: [Server #3995185] Sending the current model to client #115 (simulated).
[INFO][06:51:22]: [Server #3995185] Sending 507.38 MB of payload data to client #115 (simulated).
[INFO][06:51:22]: [Client #115] Selected by the server.
[INFO][06:51:22]: [Client #115] Loading its data source...
[INFO][06:51:22]: [Client #115] Dataset size: 2018
[INFO][06:51:22]: [Client #115] Sampler: iid
[INFO][06:51:23]: [Client #115] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:51:23]: [Client #115] Start to process inbound data.
[INFO][06:51:24]: [93m[1m[Client #115] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.01it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.97it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.235187530517578,)
[INFO][06:52:03]: [Client #115] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_115_3995237.pth.
{'train_runtime': 32.8099, 'train_samples_per_second': 184.517, 'train_steps_per_second': 2.926, 'train_loss': 3.235187530517578, 'epoch': 3.0}
[INFO][06:52:04]: [Client #115] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_115_3995237.pth.
[INFO][06:52:04]: [Client #115] Model trained.
[INFO][06:52:04]: [Client #115] Inbound data has been processed.
[INFO][06:52:04]: [Client #115] Outbound data is ready to be sent after being processed.
[INFO][06:52:09]: [Client #115] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:52:10]: [Server #3995185] Received 507.38 MB of payload data from client #115 (simulated).
[INFO][06:52:10]: [Server #3995185] Selecting client #34 for training.
[INFO][06:52:10]: [Server #3995185] Sending the current model to client #34 (simulated).
[INFO][06:52:15]: [Server #3995185] Sending 507.38 MB of payload data to client #34 (simulated).
[INFO][06:52:15]: [Client #34] Selected by the server.
[INFO][06:52:15]: [Client #34] Loading its data source...
[INFO][06:52:15]: [Client #34] Dataset size: 2018
[INFO][06:52:15]: [Client #34] Sampler: iid
[INFO][06:52:16]: [Client #34] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:52:16]: [Client #34] Start to process inbound data.
[INFO][06:52:16]: [93m[1m[Client #34] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2891632715861,)
[INFO][06:52:56]: [Client #34] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_34_3995237.pth.
{'train_runtime': 32.8448, 'train_samples_per_second': 184.321, 'train_steps_per_second': 2.923, 'train_loss': 3.2891632715861, 'epoch': 3.0}
[INFO][06:52:57]: [Client #34] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_34_3995237.pth.
[INFO][06:52:57]: [Client #34] Model trained.
[INFO][06:52:57]: [Client #34] Inbound data has been processed.
[INFO][06:52:57]: [Client #34] Outbound data is ready to be sent after being processed.
[INFO][06:53:02]: [Client #34] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:53:03]: [Server #3995185] Received 507.38 MB of payload data from client #34 (simulated).
[INFO][06:53:03]: [Server #3995185] Selecting client #177 for training.
[INFO][06:53:03]: [Server #3995185] Sending the current model to client #177 (simulated).
[INFO][06:53:08]: [Server #3995185] Sending 507.38 MB of payload data to client #177 (simulated).
[INFO][06:53:08]: [Client #177] Selected by the server.
[INFO][06:53:08]: [Client #177] Loading its data source...
[INFO][06:53:08]: [Client #177] Dataset size: 2018
[INFO][06:53:08]: [Client #177] Sampler: iid
[INFO][06:53:09]: [Client #177] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:53:09]: [Client #177] Start to process inbound data.
[INFO][06:53:09]: [93m[1m[Client #177] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.262787183125814,)
[INFO][06:53:47]: [Client #177] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
{'train_runtime': 32.3457, 'train_samples_per_second': 187.166, 'train_steps_per_second': 2.968, 'train_loss': 3.262787183125814, 'epoch': 3.0}
[INFO][06:53:48]: [Client #177] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
[INFO][06:53:49]: [Client #177] Model trained.
[INFO][06:53:49]: [Client #177] Inbound data has been processed.
[INFO][06:53:49]: [Client #177] Outbound data is ready to be sent after being processed.
[INFO][06:53:53]: [Client #177] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:53:54]: [Server #3995185] Received 507.38 MB of payload data from client #177 (simulated).
[INFO][06:53:54]: [Server #3995185] Selecting client #2 for training.
[INFO][06:53:54]: [Server #3995185] Sending the current model to client #2 (simulated).
[INFO][06:53:59]: [Server #3995185] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][06:53:59]: [Client #2] Selected by the server.
[INFO][06:53:59]: [Client #2] Loading its data source...
[INFO][06:53:59]: [Client #2] Dataset size: 2018
[INFO][06:53:59]: [Client #2] Sampler: iid
[INFO][06:54:01]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:54:01]: [Client #2] Start to process inbound data.
[INFO][06:54:01]: [93m[1m[Client #2] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:30,  1.59s/it]  2%|â–         | 2/96 [00:01<01:19,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.09it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2636947631835938,)
[INFO][06:54:39]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3995237.pth.
{'train_runtime': 32.3527, 'train_samples_per_second': 187.125, 'train_steps_per_second': 2.967, 'train_loss': 3.2636947631835938, 'epoch': 3.0}
[INFO][06:54:40]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3995237.pth.
[INFO][06:54:40]: [Client #2] Model trained.
[INFO][06:54:40]: [Client #2] Inbound data has been processed.
[INFO][06:54:40]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][06:54:45]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:54:46]: [Server #3995185] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][06:54:46]: [Server #3995185] Selecting client #26 for training.
[INFO][06:54:46]: [Server #3995185] Sending the current model to client #26 (simulated).
[INFO][06:54:50]: [Server #3995185] Sending 507.38 MB of payload data to client #26 (simulated).
[INFO][06:54:50]: [Client #26] Selected by the server.
[INFO][06:54:50]: [Client #26] Loading its data source...
[INFO][06:54:50]: [Client #26] Dataset size: 2018
[INFO][06:54:50]: [Client #26] Sampler: iid
[INFO][06:54:51]: [Client #26] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:54:51]: [Client #26] Start to process inbound data.
[INFO][06:54:52]: [93m[1m[Client #26] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:51,  1.80s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2636327743530273,)
[INFO][06:55:30]: [Client #26] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_26_3995237.pth.
{'train_runtime': 32.8113, 'train_samples_per_second': 184.509, 'train_steps_per_second': 2.926, 'train_loss': 3.2636327743530273, 'epoch': 3.0}
[INFO][06:55:31]: [Client #26] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_26_3995237.pth.
[INFO][06:55:32]: [Client #26] Model trained.
[INFO][06:55:32]: [Client #26] Inbound data has been processed.
[INFO][06:55:32]: [Client #26] Outbound data is ready to be sent after being processed.
[INFO][06:55:36]: [Client #26] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:55:37]: [Server #3995185] Received 507.38 MB of payload data from client #26 (simulated).
[INFO][06:55:37]: [Server #3995185] Selecting client #164 for training.
[INFO][06:55:37]: [Server #3995185] Sending the current model to client #164 (simulated).
[INFO][06:55:42]: [Server #3995185] Sending 507.38 MB of payload data to client #164 (simulated).
[INFO][06:55:42]: [Client #164] Selected by the server.
[INFO][06:55:42]: [Client #164] Loading its data source...
[INFO][06:55:42]: [Client #164] Dataset size: 2018
[INFO][06:55:42]: [Client #164] Sampler: iid
[INFO][06:55:43]: [Client #164] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:55:43]: [Client #164] Start to process inbound data.
[INFO][06:55:43]: [93m[1m[Client #164] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.278545697530111,)
[INFO][06:56:22]: [Client #164] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_164_3995237.pth.
{'train_runtime': 32.5367, 'train_samples_per_second': 186.067, 'train_steps_per_second': 2.951, 'train_loss': 3.278545697530111, 'epoch': 3.0}
[INFO][06:56:22]: [Client #164] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_164_3995237.pth.
[INFO][06:56:23]: [Client #164] Model trained.
[INFO][06:56:23]: [Client #164] Inbound data has been processed.
[INFO][06:56:23]: [Client #164] Outbound data is ready to be sent after being processed.
[INFO][06:56:27]: [Client #164] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:56:28]: [Server #3995185] Received 507.38 MB of payload data from client #164 (simulated).
[INFO][06:56:28]: [Server #3995185] Selecting client #50 for training.
[INFO][06:56:28]: [Server #3995185] Sending the current model to client #50 (simulated).
[INFO][06:56:32]: [Server #3995185] Sending 507.38 MB of payload data to client #50 (simulated).
[INFO][06:56:32]: [Client #50] Selected by the server.
[INFO][06:56:32]: [Client #50] Loading its data source...
[INFO][06:56:32]: [Client #50] Dataset size: 2018
[INFO][06:56:32]: [Client #50] Sampler: iid
[INFO][06:56:33]: [Client #50] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:56:33]: [Client #50] Start to process inbound data.
[INFO][06:56:33]: [93m[1m[Client #50] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.82s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:49,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.16it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.39it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.56it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.96it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.96it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2980477015177407,)
[INFO][06:57:13]: [Client #50] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_50_3995237.pth.
{'train_runtime': 33.03, 'train_samples_per_second': 183.288, 'train_steps_per_second': 2.906, 'train_loss': 3.2980477015177407, 'epoch': 3.0}
[INFO][06:57:14]: [Client #50] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_50_3995237.pth.
[INFO][06:57:14]: [Client #50] Model trained.
[INFO][06:57:14]: [Client #50] Inbound data has been processed.
[INFO][06:57:14]: [Client #50] Outbound data is ready to be sent after being processed.
[INFO][06:57:19]: [Client #50] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:57:20]: [Server #3995185] Received 507.38 MB of payload data from client #50 (simulated).
[INFO][06:57:20]: [Server #3995185] Selecting client #160 for training.
[INFO][06:57:20]: [Server #3995185] Sending the current model to client #160 (simulated).
[INFO][06:57:24]: [Server #3995185] Sending 507.38 MB of payload data to client #160 (simulated).
[INFO][06:57:24]: [Client #160] Selected by the server.
[INFO][06:57:24]: [Client #160] Loading its data source...
[INFO][06:57:24]: [Client #160] Dataset size: 2018
[INFO][06:57:24]: [Client #160] Sampler: iid
[INFO][06:57:25]: [Client #160] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:57:25]: [Client #160] Start to process inbound data.
[INFO][06:57:25]: [93m[1m[Client #160] Started training in communication round #18.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.02it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:19,  2.97it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  2.97it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.98it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.97it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.96it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.97it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.97it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.97it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.97it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2742897669474282,)
[INFO][06:58:05]: [Client #160] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_160_3995237.pth.
{'train_runtime': 33.0853, 'train_samples_per_second': 182.982, 'train_steps_per_second': 2.902, 'train_loss': 3.2742897669474282, 'epoch': 3.0}
[INFO][06:58:06]: [Client #160] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_160_3995237.pth.
[INFO][06:58:07]: [Client #160] Model trained.
[INFO][06:58:07]: [Client #160] Inbound data has been processed.
[INFO][06:58:07]: [Client #160] Outbound data is ready to be sent after being processed.
[INFO][06:58:11]: [Client #160] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:58:12]: [Server #3995185] Received 507.38 MB of payload data from client #160 (simulated).
[INFO][06:58:12]: [Server #3995185] Adding client #74 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #119 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #177 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #2 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #115 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #160 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #164 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #158 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #34 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Adding client #126 to the list of clients for aggregation.
[INFO][06:58:12]: [Server #3995185] Aggregating 10 clients in total.
[INFO][06:58:12]: [Server #3995185] Updated weights have been received.
[INFO][06:58:14]: [Server #3995185] Aggregating model weight deltas.
[INFO][06:58:15]: [Server #3995185] Finished aggregating updated weights.
[INFO][06:58:15]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.62it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.35it/s]
[INFO][06:58:25]: [93m[1m[Server #3995185] Global model perplexity: 25.80
[0m
[INFO][06:58:25]: [Server #3995185] All client reports have been processed.
[INFO][06:58:25]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_18.pth.
[INFO][06:58:29]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_18.pth.
[INFO][06:58:29]: [93m[1m
[Server #3995185] Starting round 19/50.[0m
[INFO][06:58:29]: [Server #3995185] Selected clients: [53, 112, 87, 99, 16, 27, 18, 84, 157, 90]
[INFO][06:58:29]: [Server #3995185] Selecting client #53 for training.
[INFO][06:58:29]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][06:58:36]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][06:58:36]: [Client #53] Selected by the server.
[INFO][06:58:36]: [Client #53] Loading its data source...
[INFO][06:58:36]: [Client #53] Dataset size: 2018
[INFO][06:58:36]: [Client #53] Sampler: iid
[INFO][06:58:38]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:58:38]: [Client #53] Start to process inbound data.
[INFO][06:58:38]: [93m[1m[Client #53] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.205203374226888,)
[INFO][06:59:17]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 33.0346, 'train_samples_per_second': 183.262, 'train_steps_per_second': 2.906, 'train_loss': 3.205203374226888, 'epoch': 3.0}
[INFO][06:59:18]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][06:59:19]: [Client #53] Model trained.
[INFO][06:59:19]: [Client #53] Inbound data has been processed.
[INFO][06:59:19]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][06:59:23]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][06:59:24]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][06:59:24]: [Server #3995185] Selecting client #112 for training.
[INFO][06:59:24]: [Server #3995185] Sending the current model to client #112 (simulated).
[INFO][06:59:32]: [Server #3995185] Sending 507.38 MB of payload data to client #112 (simulated).
[INFO][06:59:32]: [Client #112] Selected by the server.
[INFO][06:59:32]: [Client #112] Loading its data source...
[INFO][06:59:32]: [Client #112] Dataset size: 2018
[INFO][06:59:32]: [Client #112] Sampler: iid
[INFO][06:59:33]: [Client #112] Received 507.38 MB of payload data from the server (simulated).
[INFO][06:59:33]: [Client #112] Start to process inbound data.
[INFO][06:59:33]: [93m[1m[Client #112] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.10it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.10it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.10it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.10it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.10it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.09it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.08it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.55it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.30it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.23it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.09it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.08it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.09it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.10it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.10it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.11it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.12it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.12it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.12it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.01it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2335707346598306,)
[INFO][07:00:11]: [Client #112] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_112_3995237.pth.
{'train_runtime': 31.8841, 'train_samples_per_second': 189.875, 'train_steps_per_second': 3.011, 'train_loss': 3.2335707346598306, 'epoch': 3.0}
[INFO][07:00:12]: [Client #112] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_112_3995237.pth.
[INFO][07:00:12]: [Client #112] Model trained.
[INFO][07:00:12]: [Client #112] Inbound data has been processed.
[INFO][07:00:12]: [Client #112] Outbound data is ready to be sent after being processed.
[INFO][07:00:17]: [Client #112] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:00:19]: [Server #3995185] Received 507.38 MB of payload data from client #112 (simulated).
[INFO][07:00:19]: [Server #3995185] Selecting client #87 for training.
[INFO][07:00:19]: [Server #3995185] Sending the current model to client #87 (simulated).
[INFO][07:00:25]: [Server #3995185] Sending 507.38 MB of payload data to client #87 (simulated).
[INFO][07:00:25]: [Client #87] Selected by the server.
[INFO][07:00:25]: [Client #87] Loading its data source...
[INFO][07:00:25]: [Client #87] Dataset size: 2018
[INFO][07:00:25]: [Client #87] Sampler: iid
[INFO][07:00:27]: [Client #87] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:00:27]: [Client #87] Start to process inbound data.
[INFO][07:00:27]: [93m[1m[Client #87] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:29,  1.58s/it]  2%|â–         | 2/96 [00:01<01:18,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.06it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.06it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.06it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2297865549723306,)
[INFO][07:01:06]: [Client #87] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_87_3995237.pth.
{'train_runtime': 32.3553, 'train_samples_per_second': 187.11, 'train_steps_per_second': 2.967, 'train_loss': 3.2297865549723306, 'epoch': 3.0}
[INFO][07:01:07]: [Client #87] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_87_3995237.pth.
[INFO][07:01:07]: [Client #87] Model trained.
[INFO][07:01:07]: [Client #87] Inbound data has been processed.
[INFO][07:01:07]: [Client #87] Outbound data is ready to be sent after being processed.
[INFO][07:01:12]: [Client #87] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:01:13]: [Server #3995185] Received 507.38 MB of payload data from client #87 (simulated).
[INFO][07:01:13]: [Server #3995185] Selecting client #99 for training.
[INFO][07:01:13]: [Server #3995185] Sending the current model to client #99 (simulated).
[INFO][07:01:17]: [Server #3995185] Sending 507.38 MB of payload data to client #99 (simulated).
[INFO][07:01:17]: [Client #99] Selected by the server.
[INFO][07:01:17]: [Client #99] Loading its data source...
[INFO][07:01:17]: [Client #99] Dataset size: 2018
[INFO][07:01:17]: [Client #99] Sampler: iid
[INFO][07:01:18]: [Client #99] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:01:18]: [Client #99] Start to process inbound data.
[INFO][07:01:18]: [93m[1m[Client #99] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.21284548441569,)
[INFO][07:01:57]: [Client #99] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_99_3995237.pth.
{'train_runtime': 32.5718, 'train_samples_per_second': 185.866, 'train_steps_per_second': 2.947, 'train_loss': 3.21284548441569, 'epoch': 3.0}
[INFO][07:01:58]: [Client #99] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_99_3995237.pth.
[INFO][07:01:58]: [Client #99] Model trained.
[INFO][07:01:58]: [Client #99] Inbound data has been processed.
[INFO][07:01:58]: [Client #99] Outbound data is ready to be sent after being processed.
[INFO][07:02:02]: [Client #99] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:02:03]: [Server #3995185] Received 507.38 MB of payload data from client #99 (simulated).
[INFO][07:02:03]: [Server #3995185] Selecting client #16 for training.
[INFO][07:02:03]: [Server #3995185] Sending the current model to client #16 (simulated).
[INFO][07:02:07]: [Server #3995185] Sending 507.38 MB of payload data to client #16 (simulated).
[INFO][07:02:07]: [Client #16] Selected by the server.
[INFO][07:02:07]: [Client #16] Loading its data source...
[INFO][07:02:07]: [Client #16] Dataset size: 2018
[INFO][07:02:07]: [Client #16] Sampler: iid
[INFO][07:02:09]: [Client #16] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:02:09]: [Client #16] Start to process inbound data.
[INFO][07:02:09]: [93m[1m[Client #16] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.59s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.207310676574707,)
[INFO][07:02:47]: [Client #16] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_16_3995237.pth.
{'train_runtime': 32.4223, 'train_samples_per_second': 186.723, 'train_steps_per_second': 2.961, 'train_loss': 3.207310676574707, 'epoch': 3.0}
[INFO][07:02:48]: [Client #16] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_16_3995237.pth.
[INFO][07:02:49]: [Client #16] Model trained.
[INFO][07:02:49]: [Client #16] Inbound data has been processed.
[INFO][07:02:49]: [Client #16] Outbound data is ready to be sent after being processed.
[INFO][07:02:54]: [Client #16] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:02:54]: [Server #3995185] Received 507.38 MB of payload data from client #16 (simulated).
[INFO][07:02:54]: [Server #3995185] Selecting client #27 for training.
[INFO][07:02:54]: [Server #3995185] Sending the current model to client #27 (simulated).
[INFO][07:02:59]: [Server #3995185] Sending 507.38 MB of payload data to client #27 (simulated).
[INFO][07:02:59]: [Client #27] Selected by the server.
[INFO][07:02:59]: [Client #27] Loading its data source...
[INFO][07:02:59]: [Client #27] Dataset size: 2018
[INFO][07:02:59]: [Client #27] Sampler: iid
[INFO][07:03:01]: [Client #27] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:03:01]: [Client #27] Start to process inbound data.
[INFO][07:03:01]: [93m[1m[Client #27] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.10it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.10it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.10it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.55it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2207457224527993,)
[INFO][07:03:40]: [Client #27] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_27_3995237.pth.
{'train_runtime': 32.4593, 'train_samples_per_second': 186.511, 'train_steps_per_second': 2.958, 'train_loss': 3.2207457224527993, 'epoch': 3.0}
[INFO][07:03:40]: [Client #27] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_27_3995237.pth.
[INFO][07:03:41]: [Client #27] Model trained.
[INFO][07:03:41]: [Client #27] Inbound data has been processed.
[INFO][07:03:41]: [Client #27] Outbound data is ready to be sent after being processed.
[INFO][07:03:46]: [Client #27] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:03:47]: [Server #3995185] Received 507.38 MB of payload data from client #27 (simulated).
[INFO][07:03:47]: [Server #3995185] Selecting client #18 for training.
[INFO][07:03:47]: [Server #3995185] Sending the current model to client #18 (simulated).
[INFO][07:03:51]: [Server #3995185] Sending 507.38 MB of payload data to client #18 (simulated).
[INFO][07:03:51]: [Client #18] Selected by the server.
[INFO][07:03:51]: [Client #18] Loading its data source...
[INFO][07:03:51]: [Client #18] Dataset size: 2018
[INFO][07:03:51]: [Client #18] Sampler: iid
[INFO][07:03:52]: [Client #18] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:03:52]: [Client #18] Start to process inbound data.
[INFO][07:03:53]: [93m[1m[Client #18] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.207943598429362,)
[INFO][07:04:31]: [Client #18] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_18_3995237.pth.
{'train_runtime': 32.1926, 'train_samples_per_second': 188.056, 'train_steps_per_second': 2.982, 'train_loss': 3.207943598429362, 'epoch': 3.0}
[INFO][07:04:32]: [Client #18] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_18_3995237.pth.
[INFO][07:04:33]: [Client #18] Model trained.
[INFO][07:04:33]: [Client #18] Inbound data has been processed.
[INFO][07:04:33]: [Client #18] Outbound data is ready to be sent after being processed.
[INFO][07:04:37]: [Client #18] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:04:38]: [Server #3995185] Received 507.38 MB of payload data from client #18 (simulated).
[INFO][07:04:38]: [Server #3995185] Selecting client #84 for training.
[INFO][07:04:38]: [Server #3995185] Sending the current model to client #84 (simulated).
[INFO][07:04:43]: [Server #3995185] Sending 507.38 MB of payload data to client #84 (simulated).
[INFO][07:04:43]: [Client #84] Selected by the server.
[INFO][07:04:43]: [Client #84] Loading its data source...
[INFO][07:04:43]: [Client #84] Dataset size: 2018
[INFO][07:04:43]: [Client #84] Sampler: iid
[INFO][07:04:44]: [Client #84] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:04:44]: [Client #84] Start to process inbound data.
[INFO][07:04:45]: [93m[1m[Client #84] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.07it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2171713511149087,)
[INFO][07:05:23]: [Client #84] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_84_3995237.pth.
{'train_runtime': 32.1843, 'train_samples_per_second': 188.104, 'train_steps_per_second': 2.983, 'train_loss': 3.2171713511149087, 'epoch': 3.0}
[INFO][07:05:24]: [Client #84] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_84_3995237.pth.
[INFO][07:05:24]: [Client #84] Model trained.
[INFO][07:05:24]: [Client #84] Inbound data has been processed.
[INFO][07:05:24]: [Client #84] Outbound data is ready to be sent after being processed.
[INFO][07:05:29]: [Client #84] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:05:30]: [Server #3995185] Received 507.38 MB of payload data from client #84 (simulated).
[INFO][07:05:30]: [Server #3995185] Selecting client #157 for training.
[INFO][07:05:30]: [Server #3995185] Sending the current model to client #157 (simulated).
[INFO][07:05:35]: [Server #3995185] Sending 507.38 MB of payload data to client #157 (simulated).
[INFO][07:05:35]: [Client #157] Selected by the server.
[INFO][07:05:35]: [Client #157] Loading its data source...
[INFO][07:05:35]: [Client #157] Dataset size: 2018
[INFO][07:05:35]: [Client #157] Sampler: iid
[INFO][07:05:37]: [Client #157] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:05:37]: [Client #157] Start to process inbound data.
[INFO][07:05:37]: [93m[1m[Client #157] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.237391471862793,)
[INFO][07:06:15]: [Client #157] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_157_3995237.pth.
{'train_runtime': 32.5491, 'train_samples_per_second': 185.996, 'train_steps_per_second': 2.949, 'train_loss': 3.237391471862793, 'epoch': 3.0}
[INFO][07:06:16]: [Client #157] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_157_3995237.pth.
[INFO][07:06:17]: [Client #157] Model trained.
[INFO][07:06:17]: [Client #157] Inbound data has been processed.
[INFO][07:06:17]: [Client #157] Outbound data is ready to be sent after being processed.
[INFO][07:06:22]: [Client #157] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:06:23]: [Server #3995185] Received 507.38 MB of payload data from client #157 (simulated).
[INFO][07:06:23]: [Server #3995185] Selecting client #90 for training.
[INFO][07:06:23]: [Server #3995185] Sending the current model to client #90 (simulated).
[INFO][07:06:29]: [Server #3995185] Sending 507.38 MB of payload data to client #90 (simulated).
[INFO][07:06:29]: [Client #90] Selected by the server.
[INFO][07:06:29]: [Client #90] Loading its data source...
[INFO][07:06:29]: [Client #90] Dataset size: 2018
[INFO][07:06:29]: [Client #90] Sampler: iid
[INFO][07:06:30]: [Client #90] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:06:30]: [Client #90] Start to process inbound data.
[INFO][07:06:31]: [93m[1m[Client #90] Started training in communication round #19.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.17it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.07it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.08it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2103665669759116,)
[INFO][07:07:09]: [Client #90] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_90_3995237.pth.
{'train_runtime': 32.0762, 'train_samples_per_second': 188.738, 'train_steps_per_second': 2.993, 'train_loss': 3.2103665669759116, 'epoch': 3.0}
[INFO][07:07:10]: [Client #90] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_90_3995237.pth.
[INFO][07:07:10]: [Client #90] Model trained.
[INFO][07:07:10]: [Client #90] Inbound data has been processed.
[INFO][07:07:10]: [Client #90] Outbound data is ready to be sent after being processed.
[INFO][07:07:15]: [Client #90] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:07:16]: [Server #3995185] Received 507.38 MB of payload data from client #90 (simulated).
[INFO][07:07:16]: [Server #3995185] Adding client #128 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #170 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #186 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #197 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #53 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #27 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #18 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #16 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #31 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Adding client #121 to the list of clients for aggregation.
[INFO][07:07:16]: [Server #3995185] Aggregating 10 clients in total.
[INFO][07:07:16]: [Server #3995185] Updated weights have been received.
[INFO][07:07:17]: [Server #3995185] Aggregating model weight deltas.
[INFO][07:07:18]: [Server #3995185] Finished aggregating updated weights.
[INFO][07:07:18]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:00<00:00, 49.77it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:00<00:00, 41.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.04it/s]
[INFO][07:07:27]: [93m[1m[Server #3995185] Global model perplexity: 25.88
[0m
[INFO][07:07:27]: [Server #3995185] All client reports have been processed.
[INFO][07:07:27]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_19.pth.
[INFO][07:07:32]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_19.pth.
[INFO][07:07:32]: [93m[1m
[Server #3995185] Starting round 20/50.[0m
[INFO][07:07:32]: [Server #3995185] Selected clients: [183, 52, 37, 54, 78, 1, 81, 143, 64, 194]
[INFO][07:07:32]: [Server #3995185] Selecting client #183 for training.
[INFO][07:07:32]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][07:07:37]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][07:07:37]: [Client #183] Selected by the server.
[INFO][07:07:37]: [Client #183] Loading its data source...
[INFO][07:07:37]: [Client #183] Dataset size: 2018
[INFO][07:07:37]: [Client #183] Sampler: iid
[INFO][07:07:38]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:07:38]: [Client #183] Start to process inbound data.
[INFO][07:07:39]: [93m[1m[Client #183] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:26,  3.07it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.16658878326416,)
[INFO][07:08:16]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.0394, 'train_samples_per_second': 188.955, 'train_steps_per_second': 2.996, 'train_loss': 3.16658878326416, 'epoch': 3.0}
[INFO][07:08:17]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][07:08:18]: [Client #183] Model trained.
[INFO][07:08:18]: [Client #183] Inbound data has been processed.
[INFO][07:08:18]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][07:08:26]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:08:27]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][07:08:27]: [Server #3995185] Selecting client #52 for training.
[INFO][07:08:27]: [Server #3995185] Sending the current model to client #52 (simulated).
[INFO][07:08:32]: [Server #3995185] Sending 507.38 MB of payload data to client #52 (simulated).
[INFO][07:08:32]: [Client #52] Selected by the server.
[INFO][07:08:32]: [Client #52] Loading its data source...
[INFO][07:08:32]: [Client #52] Dataset size: 2018
[INFO][07:08:32]: [Client #52] Sampler: iid
[INFO][07:08:33]: [Client #52] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:08:33]: [Client #52] Start to process inbound data.
[INFO][07:08:33]: [93m[1m[Client #52] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:24,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.15it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.13it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.11it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.10it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.09it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.09it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.09it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.09it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.09it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.09it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.08it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.53it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2243143717447915,)
[INFO][07:09:12]: [Client #52] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_52_3995237.pth.
{'train_runtime': 32.2151, 'train_samples_per_second': 187.925, 'train_steps_per_second': 2.98, 'train_loss': 3.2243143717447915, 'epoch': 3.0}
[INFO][07:09:13]: [Client #52] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_52_3995237.pth.
[INFO][07:09:14]: [Client #52] Model trained.
[INFO][07:09:14]: [Client #52] Inbound data has been processed.
[INFO][07:09:14]: [Client #52] Outbound data is ready to be sent after being processed.
[INFO][07:09:19]: [Client #52] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:09:20]: [Server #3995185] Received 507.38 MB of payload data from client #52 (simulated).
[INFO][07:09:20]: [Server #3995185] Selecting client #37 for training.
[INFO][07:09:20]: [Server #3995185] Sending the current model to client #37 (simulated).
[INFO][07:09:26]: [Server #3995185] Sending 507.38 MB of payload data to client #37 (simulated).
[INFO][07:09:26]: [Client #37] Selected by the server.
[INFO][07:09:26]: [Client #37] Loading its data source...
[INFO][07:09:26]: [Client #37] Dataset size: 2018
[INFO][07:09:26]: [Client #37] Sampler: iid
[INFO][07:09:28]: [Client #37] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:09:28]: [Client #37] Start to process inbound data.
[INFO][07:09:29]: [93m[1m[Client #37] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2149477005004883,)
[INFO][07:10:07]: [Client #37] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
{'train_runtime': 32.5317, 'train_samples_per_second': 186.095, 'train_steps_per_second': 2.951, 'train_loss': 3.2149477005004883, 'epoch': 3.0}
[INFO][07:10:08]: [Client #37] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
[INFO][07:10:08]: [Client #37] Model trained.
[INFO][07:10:08]: [Client #37] Inbound data has been processed.
[INFO][07:10:08]: [Client #37] Outbound data is ready to be sent after being processed.
[INFO][07:10:13]: [Client #37] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:10:15]: [Server #3995185] Received 507.38 MB of payload data from client #37 (simulated).
[INFO][07:10:15]: [Server #3995185] Selecting client #54 for training.
[INFO][07:10:15]: [Server #3995185] Sending the current model to client #54 (simulated).
[INFO][07:10:22]: [Server #3995185] Sending 507.38 MB of payload data to client #54 (simulated).
[INFO][07:10:22]: [Client #54] Selected by the server.
[INFO][07:10:22]: [Client #54] Loading its data source...
[INFO][07:10:22]: [Client #54] Dataset size: 2018
[INFO][07:10:22]: [Client #54] Sampler: iid
[INFO][07:10:23]: [Client #54] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:10:23]: [Client #54] Start to process inbound data.
[INFO][07:10:24]: [93m[1m[Client #54] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.93it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.38it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2231079737345376,)
[INFO][07:11:02]: [Client #54] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
{'train_runtime': 32.7508, 'train_samples_per_second': 184.85, 'train_steps_per_second': 2.931, 'train_loss': 3.2231079737345376, 'epoch': 3.0}
[INFO][07:11:03]: [Client #54] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
[INFO][07:11:04]: [Client #54] Model trained.
[INFO][07:11:04]: [Client #54] Inbound data has been processed.
[INFO][07:11:04]: [Client #54] Outbound data is ready to be sent after being processed.
[INFO][07:11:10]: [Client #54] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:11:11]: [Server #3995185] Received 507.38 MB of payload data from client #54 (simulated).
[INFO][07:11:11]: [Server #3995185] Selecting client #78 for training.
[INFO][07:11:11]: [Server #3995185] Sending the current model to client #78 (simulated).
[INFO][07:11:19]: [Server #3995185] Sending 507.38 MB of payload data to client #78 (simulated).
[INFO][07:11:19]: [Client #78] Selected by the server.
[INFO][07:11:19]: [Client #78] Loading its data source...
[INFO][07:11:19]: [Client #78] Dataset size: 2018
[INFO][07:11:19]: [Client #78] Sampler: iid
[INFO][07:11:21]: [Client #78] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:11:21]: [Client #78] Start to process inbound data.
[INFO][07:11:21]: [93m[1m[Client #78] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.216130574544271,)
[INFO][07:12:00]: [Client #78] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3995237.pth.
{'train_runtime': 32.0512, 'train_samples_per_second': 188.885, 'train_steps_per_second': 2.995, 'train_loss': 3.216130574544271, 'epoch': 3.0}
[INFO][07:12:00]: [Client #78] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3995237.pth.
[INFO][07:12:01]: [Client #78] Model trained.
[INFO][07:12:01]: [Client #78] Inbound data has been processed.
[INFO][07:12:01]: [Client #78] Outbound data is ready to be sent after being processed.
[INFO][07:12:07]: [Client #78] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:12:08]: [Server #3995185] Received 507.38 MB of payload data from client #78 (simulated).
[INFO][07:12:08]: [Server #3995185] Selecting client #1 for training.
[INFO][07:12:08]: [Server #3995185] Sending the current model to client #1 (simulated).
[INFO][07:12:15]: [Server #3995185] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][07:12:15]: [Client #1] Selected by the server.
[INFO][07:12:15]: [Client #1] Loading its data source...
[INFO][07:12:15]: [Client #1] Dataset size: 2018
[INFO][07:12:15]: [Client #1] Sampler: iid
[INFO][07:12:16]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:12:16]: [Client #1] Start to process inbound data.
[INFO][07:12:17]: [93m[1m[Client #1] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.214069366455078,)
[INFO][07:12:55]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
{'train_runtime': 32.1684, 'train_samples_per_second': 188.197, 'train_steps_per_second': 2.984, 'train_loss': 3.214069366455078, 'epoch': 3.0}
[INFO][07:12:56]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
[INFO][07:12:56]: [Client #1] Model trained.
[INFO][07:12:56]: [Client #1] Inbound data has been processed.
[INFO][07:12:56]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][07:13:04]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:13:05]: [Server #3995185] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][07:13:05]: [Server #3995185] Selecting client #81 for training.
[INFO][07:13:05]: [Server #3995185] Sending the current model to client #81 (simulated).
[INFO][07:13:13]: [Server #3995185] Sending 507.38 MB of payload data to client #81 (simulated).
[INFO][07:13:13]: [Client #81] Selected by the server.
[INFO][07:13:13]: [Client #81] Loading its data source...
[INFO][07:13:13]: [Client #81] Dataset size: 2018
[INFO][07:13:13]: [Client #81] Sampler: iid
[INFO][07:13:14]: [Client #81] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:13:14]: [Client #81] Start to process inbound data.
[INFO][07:13:15]: [93m[1m[Client #81] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:27,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.66it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.07it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.11it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.11it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.12it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.13it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.11it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.11it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.42it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.11it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.10it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.09it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.09it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.09it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.09it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.10it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.09it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.09it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.09it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.06it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.06it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.07it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.05it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2081963221232095,)
[INFO][07:13:53]: [Client #81] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_81_3995237.pth.
{'train_runtime': 31.989, 'train_samples_per_second': 189.252, 'train_steps_per_second': 3.001, 'train_loss': 3.2081963221232095, 'epoch': 3.0}
[INFO][07:13:54]: [Client #81] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_81_3995237.pth.
[INFO][07:13:55]: [Client #81] Model trained.
[INFO][07:13:55]: [Client #81] Inbound data has been processed.
[INFO][07:13:55]: [Client #81] Outbound data is ready to be sent after being processed.
[INFO][07:14:01]: [Client #81] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:14:02]: [Server #3995185] Received 507.38 MB of payload data from client #81 (simulated).
[INFO][07:14:02]: [Server #3995185] Selecting client #143 for training.
[INFO][07:14:02]: [Server #3995185] Sending the current model to client #143 (simulated).
[INFO][07:14:09]: [Server #3995185] Sending 507.38 MB of payload data to client #143 (simulated).
[INFO][07:14:09]: [Client #143] Selected by the server.
[INFO][07:14:09]: [Client #143] Loading its data source...
[INFO][07:14:09]: [Client #143] Dataset size: 2018
[INFO][07:14:09]: [Client #143] Sampler: iid
[INFO][07:14:10]: [Client #143] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:14:10]: [Client #143] Start to process inbound data.
[INFO][07:14:10]: [93m[1m[Client #143] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.87it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2149683634440103,)
[INFO][07:14:48]: [Client #143] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
{'train_runtime': 32.0354, 'train_samples_per_second': 188.978, 'train_steps_per_second': 2.997, 'train_loss': 3.2149683634440103, 'epoch': 3.0}
[INFO][07:14:48]: [Client #143] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
[INFO][07:14:49]: [Client #143] Model trained.
[INFO][07:14:49]: [Client #143] Inbound data has been processed.
[INFO][07:14:49]: [Client #143] Outbound data is ready to be sent after being processed.
[INFO][07:14:56]: [Client #143] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:14:57]: [Server #3995185] Received 507.38 MB of payload data from client #143 (simulated).
[INFO][07:14:57]: [Server #3995185] Selecting client #64 for training.
[INFO][07:14:57]: [Server #3995185] Sending the current model to client #64 (simulated).
[INFO][07:15:04]: [Server #3995185] Sending 507.38 MB of payload data to client #64 (simulated).
[INFO][07:15:04]: [Client #64] Selected by the server.
[INFO][07:15:04]: [Client #64] Loading its data source...
[INFO][07:15:04]: [Client #64] Dataset size: 2018
[INFO][07:15:04]: [Client #64] Sampler: iid
[INFO][07:15:05]: [Client #64] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:15:05]: [Client #64] Start to process inbound data.
[INFO][07:15:05]: [93m[1m[Client #64] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.54s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2325057983398438,)
[INFO][07:15:44]: [Client #64] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_64_3995237.pth.
{'train_runtime': 32.5101, 'train_samples_per_second': 186.219, 'train_steps_per_second': 2.953, 'train_loss': 3.2325057983398438, 'epoch': 3.0}
[INFO][07:15:45]: [Client #64] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_64_3995237.pth.
[INFO][07:15:45]: [Client #64] Model trained.
[INFO][07:15:45]: [Client #64] Inbound data has been processed.
[INFO][07:15:45]: [Client #64] Outbound data is ready to be sent after being processed.
[INFO][07:15:53]: [Client #64] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:15:54]: [Server #3995185] Received 507.38 MB of payload data from client #64 (simulated).
[INFO][07:15:54]: [Server #3995185] Selecting client #194 for training.
[INFO][07:15:54]: [Server #3995185] Sending the current model to client #194 (simulated).
[INFO][07:16:00]: [Server #3995185] Sending 507.38 MB of payload data to client #194 (simulated).
[INFO][07:16:00]: [Client #194] Selected by the server.
[INFO][07:16:00]: [Client #194] Loading its data source...
[INFO][07:16:00]: [Client #194] Dataset size: 2018
[INFO][07:16:00]: [Client #194] Sampler: iid
[INFO][07:16:01]: [Client #194] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:16:01]: [Client #194] Start to process inbound data.
[INFO][07:16:02]: [93m[1m[Client #194] Started training in communication round #20.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.81s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.50it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.69it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.2197020848592124,)
[INFO][07:16:41]: [Client #194] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_194_3995237.pth.
{'train_runtime': 32.9802, 'train_samples_per_second': 183.564, 'train_steps_per_second': 2.911, 'train_loss': 3.2197020848592124, 'epoch': 3.0}
[INFO][07:16:42]: [Client #194] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_194_3995237.pth.
[INFO][07:16:43]: [Client #194] Model trained.
[INFO][07:16:43]: [Client #194] Inbound data has been processed.
[INFO][07:16:43]: [Client #194] Outbound data is ready to be sent after being processed.
[INFO][07:16:51]: [Client #194] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:16:52]: [Server #3995185] Received 507.38 MB of payload data from client #194 (simulated).
[INFO][07:16:52]: [Server #3995185] Adding client #190 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #1 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #37 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #54 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #78 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #143 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #81 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #84 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Adding client #11 to the list of clients for aggregation.
[INFO][07:16:52]: [Server #3995185] Aggregating 10 clients in total.
[INFO][07:16:52]: [Server #3995185] Updated weights have been received.
[INFO][07:16:54]: [Server #3995185] Aggregating model weight deltas.
[INFO][07:16:55]: [Server #3995185] Finished aggregating updated weights.
[INFO][07:16:55]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.36it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.68it/s]
[INFO][07:17:04]: [93m[1m[Server #3995185] Global model perplexity: 25.19
[0m
[INFO][07:17:04]: [Server #3995185] All client reports have been processed.
[INFO][07:17:05]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_20.pth.
[INFO][07:17:07]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_20.pth.
[INFO][07:17:07]: [93m[1m
[Server #3995185] Starting round 21/50.[0m
[INFO][07:17:07]: [Server #3995185] Selected clients: [144, 14, 58, 173, 184, 133, 188, 151, 42, 4]
[INFO][07:17:07]: [Server #3995185] Selecting client #144 for training.
[INFO][07:17:07]: [Server #3995185] Sending the current model to client #144 (simulated).
[INFO][07:17:12]: [Server #3995185] Sending 507.38 MB of payload data to client #144 (simulated).
[INFO][07:17:12]: [Client #144] Selected by the server.
[INFO][07:17:12]: [Client #144] Loading its data source...
[INFO][07:17:12]: [Client #144] Dataset size: 2018
[INFO][07:17:12]: [Client #144] Sampler: iid
[INFO][07:17:14]: [Client #144] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:17:14]: [Client #144] Start to process inbound data.
[INFO][07:17:14]: [93m[1m[Client #144] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.09it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1593427658081055,)
[INFO][07:17:52]: [Client #144] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
{'train_runtime': 32.2856, 'train_samples_per_second': 187.514, 'train_steps_per_second': 2.973, 'train_loss': 3.1593427658081055, 'epoch': 3.0}
[INFO][07:17:53]: [Client #144] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
[INFO][07:17:53]: [Client #144] Model trained.
[INFO][07:17:53]: [Client #144] Inbound data has been processed.
[INFO][07:17:53]: [Client #144] Outbound data is ready to be sent after being processed.
[INFO][07:17:58]: [Client #144] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:17:59]: [Server #3995185] Received 507.38 MB of payload data from client #144 (simulated).
[INFO][07:17:59]: [Server #3995185] Selecting client #14 for training.
[INFO][07:17:59]: [Server #3995185] Sending the current model to client #14 (simulated).
[INFO][07:18:04]: [Server #3995185] Sending 507.38 MB of payload data to client #14 (simulated).
[INFO][07:18:04]: [Client #14] Selected by the server.
[INFO][07:18:04]: [Client #14] Loading its data source...
[INFO][07:18:04]: [Client #14] Dataset size: 2018
[INFO][07:18:04]: [Client #14] Sampler: iid
[INFO][07:18:05]: [Client #14] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:18:05]: [Client #14] Start to process inbound data.
[INFO][07:18:05]: [93m[1m[Client #14] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.07it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.182854970296224,)
[INFO][07:18:43]: [Client #14] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
{'train_runtime': 32.2633, 'train_samples_per_second': 187.644, 'train_steps_per_second': 2.976, 'train_loss': 3.182854970296224, 'epoch': 3.0}
[INFO][07:18:44]: [Client #14] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
[INFO][07:18:45]: [Client #14] Model trained.
[INFO][07:18:45]: [Client #14] Inbound data has been processed.
[INFO][07:18:45]: [Client #14] Outbound data is ready to be sent after being processed.
[INFO][07:18:49]: [Client #14] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:18:51]: [Server #3995185] Received 507.38 MB of payload data from client #14 (simulated).
[INFO][07:18:51]: [Server #3995185] Selecting client #58 for training.
[INFO][07:18:51]: [Server #3995185] Sending the current model to client #58 (simulated).
[INFO][07:18:55]: [Server #3995185] Sending 507.38 MB of payload data to client #58 (simulated).
[INFO][07:18:55]: [Client #58] Selected by the server.
[INFO][07:18:55]: [Client #58] Loading its data source...
[INFO][07:18:55]: [Client #58] Dataset size: 2018
[INFO][07:18:55]: [Client #58] Sampler: iid
[INFO][07:18:57]: [Client #58] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:18:57]: [Client #58] Start to process inbound data.
[INFO][07:18:57]: [93m[1m[Client #58] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1771316528320312,)
[INFO][07:19:35]: [Client #58] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_58_3995237.pth.
{'train_runtime': 32.1719, 'train_samples_per_second': 188.177, 'train_steps_per_second': 2.984, 'train_loss': 3.1771316528320312, 'epoch': 3.0}
[INFO][07:19:36]: [Client #58] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_58_3995237.pth.
[INFO][07:19:36]: [Client #58] Model trained.
[INFO][07:19:36]: [Client #58] Inbound data has been processed.
[INFO][07:19:36]: [Client #58] Outbound data is ready to be sent after being processed.
[INFO][07:19:41]: [Client #58] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:19:42]: [Server #3995185] Received 507.38 MB of payload data from client #58 (simulated).
[INFO][07:19:42]: [Server #3995185] Selecting client #173 for training.
[INFO][07:19:42]: [Server #3995185] Sending the current model to client #173 (simulated).
[INFO][07:19:47]: [Server #3995185] Sending 507.38 MB of payload data to client #173 (simulated).
[INFO][07:19:47]: [Client #173] Selected by the server.
[INFO][07:19:47]: [Client #173] Loading its data source...
[INFO][07:19:47]: [Client #173] Dataset size: 2018
[INFO][07:19:47]: [Client #173] Sampler: iid
[INFO][07:19:48]: [Client #173] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:19:48]: [Client #173] Start to process inbound data.
[INFO][07:19:48]: [93m[1m[Client #173] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.48s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.32it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.154995918273926,)
[INFO][07:20:27]: [Client #173] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_173_3995237.pth.
{'train_runtime': 32.6886, 'train_samples_per_second': 185.202, 'train_steps_per_second': 2.937, 'train_loss': 3.154995918273926, 'epoch': 3.0}
[INFO][07:20:27]: [Client #173] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_173_3995237.pth.
[INFO][07:20:28]: [Client #173] Model trained.
[INFO][07:20:28]: [Client #173] Inbound data has been processed.
[INFO][07:20:28]: [Client #173] Outbound data is ready to be sent after being processed.
[INFO][07:20:32]: [Client #173] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:20:34]: [Server #3995185] Received 507.38 MB of payload data from client #173 (simulated).
[INFO][07:20:34]: [Server #3995185] Selecting client #184 for training.
[INFO][07:20:34]: [Server #3995185] Sending the current model to client #184 (simulated).
[INFO][07:20:38]: [Server #3995185] Sending 507.38 MB of payload data to client #184 (simulated).
[INFO][07:20:38]: [Client #184] Selected by the server.
[INFO][07:20:38]: [Client #184] Loading its data source...
[INFO][07:20:38]: [Client #184] Dataset size: 2018
[INFO][07:20:38]: [Client #184] Sampler: iid
[INFO][07:20:40]: [Client #184] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:20:40]: [Client #184] Start to process inbound data.
[INFO][07:20:40]: [93m[1m[Client #184] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:38,  1.67s/it]  2%|â–         | 2/96 [00:01<01:22,  1.13it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.59it/s]  4%|â–         | 4/96 [00:02<00:46,  1.97it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.176295598347982,)
[INFO][07:21:18]: [Client #184] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_184_3995237.pth.
{'train_runtime': 32.4758, 'train_samples_per_second': 186.416, 'train_steps_per_second': 2.956, 'train_loss': 3.176295598347982, 'epoch': 3.0}
[INFO][07:21:19]: [Client #184] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_184_3995237.pth.
[INFO][07:21:19]: [Client #184] Model trained.
[INFO][07:21:19]: [Client #184] Inbound data has been processed.
[INFO][07:21:19]: [Client #184] Outbound data is ready to be sent after being processed.
[INFO][07:21:25]: [Client #184] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:21:26]: [Server #3995185] Received 507.38 MB of payload data from client #184 (simulated).
[INFO][07:21:26]: [Server #3995185] Selecting client #133 for training.
[INFO][07:21:26]: [Server #3995185] Sending the current model to client #133 (simulated).
[INFO][07:21:31]: [Server #3995185] Sending 507.38 MB of payload data to client #133 (simulated).
[INFO][07:21:31]: [Client #133] Selected by the server.
[INFO][07:21:31]: [Client #133] Loading its data source...
[INFO][07:21:31]: [Client #133] Dataset size: 2018
[INFO][07:21:31]: [Client #133] Sampler: iid
[INFO][07:21:32]: [Client #133] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:21:32]: [Client #133] Start to process inbound data.
[INFO][07:21:32]: [93m[1m[Client #133] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:45,  1.74s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.160630226135254,)
[INFO][07:22:11]: [Client #133] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_133_3995237.pth.
{'train_runtime': 32.9606, 'train_samples_per_second': 183.674, 'train_steps_per_second': 2.913, 'train_loss': 3.160630226135254, 'epoch': 3.0}
[INFO][07:22:12]: [Client #133] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_133_3995237.pth.
[INFO][07:22:13]: [Client #133] Model trained.
[INFO][07:22:13]: [Client #133] Inbound data has been processed.
[INFO][07:22:13]: [Client #133] Outbound data is ready to be sent after being processed.
[INFO][07:22:17]: [Client #133] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:22:18]: [Server #3995185] Received 507.38 MB of payload data from client #133 (simulated).
[INFO][07:22:18]: [Server #3995185] Selecting client #188 for training.
[INFO][07:22:18]: [Server #3995185] Sending the current model to client #188 (simulated).
[INFO][07:22:23]: [Server #3995185] Sending 507.38 MB of payload data to client #188 (simulated).
[INFO][07:22:23]: [Client #188] Selected by the server.
[INFO][07:22:23]: [Client #188] Loading its data source...
[INFO][07:22:23]: [Client #188] Dataset size: 2018
[INFO][07:22:23]: [Client #188] Sampler: iid
[INFO][07:22:24]: [Client #188] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:22:24]: [Client #188] Start to process inbound data.
[INFO][07:22:24]: [93m[1m[Client #188] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.10it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.05it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.196277936299642,)
[INFO][07:23:04]: [Client #188] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
{'train_runtime': 32.9298, 'train_samples_per_second': 183.846, 'train_steps_per_second': 2.915, 'train_loss': 3.196277936299642, 'epoch': 3.0}
[INFO][07:23:05]: [Client #188] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
[INFO][07:23:05]: [Client #188] Model trained.
[INFO][07:23:05]: [Client #188] Inbound data has been processed.
[INFO][07:23:05]: [Client #188] Outbound data is ready to be sent after being processed.
[INFO][07:23:10]: [Client #188] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:23:11]: [Server #3995185] Received 507.38 MB of payload data from client #188 (simulated).
[INFO][07:23:11]: [Server #3995185] Selecting client #151 for training.
[INFO][07:23:11]: [Server #3995185] Sending the current model to client #151 (simulated).
[INFO][07:23:15]: [Server #3995185] Sending 507.38 MB of payload data to client #151 (simulated).
[INFO][07:23:15]: [Client #151] Selected by the server.
[INFO][07:23:15]: [Client #151] Loading its data source...
[INFO][07:23:15]: [Client #151] Dataset size: 2018
[INFO][07:23:15]: [Client #151] Sampler: iid
[INFO][07:23:16]: [Client #151] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:23:16]: [Client #151] Start to process inbound data.
[INFO][07:23:17]: [93m[1m[Client #151] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1265598932902017,)
[INFO][07:23:55]: [Client #151] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
{'train_runtime': 32.2759, 'train_samples_per_second': 187.57, 'train_steps_per_second': 2.974, 'train_loss': 3.1265598932902017, 'epoch': 3.0}
[INFO][07:23:55]: [Client #151] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
[INFO][07:23:56]: [Client #151] Model trained.
[INFO][07:23:56]: [Client #151] Inbound data has been processed.
[INFO][07:23:56]: [Client #151] Outbound data is ready to be sent after being processed.
[INFO][07:24:00]: [Client #151] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:24:02]: [Server #3995185] Received 507.38 MB of payload data from client #151 (simulated).
[INFO][07:24:02]: [Server #3995185] Selecting client #42 for training.
[INFO][07:24:02]: [Server #3995185] Sending the current model to client #42 (simulated).
[INFO][07:24:07]: [Server #3995185] Sending 507.38 MB of payload data to client #42 (simulated).
[INFO][07:24:07]: [Client #42] Selected by the server.
[INFO][07:24:07]: [Client #42] Loading its data source...
[INFO][07:24:07]: [Client #42] Dataset size: 2018
[INFO][07:24:07]: [Client #42] Sampler: iid
[INFO][07:24:08]: [Client #42] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:24:08]: [Client #42] Start to process inbound data.
[INFO][07:24:08]: [93m[1m[Client #42] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.48s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.173173268636068,)
[INFO][07:24:46]: [Client #42] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_42_3995237.pth.
{'train_runtime': 32.3207, 'train_samples_per_second': 187.31, 'train_steps_per_second': 2.97, 'train_loss': 3.173173268636068, 'epoch': 3.0}
[INFO][07:24:47]: [Client #42] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_42_3995237.pth.
[INFO][07:24:47]: [Client #42] Model trained.
[INFO][07:24:47]: [Client #42] Inbound data has been processed.
[INFO][07:24:47]: [Client #42] Outbound data is ready to be sent after being processed.
[INFO][07:24:52]: [Client #42] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:24:53]: [Server #3995185] Received 507.38 MB of payload data from client #42 (simulated).
[INFO][07:24:53]: [Server #3995185] Selecting client #4 for training.
[INFO][07:24:53]: [Server #3995185] Sending the current model to client #4 (simulated).
[INFO][07:24:58]: [Server #3995185] Sending 507.38 MB of payload data to client #4 (simulated).
[INFO][07:24:58]: [Client #4] Selected by the server.
[INFO][07:24:58]: [Client #4] Loading its data source...
[INFO][07:24:58]: [Client #4] Dataset size: 2018
[INFO][07:24:58]: [Client #4] Sampler: iid
[INFO][07:24:59]: [Client #4] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:24:59]: [Client #4] Start to process inbound data.
[INFO][07:24:59]: [93m[1m[Client #4] Started training in communication round #21.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:33,  1.61s/it]  2%|â–         | 2/96 [00:01<01:21,  1.16it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.61it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.09it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.97it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1721534729003906,)
[INFO][07:25:39]: [Client #4] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3995237.pth.
{'train_runtime': 32.8991, 'train_samples_per_second': 184.017, 'train_steps_per_second': 2.918, 'train_loss': 3.1721534729003906, 'epoch': 3.0}
[INFO][07:25:39]: [Client #4] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_4_3995237.pth.
[INFO][07:25:40]: [Client #4] Model trained.
[INFO][07:25:40]: [Client #4] Inbound data has been processed.
[INFO][07:25:40]: [Client #4] Outbound data is ready to be sent after being processed.
[INFO][07:25:45]: [Client #4] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:25:46]: [Server #3995185] Received 507.38 MB of payload data from client #4 (simulated).
[INFO][07:25:46]: [Server #3995185] Adding client #26 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #50 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #112 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #14 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #144 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #151 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #188 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #42 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #173 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Adding client #194 to the list of clients for aggregation.
[INFO][07:25:46]: [Server #3995185] Aggregating 10 clients in total.
[INFO][07:25:46]: [Server #3995185] Updated weights have been received.
[INFO][07:25:47]: [Server #3995185] Aggregating model weight deltas.
[INFO][07:25:48]: [Server #3995185] Finished aggregating updated weights.
[INFO][07:25:48]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.49it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 40.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.01it/s]
[INFO][07:25:57]: [93m[1m[Server #3995185] Global model perplexity: 24.76
[0m
[INFO][07:25:57]: [Server #3995185] All client reports have been processed.
[INFO][07:25:58]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_21.pth.
[INFO][07:26:00]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_21.pth.
[INFO][07:26:00]: [93m[1m
[Server #3995185] Starting round 22/50.[0m
[INFO][07:26:00]: [Server #3995185] Selected clients: [33, 148, 104, 193, 89, 69, 41, 149, 43, 200]
[INFO][07:26:00]: [Server #3995185] Selecting client #33 for training.
[INFO][07:26:00]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][07:26:05]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][07:26:05]: [Client #33] Selected by the server.
[INFO][07:26:05]: [Client #33] Loading its data source...
[INFO][07:26:05]: [Client #33] Dataset size: 2018
[INFO][07:26:05]: [Client #33] Sampler: iid
[INFO][07:26:07]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:26:07]: [Client #33] Start to process inbound data.
[INFO][07:26:07]: [93m[1m[Client #33] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.17it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.16it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.15it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.15it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.14it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.15it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.15it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:15,  3.15it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.14it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.15it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:14,  3.15it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.15it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.15it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:13,  3.14it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.15it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.15it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.15it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.14it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.14it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.14it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:19<00:11,  3.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.14it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.14it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.14it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.14it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.60it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.44it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:08,  3.34it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.28it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.24it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.18it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.17it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.16it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.15it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:06,  3.15it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:24<00:06,  3.14it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.14it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.14it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.13it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.13it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.13it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.13it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.13it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.13it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.13it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.13it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.12it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.12it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.12it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.12it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.57it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.04it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.129709561665853,)
[INFO][07:26:44]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 31.5493, 'train_samples_per_second': 191.89, 'train_steps_per_second': 3.043, 'train_loss': 3.129709561665853, 'epoch': 3.0}
[INFO][07:26:45]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][07:26:45]: [Client #33] Model trained.
[INFO][07:26:45]: [Client #33] Inbound data has been processed.
[INFO][07:26:45]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][07:26:50]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:26:52]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][07:26:52]: [Server #3995185] Selecting client #148 for training.
[INFO][07:26:52]: [Server #3995185] Sending the current model to client #148 (simulated).
[INFO][07:26:58]: [Server #3995185] Sending 507.38 MB of payload data to client #148 (simulated).
[INFO][07:26:58]: [Client #148] Selected by the server.
[INFO][07:26:58]: [Client #148] Loading its data source...
[INFO][07:26:58]: [Client #148] Dataset size: 2018
[INFO][07:26:58]: [Client #148] Sampler: iid
[INFO][07:26:59]: [Client #148] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:26:59]: [Client #148] Start to process inbound data.
[INFO][07:26:59]: [93m[1m[Client #148] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1426289876302085,)
[INFO][07:27:37]: [Client #148] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_148_3995237.pth.
{'train_runtime': 32.3684, 'train_samples_per_second': 187.034, 'train_steps_per_second': 2.966, 'train_loss': 3.1426289876302085, 'epoch': 3.0}
[INFO][07:27:38]: [Client #148] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_148_3995237.pth.
[INFO][07:27:39]: [Client #148] Model trained.
[INFO][07:27:39]: [Client #148] Inbound data has been processed.
[INFO][07:27:39]: [Client #148] Outbound data is ready to be sent after being processed.
[INFO][07:27:45]: [Client #148] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:27:46]: [Server #3995185] Received 507.38 MB of payload data from client #148 (simulated).
[INFO][07:27:46]: [Server #3995185] Selecting client #104 for training.
[INFO][07:27:46]: [Server #3995185] Sending the current model to client #104 (simulated).
[INFO][07:27:51]: [Server #3995185] Sending 507.38 MB of payload data to client #104 (simulated).
[INFO][07:27:51]: [Client #104] Selected by the server.
[INFO][07:27:51]: [Client #104] Loading its data source...
[INFO][07:27:51]: [Client #104] Dataset size: 2018
[INFO][07:27:51]: [Client #104] Sampler: iid
[INFO][07:27:52]: [Client #104] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:27:52]: [Client #104] Start to process inbound data.
[INFO][07:27:53]: [93m[1m[Client #104] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.106103261311849,)
[INFO][07:28:31]: [Client #104] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_104_3995237.pth.
{'train_runtime': 32.4151, 'train_samples_per_second': 186.765, 'train_steps_per_second': 2.962, 'train_loss': 3.106103261311849, 'epoch': 3.0}
[INFO][07:28:32]: [Client #104] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_104_3995237.pth.
[INFO][07:28:32]: [Client #104] Model trained.
[INFO][07:28:32]: [Client #104] Inbound data has been processed.
[INFO][07:28:32]: [Client #104] Outbound data is ready to be sent after being processed.
[INFO][07:28:37]: [Client #104] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:28:38]: [Server #3995185] Received 507.38 MB of payload data from client #104 (simulated).
[INFO][07:28:38]: [Server #3995185] Selecting client #193 for training.
[INFO][07:28:38]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][07:28:42]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][07:28:42]: [Client #193] Selected by the server.
[INFO][07:28:42]: [Client #193] Loading its data source...
[INFO][07:28:42]: [Client #193] Dataset size: 2018
[INFO][07:28:42]: [Client #193] Sampler: iid
[INFO][07:28:44]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:28:44]: [Client #193] Start to process inbound data.
[INFO][07:28:44]: [93m[1m[Client #193] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.112542152404785,)
[INFO][07:29:21]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 32.2179, 'train_samples_per_second': 187.908, 'train_steps_per_second': 2.98, 'train_loss': 3.112542152404785, 'epoch': 3.0}
[INFO][07:29:22]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][07:29:23]: [Client #193] Model trained.
[INFO][07:29:23]: [Client #193] Inbound data has been processed.
[INFO][07:29:23]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][07:29:28]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:29:29]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][07:29:29]: [Server #3995185] Selecting client #89 for training.
[INFO][07:29:29]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][07:29:34]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][07:29:34]: [Client #89] Selected by the server.
[INFO][07:29:34]: [Client #89] Loading its data source...
[INFO][07:29:34]: [Client #89] Dataset size: 2018
[INFO][07:29:34]: [Client #89] Sampler: iid
[INFO][07:29:35]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:29:35]: [Client #89] Start to process inbound data.
[INFO][07:29:35]: [93m[1m[Client #89] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.106679598490397,)
[INFO][07:30:13]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 32.5305, 'train_samples_per_second': 186.102, 'train_steps_per_second': 2.951, 'train_loss': 3.106679598490397, 'epoch': 3.0}
[INFO][07:30:14]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][07:30:14]: [Client #89] Model trained.
[INFO][07:30:14]: [Client #89] Inbound data has been processed.
[INFO][07:30:14]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][07:30:19]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:30:20]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][07:30:20]: [Server #3995185] Selecting client #69 for training.
[INFO][07:30:20]: [Server #3995185] Sending the current model to client #69 (simulated).
[INFO][07:30:25]: [Server #3995185] Sending 507.38 MB of payload data to client #69 (simulated).
[INFO][07:30:25]: [Client #69] Selected by the server.
[INFO][07:30:25]: [Client #69] Loading its data source...
[INFO][07:30:25]: [Client #69] Dataset size: 2018
[INFO][07:30:25]: [Client #69] Sampler: iid
[INFO][07:30:26]: [Client #69] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:30:26]: [Client #69] Start to process inbound data.
[INFO][07:30:26]: [93m[1m[Client #69] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:33,  1.62s/it]  2%|â–         | 2/96 [00:01<01:21,  1.16it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.61it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.94it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.96it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.97it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.98it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.00it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.99it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.169605255126953,)
[INFO][07:31:06]: [Client #69] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3995237.pth.
{'train_runtime': 32.9214, 'train_samples_per_second': 183.893, 'train_steps_per_second': 2.916, 'train_loss': 3.169605255126953, 'epoch': 3.0}
[INFO][07:31:07]: [Client #69] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3995237.pth.
[INFO][07:31:07]: [Client #69] Model trained.
[INFO][07:31:07]: [Client #69] Inbound data has been processed.
[INFO][07:31:07]: [Client #69] Outbound data is ready to be sent after being processed.
[INFO][07:31:12]: [Client #69] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:31:13]: [Server #3995185] Received 507.38 MB of payload data from client #69 (simulated).
[INFO][07:31:13]: [Server #3995185] Selecting client #41 for training.
[INFO][07:31:13]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][07:31:17]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][07:31:17]: [Client #41] Selected by the server.
[INFO][07:31:17]: [Client #41] Loading its data source...
[INFO][07:31:17]: [Client #41] Dataset size: 2018
[INFO][07:31:17]: [Client #41] Sampler: iid
[INFO][07:31:18]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:31:18]: [Client #41] Start to process inbound data.
[INFO][07:31:18]: [93m[1m[Client #41] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:16,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1378234227498374,)
[INFO][07:31:57]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.2688, 'train_samples_per_second': 187.612, 'train_steps_per_second': 2.975, 'train_loss': 3.1378234227498374, 'epoch': 3.0}
[INFO][07:31:57]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][07:31:58]: [Client #41] Model trained.
[INFO][07:31:58]: [Client #41] Inbound data has been processed.
[INFO][07:31:58]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][07:32:03]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:32:04]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][07:32:04]: [Server #3995185] Selecting client #149 for training.
[INFO][07:32:04]: [Server #3995185] Sending the current model to client #149 (simulated).
[INFO][07:32:09]: [Server #3995185] Sending 507.38 MB of payload data to client #149 (simulated).
[INFO][07:32:09]: [Client #149] Selected by the server.
[INFO][07:32:09]: [Client #149] Loading its data source...
[INFO][07:32:09]: [Client #149] Dataset size: 2018
[INFO][07:32:09]: [Client #149] Sampler: iid
[INFO][07:32:10]: [Client #149] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:32:10]: [Client #149] Start to process inbound data.
[INFO][07:32:11]: [93m[1m[Client #149] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.135105768839518,)
[INFO][07:32:49]: [Client #149] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
{'train_runtime': 32.4047, 'train_samples_per_second': 186.825, 'train_steps_per_second': 2.963, 'train_loss': 3.135105768839518, 'epoch': 3.0}
[INFO][07:32:50]: [Client #149] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
[INFO][07:32:50]: [Client #149] Model trained.
[INFO][07:32:50]: [Client #149] Inbound data has been processed.
[INFO][07:32:50]: [Client #149] Outbound data is ready to be sent after being processed.
[INFO][07:32:55]: [Client #149] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:32:56]: [Server #3995185] Received 507.38 MB of payload data from client #149 (simulated).
[INFO][07:32:56]: [Server #3995185] Selecting client #43 for training.
[INFO][07:32:56]: [Server #3995185] Sending the current model to client #43 (simulated).
[INFO][07:33:01]: [Server #3995185] Sending 507.38 MB of payload data to client #43 (simulated).
[INFO][07:33:01]: [Client #43] Selected by the server.
[INFO][07:33:01]: [Client #43] Loading its data source...
[INFO][07:33:01]: [Client #43] Dataset size: 2018
[INFO][07:33:01]: [Client #43] Sampler: iid
[INFO][07:33:02]: [Client #43] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:33:02]: [Client #43] Start to process inbound data.
[INFO][07:33:02]: [93m[1m[Client #43] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.53it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.159182548522949,)
[INFO][07:33:40]: [Client #43] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
{'train_runtime': 32.3251, 'train_samples_per_second': 187.285, 'train_steps_per_second': 2.97, 'train_loss': 3.159182548522949, 'epoch': 3.0}
[INFO][07:33:41]: [Client #43] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
[INFO][07:33:42]: [Client #43] Model trained.
[INFO][07:33:42]: [Client #43] Inbound data has been processed.
[INFO][07:33:42]: [Client #43] Outbound data is ready to be sent after being processed.
[INFO][07:33:47]: [Client #43] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:33:48]: [Server #3995185] Received 507.38 MB of payload data from client #43 (simulated).
[INFO][07:33:48]: [Server #3995185] Selecting client #200 for training.
[INFO][07:33:48]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][07:33:53]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][07:33:53]: [Client #200] Selected by the server.
[INFO][07:33:53]: [Client #200] Loading its data source...
[INFO][07:33:53]: [Client #200] Dataset size: 2018
[INFO][07:33:53]: [Client #200] Sampler: iid
[INFO][07:33:55]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:33:55]: [Client #200] Start to process inbound data.
[INFO][07:33:55]: [93m[1m[Client #200] Started training in communication round #22.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1292031606038413,)
[INFO][07:34:33]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 32.5666, 'train_samples_per_second': 185.896, 'train_steps_per_second': 2.948, 'train_loss': 3.1292031606038413, 'epoch': 3.0}
[INFO][07:34:34]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][07:34:35]: [Client #200] Model trained.
[INFO][07:34:35]: [Client #200] Inbound data has been processed.
[INFO][07:34:35]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][07:34:40]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:34:41]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][07:34:41]: [Server #3995185] Adding client #4 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #43 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #87 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #90 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #99 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #149 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Adding client #157 to the list of clients for aggregation.
[INFO][07:34:41]: [Server #3995185] Aggregating 10 clients in total.
[INFO][07:34:41]: [Server #3995185] Updated weights have been received.
[INFO][07:34:42]: [Server #3995185] Aggregating model weight deltas.
[INFO][07:34:43]: [Server #3995185] Finished aggregating updated weights.
[INFO][07:34:43]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.59it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.28it/s]
[INFO][07:34:52]: [93m[1m[Server #3995185] Global model perplexity: 24.65
[0m
[INFO][07:34:52]: [Server #3995185] All client reports have been processed.
[INFO][07:34:52]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_22.pth.
[INFO][07:34:58]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_22.pth.
[INFO][07:34:58]: [93m[1m
[Server #3995185] Starting round 23/50.[0m
[INFO][07:34:58]: [Server #3995185] Selected clients: [13, 7, 66, 5, 163, 3, 46, 45, 10, 23]
[INFO][07:34:58]: [Server #3995185] Selecting client #13 for training.
[INFO][07:34:58]: [Server #3995185] Sending the current model to client #13 (simulated).
[INFO][07:35:05]: [Server #3995185] Sending 507.38 MB of payload data to client #13 (simulated).
[INFO][07:35:05]: [Client #13] Selected by the server.
[INFO][07:35:05]: [Client #13] Loading its data source...
[INFO][07:35:05]: [Client #13] Dataset size: 2018
[INFO][07:35:05]: [Client #13] Sampler: iid
[INFO][07:35:07]: [Client #13] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:35:07]: [Client #13] Start to process inbound data.
[INFO][07:35:07]: [93m[1m[Client #13] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:39,  1.68s/it]  2%|â–         | 2/96 [00:02<01:22,  1.13it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.59it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.077697436014811,)
[INFO][07:35:47]: [Client #13] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
{'train_runtime': 32.6069, 'train_samples_per_second': 185.666, 'train_steps_per_second': 2.944, 'train_loss': 3.077697436014811, 'epoch': 3.0}
[INFO][07:35:48]: [Client #13] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
[INFO][07:35:48]: [Client #13] Model trained.
[INFO][07:35:48]: [Client #13] Inbound data has been processed.
[INFO][07:35:48]: [Client #13] Outbound data is ready to be sent after being processed.
[INFO][07:35:55]: [Client #13] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:35:56]: [Server #3995185] Received 507.38 MB of payload data from client #13 (simulated).
[INFO][07:35:56]: [Server #3995185] Selecting client #7 for training.
[INFO][07:35:56]: [Server #3995185] Sending the current model to client #7 (simulated).
[INFO][07:36:01]: [Server #3995185] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][07:36:01]: [Client #7] Selected by the server.
[INFO][07:36:01]: [Client #7] Loading its data source...
[INFO][07:36:01]: [Client #7] Dataset size: 2018
[INFO][07:36:01]: [Client #7] Sampler: iid
[INFO][07:36:02]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:36:02]: [Client #7] Start to process inbound data.
[INFO][07:36:02]: [93m[1m[Client #7] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.78s/it]  2%|â–         | 2/96 [00:02<01:27,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.08940855662028,)
[INFO][07:36:42]: [Client #7] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3995237.pth.
{'train_runtime': 32.896, 'train_samples_per_second': 184.035, 'train_steps_per_second': 2.918, 'train_loss': 3.08940855662028, 'epoch': 3.0}
[INFO][07:36:43]: [Client #7] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_7_3995237.pth.
[INFO][07:36:43]: [Client #7] Model trained.
[INFO][07:36:43]: [Client #7] Inbound data has been processed.
[INFO][07:36:43]: [Client #7] Outbound data is ready to be sent after being processed.
[INFO][07:36:48]: [Client #7] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:36:49]: [Server #3995185] Received 507.38 MB of payload data from client #7 (simulated).
[INFO][07:36:49]: [Server #3995185] Selecting client #66 for training.
[INFO][07:36:49]: [Server #3995185] Sending the current model to client #66 (simulated).
[INFO][07:36:54]: [Server #3995185] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][07:36:54]: [Client #66] Selected by the server.
[INFO][07:36:54]: [Client #66] Loading its data source...
[INFO][07:36:54]: [Client #66] Dataset size: 2018
[INFO][07:36:54]: [Client #66] Sampler: iid
[INFO][07:36:56]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:36:56]: [Client #66] Start to process inbound data.
[INFO][07:36:56]: [93m[1m[Client #66] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.48s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  2.99it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1391894022623696,)
[INFO][07:37:35]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
{'train_runtime': 32.7653, 'train_samples_per_second': 184.768, 'train_steps_per_second': 2.93, 'train_loss': 3.1391894022623696, 'epoch': 3.0}
[INFO][07:37:36]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
[INFO][07:37:36]: [Client #66] Model trained.
[INFO][07:37:36]: [Client #66] Inbound data has been processed.
[INFO][07:37:36]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][07:37:41]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:37:42]: [Server #3995185] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][07:37:42]: [Server #3995185] Selecting client #5 for training.
[INFO][07:37:42]: [Server #3995185] Sending the current model to client #5 (simulated).
[INFO][07:37:53]: [Server #3995185] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][07:37:53]: [Client #5] Selected by the server.
[INFO][07:37:53]: [Client #5] Loading its data source...
[INFO][07:37:53]: [Client #5] Dataset size: 2018
[INFO][07:37:53]: [Client #5] Sampler: iid
[INFO][07:37:54]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:37:54]: [Client #5] Start to process inbound data.
[INFO][07:37:55]: [93m[1m[Client #5] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0857518513997397,)
[INFO][07:38:35]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
{'train_runtime': 32.8724, 'train_samples_per_second': 184.167, 'train_steps_per_second': 2.92, 'train_loss': 3.0857518513997397, 'epoch': 3.0}
[INFO][07:38:35]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
[INFO][07:38:36]: [Client #5] Model trained.
[INFO][07:38:36]: [Client #5] Inbound data has been processed.
[INFO][07:38:36]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][07:38:44]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:38:45]: [Server #3995185] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][07:38:45]: [Server #3995185] Selecting client #163 for training.
[INFO][07:38:45]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][07:38:51]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][07:38:52]: [Client #163] Selected by the server.
[INFO][07:38:52]: [Client #163] Loading its data source...
[INFO][07:38:52]: [Client #163] Dataset size: 2018
[INFO][07:38:52]: [Client #163] Sampler: iid
[INFO][07:38:53]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:38:53]: [Client #163] Start to process inbound data.
[INFO][07:38:53]: [93m[1m[Client #163] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.07it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.29it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0755615234375,)
[INFO][07:39:31]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.0943, 'train_samples_per_second': 188.632, 'train_steps_per_second': 2.991, 'train_loss': 3.0755615234375, 'epoch': 3.0}
[INFO][07:39:32]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][07:39:33]: [Client #163] Model trained.
[INFO][07:39:33]: [Client #163] Inbound data has been processed.
[INFO][07:39:33]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][07:39:40]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:39:41]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][07:39:41]: [Server #3995185] Selecting client #3 for training.
[INFO][07:39:41]: [Server #3995185] Sending the current model to client #3 (simulated).
[INFO][07:39:48]: [Server #3995185] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][07:39:48]: [Client #3] Selected by the server.
[INFO][07:39:48]: [Client #3] Loading its data source...
[INFO][07:39:48]: [Client #3] Dataset size: 2018
[INFO][07:39:48]: [Client #3] Sampler: iid
[INFO][07:39:49]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:39:49]: [Client #3] Start to process inbound data.
[INFO][07:39:49]: [93m[1m[Client #3] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1107667287190757,)
[INFO][07:40:27]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3995237.pth.
{'train_runtime': 32.1107, 'train_samples_per_second': 188.535, 'train_steps_per_second': 2.99, 'train_loss': 3.1107667287190757, 'epoch': 3.0}
[INFO][07:40:28]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3995237.pth.
[INFO][07:40:28]: [Client #3] Model trained.
[INFO][07:40:28]: [Client #3] Inbound data has been processed.
[INFO][07:40:28]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][07:40:36]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:40:38]: [Server #3995185] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][07:40:38]: [Server #3995185] Selecting client #46 for training.
[INFO][07:40:38]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][07:40:47]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][07:40:47]: [Client #46] Selected by the server.
[INFO][07:40:47]: [Client #46] Loading its data source...
[INFO][07:40:47]: [Client #46] Dataset size: 2018
[INFO][07:40:47]: [Client #46] Sampler: iid
[INFO][07:40:48]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:40:48]: [Client #46] Start to process inbound data.
[INFO][07:40:49]: [93m[1m[Client #46] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.08it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.09it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.54it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.08it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.06it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1258420944213867,)
[INFO][07:41:27]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.0359, 'train_samples_per_second': 188.975, 'train_steps_per_second': 2.997, 'train_loss': 3.1258420944213867, 'epoch': 3.0}
[INFO][07:41:28]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][07:41:28]: [Client #46] Model trained.
[INFO][07:41:28]: [Client #46] Inbound data has been processed.
[INFO][07:41:28]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][07:41:36]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:41:37]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][07:41:37]: [Server #3995185] Selecting client #45 for training.
[INFO][07:41:37]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][07:41:45]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][07:41:45]: [Client #45] Selected by the server.
[INFO][07:41:45]: [Client #45] Loading its data source...
[INFO][07:41:45]: [Client #45] Dataset size: 2018
[INFO][07:41:45]: [Client #45] Sampler: iid
[INFO][07:41:46]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:41:46]: [Client #45] Start to process inbound data.
[INFO][07:41:46]: [93m[1m[Client #45] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:27,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.94it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0699742635091147,)
[INFO][07:42:25]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.5838, 'train_samples_per_second': 185.798, 'train_steps_per_second': 2.946, 'train_loss': 3.0699742635091147, 'epoch': 3.0}
[INFO][07:42:26]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][07:42:26]: [Client #45] Model trained.
[INFO][07:42:26]: [Client #45] Inbound data has been processed.
[INFO][07:42:26]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][07:42:33]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:42:34]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][07:42:34]: [Server #3995185] Selecting client #10 for training.
[INFO][07:42:34]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][07:42:43]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][07:42:43]: [Client #10] Selected by the server.
[INFO][07:42:43]: [Client #10] Loading its data source...
[INFO][07:42:43]: [Client #10] Dataset size: 2018
[INFO][07:42:43]: [Client #10] Sampler: iid
[INFO][07:42:44]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:42:44]: [Client #10] Start to process inbound data.
[INFO][07:42:44]: [93m[1m[Client #10] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.11it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.11it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1268288294474282,)
[INFO][07:43:22]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.019, 'train_samples_per_second': 189.076, 'train_steps_per_second': 2.998, 'train_loss': 3.1268288294474282, 'epoch': 3.0}
[INFO][07:43:23]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][07:43:23]: [Client #10] Model trained.
[INFO][07:43:23]: [Client #10] Inbound data has been processed.
[INFO][07:43:23]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][07:43:32]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:43:33]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][07:43:33]: [Server #3995185] Selecting client #23 for training.
[INFO][07:43:33]: [Server #3995185] Sending the current model to client #23 (simulated).
[INFO][07:43:40]: [Server #3995185] Sending 507.38 MB of payload data to client #23 (simulated).
[INFO][07:43:40]: [Client #23] Selected by the server.
[INFO][07:43:40]: [Client #23] Loading its data source...
[INFO][07:43:40]: [Client #23] Dataset size: 2018
[INFO][07:43:40]: [Client #23] Sampler: iid
[INFO][07:43:42]: [Client #23] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:43:42]: [Client #23] Start to process inbound data.
[INFO][07:43:42]: [93m[1m[Client #23] Started training in communication round #23.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.23it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.10it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.1034631729125977,)
[INFO][07:44:19]: [Client #23] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
{'train_runtime': 32.0591, 'train_samples_per_second': 188.839, 'train_steps_per_second': 2.994, 'train_loss': 3.1034631729125977, 'epoch': 3.0}
[INFO][07:44:20]: [Client #23] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
[INFO][07:44:21]: [Client #23] Model trained.
[INFO][07:44:21]: [Client #23] Inbound data has been processed.
[INFO][07:44:21]: [Client #23] Outbound data is ready to be sent after being processed.
[INFO][07:44:28]: [Client #23] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:44:29]: [Server #3995185] Received 507.38 MB of payload data from client #23 (simulated).
[INFO][07:44:29]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #69 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #104 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #148 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #5 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #13 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #23 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][07:44:29]: [Server #3995185] Aggregating 10 clients in total.
[INFO][07:44:29]: [Server #3995185] Updated weights have been received.
[INFO][07:44:30]: [Server #3995185] Aggregating model weight deltas.
[INFO][07:44:31]: [Server #3995185] Finished aggregating updated weights.
[INFO][07:44:31]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.41it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.56it/s]
[INFO][07:44:40]: [93m[1m[Server #3995185] Global model perplexity: 24.02
[0m
[INFO][07:44:40]: [Server #3995185] All client reports have been processed.
[INFO][07:44:41]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_23.pth.
[INFO][07:44:44]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_23.pth.
[INFO][07:44:44]: [93m[1m
[Server #3995185] Starting round 24/50.[0m
[INFO][07:44:44]: [Server #3995185] Selected clients: [59, 88, 71, 119, 62, 132, 97, 113, 9, 177]
[INFO][07:44:44]: [Server #3995185] Selecting client #59 for training.
[INFO][07:44:44]: [Server #3995185] Sending the current model to client #59 (simulated).
[INFO][07:44:49]: [Server #3995185] Sending 507.38 MB of payload data to client #59 (simulated).
[INFO][07:44:49]: [Client #59] Selected by the server.
[INFO][07:44:49]: [Client #59] Loading its data source...
[INFO][07:44:49]: [Client #59] Dataset size: 2018
[INFO][07:44:49]: [Client #59] Sampler: iid
[INFO][07:44:50]: [Client #59] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:44:50]: [Client #59] Start to process inbound data.
[INFO][07:44:50]: [93m[1m[Client #59] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.42it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.08it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.09it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.08it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.062814394632975,)
[INFO][07:45:28]: [Client #59] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_59_3995237.pth.
{'train_runtime': 32.0806, 'train_samples_per_second': 188.712, 'train_steps_per_second': 2.992, 'train_loss': 3.062814394632975, 'epoch': 3.0}
[INFO][07:45:29]: [Client #59] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_59_3995237.pth.
[INFO][07:45:30]: [Client #59] Model trained.
[INFO][07:45:30]: [Client #59] Inbound data has been processed.
[INFO][07:45:30]: [Client #59] Outbound data is ready to be sent after being processed.
[INFO][07:45:37]: [Client #59] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:45:38]: [Server #3995185] Received 507.38 MB of payload data from client #59 (simulated).
[INFO][07:45:38]: [Server #3995185] Selecting client #88 for training.
[INFO][07:45:38]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][07:45:42]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][07:45:42]: [Client #88] Selected by the server.
[INFO][07:45:42]: [Client #88] Loading its data source...
[INFO][07:45:42]: [Client #88] Dataset size: 2018
[INFO][07:45:42]: [Client #88] Sampler: iid
[INFO][07:45:44]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:45:44]: [Client #88] Start to process inbound data.
[INFO][07:45:44]: [93m[1m[Client #88] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0750112533569336,)
[INFO][07:46:22]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 32.4533, 'train_samples_per_second': 186.545, 'train_steps_per_second': 2.958, 'train_loss': 3.0750112533569336, 'epoch': 3.0}
[INFO][07:46:23]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][07:46:23]: [Client #88] Model trained.
[INFO][07:46:23]: [Client #88] Inbound data has been processed.
[INFO][07:46:23]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][07:46:31]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:46:32]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][07:46:32]: [Server #3995185] Selecting client #71 for training.
[INFO][07:46:32]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][07:46:37]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][07:46:37]: [Client #71] Selected by the server.
[INFO][07:46:37]: [Client #71] Loading its data source...
[INFO][07:46:37]: [Client #71] Dataset size: 2018
[INFO][07:46:37]: [Client #71] Sampler: iid
[INFO][07:46:38]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:46:38]: [Client #71] Start to process inbound data.
[INFO][07:46:38]: [93m[1m[Client #71] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.71s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.026996930440267,)
[INFO][07:47:17]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.8162, 'train_samples_per_second': 184.482, 'train_steps_per_second': 2.925, 'train_loss': 3.026996930440267, 'epoch': 3.0}
[INFO][07:47:17]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][07:47:19]: [Client #71] Model trained.
[INFO][07:47:19]: [Client #71] Inbound data has been processed.
[INFO][07:47:19]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][07:47:27]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:47:28]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][07:47:28]: [Server #3995185] Selecting client #119 for training.
[INFO][07:47:28]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][07:47:33]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][07:47:33]: [Client #119] Selected by the server.
[INFO][07:47:33]: [Client #119] Loading its data source...
[INFO][07:47:33]: [Client #119] Dataset size: 2018
[INFO][07:47:33]: [Client #119] Sampler: iid
[INFO][07:47:34]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:47:34]: [Client #119] Start to process inbound data.
[INFO][07:47:35]: [93m[1m[Client #119] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0251359939575195,)
[INFO][07:48:14]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 32.9139, 'train_samples_per_second': 183.935, 'train_steps_per_second': 2.917, 'train_loss': 3.0251359939575195, 'epoch': 3.0}
[INFO][07:48:15]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][07:48:16]: [Client #119] Model trained.
[INFO][07:48:16]: [Client #119] Inbound data has been processed.
[INFO][07:48:16]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][07:48:21]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:48:22]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][07:48:22]: [Server #3995185] Selecting client #62 for training.
[INFO][07:48:22]: [Server #3995185] Sending the current model to client #62 (simulated).
[INFO][07:48:26]: [Server #3995185] Sending 507.38 MB of payload data to client #62 (simulated).
[INFO][07:48:26]: [Client #62] Selected by the server.
[INFO][07:48:26]: [Client #62] Loading its data source...
[INFO][07:48:26]: [Client #62] Dataset size: 2018
[INFO][07:48:26]: [Client #62] Sampler: iid
[INFO][07:48:27]: [Client #62] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:48:27]: [Client #62] Start to process inbound data.
[INFO][07:48:28]: [93m[1m[Client #62] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.78s/it]  2%|â–         | 2/96 [00:02<01:27,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.98it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.97it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.96it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.96it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.077877680460612,)
[INFO][07:49:07]: [Client #62] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
{'train_runtime': 32.9537, 'train_samples_per_second': 183.712, 'train_steps_per_second': 2.913, 'train_loss': 3.077877680460612, 'epoch': 3.0}
[INFO][07:49:08]: [Client #62] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
[INFO][07:49:08]: [Client #62] Model trained.
[INFO][07:49:08]: [Client #62] Inbound data has been processed.
[INFO][07:49:08]: [Client #62] Outbound data is ready to be sent after being processed.
[INFO][07:49:13]: [Client #62] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:49:15]: [Server #3995185] Received 507.38 MB of payload data from client #62 (simulated).
[INFO][07:49:15]: [Server #3995185] Selecting client #132 for training.
[INFO][07:49:15]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][07:49:20]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][07:49:20]: [Client #132] Selected by the server.
[INFO][07:49:20]: [Client #132] Loading its data source...
[INFO][07:49:20]: [Client #132] Dataset size: 2018
[INFO][07:49:20]: [Client #132] Sampler: iid
[INFO][07:49:21]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:49:21]: [Client #132] Start to process inbound data.
[INFO][07:49:21]: [93m[1m[Client #132] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0871105194091797,)
[INFO][07:49:59]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 32.5343, 'train_samples_per_second': 186.08, 'train_steps_per_second': 2.951, 'train_loss': 3.0871105194091797, 'epoch': 3.0}
[INFO][07:50:00]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][07:50:01]: [Client #132] Model trained.
[INFO][07:50:01]: [Client #132] Inbound data has been processed.
[INFO][07:50:01]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][07:50:05]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:50:07]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][07:50:07]: [Server #3995185] Selecting client #97 for training.
[INFO][07:50:07]: [Server #3995185] Sending the current model to client #97 (simulated).
[INFO][07:50:12]: [Server #3995185] Sending 507.38 MB of payload data to client #97 (simulated).
[INFO][07:50:12]: [Client #97] Selected by the server.
[INFO][07:50:12]: [Client #97] Loading its data source...
[INFO][07:50:12]: [Client #97] Dataset size: 2018
[INFO][07:50:12]: [Client #97] Sampler: iid
[INFO][07:50:13]: [Client #97] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:50:13]: [Client #97] Start to process inbound data.
[INFO][07:50:13]: [93m[1m[Client #97] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:25,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.22it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.06005064646403,)
[INFO][07:50:52]: [Client #97] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_97_3995237.pth.
{'train_runtime': 32.4092, 'train_samples_per_second': 186.799, 'train_steps_per_second': 2.962, 'train_loss': 3.06005064646403, 'epoch': 3.0}
[INFO][07:50:52]: [Client #97] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_97_3995237.pth.
[INFO][07:50:53]: [Client #97] Model trained.
[INFO][07:50:53]: [Client #97] Inbound data has been processed.
[INFO][07:50:53]: [Client #97] Outbound data is ready to be sent after being processed.
[INFO][07:50:58]: [Client #97] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:50:59]: [Server #3995185] Received 507.38 MB of payload data from client #97 (simulated).
[INFO][07:50:59]: [Server #3995185] Selecting client #113 for training.
[INFO][07:50:59]: [Server #3995185] Sending the current model to client #113 (simulated).
[INFO][07:51:03]: [Server #3995185] Sending 507.38 MB of payload data to client #113 (simulated).
[INFO][07:51:03]: [Client #113] Selected by the server.
[INFO][07:51:03]: [Client #113] Loading its data source...
[INFO][07:51:03]: [Client #113] Dataset size: 2018
[INFO][07:51:03]: [Client #113] Sampler: iid
[INFO][07:51:05]: [Client #113] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:51:05]: [Client #113] Start to process inbound data.
[INFO][07:51:05]: [93m[1m[Client #113] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.98it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.97it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.98it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.085964838663737,)
[INFO][07:51:43]: [Client #113] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_113_3995237.pth.
{'train_runtime': 32.5897, 'train_samples_per_second': 185.764, 'train_steps_per_second': 2.946, 'train_loss': 3.085964838663737, 'epoch': 3.0}
[INFO][07:51:44]: [Client #113] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_113_3995237.pth.
[INFO][07:51:44]: [Client #113] Model trained.
[INFO][07:51:44]: [Client #113] Inbound data has been processed.
[INFO][07:51:44]: [Client #113] Outbound data is ready to be sent after being processed.
[INFO][07:51:49]: [Client #113] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:51:51]: [Server #3995185] Received 507.38 MB of payload data from client #113 (simulated).
[INFO][07:51:51]: [Server #3995185] Selecting client #9 for training.
[INFO][07:51:51]: [Server #3995185] Sending the current model to client #9 (simulated).
[INFO][07:51:56]: [Server #3995185] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][07:51:56]: [Client #9] Selected by the server.
[INFO][07:51:56]: [Client #9] Loading its data source...
[INFO][07:51:56]: [Client #9] Dataset size: 2018
[INFO][07:51:56]: [Client #9] Sampler: iid
[INFO][07:51:57]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:51:57]: [Client #9] Start to process inbound data.
[INFO][07:51:57]: [93m[1m[Client #9] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.10it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.11it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.12it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.12it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.43it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.34it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.27it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.20it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.18it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.14it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.13it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.13it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.13it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.12it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.12it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.12it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.12it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.12it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.12it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.12it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.12it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.12it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.13it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.13it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.13it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.13it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.13it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.13it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.13it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.13it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.58it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.32it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.26it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.21it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.18it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.16it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.14it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.13it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.13it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.13it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.12it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.12it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.12it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.12it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.12it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.12it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.11it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.10it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.10it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.10it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.07it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.03it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0412251154581704,)
[INFO][07:52:35]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
{'train_runtime': 31.6503, 'train_samples_per_second': 191.278, 'train_steps_per_second': 3.033, 'train_loss': 3.0412251154581704, 'epoch': 3.0}
[INFO][07:52:35]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
[INFO][07:52:36]: [Client #9] Model trained.
[INFO][07:52:36]: [Client #9] Inbound data has been processed.
[INFO][07:52:36]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][07:52:41]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:52:42]: [Server #3995185] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][07:52:42]: [Server #3995185] Selecting client #177 for training.
[INFO][07:52:42]: [Server #3995185] Sending the current model to client #177 (simulated).
[INFO][07:52:47]: [Server #3995185] Sending 507.38 MB of payload data to client #177 (simulated).
[INFO][07:52:47]: [Client #177] Selected by the server.
[INFO][07:52:47]: [Client #177] Loading its data source...
[INFO][07:52:47]: [Client #177] Dataset size: 2018
[INFO][07:52:47]: [Client #177] Sampler: iid
[INFO][07:52:48]: [Client #177] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:52:48]: [Client #177] Start to process inbound data.
[INFO][07:52:48]: [93m[1m[Client #177] Started training in communication round #24.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0743840535481772,)
[INFO][07:53:26]: [Client #177] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
{'train_runtime': 32.1999, 'train_samples_per_second': 188.013, 'train_steps_per_second': 2.981, 'train_loss': 3.0743840535481772, 'epoch': 3.0}
[INFO][07:53:27]: [Client #177] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
[INFO][07:53:27]: [Client #177] Model trained.
[INFO][07:53:27]: [Client #177] Inbound data has been processed.
[INFO][07:53:27]: [Client #177] Outbound data is ready to be sent after being processed.
[INFO][07:53:32]: [Client #177] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:53:33]: [Server #3995185] Received 507.38 MB of payload data from client #177 (simulated).
[INFO][07:53:33]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #66 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #3 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #7 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #9 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #62 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #88 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Adding client #119 to the list of clients for aggregation.
[INFO][07:53:33]: [Server #3995185] Aggregating 10 clients in total.
[INFO][07:53:33]: [Server #3995185] Updated weights have been received.
[INFO][07:53:34]: [Server #3995185] Aggregating model weight deltas.
[INFO][07:53:35]: [Server #3995185] Finished aggregating updated weights.
[INFO][07:53:35]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.53it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.29it/s]
[INFO][07:53:44]: [93m[1m[Server #3995185] Global model perplexity: 23.73
[0m
[INFO][07:53:44]: [Server #3995185] All client reports have been processed.
[INFO][07:53:44]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_24.pth.
[INFO][07:53:48]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_24.pth.
[INFO][07:53:48]: [93m[1m
[Server #3995185] Starting round 25/50.[0m
[INFO][07:53:48]: [Server #3995185] Selected clients: [89, 144, 57, 200, 195, 53, 159, 183, 149, 1]
[INFO][07:53:48]: [Server #3995185] Selecting client #89 for training.
[INFO][07:53:48]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][07:53:53]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][07:53:53]: [Client #89] Selected by the server.
[INFO][07:53:53]: [Client #89] Loading its data source...
[INFO][07:53:53]: [Client #89] Dataset size: 2018
[INFO][07:53:53]: [Client #89] Sampler: iid
[INFO][07:53:54]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:53:54]: [Client #89] Start to process inbound data.
[INFO][07:53:54]: [93m[1m[Client #89] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:57,  1.86s/it]  2%|â–         | 2/96 [00:02<01:30,  1.04it/s]  3%|â–Ž         | 3/96 [00:02<01:02,  1.49it/s]  4%|â–         | 4/96 [00:02<00:49,  1.87it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.17it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.40it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.71it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.961428960164388,)
[INFO][07:54:34]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 32.9441, 'train_samples_per_second': 183.766, 'train_steps_per_second': 2.914, 'train_loss': 2.961428960164388, 'epoch': 3.0}
[INFO][07:54:35]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][07:54:35]: [Client #89] Model trained.
[INFO][07:54:35]: [Client #89] Inbound data has been processed.
[INFO][07:54:35]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][07:54:40]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:54:41]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][07:54:41]: [Server #3995185] Selecting client #144 for training.
[INFO][07:54:41]: [Server #3995185] Sending the current model to client #144 (simulated).
[INFO][07:54:46]: [Server #3995185] Sending 507.38 MB of payload data to client #144 (simulated).
[INFO][07:54:46]: [Client #144] Selected by the server.
[INFO][07:54:46]: [Client #144] Loading its data source...
[INFO][07:54:46]: [Client #144] Dataset size: 2018
[INFO][07:54:46]: [Client #144] Sampler: iid
[INFO][07:54:47]: [Client #144] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:54:47]: [Client #144] Start to process inbound data.
[INFO][07:54:47]: [93m[1m[Client #144] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:40,  1.69s/it]  2%|â–         | 2/96 [00:02<01:24,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0282793045043945,)
[INFO][07:55:27]: [Client #144] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
{'train_runtime': 32.769, 'train_samples_per_second': 184.748, 'train_steps_per_second': 2.93, 'train_loss': 3.0282793045043945, 'epoch': 3.0}
[INFO][07:55:28]: [Client #144] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
[INFO][07:55:29]: [Client #144] Model trained.
[INFO][07:55:29]: [Client #144] Inbound data has been processed.
[INFO][07:55:29]: [Client #144] Outbound data is ready to be sent after being processed.
[INFO][07:55:33]: [Client #144] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:55:35]: [Server #3995185] Received 507.38 MB of payload data from client #144 (simulated).
[INFO][07:55:35]: [Server #3995185] Selecting client #57 for training.
[INFO][07:55:35]: [Server #3995185] Sending the current model to client #57 (simulated).
[INFO][07:55:39]: [Server #3995185] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][07:55:39]: [Client #57] Selected by the server.
[INFO][07:55:39]: [Client #57] Loading its data source...
[INFO][07:55:39]: [Client #57] Dataset size: 2018
[INFO][07:55:39]: [Client #57] Sampler: iid
[INFO][07:55:41]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:55:41]: [Client #57] Start to process inbound data.
[INFO][07:55:41]: [93m[1m[Client #57] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.022196133931478,)
[INFO][07:56:20]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
{'train_runtime': 32.3996, 'train_samples_per_second': 186.854, 'train_steps_per_second': 2.963, 'train_loss': 3.022196133931478, 'epoch': 3.0}
[INFO][07:56:20]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
[INFO][07:56:21]: [Client #57] Model trained.
[INFO][07:56:21]: [Client #57] Inbound data has been processed.
[INFO][07:56:21]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][07:56:25]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:56:27]: [Server #3995185] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][07:56:27]: [Server #3995185] Selecting client #200 for training.
[INFO][07:56:27]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][07:56:31]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][07:56:31]: [Client #200] Selected by the server.
[INFO][07:56:31]: [Client #200] Loading its data source...
[INFO][07:56:31]: [Client #200] Dataset size: 2018
[INFO][07:56:31]: [Client #200] Sampler: iid
[INFO][07:56:33]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:56:33]: [Client #200] Start to process inbound data.
[INFO][07:56:33]: [93m[1m[Client #200] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0525728861490884,)
[INFO][07:57:10]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 32.2782, 'train_samples_per_second': 187.557, 'train_steps_per_second': 2.974, 'train_loss': 3.0525728861490884, 'epoch': 3.0}
[INFO][07:57:11]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][07:57:12]: [Client #200] Model trained.
[INFO][07:57:12]: [Client #200] Inbound data has been processed.
[INFO][07:57:12]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][07:57:16]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:57:17]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][07:57:17]: [Server #3995185] Selecting client #195 for training.
[INFO][07:57:17]: [Server #3995185] Sending the current model to client #195 (simulated).
[INFO][07:57:22]: [Server #3995185] Sending 507.38 MB of payload data to client #195 (simulated).
[INFO][07:57:22]: [Client #195] Selected by the server.
[INFO][07:57:22]: [Client #195] Loading its data source...
[INFO][07:57:22]: [Client #195] Dataset size: 2018
[INFO][07:57:22]: [Client #195] Sampler: iid
[INFO][07:57:23]: [Client #195] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:57:23]: [Client #195] Start to process inbound data.
[INFO][07:57:24]: [93m[1m[Client #195] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0338916778564453,)
[INFO][07:58:02]: [Client #195] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_195_3995237.pth.
{'train_runtime': 32.2704, 'train_samples_per_second': 187.602, 'train_steps_per_second': 2.975, 'train_loss': 3.0338916778564453, 'epoch': 3.0}
[INFO][07:58:02]: [Client #195] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_195_3995237.pth.
[INFO][07:58:03]: [Client #195] Model trained.
[INFO][07:58:03]: [Client #195] Inbound data has been processed.
[INFO][07:58:03]: [Client #195] Outbound data is ready to be sent after being processed.
[INFO][07:58:08]: [Client #195] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:58:09]: [Server #3995185] Received 507.38 MB of payload data from client #195 (simulated).
[INFO][07:58:09]: [Server #3995185] Selecting client #53 for training.
[INFO][07:58:09]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][07:58:14]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][07:58:14]: [Client #53] Selected by the server.
[INFO][07:58:14]: [Client #53] Loading its data source...
[INFO][07:58:14]: [Client #53] Dataset size: 2018
[INFO][07:58:14]: [Client #53] Sampler: iid
[INFO][07:58:15]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:58:15]: [Client #53] Start to process inbound data.
[INFO][07:58:15]: [93m[1m[Client #53] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0193182627360025,)
[INFO][07:58:54]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 32.3787, 'train_samples_per_second': 186.975, 'train_steps_per_second': 2.965, 'train_loss': 3.0193182627360025, 'epoch': 3.0}
[INFO][07:58:54]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][07:58:55]: [Client #53] Model trained.
[INFO][07:58:55]: [Client #53] Inbound data has been processed.
[INFO][07:58:55]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][07:59:00]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:59:01]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][07:59:01]: [Server #3995185] Selecting client #159 for training.
[INFO][07:59:01]: [Server #3995185] Sending the current model to client #159 (simulated).
[INFO][07:59:05]: [Server #3995185] Sending 507.38 MB of payload data to client #159 (simulated).
[INFO][07:59:05]: [Client #159] Selected by the server.
[INFO][07:59:05]: [Client #159] Loading its data source...
[INFO][07:59:05]: [Client #159] Dataset size: 2018
[INFO][07:59:05]: [Client #159] Sampler: iid
[INFO][07:59:07]: [Client #159] Received 507.38 MB of payload data from the server (simulated).
[INFO][07:59:07]: [Client #159] Start to process inbound data.
[INFO][07:59:07]: [93m[1m[Client #159] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.04842472076416,)
[INFO][07:59:45]: [Client #159] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_159_3995237.pth.
{'train_runtime': 32.5571, 'train_samples_per_second': 185.95, 'train_steps_per_second': 2.949, 'train_loss': 3.04842472076416, 'epoch': 3.0}
[INFO][07:59:46]: [Client #159] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_159_3995237.pth.
[INFO][07:59:47]: [Client #159] Model trained.
[INFO][07:59:47]: [Client #159] Inbound data has been processed.
[INFO][07:59:47]: [Client #159] Outbound data is ready to be sent after being processed.
[INFO][07:59:51]: [Client #159] Sent 507.38 MB of payload data to the server (simulated).
[INFO][07:59:52]: [Server #3995185] Received 507.38 MB of payload data from client #159 (simulated).
[INFO][07:59:52]: [Server #3995185] Selecting client #183 for training.
[INFO][07:59:52]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][07:59:59]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][07:59:59]: [Client #183] Selected by the server.
[INFO][07:59:59]: [Client #183] Loading its data source...
[INFO][07:59:59]: [Client #183] Dataset size: 2018
[INFO][07:59:59]: [Client #183] Sampler: iid
[INFO][08:00:00]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:00:00]: [Client #183] Start to process inbound data.
[INFO][08:00:00]: [93m[1m[Client #183] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9864981969197593,)
[INFO][08:00:39]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.5737, 'train_samples_per_second': 185.856, 'train_steps_per_second': 2.947, 'train_loss': 2.9864981969197593, 'epoch': 3.0}
[INFO][08:00:39]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][08:00:40]: [Client #183] Model trained.
[INFO][08:00:40]: [Client #183] Inbound data has been processed.
[INFO][08:00:40]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][08:00:47]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:00:48]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][08:00:48]: [Server #3995185] Selecting client #149 for training.
[INFO][08:00:48]: [Server #3995185] Sending the current model to client #149 (simulated).
[INFO][08:00:52]: [Server #3995185] Sending 507.38 MB of payload data to client #149 (simulated).
[INFO][08:00:52]: [Client #149] Selected by the server.
[INFO][08:00:52]: [Client #149] Loading its data source...
[INFO][08:00:52]: [Client #149] Dataset size: 2018
[INFO][08:00:52]: [Client #149] Sampler: iid
[INFO][08:00:54]: [Client #149] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:00:54]: [Client #149] Start to process inbound data.
[INFO][08:00:54]: [93m[1m[Client #149] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.77s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.988201459248861,)
[INFO][08:01:33]: [Client #149] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
{'train_runtime': 32.7657, 'train_samples_per_second': 184.766, 'train_steps_per_second': 2.93, 'train_loss': 2.988201459248861, 'epoch': 3.0}
[INFO][08:01:34]: [Client #149] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
[INFO][08:01:34]: [Client #149] Model trained.
[INFO][08:01:34]: [Client #149] Inbound data has been processed.
[INFO][08:01:34]: [Client #149] Outbound data is ready to be sent after being processed.
[INFO][08:01:39]: [Client #149] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:01:40]: [Server #3995185] Received 507.38 MB of payload data from client #149 (simulated).
[INFO][08:01:40]: [Server #3995185] Selecting client #1 for training.
[INFO][08:01:40]: [Server #3995185] Sending the current model to client #1 (simulated).
[INFO][08:01:45]: [Server #3995185] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][08:01:45]: [Client #1] Selected by the server.
[INFO][08:01:45]: [Client #1] Loading its data source...
[INFO][08:01:45]: [Client #1] Dataset size: 2018
[INFO][08:01:45]: [Client #1] Sampler: iid
[INFO][08:01:46]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:01:46]: [Client #1] Start to process inbound data.
[INFO][08:01:46]: [93m[1m[Client #1] Started training in communication round #25.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.030146598815918,)
[INFO][08:02:24]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
{'train_runtime': 32.3514, 'train_samples_per_second': 187.132, 'train_steps_per_second': 2.967, 'train_loss': 3.030146598815918, 'epoch': 3.0}
[INFO][08:02:25]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
[INFO][08:02:26]: [Client #1] Model trained.
[INFO][08:02:26]: [Client #1] Inbound data has been processed.
[INFO][08:02:26]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][08:02:31]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:02:32]: [Server #3995185] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][08:02:32]: [Server #3995185] Adding client #132 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #177 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #59 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #113 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #52 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #97 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #64 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #1 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #53 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Adding client #57 to the list of clients for aggregation.
[INFO][08:02:32]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:02:32]: [Server #3995185] Updated weights have been received.
[INFO][08:02:34]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:02:35]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:02:35]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.60it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.47it/s]
[INFO][08:02:44]: [93m[1m[Server #3995185] Global model perplexity: 23.67
[0m
[INFO][08:02:44]: [Server #3995185] All client reports have been processed.
[INFO][08:02:44]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_25.pth.
[INFO][08:02:50]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_25.pth.
[INFO][08:02:50]: [93m[1m
[Server #3995185] Starting round 26/50.[0m
[INFO][08:02:50]: [Server #3995185] Selected clients: [13, 9, 54, 10, 193, 14, 119, 116, 46, 131]
[INFO][08:02:50]: [Server #3995185] Selecting client #13 for training.
[INFO][08:02:50]: [Server #3995185] Sending the current model to client #13 (simulated).
[INFO][08:02:55]: [Server #3995185] Sending 507.38 MB of payload data to client #13 (simulated).
[INFO][08:02:55]: [Client #13] Selected by the server.
[INFO][08:02:55]: [Client #13] Loading its data source...
[INFO][08:02:55]: [Client #13] Dataset size: 2018
[INFO][08:02:55]: [Client #13] Sampler: iid
[INFO][08:02:57]: [Client #13] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:02:57]: [Client #13] Start to process inbound data.
[INFO][08:02:57]: [93m[1m[Client #13] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.968952496846517,)
[INFO][08:03:35]: [Client #13] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
{'train_runtime': 32.3622, 'train_samples_per_second': 187.07, 'train_steps_per_second': 2.966, 'train_loss': 2.968952496846517, 'epoch': 3.0}
[INFO][08:03:36]: [Client #13] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
[INFO][08:03:36]: [Client #13] Model trained.
[INFO][08:03:36]: [Client #13] Inbound data has been processed.
[INFO][08:03:36]: [Client #13] Outbound data is ready to be sent after being processed.
[INFO][08:03:41]: [Client #13] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:03:42]: [Server #3995185] Received 507.38 MB of payload data from client #13 (simulated).
[INFO][08:03:42]: [Server #3995185] Selecting client #9 for training.
[INFO][08:03:42]: [Server #3995185] Sending the current model to client #9 (simulated).
[INFO][08:03:47]: [Server #3995185] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][08:03:47]: [Client #9] Selected by the server.
[INFO][08:03:47]: [Client #9] Loading its data source...
[INFO][08:03:47]: [Client #9] Dataset size: 2018
[INFO][08:03:47]: [Client #9] Sampler: iid
[INFO][08:03:48]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:03:48]: [Client #9] Start to process inbound data.
[INFO][08:03:48]: [93m[1m[Client #9] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.983508745829264,)
[INFO][08:04:27]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
{'train_runtime': 32.5182, 'train_samples_per_second': 186.173, 'train_steps_per_second': 2.952, 'train_loss': 2.983508745829264, 'epoch': 3.0}
[INFO][08:04:27]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
[INFO][08:04:28]: [Client #9] Model trained.
[INFO][08:04:28]: [Client #9] Inbound data has been processed.
[INFO][08:04:28]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][08:04:33]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:04:34]: [Server #3995185] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][08:04:34]: [Server #3995185] Selecting client #54 for training.
[INFO][08:04:34]: [Server #3995185] Sending the current model to client #54 (simulated).
[INFO][08:04:39]: [Server #3995185] Sending 507.38 MB of payload data to client #54 (simulated).
[INFO][08:04:39]: [Client #54] Selected by the server.
[INFO][08:04:39]: [Client #54] Loading its data source...
[INFO][08:04:39]: [Client #54] Dataset size: 2018
[INFO][08:04:39]: [Client #54] Sampler: iid
[INFO][08:04:40]: [Client #54] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:04:40]: [Client #54] Start to process inbound data.
[INFO][08:04:40]: [93m[1m[Client #54] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:24,  1.52s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.05it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0739399592081704,)
[INFO][08:05:18]: [Client #54] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
{'train_runtime': 32.3757, 'train_samples_per_second': 186.992, 'train_steps_per_second': 2.965, 'train_loss': 3.0739399592081704, 'epoch': 3.0}
[INFO][08:05:19]: [Client #54] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
[INFO][08:05:20]: [Client #54] Model trained.
[INFO][08:05:20]: [Client #54] Inbound data has been processed.
[INFO][08:05:20]: [Client #54] Outbound data is ready to be sent after being processed.
[INFO][08:05:27]: [Client #54] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:05:28]: [Server #3995185] Received 507.38 MB of payload data from client #54 (simulated).
[INFO][08:05:28]: [Server #3995185] Selecting client #10 for training.
[INFO][08:05:28]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][08:05:32]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][08:05:32]: [Client #10] Selected by the server.
[INFO][08:05:32]: [Client #10] Loading its data source...
[INFO][08:05:32]: [Client #10] Dataset size: 2018
[INFO][08:05:32]: [Client #10] Sampler: iid
[INFO][08:05:34]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:05:34]: [Client #10] Start to process inbound data.
[INFO][08:05:35]: [93m[1m[Client #10] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.11it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0362927118937173,)
[INFO][08:06:13]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.3239, 'train_samples_per_second': 187.291, 'train_steps_per_second': 2.97, 'train_loss': 3.0362927118937173, 'epoch': 3.0}
[INFO][08:06:13]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][08:06:14]: [Client #10] Model trained.
[INFO][08:06:14]: [Client #10] Inbound data has been processed.
[INFO][08:06:14]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][08:06:19]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:06:20]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][08:06:20]: [Server #3995185] Selecting client #193 for training.
[INFO][08:06:20]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][08:06:25]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][08:06:26]: [Client #193] Selected by the server.
[INFO][08:06:26]: [Client #193] Loading its data source...
[INFO][08:06:26]: [Client #193] Dataset size: 2018
[INFO][08:06:26]: [Client #193] Sampler: iid
[INFO][08:06:27]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:06:27]: [Client #193] Start to process inbound data.
[INFO][08:06:28]: [93m[1m[Client #193] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9645891189575195,)
[INFO][08:07:06]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 32.4555, 'train_samples_per_second': 186.532, 'train_steps_per_second': 2.958, 'train_loss': 2.9645891189575195, 'epoch': 3.0}
[INFO][08:07:06]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][08:07:07]: [Client #193] Model trained.
[INFO][08:07:07]: [Client #193] Inbound data has been processed.
[INFO][08:07:07]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][08:07:12]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:07:13]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][08:07:13]: [Server #3995185] Selecting client #14 for training.
[INFO][08:07:13]: [Server #3995185] Sending the current model to client #14 (simulated).
[INFO][08:07:18]: [Server #3995185] Sending 507.38 MB of payload data to client #14 (simulated).
[INFO][08:07:18]: [Client #14] Selected by the server.
[INFO][08:07:18]: [Client #14] Loading its data source...
[INFO][08:07:18]: [Client #14] Dataset size: 2018
[INFO][08:07:18]: [Client #14] Sampler: iid
[INFO][08:07:19]: [Client #14] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:07:19]: [Client #14] Start to process inbound data.
[INFO][08:07:20]: [93m[1m[Client #14] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:11,  1.39s/it]  2%|â–         | 2/96 [00:01<01:11,  1.32it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.07it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0564146041870117,)
[INFO][08:07:58]: [Client #14] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
{'train_runtime': 32.2439, 'train_samples_per_second': 187.756, 'train_steps_per_second': 2.977, 'train_loss': 3.0564146041870117, 'epoch': 3.0}
[INFO][08:07:59]: [Client #14] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
[INFO][08:07:59]: [Client #14] Model trained.
[INFO][08:07:59]: [Client #14] Inbound data has been processed.
[INFO][08:07:59]: [Client #14] Outbound data is ready to be sent after being processed.
[INFO][08:08:04]: [Client #14] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:08:05]: [Server #3995185] Received 507.38 MB of payload data from client #14 (simulated).
[INFO][08:08:05]: [Server #3995185] Selecting client #119 for training.
[INFO][08:08:05]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][08:08:11]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][08:08:11]: [Client #119] Selected by the server.
[INFO][08:08:11]: [Client #119] Loading its data source...
[INFO][08:08:11]: [Client #119] Dataset size: 2018
[INFO][08:08:11]: [Client #119] Sampler: iid
[INFO][08:08:13]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:08:13]: [Client #119] Start to process inbound data.
[INFO][08:08:14]: [93m[1m[Client #119] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9676284790039062,)
[INFO][08:08:52]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 32.5512, 'train_samples_per_second': 185.984, 'train_steps_per_second': 2.949, 'train_loss': 2.9676284790039062, 'epoch': 3.0}
[INFO][08:08:53]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][08:08:54]: [Client #119] Model trained.
[INFO][08:08:54]: [Client #119] Inbound data has been processed.
[INFO][08:08:54]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][08:08:59]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:09:00]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][08:09:00]: [Server #3995185] Selecting client #116 for training.
[INFO][08:09:00]: [Server #3995185] Sending the current model to client #116 (simulated).
[INFO][08:09:08]: [Server #3995185] Sending 507.38 MB of payload data to client #116 (simulated).
[INFO][08:09:08]: [Client #116] Selected by the server.
[INFO][08:09:08]: [Client #116] Loading its data source...
[INFO][08:09:08]: [Client #116] Dataset size: 2018
[INFO][08:09:08]: [Client #116] Sampler: iid
[INFO][08:09:09]: [Client #116] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:09:09]: [Client #116] Start to process inbound data.
[INFO][08:09:09]: [93m[1m[Client #116] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.08it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.08it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.09it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.09it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.10it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.085142135620117,)
[INFO][08:09:47]: [Client #116] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_116_3995237.pth.
{'train_runtime': 32.1503, 'train_samples_per_second': 188.303, 'train_steps_per_second': 2.986, 'train_loss': 3.085142135620117, 'epoch': 3.0}
[INFO][08:09:48]: [Client #116] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_116_3995237.pth.
[INFO][08:09:48]: [Client #116] Model trained.
[INFO][08:09:48]: [Client #116] Inbound data has been processed.
[INFO][08:09:48]: [Client #116] Outbound data is ready to be sent after being processed.
[INFO][08:09:53]: [Client #116] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:09:54]: [Server #3995185] Received 507.38 MB of payload data from client #116 (simulated).
[INFO][08:09:54]: [Server #3995185] Selecting client #46 for training.
[INFO][08:09:54]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][08:10:01]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][08:10:01]: [Client #46] Selected by the server.
[INFO][08:10:01]: [Client #46] Loading its data source...
[INFO][08:10:01]: [Client #46] Dataset size: 2018
[INFO][08:10:01]: [Client #46] Sampler: iid
[INFO][08:10:02]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:10:02]: [Client #46] Start to process inbound data.
[INFO][08:10:02]: [93m[1m[Client #46] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0530401865641275,)
[INFO][08:10:40]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.5297, 'train_samples_per_second': 186.107, 'train_steps_per_second': 2.951, 'train_loss': 3.0530401865641275, 'epoch': 3.0}
[INFO][08:10:41]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][08:10:42]: [Client #46] Model trained.
[INFO][08:10:42]: [Client #46] Inbound data has been processed.
[INFO][08:10:42]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][08:10:47]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:10:48]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][08:10:48]: [Server #3995185] Selecting client #131 for training.
[INFO][08:10:48]: [Server #3995185] Sending the current model to client #131 (simulated).
[INFO][08:10:57]: [Server #3995185] Sending 507.38 MB of payload data to client #131 (simulated).
[INFO][08:10:57]: [Client #131] Selected by the server.
[INFO][08:10:57]: [Client #131] Loading its data source...
[INFO][08:10:57]: [Client #131] Dataset size: 2018
[INFO][08:10:57]: [Client #131] Sampler: iid
[INFO][08:10:59]: [Client #131] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:10:59]: [Client #131] Start to process inbound data.
[INFO][08:10:59]: [93m[1m[Client #131] Started training in communication round #26.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.037678082784017,)
[INFO][08:11:37]: [Client #131] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_131_3995237.pth.
{'train_runtime': 32.5643, 'train_samples_per_second': 185.909, 'train_steps_per_second': 2.948, 'train_loss': 3.037678082784017, 'epoch': 3.0}
[INFO][08:11:38]: [Client #131] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_131_3995237.pth.
[INFO][08:11:39]: [Client #131] Model trained.
[INFO][08:11:39]: [Client #131] Inbound data has been processed.
[INFO][08:11:39]: [Client #131] Outbound data is ready to be sent after being processed.
[INFO][08:11:44]: [Client #131] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:11:45]: [Server #3995185] Received 507.38 MB of payload data from client #131 (simulated).
[INFO][08:11:45]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #144 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #149 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #159 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #195 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #58 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #133 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Adding client #184 to the list of clients for aggregation.
[INFO][08:11:45]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:11:45]: [Server #3995185] Updated weights have been received.
[INFO][08:11:47]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:11:48]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:11:48]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.62it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.30it/s]
[INFO][08:11:57]: [93m[1m[Server #3995185] Global model perplexity: 23.77
[0m
[INFO][08:11:57]: [Server #3995185] All client reports have been processed.
[INFO][08:11:57]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_26.pth.
[INFO][08:12:01]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_26.pth.
[INFO][08:12:01]: [93m[1m
[Server #3995185] Starting round 27/50.[0m
[INFO][08:12:01]: [Server #3995185] Selected clients: [1, 78, 41, 188, 111, 57, 5, 80, 37, 151]
[INFO][08:12:01]: [Server #3995185] Selecting client #1 for training.
[INFO][08:12:01]: [Server #3995185] Sending the current model to client #1 (simulated).
[INFO][08:12:09]: [Server #3995185] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][08:12:09]: [Client #1] Selected by the server.
[INFO][08:12:09]: [Client #1] Loading its data source...
[INFO][08:12:09]: [Client #1] Dataset size: 2018
[INFO][08:12:09]: [Client #1] Sampler: iid
[INFO][08:12:11]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:12:11]: [Client #1] Start to process inbound data.
[INFO][08:12:11]: [93m[1m[Client #1] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:35,  1.64s/it]  2%|â–         | 2/96 [00:01<01:21,  1.15it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.61it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.009028116861979,)
[INFO][08:12:50]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
{'train_runtime': 32.5653, 'train_samples_per_second': 185.904, 'train_steps_per_second': 2.948, 'train_loss': 3.009028116861979, 'epoch': 3.0}
[INFO][08:12:51]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
[INFO][08:12:51]: [Client #1] Model trained.
[INFO][08:12:51]: [Client #1] Inbound data has been processed.
[INFO][08:12:51]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][08:12:59]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:13:00]: [Server #3995185] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][08:13:00]: [Server #3995185] Selecting client #78 for training.
[INFO][08:13:00]: [Server #3995185] Sending the current model to client #78 (simulated).
[INFO][08:13:07]: [Server #3995185] Sending 507.38 MB of payload data to client #78 (simulated).
[INFO][08:13:07]: [Client #78] Selected by the server.
[INFO][08:13:07]: [Client #78] Loading its data source...
[INFO][08:13:07]: [Client #78] Dataset size: 2018
[INFO][08:13:07]: [Client #78] Sampler: iid
[INFO][08:13:08]: [Client #78] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:13:08]: [Client #78] Start to process inbound data.
[INFO][08:13:09]: [93m[1m[Client #78] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0435479482014975,)
[INFO][08:13:47]: [Client #78] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3995237.pth.
{'train_runtime': 32.5406, 'train_samples_per_second': 186.045, 'train_steps_per_second': 2.95, 'train_loss': 3.0435479482014975, 'epoch': 3.0}
[INFO][08:13:48]: [Client #78] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3995237.pth.
[INFO][08:13:48]: [Client #78] Model trained.
[INFO][08:13:48]: [Client #78] Inbound data has been processed.
[INFO][08:13:48]: [Client #78] Outbound data is ready to be sent after being processed.
[INFO][08:13:57]: [Client #78] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:13:58]: [Server #3995185] Received 507.38 MB of payload data from client #78 (simulated).
[INFO][08:13:58]: [Server #3995185] Selecting client #41 for training.
[INFO][08:13:58]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][08:14:09]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][08:14:09]: [Client #41] Selected by the server.
[INFO][08:14:09]: [Client #41] Loading its data source...
[INFO][08:14:09]: [Client #41] Dataset size: 2018
[INFO][08:14:09]: [Client #41] Sampler: iid
[INFO][08:14:10]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:14:10]: [Client #41] Start to process inbound data.
[INFO][08:14:10]: [93m[1m[Client #41] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:51,  1.80s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9888509114583335,)
[INFO][08:14:50]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.8464, 'train_samples_per_second': 184.312, 'train_steps_per_second': 2.923, 'train_loss': 2.9888509114583335, 'epoch': 3.0}
[INFO][08:14:51]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][08:14:52]: [Client #41] Model trained.
[INFO][08:14:52]: [Client #41] Inbound data has been processed.
[INFO][08:14:52]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][08:15:00]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:15:01]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][08:15:01]: [Server #3995185] Selecting client #188 for training.
[INFO][08:15:01]: [Server #3995185] Sending the current model to client #188 (simulated).
[INFO][08:15:07]: [Server #3995185] Sending 507.38 MB of payload data to client #188 (simulated).
[INFO][08:15:07]: [Client #188] Selected by the server.
[INFO][08:15:07]: [Client #188] Loading its data source...
[INFO][08:15:07]: [Client #188] Dataset size: 2018
[INFO][08:15:07]: [Client #188] Sampler: iid
[INFO][08:15:08]: [Client #188] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:15:08]: [Client #188] Start to process inbound data.
[INFO][08:15:09]: [93m[1m[Client #188] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.16it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.26it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.067793528238932,)
[INFO][08:15:48]: [Client #188] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
{'train_runtime': 32.6443, 'train_samples_per_second': 185.454, 'train_steps_per_second': 2.941, 'train_loss': 3.067793528238932, 'epoch': 3.0}
[INFO][08:15:49]: [Client #188] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
[INFO][08:15:49]: [Client #188] Model trained.
[INFO][08:15:49]: [Client #188] Inbound data has been processed.
[INFO][08:15:49]: [Client #188] Outbound data is ready to be sent after being processed.
[INFO][08:15:57]: [Client #188] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:15:59]: [Server #3995185] Received 507.38 MB of payload data from client #188 (simulated).
[INFO][08:15:59]: [Server #3995185] Selecting client #111 for training.
[INFO][08:15:59]: [Server #3995185] Sending the current model to client #111 (simulated).
[INFO][08:16:03]: [Server #3995185] Sending 507.38 MB of payload data to client #111 (simulated).
[INFO][08:16:03]: [Client #111] Selected by the server.
[INFO][08:16:03]: [Client #111] Loading its data source...
[INFO][08:16:03]: [Client #111] Dataset size: 2018
[INFO][08:16:03]: [Client #111] Sampler: iid
[INFO][08:16:05]: [Client #111] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:16:05]: [Client #111] Start to process inbound data.
[INFO][08:16:05]: [93m[1m[Client #111] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0433486302693686,)
[INFO][08:16:44]: [Client #111] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_111_3995237.pth.
{'train_runtime': 32.4725, 'train_samples_per_second': 186.435, 'train_steps_per_second': 2.956, 'train_loss': 3.0433486302693686, 'epoch': 3.0}
[INFO][08:16:44]: [Client #111] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_111_3995237.pth.
[INFO][08:16:45]: [Client #111] Model trained.
[INFO][08:16:45]: [Client #111] Inbound data has been processed.
[INFO][08:16:45]: [Client #111] Outbound data is ready to be sent after being processed.
[INFO][08:16:53]: [Client #111] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:16:54]: [Server #3995185] Received 507.38 MB of payload data from client #111 (simulated).
[INFO][08:16:54]: [Server #3995185] Selecting client #57 for training.
[INFO][08:16:54]: [Server #3995185] Sending the current model to client #57 (simulated).
[INFO][08:16:59]: [Server #3995185] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][08:16:59]: [Client #57] Selected by the server.
[INFO][08:16:59]: [Client #57] Loading its data source...
[INFO][08:16:59]: [Client #57] Dataset size: 2018
[INFO][08:16:59]: [Client #57] Sampler: iid
[INFO][08:17:01]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:17:01]: [Client #57] Start to process inbound data.
[INFO][08:17:01]: [93m[1m[Client #57] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0080086390177407,)
[INFO][08:17:39]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
{'train_runtime': 32.1786, 'train_samples_per_second': 188.137, 'train_steps_per_second': 2.983, 'train_loss': 3.0080086390177407, 'epoch': 3.0}
[INFO][08:17:40]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
[INFO][08:17:40]: [Client #57] Model trained.
[INFO][08:17:40]: [Client #57] Inbound data has been processed.
[INFO][08:17:40]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][08:17:47]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:17:48]: [Server #3995185] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][08:17:48]: [Server #3995185] Selecting client #5 for training.
[INFO][08:17:48]: [Server #3995185] Sending the current model to client #5 (simulated).
[INFO][08:17:53]: [Server #3995185] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][08:17:53]: [Client #5] Selected by the server.
[INFO][08:17:53]: [Client #5] Loading its data source...
[INFO][08:17:53]: [Client #5] Dataset size: 2018
[INFO][08:17:53]: [Client #5] Sampler: iid
[INFO][08:17:55]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:17:55]: [Client #5] Start to process inbound data.
[INFO][08:17:55]: [93m[1m[Client #5] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.990859031677246,)
[INFO][08:18:33]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
{'train_runtime': 32.4779, 'train_samples_per_second': 186.404, 'train_steps_per_second': 2.956, 'train_loss': 2.990859031677246, 'epoch': 3.0}
[INFO][08:18:34]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
[INFO][08:18:35]: [Client #5] Model trained.
[INFO][08:18:35]: [Client #5] Inbound data has been processed.
[INFO][08:18:35]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][08:18:40]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:18:41]: [Server #3995185] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][08:18:41]: [Server #3995185] Selecting client #80 for training.
[INFO][08:18:41]: [Server #3995185] Sending the current model to client #80 (simulated).
[INFO][08:18:47]: [Server #3995185] Sending 507.38 MB of payload data to client #80 (simulated).
[INFO][08:18:47]: [Client #80] Selected by the server.
[INFO][08:18:47]: [Client #80] Loading its data source...
[INFO][08:18:47]: [Client #80] Dataset size: 2018
[INFO][08:18:47]: [Client #80] Sampler: iid
[INFO][08:18:48]: [Client #80] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:18:48]: [Client #80] Start to process inbound data.
[INFO][08:18:49]: [93m[1m[Client #80] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.11it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.11it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0601962407430015,)
[INFO][08:19:26]: [Client #80] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_80_3995237.pth.
{'train_runtime': 32.1852, 'train_samples_per_second': 188.099, 'train_steps_per_second': 2.983, 'train_loss': 3.0601962407430015, 'epoch': 3.0}
[INFO][08:19:27]: [Client #80] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_80_3995237.pth.
[INFO][08:19:28]: [Client #80] Model trained.
[INFO][08:19:28]: [Client #80] Inbound data has been processed.
[INFO][08:19:28]: [Client #80] Outbound data is ready to be sent after being processed.
[INFO][08:19:34]: [Client #80] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:19:35]: [Server #3995185] Received 507.38 MB of payload data from client #80 (simulated).
[INFO][08:19:35]: [Server #3995185] Selecting client #37 for training.
[INFO][08:19:35]: [Server #3995185] Sending the current model to client #37 (simulated).
[INFO][08:19:40]: [Server #3995185] Sending 507.38 MB of payload data to client #37 (simulated).
[INFO][08:19:40]: [Client #37] Selected by the server.
[INFO][08:19:40]: [Client #37] Loading its data source...
[INFO][08:19:40]: [Client #37] Dataset size: 2018
[INFO][08:19:40]: [Client #37] Sampler: iid
[INFO][08:19:41]: [Client #37] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:19:41]: [Client #37] Start to process inbound data.
[INFO][08:19:41]: [93m[1m[Client #37] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.006924629211426,)
[INFO][08:20:19]: [Client #37] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
{'train_runtime': 32.2086, 'train_samples_per_second': 187.962, 'train_steps_per_second': 2.981, 'train_loss': 3.006924629211426, 'epoch': 3.0}
[INFO][08:20:20]: [Client #37] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
[INFO][08:20:20]: [Client #37] Model trained.
[INFO][08:20:20]: [Client #37] Inbound data has been processed.
[INFO][08:20:20]: [Client #37] Outbound data is ready to be sent after being processed.
[INFO][08:20:25]: [Client #37] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:20:26]: [Server #3995185] Received 507.38 MB of payload data from client #37 (simulated).
[INFO][08:20:26]: [Server #3995185] Selecting client #151 for training.
[INFO][08:20:26]: [Server #3995185] Sending the current model to client #151 (simulated).
[INFO][08:20:31]: [Server #3995185] Sending 507.38 MB of payload data to client #151 (simulated).
[INFO][08:20:31]: [Client #151] Selected by the server.
[INFO][08:20:31]: [Client #151] Loading its data source...
[INFO][08:20:31]: [Client #151] Dataset size: 2018
[INFO][08:20:31]: [Client #151] Sampler: iid
[INFO][08:20:32]: [Client #151] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:20:32]: [Client #151] Start to process inbound data.
[INFO][08:20:33]: [93m[1m[Client #151] Started training in communication round #27.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.975924491882324,)
[INFO][08:21:11]: [Client #151] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
{'train_runtime': 32.4696, 'train_samples_per_second': 186.451, 'train_steps_per_second': 2.957, 'train_loss': 2.975924491882324, 'epoch': 3.0}
[INFO][08:21:12]: [Client #151] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
[INFO][08:21:12]: [Client #151] Model trained.
[INFO][08:21:12]: [Client #151] Inbound data has been processed.
[INFO][08:21:12]: [Client #151] Outbound data is ready to be sent after being processed.
[INFO][08:21:20]: [Client #151] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:21:21]: [Server #3995185] Received 507.38 MB of payload data from client #151 (simulated).
[INFO][08:21:21]: [Server #3995185] Adding client #9 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #13 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #14 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #54 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #119 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #131 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Adding client #116 to the list of clients for aggregation.
[INFO][08:21:21]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:21:21]: [Server #3995185] Updated weights have been received.
[INFO][08:21:22]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:21:23]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:21:23]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:00<00:00, 47.34it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:00<00:00, 40.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 38.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 38.57it/s]
[INFO][08:21:32]: [93m[1m[Server #3995185] Global model perplexity: 23.23
[0m
[INFO][08:21:32]: [Server #3995185] All client reports have been processed.
[INFO][08:21:32]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_27.pth.
[INFO][08:21:36]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_27.pth.
[INFO][08:21:36]: [93m[1m
[Server #3995185] Starting round 28/50.[0m
[INFO][08:21:36]: [Server #3995185] Selected clients: [17, 132, 45, 71, 143, 10, 193, 43, 89, 85]
[INFO][08:21:36]: [Server #3995185] Selecting client #17 for training.
[INFO][08:21:36]: [Server #3995185] Sending the current model to client #17 (simulated).
[INFO][08:21:41]: [Server #3995185] Sending 507.38 MB of payload data to client #17 (simulated).
[INFO][08:21:41]: [Client #17] Selected by the server.
[INFO][08:21:41]: [Client #17] Loading its data source...
[INFO][08:21:41]: [Client #17] Dataset size: 2018
[INFO][08:21:41]: [Client #17] Sampler: iid
[INFO][08:21:42]: [Client #17] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:21:42]: [Client #17] Start to process inbound data.
[INFO][08:21:42]: [93m[1m[Client #17] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:54,  1.83s/it]  2%|â–         | 2/96 [00:02<01:28,  1.06it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:48,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9683284759521484,)
[INFO][08:22:21]: [Client #17] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3995237.pth.
{'train_runtime': 32.8456, 'train_samples_per_second': 184.317, 'train_steps_per_second': 2.923, 'train_loss': 2.9683284759521484, 'epoch': 3.0}
[INFO][08:22:22]: [Client #17] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_17_3995237.pth.
[INFO][08:22:23]: [Client #17] Model trained.
[INFO][08:22:23]: [Client #17] Inbound data has been processed.
[INFO][08:22:23]: [Client #17] Outbound data is ready to be sent after being processed.
[INFO][08:22:28]: [Client #17] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:22:29]: [Server #3995185] Received 507.38 MB of payload data from client #17 (simulated).
[INFO][08:22:29]: [Server #3995185] Selecting client #132 for training.
[INFO][08:22:29]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][08:22:34]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][08:22:34]: [Client #132] Selected by the server.
[INFO][08:22:34]: [Client #132] Loading its data source...
[INFO][08:22:34]: [Client #132] Dataset size: 2018
[INFO][08:22:34]: [Client #132] Sampler: iid
[INFO][08:22:35]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:22:35]: [Client #132] Start to process inbound data.
[INFO][08:22:35]: [93m[1m[Client #132] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:50,  1.80s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.97it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9803593953450522,)
[INFO][08:23:15]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 33.005, 'train_samples_per_second': 183.427, 'train_steps_per_second': 2.909, 'train_loss': 2.9803593953450522, 'epoch': 3.0}
[INFO][08:23:16]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][08:23:16]: [Client #132] Model trained.
[INFO][08:23:16]: [Client #132] Inbound data has been processed.
[INFO][08:23:16]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][08:23:21]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:23:22]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][08:23:22]: [Server #3995185] Selecting client #45 for training.
[INFO][08:23:22]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][08:23:27]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][08:23:27]: [Client #45] Selected by the server.
[INFO][08:23:27]: [Client #45] Loading its data source...
[INFO][08:23:27]: [Client #45] Dataset size: 2018
[INFO][08:23:27]: [Client #45] Sampler: iid
[INFO][08:23:28]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:23:28]: [Client #45] Start to process inbound data.
[INFO][08:23:28]: [93m[1m[Client #45] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.929690361022949,)
[INFO][08:24:06]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.3184, 'train_samples_per_second': 187.323, 'train_steps_per_second': 2.97, 'train_loss': 2.929690361022949, 'epoch': 3.0}
[INFO][08:24:06]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][08:24:07]: [Client #45] Model trained.
[INFO][08:24:07]: [Client #45] Inbound data has been processed.
[INFO][08:24:07]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][08:24:13]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:24:14]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][08:24:14]: [Server #3995185] Selecting client #71 for training.
[INFO][08:24:14]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][08:24:19]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][08:24:19]: [Client #71] Selected by the server.
[INFO][08:24:19]: [Client #71] Loading its data source...
[INFO][08:24:19]: [Client #71] Dataset size: 2018
[INFO][08:24:19]: [Client #71] Sampler: iid
[INFO][08:24:21]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:24:21]: [Client #71] Start to process inbound data.
[INFO][08:24:21]: [93m[1m[Client #71] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9355767567952475,)
[INFO][08:24:59]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.3441, 'train_samples_per_second': 187.175, 'train_steps_per_second': 2.968, 'train_loss': 2.9355767567952475, 'epoch': 3.0}
[INFO][08:25:00]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][08:25:00]: [Client #71] Model trained.
[INFO][08:25:00]: [Client #71] Inbound data has been processed.
[INFO][08:25:00]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][08:25:05]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:25:06]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][08:25:06]: [Server #3995185] Selecting client #143 for training.
[INFO][08:25:06]: [Server #3995185] Sending the current model to client #143 (simulated).
[INFO][08:25:11]: [Server #3995185] Sending 507.38 MB of payload data to client #143 (simulated).
[INFO][08:25:11]: [Client #143] Selected by the server.
[INFO][08:25:11]: [Client #143] Loading its data source...
[INFO][08:25:11]: [Client #143] Dataset size: 2018
[INFO][08:25:11]: [Client #143] Sampler: iid
[INFO][08:25:13]: [Client #143] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:25:13]: [Client #143] Start to process inbound data.
[INFO][08:25:13]: [93m[1m[Client #143] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.989827791849772,)
[INFO][08:25:51]: [Client #143] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
{'train_runtime': 32.4065, 'train_samples_per_second': 186.814, 'train_steps_per_second': 2.962, 'train_loss': 2.989827791849772, 'epoch': 3.0}
[INFO][08:25:52]: [Client #143] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
[INFO][08:25:53]: [Client #143] Model trained.
[INFO][08:25:53]: [Client #143] Inbound data has been processed.
[INFO][08:25:53]: [Client #143] Outbound data is ready to be sent after being processed.
[INFO][08:25:58]: [Client #143] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:25:59]: [Server #3995185] Received 507.38 MB of payload data from client #143 (simulated).
[INFO][08:25:59]: [Server #3995185] Selecting client #10 for training.
[INFO][08:25:59]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][08:26:04]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][08:26:04]: [Client #10] Selected by the server.
[INFO][08:26:04]: [Client #10] Loading its data source...
[INFO][08:26:04]: [Client #10] Dataset size: 2018
[INFO][08:26:04]: [Client #10] Sampler: iid
[INFO][08:26:06]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:26:06]: [Client #10] Start to process inbound data.
[INFO][08:26:06]: [93m[1m[Client #10] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:24,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.00it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.98it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.96it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.937785784403483,)
[INFO][08:26:46]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.7486, 'train_samples_per_second': 184.863, 'train_steps_per_second': 2.931, 'train_loss': 2.937785784403483, 'epoch': 3.0}
[INFO][08:26:46]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][08:26:47]: [Client #10] Model trained.
[INFO][08:26:47]: [Client #10] Inbound data has been processed.
[INFO][08:26:47]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][08:26:52]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:26:53]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][08:26:53]: [Server #3995185] Selecting client #193 for training.
[INFO][08:26:53]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][08:26:58]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][08:26:58]: [Client #193] Selected by the server.
[INFO][08:26:58]: [Client #193] Loading its data source...
[INFO][08:26:58]: [Client #193] Dataset size: 2018
[INFO][08:26:58]: [Client #193] Sampler: iid
[INFO][08:26:59]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:26:59]: [Client #193] Start to process inbound data.
[INFO][08:26:59]: [93m[1m[Client #193] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.78s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.90it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.19it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.00it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.00it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.99it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.43it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.28it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.12it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.08it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.00it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  2.99it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:18,  2.99it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  2.98it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8657541275024414,)
[INFO][08:27:38]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 33.0564, 'train_samples_per_second': 183.141, 'train_steps_per_second': 2.904, 'train_loss': 2.8657541275024414, 'epoch': 3.0}
[INFO][08:27:39]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][08:27:40]: [Client #193] Model trained.
[INFO][08:27:40]: [Client #193] Inbound data has been processed.
[INFO][08:27:40]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][08:27:46]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:27:47]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][08:27:47]: [Server #3995185] Selecting client #43 for training.
[INFO][08:27:47]: [Server #3995185] Sending the current model to client #43 (simulated).
[INFO][08:27:52]: [Server #3995185] Sending 507.38 MB of payload data to client #43 (simulated).
[INFO][08:27:52]: [Client #43] Selected by the server.
[INFO][08:27:52]: [Client #43] Loading its data source...
[INFO][08:27:52]: [Client #43] Dataset size: 2018
[INFO][08:27:52]: [Client #43] Sampler: iid
[INFO][08:27:53]: [Client #43] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:27:53]: [Client #43] Start to process inbound data.
[INFO][08:27:54]: [93m[1m[Client #43] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:46,  1.75s/it]  2%|â–         | 2/96 [00:02<01:26,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.54it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.58it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.19it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.13it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.06it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.99it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.95it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.985109329223633,)
[INFO][08:28:33]: [Client #43] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
{'train_runtime': 33.154, 'train_samples_per_second': 182.602, 'train_steps_per_second': 2.896, 'train_loss': 2.985109329223633, 'epoch': 3.0}
[INFO][08:28:34]: [Client #43] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
[INFO][08:28:34]: [Client #43] Model trained.
[INFO][08:28:34]: [Client #43] Inbound data has been processed.
[INFO][08:28:34]: [Client #43] Outbound data is ready to be sent after being processed.
[INFO][08:28:39]: [Client #43] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:28:40]: [Server #3995185] Received 507.38 MB of payload data from client #43 (simulated).
[INFO][08:28:40]: [Server #3995185] Selecting client #89 for training.
[INFO][08:28:40]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][08:28:45]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][08:28:45]: [Client #89] Selected by the server.
[INFO][08:28:45]: [Client #89] Loading its data source...
[INFO][08:28:45]: [Client #89] Dataset size: 2018
[INFO][08:28:45]: [Client #89] Sampler: iid
[INFO][08:28:46]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:28:46]: [Client #89] Start to process inbound data.
[INFO][08:28:46]: [93m[1m[Client #89] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9341713587443032,)
[INFO][08:29:24]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 32.5867, 'train_samples_per_second': 185.781, 'train_steps_per_second': 2.946, 'train_loss': 2.9341713587443032, 'epoch': 3.0}
[INFO][08:29:25]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][08:29:26]: [Client #89] Model trained.
[INFO][08:29:26]: [Client #89] Inbound data has been processed.
[INFO][08:29:26]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][08:29:31]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:29:32]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][08:29:32]: [Server #3995185] Selecting client #85 for training.
[INFO][08:29:32]: [Server #3995185] Sending the current model to client #85 (simulated).
[INFO][08:29:38]: [Server #3995185] Sending 507.38 MB of payload data to client #85 (simulated).
[INFO][08:29:38]: [Client #85] Selected by the server.
[INFO][08:29:38]: [Client #85] Loading its data source...
[INFO][08:29:38]: [Client #85] Dataset size: 2018
[INFO][08:29:38]: [Client #85] Sampler: iid
[INFO][08:29:40]: [Client #85] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:29:40]: [Client #85] Start to process inbound data.
[INFO][08:29:40]: [93m[1m[Client #85] Started training in communication round #28.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:59,  1.89s/it]  2%|â–         | 2/96 [00:02<01:31,  1.03it/s]  3%|â–Ž         | 3/96 [00:02<01:03,  1.47it/s]  4%|â–         | 4/96 [00:02<00:49,  1.85it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.14it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.38it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.55it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.68it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.77it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.84it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.89it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.988887151082357,)
[INFO][08:30:20]: [Client #85] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
{'train_runtime': 33.1051, 'train_samples_per_second': 182.872, 'train_steps_per_second': 2.9, 'train_loss': 2.988887151082357, 'epoch': 3.0}
[INFO][08:30:21]: [Client #85] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
[INFO][08:30:21]: [Client #85] Model trained.
[INFO][08:30:21]: [Client #85] Inbound data has been processed.
[INFO][08:30:21]: [Client #85] Outbound data is ready to be sent after being processed.
[INFO][08:30:26]: [Client #85] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:30:27]: [Server #3995185] Received 507.38 MB of payload data from client #85 (simulated).
[INFO][08:30:27]: [Server #3995185] Adding client #1 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #5 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #37 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #57 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #78 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #151 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #188 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #80 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Adding client #111 to the list of clients for aggregation.
[INFO][08:30:27]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:30:27]: [Server #3995185] Updated weights have been received.
[INFO][08:30:28]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:30:29]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:30:29]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.63it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.30it/s]
[INFO][08:30:39]: [93m[1m[Server #3995185] Global model perplexity: 23.37
[0m
[INFO][08:30:39]: [Server #3995185] All client reports have been processed.
[INFO][08:30:39]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_28.pth.
[INFO][08:30:42]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_28.pth.
[INFO][08:30:42]: [93m[1m
[Server #3995185] Starting round 29/50.[0m
[INFO][08:30:42]: [Server #3995185] Selected clients: [78, 88, 46, 57, 66, 163, 41, 2, 33, 54]
[INFO][08:30:42]: [Server #3995185] Selecting client #78 for training.
[INFO][08:30:42]: [Server #3995185] Sending the current model to client #78 (simulated).
[INFO][08:30:50]: [Server #3995185] Sending 507.38 MB of payload data to client #78 (simulated).
[INFO][08:30:50]: [Client #78] Selected by the server.
[INFO][08:30:50]: [Client #78] Loading its data source...
[INFO][08:30:50]: [Client #78] Dataset size: 2018
[INFO][08:30:50]: [Client #78] Sampler: iid
[INFO][08:30:52]: [Client #78] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:30:52]: [Client #78] Start to process inbound data.
[INFO][08:30:53]: [93m[1m[Client #78] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.48s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.08it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.07it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.06it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.07it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.08it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9586706161499023,)
[INFO][08:31:31]: [Client #78] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3995237.pth.
{'train_runtime': 32.2692, 'train_samples_per_second': 187.609, 'train_steps_per_second': 2.975, 'train_loss': 2.9586706161499023, 'epoch': 3.0}
[INFO][08:31:32]: [Client #78] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_78_3995237.pth.
[INFO][08:31:32]: [Client #78] Model trained.
[INFO][08:31:32]: [Client #78] Inbound data has been processed.
[INFO][08:31:32]: [Client #78] Outbound data is ready to be sent after being processed.
[INFO][08:31:37]: [Client #78] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:31:39]: [Server #3995185] Received 507.38 MB of payload data from client #78 (simulated).
[INFO][08:31:39]: [Server #3995185] Selecting client #88 for training.
[INFO][08:31:39]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][08:31:47]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][08:31:47]: [Client #88] Selected by the server.
[INFO][08:31:47]: [Client #88] Loading its data source...
[INFO][08:31:47]: [Client #88] Dataset size: 2018
[INFO][08:31:47]: [Client #88] Sampler: iid
[INFO][08:31:48]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:31:48]: [Client #88] Start to process inbound data.
[INFO][08:31:49]: [93m[1m[Client #88] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.48s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9863341649373374,)
[INFO][08:32:27]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 32.5505, 'train_samples_per_second': 185.988, 'train_steps_per_second': 2.949, 'train_loss': 2.9863341649373374, 'epoch': 3.0}
[INFO][08:32:28]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][08:32:29]: [Client #88] Model trained.
[INFO][08:32:29]: [Client #88] Inbound data has been processed.
[INFO][08:32:29]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][08:32:34]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:32:35]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][08:32:35]: [Server #3995185] Selecting client #46 for training.
[INFO][08:32:35]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][08:32:46]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][08:32:46]: [Client #46] Selected by the server.
[INFO][08:32:46]: [Client #46] Loading its data source...
[INFO][08:32:46]: [Client #46] Dataset size: 2018
[INFO][08:32:46]: [Client #46] Sampler: iid
[INFO][08:32:47]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:32:47]: [Client #46] Start to process inbound data.
[INFO][08:32:48]: [93m[1m[Client #46] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.79s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9945898056030273,)
[INFO][08:33:27]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.935, 'train_samples_per_second': 183.816, 'train_steps_per_second': 2.915, 'train_loss': 2.9945898056030273, 'epoch': 3.0}
[INFO][08:33:28]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][08:33:29]: [Client #46] Model trained.
[INFO][08:33:29]: [Client #46] Inbound data has been processed.
[INFO][08:33:29]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][08:33:36]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:33:37]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][08:33:37]: [Server #3995185] Selecting client #57 for training.
[INFO][08:33:37]: [Server #3995185] Sending the current model to client #57 (simulated).
[INFO][08:33:46]: [Server #3995185] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][08:33:46]: [Client #57] Selected by the server.
[INFO][08:33:46]: [Client #57] Loading its data source...
[INFO][08:33:46]: [Client #57] Dataset size: 2018
[INFO][08:33:46]: [Client #57] Sampler: iid
[INFO][08:33:47]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:33:47]: [Client #57] Start to process inbound data.
[INFO][08:33:48]: [93m[1m[Client #57] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.72s/it]  2%|â–         | 2/96 [00:02<01:25,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.901484489440918,)
[INFO][08:34:27]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
{'train_runtime': 32.9198, 'train_samples_per_second': 183.902, 'train_steps_per_second': 2.916, 'train_loss': 2.901484489440918, 'epoch': 3.0}
[INFO][08:34:28]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
[INFO][08:34:28]: [Client #57] Model trained.
[INFO][08:34:28]: [Client #57] Inbound data has been processed.
[INFO][08:34:28]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][08:34:34]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:34:35]: [Server #3995185] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][08:34:35]: [Server #3995185] Selecting client #66 for training.
[INFO][08:34:35]: [Server #3995185] Sending the current model to client #66 (simulated).
[INFO][08:34:41]: [Server #3995185] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][08:34:41]: [Client #66] Selected by the server.
[INFO][08:34:41]: [Client #66] Loading its data source...
[INFO][08:34:41]: [Client #66] Dataset size: 2018
[INFO][08:34:41]: [Client #66] Sampler: iid
[INFO][08:34:43]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:34:43]: [Client #66] Start to process inbound data.
[INFO][08:34:43]: [93m[1m[Client #66] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0105056762695312,)
[INFO][08:35:21]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
{'train_runtime': 32.4798, 'train_samples_per_second': 186.393, 'train_steps_per_second': 2.956, 'train_loss': 3.0105056762695312, 'epoch': 3.0}
[INFO][08:35:22]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
[INFO][08:35:22]: [Client #66] Model trained.
[INFO][08:35:22]: [Client #66] Inbound data has been processed.
[INFO][08:35:22]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][08:35:27]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:35:28]: [Server #3995185] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][08:35:28]: [Server #3995185] Selecting client #163 for training.
[INFO][08:35:28]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][08:35:35]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][08:35:35]: [Client #163] Selected by the server.
[INFO][08:35:35]: [Client #163] Loading its data source...
[INFO][08:35:35]: [Client #163] Dataset size: 2018
[INFO][08:35:35]: [Client #163] Sampler: iid
[INFO][08:35:36]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:35:36]: [Client #163] Start to process inbound data.
[INFO][08:35:36]: [93m[1m[Client #163] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.05it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9112771352132163,)
[INFO][08:36:14]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.1011, 'train_samples_per_second': 188.592, 'train_steps_per_second': 2.991, 'train_loss': 2.9112771352132163, 'epoch': 3.0}
[INFO][08:36:15]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][08:36:16]: [Client #163] Model trained.
[INFO][08:36:16]: [Client #163] Inbound data has been processed.
[INFO][08:36:16]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][08:36:22]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:36:23]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][08:36:23]: [Server #3995185] Selecting client #41 for training.
[INFO][08:36:23]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][08:36:29]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][08:36:29]: [Client #41] Selected by the server.
[INFO][08:36:29]: [Client #41] Loading its data source...
[INFO][08:36:29]: [Client #41] Dataset size: 2018
[INFO][08:36:29]: [Client #41] Sampler: iid
[INFO][08:36:30]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:36:30]: [Client #41] Start to process inbound data.
[INFO][08:36:30]: [93m[1m[Client #41] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.09it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.878650347391764,)
[INFO][08:37:08]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.1681, 'train_samples_per_second': 188.199, 'train_steps_per_second': 2.984, 'train_loss': 2.878650347391764, 'epoch': 3.0}
[INFO][08:37:09]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][08:37:10]: [Client #41] Model trained.
[INFO][08:37:10]: [Client #41] Inbound data has been processed.
[INFO][08:37:10]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][08:37:17]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:37:18]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][08:37:18]: [Server #3995185] Selecting client #2 for training.
[INFO][08:37:18]: [Server #3995185] Sending the current model to client #2 (simulated).
[INFO][08:37:26]: [Server #3995185] Sending 507.38 MB of payload data to client #2 (simulated).
[INFO][08:37:26]: [Client #2] Selected by the server.
[INFO][08:37:26]: [Client #2] Loading its data source...
[INFO][08:37:26]: [Client #2] Dataset size: 2018
[INFO][08:37:26]: [Client #2] Sampler: iid
[INFO][08:37:27]: [Client #2] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:37:27]: [Client #2] Start to process inbound data.
[INFO][08:37:27]: [93m[1m[Client #2] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.71s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.91it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.99it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.06it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0161237716674805,)
[INFO][08:38:06]: [Client #2] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3995237.pth.
{'train_runtime': 32.9794, 'train_samples_per_second': 183.569, 'train_steps_per_second': 2.911, 'train_loss': 3.0161237716674805, 'epoch': 3.0}
[INFO][08:38:07]: [Client #2] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_2_3995237.pth.
[INFO][08:38:08]: [Client #2] Model trained.
[INFO][08:38:08]: [Client #2] Inbound data has been processed.
[INFO][08:38:08]: [Client #2] Outbound data is ready to be sent after being processed.
[INFO][08:38:17]: [Client #2] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:38:18]: [Server #3995185] Received 507.38 MB of payload data from client #2 (simulated).
[INFO][08:38:18]: [Server #3995185] Selecting client #33 for training.
[INFO][08:38:18]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][08:38:22]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][08:38:22]: [Client #33] Selected by the server.
[INFO][08:38:22]: [Client #33] Loading its data source...
[INFO][08:38:22]: [Client #33] Dataset size: 2018
[INFO][08:38:22]: [Client #33] Sampler: iid
[INFO][08:38:24]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:38:24]: [Client #33] Start to process inbound data.
[INFO][08:38:24]: [93m[1m[Client #33] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.93308162689209,)
[INFO][08:39:02]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 32.1875, 'train_samples_per_second': 188.085, 'train_steps_per_second': 2.983, 'train_loss': 2.93308162689209, 'epoch': 3.0}
[INFO][08:39:03]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][08:39:04]: [Client #33] Model trained.
[INFO][08:39:04]: [Client #33] Inbound data has been processed.
[INFO][08:39:04]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][08:39:09]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:39:10]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][08:39:10]: [Server #3995185] Selecting client #54 for training.
[INFO][08:39:10]: [Server #3995185] Sending the current model to client #54 (simulated).
[INFO][08:39:17]: [Server #3995185] Sending 507.38 MB of payload data to client #54 (simulated).
[INFO][08:39:17]: [Client #54] Selected by the server.
[INFO][08:39:17]: [Client #54] Loading its data source...
[INFO][08:39:17]: [Client #54] Dataset size: 2018
[INFO][08:39:17]: [Client #54] Sampler: iid
[INFO][08:39:19]: [Client #54] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:39:19]: [Client #54] Start to process inbound data.
[INFO][08:39:19]: [93m[1m[Client #54] Started training in communication round #29.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.12it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.11it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.10it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.04it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.05it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.026137669881185,)
[INFO][08:39:57]: [Client #54] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
{'train_runtime': 32.358, 'train_samples_per_second': 187.095, 'train_steps_per_second': 2.967, 'train_loss': 3.026137669881185, 'epoch': 3.0}
[INFO][08:39:58]: [Client #54] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
[INFO][08:39:59]: [Client #54] Model trained.
[INFO][08:39:59]: [Client #54] Inbound data has been processed.
[INFO][08:39:59]: [Client #54] Outbound data is ready to be sent after being processed.
[INFO][08:40:04]: [Client #54] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:40:05]: [Server #3995185] Received 507.38 MB of payload data from client #54 (simulated).
[INFO][08:40:05]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #17 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #43 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #85 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #132 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #143 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][08:40:05]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:40:05]: [Server #3995185] Updated weights have been received.
[INFO][08:40:07]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:40:07]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:40:07]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.57it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.16it/s]
[INFO][08:40:16]: [93m[1m[Server #3995185] Global model perplexity: 23.15
[0m
[INFO][08:40:16]: [Server #3995185] All client reports have been processed.
[INFO][08:40:16]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_29.pth.
[INFO][08:40:19]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_29.pth.
[INFO][08:40:20]: [93m[1m
[Server #3995185] Starting round 30/50.[0m
[INFO][08:40:20]: [Server #3995185] Selected clients: [14, 71, 45, 164, 200, 61, 115, 143, 37, 10]
[INFO][08:40:20]: [Server #3995185] Selecting client #14 for training.
[INFO][08:40:20]: [Server #3995185] Sending the current model to client #14 (simulated).
[INFO][08:40:26]: [Server #3995185] Sending 507.38 MB of payload data to client #14 (simulated).
[INFO][08:40:26]: [Client #14] Selected by the server.
[INFO][08:40:26]: [Client #14] Loading its data source...
[INFO][08:40:26]: [Client #14] Dataset size: 2018
[INFO][08:40:26]: [Client #14] Sampler: iid
[INFO][08:40:27]: [Client #14] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:40:27]: [Client #14] Start to process inbound data.
[INFO][08:40:27]: [93m[1m[Client #14] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.94560178120931,)
[INFO][08:41:05]: [Client #14] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
{'train_runtime': 32.4177, 'train_samples_per_second': 186.75, 'train_steps_per_second': 2.961, 'train_loss': 2.94560178120931, 'epoch': 3.0}
[INFO][08:41:06]: [Client #14] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
[INFO][08:41:07]: [Client #14] Model trained.
[INFO][08:41:07]: [Client #14] Inbound data has been processed.
[INFO][08:41:07]: [Client #14] Outbound data is ready to be sent after being processed.
[INFO][08:41:12]: [Client #14] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:41:13]: [Server #3995185] Received 507.38 MB of payload data from client #14 (simulated).
[INFO][08:41:13]: [Server #3995185] Selecting client #71 for training.
[INFO][08:41:13]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][08:41:19]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][08:41:19]: [Client #71] Selected by the server.
[INFO][08:41:19]: [Client #71] Loading its data source...
[INFO][08:41:19]: [Client #71] Dataset size: 2018
[INFO][08:41:19]: [Client #71] Sampler: iid
[INFO][08:41:20]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:41:20]: [Client #71] Start to process inbound data.
[INFO][08:41:20]: [93m[1m[Client #71] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:23,  1.51s/it]  2%|â–         | 2/96 [00:01<01:16,  1.22it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.94it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8229344685872397,)
[INFO][08:41:59]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.7889, 'train_samples_per_second': 184.635, 'train_steps_per_second': 2.928, 'train_loss': 2.8229344685872397, 'epoch': 3.0}
[INFO][08:42:00]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][08:42:00]: [Client #71] Model trained.
[INFO][08:42:00]: [Client #71] Inbound data has been processed.
[INFO][08:42:00]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][08:42:06]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:42:07]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][08:42:07]: [Server #3995185] Selecting client #45 for training.
[INFO][08:42:07]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][08:42:12]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][08:42:12]: [Client #45] Selected by the server.
[INFO][08:42:12]: [Client #45] Loading its data source...
[INFO][08:42:12]: [Client #45] Dataset size: 2018
[INFO][08:42:12]: [Client #45] Sampler: iid
[INFO][08:42:13]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:42:13]: [Client #45] Start to process inbound data.
[INFO][08:42:13]: [93m[1m[Client #45] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8181241353352866,)
[INFO][08:42:51]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.1947, 'train_samples_per_second': 188.043, 'train_steps_per_second': 2.982, 'train_loss': 2.8181241353352866, 'epoch': 3.0}
[INFO][08:42:52]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][08:42:52]: [Client #45] Model trained.
[INFO][08:42:52]: [Client #45] Inbound data has been processed.
[INFO][08:42:52]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][08:42:57]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:42:58]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][08:42:58]: [Server #3995185] Selecting client #164 for training.
[INFO][08:42:58]: [Server #3995185] Sending the current model to client #164 (simulated).
[INFO][08:43:03]: [Server #3995185] Sending 507.38 MB of payload data to client #164 (simulated).
[INFO][08:43:03]: [Client #164] Selected by the server.
[INFO][08:43:03]: [Client #164] Loading its data source...
[INFO][08:43:03]: [Client #164] Dataset size: 2018
[INFO][08:43:03]: [Client #164] Sampler: iid
[INFO][08:43:04]: [Client #164] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:43:04]: [Client #164] Start to process inbound data.
[INFO][08:43:04]: [93m[1m[Client #164] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:48,  1.78s/it]  2%|â–         | 2/96 [00:02<01:27,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.52it/s]  4%|â–         | 4/96 [00:02<00:48,  1.89it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.41it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.57it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.70it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.79it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.93it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.95it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.99it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.99it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  2.98it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  2.98it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:24,  2.98it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  2.98it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  2.98it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  2.99it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  2.98it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.98it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.98it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.44it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.09it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.04it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.03it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.98it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (3.0147889455159507,)
[INFO][08:43:43]: [Client #164] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_164_3995237.pth.
{'train_runtime': 33.1268, 'train_samples_per_second': 182.752, 'train_steps_per_second': 2.898, 'train_loss': 3.0147889455159507, 'epoch': 3.0}
[INFO][08:43:44]: [Client #164] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_164_3995237.pth.
[INFO][08:43:45]: [Client #164] Model trained.
[INFO][08:43:45]: [Client #164] Inbound data has been processed.
[INFO][08:43:45]: [Client #164] Outbound data is ready to be sent after being processed.
[INFO][08:43:50]: [Client #164] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:43:51]: [Server #3995185] Received 507.38 MB of payload data from client #164 (simulated).
[INFO][08:43:51]: [Server #3995185] Selecting client #200 for training.
[INFO][08:43:51]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][08:43:56]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][08:43:56]: [Client #200] Selected by the server.
[INFO][08:43:56]: [Client #200] Loading its data source...
[INFO][08:43:56]: [Client #200] Dataset size: 2018
[INFO][08:43:56]: [Client #200] Sampler: iid
[INFO][08:43:57]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:43:57]: [Client #200] Start to process inbound data.
[INFO][08:43:57]: [93m[1m[Client #200] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9962240854899087,)
[INFO][08:44:35]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 32.4773, 'train_samples_per_second': 186.407, 'train_steps_per_second': 2.956, 'train_loss': 2.9962240854899087, 'epoch': 3.0}
[INFO][08:44:36]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][08:44:36]: [Client #200] Model trained.
[INFO][08:44:36]: [Client #200] Inbound data has been processed.
[INFO][08:44:36]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][08:44:41]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:44:42]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][08:44:42]: [Server #3995185] Selecting client #61 for training.
[INFO][08:44:42]: [Server #3995185] Sending the current model to client #61 (simulated).
[INFO][08:44:48]: [Server #3995185] Sending 507.38 MB of payload data to client #61 (simulated).
[INFO][08:44:48]: [Client #61] Selected by the server.
[INFO][08:44:48]: [Client #61] Loading its data source...
[INFO][08:44:48]: [Client #61] Dataset size: 2018
[INFO][08:44:48]: [Client #61] Sampler: iid
[INFO][08:44:49]: [Client #61] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:44:49]: [Client #61] Start to process inbound data.
[INFO][08:44:49]: [93m[1m[Client #61] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:27,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.66it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.00it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.943033218383789,)
[INFO][08:45:28]: [Client #61] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_61_3995237.pth.
{'train_runtime': 32.665, 'train_samples_per_second': 185.336, 'train_steps_per_second': 2.939, 'train_loss': 2.943033218383789, 'epoch': 3.0}
[INFO][08:45:29]: [Client #61] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_61_3995237.pth.
[INFO][08:45:30]: [Client #61] Model trained.
[INFO][08:45:30]: [Client #61] Inbound data has been processed.
[INFO][08:45:30]: [Client #61] Outbound data is ready to be sent after being processed.
[INFO][08:45:35]: [Client #61] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:45:36]: [Server #3995185] Received 507.38 MB of payload data from client #61 (simulated).
[INFO][08:45:36]: [Server #3995185] Selecting client #115 for training.
[INFO][08:45:36]: [Server #3995185] Sending the current model to client #115 (simulated).
[INFO][08:45:40]: [Server #3995185] Sending 507.38 MB of payload data to client #115 (simulated).
[INFO][08:45:40]: [Client #115] Selected by the server.
[INFO][08:45:40]: [Client #115] Loading its data source...
[INFO][08:45:40]: [Client #115] Dataset size: 2018
[INFO][08:45:40]: [Client #115] Sampler: iid
[INFO][08:45:42]: [Client #115] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:45:42]: [Client #115] Start to process inbound data.
[INFO][08:45:42]: [93m[1m[Client #115] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.59s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.63it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.98it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.98it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.97it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.95it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.95it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.96it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.96it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.96it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.95it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.909163157145182,)
[INFO][08:46:20]: [Client #115] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_115_3995237.pth.
{'train_runtime': 32.8301, 'train_samples_per_second': 184.404, 'train_steps_per_second': 2.924, 'train_loss': 2.909163157145182, 'epoch': 3.0}
[INFO][08:46:21]: [Client #115] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_115_3995237.pth.
[INFO][08:46:23]: [Client #115] Model trained.
[INFO][08:46:23]: [Client #115] Inbound data has been processed.
[INFO][08:46:23]: [Client #115] Outbound data is ready to be sent after being processed.
[INFO][08:46:27]: [Client #115] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:46:29]: [Server #3995185] Received 507.38 MB of payload data from client #115 (simulated).
[INFO][08:46:29]: [Server #3995185] Selecting client #143 for training.
[INFO][08:46:29]: [Server #3995185] Sending the current model to client #143 (simulated).
[INFO][08:46:33]: [Server #3995185] Sending 507.38 MB of payload data to client #143 (simulated).
[INFO][08:46:33]: [Client #143] Selected by the server.
[INFO][08:46:33]: [Client #143] Loading its data source...
[INFO][08:46:33]: [Client #143] Dataset size: 2018
[INFO][08:46:33]: [Client #143] Sampler: iid
[INFO][08:46:35]: [Client #143] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:46:35]: [Client #143] Start to process inbound data.
[INFO][08:46:35]: [93m[1m[Client #143] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.59s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.63it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.97it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.96it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.96it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.95it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.96it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8769877751668296,)
[INFO][08:47:14]: [Client #143] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
{'train_runtime': 32.7558, 'train_samples_per_second': 184.822, 'train_steps_per_second': 2.931, 'train_loss': 2.8769877751668296, 'epoch': 3.0}
[INFO][08:47:15]: [Client #143] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
[INFO][08:47:15]: [Client #143] Model trained.
[INFO][08:47:15]: [Client #143] Inbound data has been processed.
[INFO][08:47:15]: [Client #143] Outbound data is ready to be sent after being processed.
[INFO][08:47:21]: [Client #143] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:47:23]: [Server #3995185] Received 507.38 MB of payload data from client #143 (simulated).
[INFO][08:47:23]: [Server #3995185] Selecting client #37 for training.
[INFO][08:47:23]: [Server #3995185] Sending the current model to client #37 (simulated).
[INFO][08:47:27]: [Server #3995185] Sending 507.38 MB of payload data to client #37 (simulated).
[INFO][08:47:27]: [Client #37] Selected by the server.
[INFO][08:47:27]: [Client #37] Loading its data source...
[INFO][08:47:27]: [Client #37] Dataset size: 2018
[INFO][08:47:27]: [Client #37] Sampler: iid
[INFO][08:47:29]: [Client #37] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:47:29]: [Client #37] Start to process inbound data.
[INFO][08:47:29]: [93m[1m[Client #37] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.96it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.29it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.23it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.19it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.15it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:07,  3.14it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.13it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.12it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.12it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.12it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.12it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.12it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.11it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.11it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.11it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.11it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.11it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.11it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.11it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.12it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.12it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9371652603149414,)
[INFO][08:48:07]: [Client #37] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
{'train_runtime': 31.9967, 'train_samples_per_second': 189.207, 'train_steps_per_second': 3.0, 'train_loss': 2.9371652603149414, 'epoch': 3.0}
[INFO][08:48:07]: [Client #37] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
[INFO][08:48:08]: [Client #37] Model trained.
[INFO][08:48:08]: [Client #37] Inbound data has been processed.
[INFO][08:48:08]: [Client #37] Outbound data is ready to be sent after being processed.
[INFO][08:48:13]: [Client #37] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:48:14]: [Server #3995185] Received 507.38 MB of payload data from client #37 (simulated).
[INFO][08:48:14]: [Server #3995185] Selecting client #10 for training.
[INFO][08:48:14]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][08:48:19]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][08:48:19]: [Client #10] Selected by the server.
[INFO][08:48:19]: [Client #10] Loading its data source...
[INFO][08:48:19]: [Client #10] Dataset size: 2018
[INFO][08:48:19]: [Client #10] Sampler: iid
[INFO][08:48:20]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:48:20]: [Client #10] Start to process inbound data.
[INFO][08:48:20]: [93m[1m[Client #10] Started training in communication round #30.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8644307454427085,)
[INFO][08:48:59]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.5836, 'train_samples_per_second': 185.799, 'train_steps_per_second': 2.946, 'train_loss': 2.8644307454427085, 'epoch': 3.0}
[INFO][08:49:00]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][08:49:00]: [Client #10] Model trained.
[INFO][08:49:00]: [Client #10] Inbound data has been processed.
[INFO][08:49:00]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][08:49:05]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:49:06]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][08:49:06]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #54 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #57 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #66 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #78 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #88 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Adding client #2 to the list of clients for aggregation.
[INFO][08:49:06]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:49:06]: [Server #3995185] Updated weights have been received.
[INFO][08:49:08]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:49:09]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:49:09]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.49it/s]
[INFO][08:49:16]: [93m[1m[Server #3995185] Global model perplexity: 22.92
[0m
[INFO][08:49:16]: [Server #3995185] All client reports have been processed.
[INFO][08:49:17]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_30.pth.
[INFO][08:49:21]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_30.pth.
[INFO][08:49:21]: [93m[1m
[Server #3995185] Starting round 31/50.[0m
[INFO][08:49:21]: [Server #3995185] Selected clients: [41, 1, 33, 89, 5, 160, 23, 66, 183, 177]
[INFO][08:49:21]: [Server #3995185] Selecting client #41 for training.
[INFO][08:49:21]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][08:49:26]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][08:49:26]: [Client #41] Selected by the server.
[INFO][08:49:26]: [Client #41] Loading its data source...
[INFO][08:49:26]: [Client #41] Dataset size: 2018
[INFO][08:49:26]: [Client #41] Sampler: iid
[INFO][08:49:27]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:49:27]: [Client #41] Start to process inbound data.
[INFO][08:49:28]: [93m[1m[Client #41] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7950312296549478,)
[INFO][08:50:06]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.4688, 'train_samples_per_second': 186.456, 'train_steps_per_second': 2.957, 'train_loss': 2.7950312296549478, 'epoch': 3.0}
[INFO][08:50:07]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][08:50:08]: [Client #41] Model trained.
[INFO][08:50:08]: [Client #41] Inbound data has been processed.
[INFO][08:50:08]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][08:50:13]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:50:14]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][08:50:14]: [Server #3995185] Selecting client #1 for training.
[INFO][08:50:14]: [Server #3995185] Sending the current model to client #1 (simulated).
[INFO][08:50:19]: [Server #3995185] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][08:50:19]: [Client #1] Selected by the server.
[INFO][08:50:19]: [Client #1] Loading its data source...
[INFO][08:50:19]: [Client #1] Dataset size: 2018
[INFO][08:50:19]: [Client #1] Sampler: iid
[INFO][08:50:20]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:50:20]: [Client #1] Start to process inbound data.
[INFO][08:50:21]: [93m[1m[Client #1] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:37,  1.66s/it]  2%|â–         | 2/96 [00:01<01:22,  1.14it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.60it/s]  4%|â–         | 4/96 [00:02<00:46,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.97it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8770920435587564,)
[INFO][08:51:00]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
{'train_runtime': 32.7122, 'train_samples_per_second': 185.069, 'train_steps_per_second': 2.935, 'train_loss': 2.8770920435587564, 'epoch': 3.0}
[INFO][08:51:01]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
[INFO][08:51:01]: [Client #1] Model trained.
[INFO][08:51:01]: [Client #1] Inbound data has been processed.
[INFO][08:51:01]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][08:51:06]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:51:08]: [Server #3995185] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][08:51:08]: [Server #3995185] Selecting client #33 for training.
[INFO][08:51:08]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][08:51:13]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][08:51:13]: [Client #33] Selected by the server.
[INFO][08:51:13]: [Client #33] Loading its data source...
[INFO][08:51:13]: [Client #33] Dataset size: 2018
[INFO][08:51:13]: [Client #33] Sampler: iid
[INFO][08:51:14]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:51:14]: [Client #33] Start to process inbound data.
[INFO][08:51:15]: [93m[1m[Client #33] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.66it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.76it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.04it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.02it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.00it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.84740416208903,)
[INFO][08:51:53]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 32.7575, 'train_samples_per_second': 184.813, 'train_steps_per_second': 2.931, 'train_loss': 2.84740416208903, 'epoch': 3.0}
[INFO][08:51:54]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][08:51:55]: [Client #33] Model trained.
[INFO][08:51:55]: [Client #33] Inbound data has been processed.
[INFO][08:51:55]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][08:52:00]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:52:01]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][08:52:01]: [Server #3995185] Selecting client #89 for training.
[INFO][08:52:01]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][08:52:06]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][08:52:06]: [Client #89] Selected by the server.
[INFO][08:52:06]: [Client #89] Loading its data source...
[INFO][08:52:06]: [Client #89] Dataset size: 2018
[INFO][08:52:06]: [Client #89] Sampler: iid
[INFO][08:52:07]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:52:07]: [Client #89] Start to process inbound data.
[INFO][08:52:08]: [93m[1m[Client #89] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:36,  1.65s/it]  2%|â–         | 2/96 [00:01<01:21,  1.15it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.99it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.830423355102539,)
[INFO][08:52:46]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 32.5758, 'train_samples_per_second': 185.843, 'train_steps_per_second': 2.947, 'train_loss': 2.830423355102539, 'epoch': 3.0}
[INFO][08:52:47]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][08:52:48]: [Client #89] Model trained.
[INFO][08:52:48]: [Client #89] Inbound data has been processed.
[INFO][08:52:48]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][08:52:53]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:52:54]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][08:52:54]: [Server #3995185] Selecting client #5 for training.
[INFO][08:52:54]: [Server #3995185] Sending the current model to client #5 (simulated).
[INFO][08:53:01]: [Server #3995185] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][08:53:01]: [Client #5] Selected by the server.
[INFO][08:53:01]: [Client #5] Loading its data source...
[INFO][08:53:01]: [Client #5] Dataset size: 2018
[INFO][08:53:01]: [Client #5] Sampler: iid
[INFO][08:53:02]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:53:02]: [Client #5] Start to process inbound data.
[INFO][08:53:02]: [93m[1m[Client #5] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.85957400004069,)
[INFO][08:53:40]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
{'train_runtime': 32.3971, 'train_samples_per_second': 186.869, 'train_steps_per_second': 2.963, 'train_loss': 2.85957400004069, 'epoch': 3.0}
[INFO][08:53:41]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
[INFO][08:53:42]: [Client #5] Model trained.
[INFO][08:53:42]: [Client #5] Inbound data has been processed.
[INFO][08:53:42]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][08:53:49]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:53:50]: [Server #3995185] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][08:53:50]: [Server #3995185] Selecting client #160 for training.
[INFO][08:53:50]: [Server #3995185] Sending the current model to client #160 (simulated).
[INFO][08:53:55]: [Server #3995185] Sending 507.38 MB of payload data to client #160 (simulated).
[INFO][08:53:55]: [Client #160] Selected by the server.
[INFO][08:53:55]: [Client #160] Loading its data source...
[INFO][08:53:55]: [Client #160] Dataset size: 2018
[INFO][08:53:55]: [Client #160] Sampler: iid
[INFO][08:53:56]: [Client #160] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:53:56]: [Client #160] Start to process inbound data.
[INFO][08:53:57]: [93m[1m[Client #160] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.48s/it]  2%|â–         | 2/96 [00:01<01:14,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9826647440592446,)
[INFO][08:54:35]: [Client #160] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_160_3995237.pth.
{'train_runtime': 32.1985, 'train_samples_per_second': 188.021, 'train_steps_per_second': 2.982, 'train_loss': 2.9826647440592446, 'epoch': 3.0}
[INFO][08:54:36]: [Client #160] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_160_3995237.pth.
[INFO][08:54:37]: [Client #160] Model trained.
[INFO][08:54:37]: [Client #160] Inbound data has been processed.
[INFO][08:54:37]: [Client #160] Outbound data is ready to be sent after being processed.
[INFO][08:54:42]: [Client #160] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:54:43]: [Server #3995185] Received 507.38 MB of payload data from client #160 (simulated).
[INFO][08:54:43]: [Server #3995185] Selecting client #23 for training.
[INFO][08:54:43]: [Server #3995185] Sending the current model to client #23 (simulated).
[INFO][08:54:50]: [Server #3995185] Sending 507.38 MB of payload data to client #23 (simulated).
[INFO][08:54:50]: [Client #23] Selected by the server.
[INFO][08:54:50]: [Client #23] Loading its data source...
[INFO][08:54:50]: [Client #23] Dataset size: 2018
[INFO][08:54:50]: [Client #23] Sampler: iid
[INFO][08:54:51]: [Client #23] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:54:51]: [Client #23] Start to process inbound data.
[INFO][08:54:51]: [93m[1m[Client #23] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:11,  1.38s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.930301030476888,)
[INFO][08:55:29]: [Client #23] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
{'train_runtime': 32.2661, 'train_samples_per_second': 187.627, 'train_steps_per_second': 2.975, 'train_loss': 2.930301030476888, 'epoch': 3.0}
[INFO][08:55:30]: [Client #23] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
[INFO][08:55:30]: [Client #23] Model trained.
[INFO][08:55:30]: [Client #23] Inbound data has been processed.
[INFO][08:55:30]: [Client #23] Outbound data is ready to be sent after being processed.
[INFO][08:55:35]: [Client #23] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:55:36]: [Server #3995185] Received 507.38 MB of payload data from client #23 (simulated).
[INFO][08:55:36]: [Server #3995185] Selecting client #66 for training.
[INFO][08:55:36]: [Server #3995185] Sending the current model to client #66 (simulated).
[INFO][08:55:42]: [Server #3995185] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][08:55:42]: [Client #66] Selected by the server.
[INFO][08:55:42]: [Client #66] Loading its data source...
[INFO][08:55:42]: [Client #66] Dataset size: 2018
[INFO][08:55:42]: [Client #66] Sampler: iid
[INFO][08:55:44]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:55:44]: [Client #66] Start to process inbound data.
[INFO][08:55:45]: [93m[1m[Client #66] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:11,  1.38s/it]  2%|â–         | 2/96 [00:01<01:11,  1.32it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.908431053161621,)
[INFO][08:56:23]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
{'train_runtime': 32.4815, 'train_samples_per_second': 186.383, 'train_steps_per_second': 2.956, 'train_loss': 2.908431053161621, 'epoch': 3.0}
[INFO][08:56:23]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
[INFO][08:56:24]: [Client #66] Model trained.
[INFO][08:56:24]: [Client #66] Inbound data has been processed.
[INFO][08:56:24]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][08:56:29]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:56:30]: [Server #3995185] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][08:56:30]: [Server #3995185] Selecting client #183 for training.
[INFO][08:56:30]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][08:56:40]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][08:56:40]: [Client #183] Selected by the server.
[INFO][08:56:40]: [Client #183] Loading its data source...
[INFO][08:56:40]: [Client #183] Dataset size: 2018
[INFO][08:56:40]: [Client #183] Sampler: iid
[INFO][08:56:41]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:56:41]: [Client #183] Start to process inbound data.
[INFO][08:56:42]: [93m[1m[Client #183] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.11it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.12it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.57it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.43it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.34it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.28it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.23it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.21it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:17,  3.18it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.17it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.16it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.12it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8343718846639,)
[INFO][08:57:20]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.2719, 'train_samples_per_second': 187.594, 'train_steps_per_second': 2.975, 'train_loss': 2.8343718846639, 'epoch': 3.0}
[INFO][08:57:20]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][08:57:21]: [Client #183] Model trained.
[INFO][08:57:21]: [Client #183] Inbound data has been processed.
[INFO][08:57:21]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][08:57:28]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:57:29]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][08:57:29]: [Server #3995185] Selecting client #177 for training.
[INFO][08:57:29]: [Server #3995185] Sending the current model to client #177 (simulated).
[INFO][08:57:33]: [Server #3995185] Sending 507.38 MB of payload data to client #177 (simulated).
[INFO][08:57:33]: [Client #177] Selected by the server.
[INFO][08:57:33]: [Client #177] Loading its data source...
[INFO][08:57:33]: [Client #177] Dataset size: 2018
[INFO][08:57:33]: [Client #177] Sampler: iid
[INFO][08:57:34]: [Client #177] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:57:34]: [Client #177] Start to process inbound data.
[INFO][08:57:35]: [93m[1m[Client #177] Started training in communication round #31.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.95121701558431,)
[INFO][08:58:13]: [Client #177] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
{'train_runtime': 32.576, 'train_samples_per_second': 185.843, 'train_steps_per_second': 2.947, 'train_loss': 2.95121701558431, 'epoch': 3.0}
[INFO][08:58:14]: [Client #177] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
[INFO][08:58:15]: [Client #177] Model trained.
[INFO][08:58:15]: [Client #177] Inbound data has been processed.
[INFO][08:58:15]: [Client #177] Outbound data is ready to be sent after being processed.
[INFO][08:58:20]: [Client #177] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:58:21]: [Server #3995185] Received 507.38 MB of payload data from client #177 (simulated).
[INFO][08:58:21]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #14 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #37 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #143 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #61 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #115 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Adding client #164 to the list of clients for aggregation.
[INFO][08:58:21]: [Server #3995185] Aggregating 10 clients in total.
[INFO][08:58:21]: [Server #3995185] Updated weights have been received.
[INFO][08:58:22]: [Server #3995185] Aggregating model weight deltas.
[INFO][08:58:23]: [Server #3995185] Finished aggregating updated weights.
[INFO][08:58:23]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.76it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.38it/s]
[INFO][08:58:30]: [93m[1m[Server #3995185] Global model perplexity: 22.81
[0m
[INFO][08:58:30]: [Server #3995185] All client reports have been processed.
[INFO][08:58:31]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_31.pth.
[INFO][08:58:37]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_31.pth.
[INFO][08:58:37]: [93m[1m
[Server #3995185] Starting round 32/50.[0m
[INFO][08:58:37]: [Server #3995185] Selected clients: [13, 151, 71, 46, 149, 57, 188, 85, 132, 45]
[INFO][08:58:37]: [Server #3995185] Selecting client #13 for training.
[INFO][08:58:37]: [Server #3995185] Sending the current model to client #13 (simulated).
[INFO][08:58:46]: [Server #3995185] Sending 507.38 MB of payload data to client #13 (simulated).
[INFO][08:58:46]: [Client #13] Selected by the server.
[INFO][08:58:46]: [Client #13] Loading its data source...
[INFO][08:58:46]: [Client #13] Dataset size: 2018
[INFO][08:58:46]: [Client #13] Sampler: iid
[INFO][08:58:47]: [Client #13] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:58:47]: [Client #13] Start to process inbound data.
[INFO][08:58:47]: [93m[1m[Client #13] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.62it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.05it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.10it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.11it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.11it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.13it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.13it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.12it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.10it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.10it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.14it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.11it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.792324701944987,)
[INFO][08:59:25]: [Client #13] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
{'train_runtime': 31.9983, 'train_samples_per_second': 189.197, 'train_steps_per_second': 3.0, 'train_loss': 2.792324701944987, 'epoch': 3.0}
[INFO][08:59:25]: [Client #13] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_13_3995237.pth.
[INFO][08:59:26]: [Client #13] Model trained.
[INFO][08:59:26]: [Client #13] Inbound data has been processed.
[INFO][08:59:26]: [Client #13] Outbound data is ready to be sent after being processed.
[INFO][08:59:33]: [Client #13] Sent 507.38 MB of payload data to the server (simulated).
[INFO][08:59:34]: [Server #3995185] Received 507.38 MB of payload data from client #13 (simulated).
[INFO][08:59:34]: [Server #3995185] Selecting client #151 for training.
[INFO][08:59:34]: [Server #3995185] Sending the current model to client #151 (simulated).
[INFO][08:59:42]: [Server #3995185] Sending 507.38 MB of payload data to client #151 (simulated).
[INFO][08:59:42]: [Client #151] Selected by the server.
[INFO][08:59:42]: [Client #151] Loading its data source...
[INFO][08:59:42]: [Client #151] Dataset size: 2018
[INFO][08:59:42]: [Client #151] Sampler: iid
[INFO][08:59:43]: [Client #151] Received 507.38 MB of payload data from the server (simulated).
[INFO][08:59:43]: [Client #151] Start to process inbound data.
[INFO][08:59:44]: [93m[1m[Client #151] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.10it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.09it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.10it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.08it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.09it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.95it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.851323127746582,)
[INFO][09:00:22]: [Client #151] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
{'train_runtime': 32.0569, 'train_samples_per_second': 188.852, 'train_steps_per_second': 2.995, 'train_loss': 2.851323127746582, 'epoch': 3.0}
[INFO][09:00:22]: [Client #151] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
[INFO][09:00:23]: [Client #151] Model trained.
[INFO][09:00:23]: [Client #151] Inbound data has been processed.
[INFO][09:00:23]: [Client #151] Outbound data is ready to be sent after being processed.
[INFO][09:00:32]: [Client #151] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:00:33]: [Server #3995185] Received 507.38 MB of payload data from client #151 (simulated).
[INFO][09:00:33]: [Server #3995185] Selecting client #71 for training.
[INFO][09:00:33]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][09:00:39]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][09:00:39]: [Client #71] Selected by the server.
[INFO][09:00:39]: [Client #71] Loading its data source...
[INFO][09:00:39]: [Client #71] Dataset size: 2018
[INFO][09:00:39]: [Client #71] Sampler: iid
[INFO][09:00:40]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:00:40]: [Client #71] Start to process inbound data.
[INFO][09:00:40]: [93m[1m[Client #71] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7287317911783853,)
[INFO][09:01:18]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.2043, 'train_samples_per_second': 187.987, 'train_steps_per_second': 2.981, 'train_loss': 2.7287317911783853, 'epoch': 3.0}
[INFO][09:01:18]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][09:01:20]: [Client #71] Model trained.
[INFO][09:01:20]: [Client #71] Inbound data has been processed.
[INFO][09:01:20]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][09:01:27]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:01:28]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][09:01:28]: [Server #3995185] Selecting client #46 for training.
[INFO][09:01:28]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][09:01:34]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][09:01:34]: [Client #46] Selected by the server.
[INFO][09:01:34]: [Client #46] Loading its data source...
[INFO][09:01:34]: [Client #46] Dataset size: 2018
[INFO][09:01:34]: [Client #46] Sampler: iid
[INFO][09:01:35]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:01:35]: [Client #46] Start to process inbound data.
[INFO][09:01:36]: [93m[1m[Client #46] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9145094553629556,)
[INFO][09:02:14]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.3894, 'train_samples_per_second': 186.913, 'train_steps_per_second': 2.964, 'train_loss': 2.9145094553629556, 'epoch': 3.0}
[INFO][09:02:15]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][09:02:16]: [Client #46] Model trained.
[INFO][09:02:16]: [Client #46] Inbound data has been processed.
[INFO][09:02:16]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][09:02:22]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:02:23]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][09:02:23]: [Server #3995185] Selecting client #149 for training.
[INFO][09:02:23]: [Server #3995185] Sending the current model to client #149 (simulated).
[INFO][09:02:28]: [Server #3995185] Sending 507.38 MB of payload data to client #149 (simulated).
[INFO][09:02:28]: [Client #149] Selected by the server.
[INFO][09:02:28]: [Client #149] Loading its data source...
[INFO][09:02:28]: [Client #149] Dataset size: 2018
[INFO][09:02:28]: [Client #149] Sampler: iid
[INFO][09:02:29]: [Client #149] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:02:29]: [Client #149] Start to process inbound data.
[INFO][09:02:29]: [93m[1m[Client #149] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.870014508565267,)
[INFO][09:03:07]: [Client #149] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
{'train_runtime': 32.5106, 'train_samples_per_second': 186.216, 'train_steps_per_second': 2.953, 'train_loss': 2.870014508565267, 'epoch': 3.0}
[INFO][09:03:08]: [Client #149] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
[INFO][09:03:09]: [Client #149] Model trained.
[INFO][09:03:09]: [Client #149] Inbound data has been processed.
[INFO][09:03:09]: [Client #149] Outbound data is ready to be sent after being processed.
[INFO][09:03:14]: [Client #149] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:03:15]: [Server #3995185] Received 507.38 MB of payload data from client #149 (simulated).
[INFO][09:03:15]: [Server #3995185] Selecting client #57 for training.
[INFO][09:03:15]: [Server #3995185] Sending the current model to client #57 (simulated).
[INFO][09:03:20]: [Server #3995185] Sending 507.38 MB of payload data to client #57 (simulated).
[INFO][09:03:20]: [Client #57] Selected by the server.
[INFO][09:03:20]: [Client #57] Loading its data source...
[INFO][09:03:20]: [Client #57] Dataset size: 2018
[INFO][09:03:20]: [Client #57] Sampler: iid
[INFO][09:03:21]: [Client #57] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:03:21]: [Client #57] Start to process inbound data.
[INFO][09:03:21]: [93m[1m[Client #57] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8375574747721353,)
[INFO][09:03:59]: [Client #57] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
{'train_runtime': 32.3389, 'train_samples_per_second': 187.205, 'train_steps_per_second': 2.969, 'train_loss': 2.8375574747721353, 'epoch': 3.0}
[INFO][09:04:00]: [Client #57] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_57_3995237.pth.
[INFO][09:04:00]: [Client #57] Model trained.
[INFO][09:04:00]: [Client #57] Inbound data has been processed.
[INFO][09:04:00]: [Client #57] Outbound data is ready to be sent after being processed.
[INFO][09:04:05]: [Client #57] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:04:06]: [Server #3995185] Received 507.38 MB of payload data from client #57 (simulated).
[INFO][09:04:06]: [Server #3995185] Selecting client #188 for training.
[INFO][09:04:06]: [Server #3995185] Sending the current model to client #188 (simulated).
[INFO][09:04:11]: [Server #3995185] Sending 507.38 MB of payload data to client #188 (simulated).
[INFO][09:04:11]: [Client #188] Selected by the server.
[INFO][09:04:11]: [Client #188] Loading its data source...
[INFO][09:04:11]: [Client #188] Dataset size: 2018
[INFO][09:04:11]: [Client #188] Sampler: iid
[INFO][09:04:12]: [Client #188] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:04:12]: [Client #188] Start to process inbound data.
[INFO][09:04:12]: [93m[1m[Client #188] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:33,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.16it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  1.97it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.988372484842936,)
[INFO][09:04:51]: [Client #188] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
{'train_runtime': 32.7536, 'train_samples_per_second': 184.835, 'train_steps_per_second': 2.931, 'train_loss': 2.988372484842936, 'epoch': 3.0}
[INFO][09:04:52]: [Client #188] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
[INFO][09:04:53]: [Client #188] Model trained.
[INFO][09:04:53]: [Client #188] Inbound data has been processed.
[INFO][09:04:53]: [Client #188] Outbound data is ready to be sent after being processed.
[INFO][09:04:58]: [Client #188] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:04:59]: [Server #3995185] Received 507.38 MB of payload data from client #188 (simulated).
[INFO][09:04:59]: [Server #3995185] Selecting client #85 for training.
[INFO][09:04:59]: [Server #3995185] Sending the current model to client #85 (simulated).
[INFO][09:05:04]: [Server #3995185] Sending 507.38 MB of payload data to client #85 (simulated).
[INFO][09:05:04]: [Client #85] Selected by the server.
[INFO][09:05:04]: [Client #85] Loading its data source...
[INFO][09:05:04]: [Client #85] Dataset size: 2018
[INFO][09:05:04]: [Client #85] Sampler: iid
[INFO][09:05:05]: [Client #85] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:05:05]: [Client #85] Start to process inbound data.
[INFO][09:05:05]: [93m[1m[Client #85] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.08it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.08it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.09it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.09it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.09it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.09it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.09it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.09it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.09it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.09it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.54it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8432223002115884,)
[INFO][09:05:44]: [Client #85] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
{'train_runtime': 32.1577, 'train_samples_per_second': 188.26, 'train_steps_per_second': 2.985, 'train_loss': 2.8432223002115884, 'epoch': 3.0}
[INFO][09:05:44]: [Client #85] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
[INFO][09:05:45]: [Client #85] Model trained.
[INFO][09:05:45]: [Client #85] Inbound data has been processed.
[INFO][09:05:45]: [Client #85] Outbound data is ready to be sent after being processed.
[INFO][09:05:53]: [Client #85] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:05:54]: [Server #3995185] Received 507.38 MB of payload data from client #85 (simulated).
[INFO][09:05:54]: [Server #3995185] Selecting client #132 for training.
[INFO][09:05:54]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][09:06:02]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][09:06:02]: [Client #132] Selected by the server.
[INFO][09:06:02]: [Client #132] Loading its data source...
[INFO][09:06:02]: [Client #132] Dataset size: 2018
[INFO][09:06:02]: [Client #132] Sampler: iid
[INFO][09:06:03]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:06:03]: [Client #132] Start to process inbound data.
[INFO][09:06:03]: [93m[1m[Client #132] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.882383664449056,)
[INFO][09:06:41]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 32.3632, 'train_samples_per_second': 187.064, 'train_steps_per_second': 2.966, 'train_loss': 2.882383664449056, 'epoch': 3.0}
[INFO][09:06:42]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][09:06:43]: [Client #132] Model trained.
[INFO][09:06:43]: [Client #132] Inbound data has been processed.
[INFO][09:06:43]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][09:06:49]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:06:50]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][09:06:50]: [Server #3995185] Selecting client #45 for training.
[INFO][09:06:50]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][09:06:56]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][09:06:56]: [Client #45] Selected by the server.
[INFO][09:06:56]: [Client #45] Loading its data source...
[INFO][09:06:56]: [Client #45] Dataset size: 2018
[INFO][09:06:56]: [Client #45] Sampler: iid
[INFO][09:06:57]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:06:57]: [Client #45] Start to process inbound data.
[INFO][09:06:58]: [93m[1m[Client #45] Started training in communication round #32.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.09it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.722810427347819,)
[INFO][09:07:36]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.2444, 'train_samples_per_second': 187.754, 'train_steps_per_second': 2.977, 'train_loss': 2.722810427347819, 'epoch': 3.0}
[INFO][09:07:37]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][09:07:37]: [Client #45] Model trained.
[INFO][09:07:37]: [Client #45] Inbound data has been processed.
[INFO][09:07:37]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][09:07:45]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:07:46]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][09:07:46]: [Server #3995185] Adding client #1 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #5 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #23 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #66 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #177 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Adding client #160 to the list of clients for aggregation.
[INFO][09:07:46]: [Server #3995185] Aggregating 10 clients in total.
[INFO][09:07:46]: [Server #3995185] Updated weights have been received.
[INFO][09:07:47]: [Server #3995185] Aggregating model weight deltas.
[INFO][09:07:48]: [Server #3995185] Finished aggregating updated weights.
[INFO][09:07:48]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.82it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.40it/s]
[INFO][09:07:56]: [93m[1m[Server #3995185] Global model perplexity: 22.75
[0m
[INFO][09:07:56]: [Server #3995185] All client reports have been processed.
[INFO][09:07:56]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_32.pth.
[INFO][09:08:00]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_32.pth.
[INFO][09:08:00]: [93m[1m
[Server #3995185] Starting round 33/50.[0m
[INFO][09:08:00]: [Server #3995185] Selected clients: [88, 54, 1, 77, 10, 193, 27, 177, 163, 41]
[INFO][09:08:00]: [Server #3995185] Selecting client #88 for training.
[INFO][09:08:00]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][09:08:05]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][09:08:05]: [Client #88] Selected by the server.
[INFO][09:08:05]: [Client #88] Loading its data source...
[INFO][09:08:05]: [Client #88] Dataset size: 2018
[INFO][09:08:05]: [Client #88] Sampler: iid
[INFO][09:08:06]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:08:06]: [Client #88] Start to process inbound data.
[INFO][09:08:06]: [93m[1m[Client #88] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.10it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.11it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.12it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.12it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.14it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.14it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.14it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.14it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.15it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.15it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.15it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.15it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.60it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:08,  3.45it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:08,  3.35it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.28it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.23it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.17it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.16it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.15it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.14it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.14it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.13it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.13it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.13it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.12it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.12it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.12it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.55it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.04it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.875659942626953,)
[INFO][09:08:43]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 31.6124, 'train_samples_per_second': 191.507, 'train_steps_per_second': 3.037, 'train_loss': 2.875659942626953, 'epoch': 3.0}
[INFO][09:08:44]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][09:08:45]: [Client #88] Model trained.
[INFO][09:08:45]: [Client #88] Inbound data has been processed.
[INFO][09:08:45]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][09:08:50]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:08:51]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][09:08:51]: [Server #3995185] Selecting client #54 for training.
[INFO][09:08:51]: [Server #3995185] Sending the current model to client #54 (simulated).
[INFO][09:08:56]: [Server #3995185] Sending 507.38 MB of payload data to client #54 (simulated).
[INFO][09:08:56]: [Client #54] Selected by the server.
[INFO][09:08:56]: [Client #54] Loading its data source...
[INFO][09:08:56]: [Client #54] Dataset size: 2018
[INFO][09:08:56]: [Client #54] Sampler: iid
[INFO][09:08:57]: [Client #54] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:08:57]: [Client #54] Start to process inbound data.
[INFO][09:08:58]: [93m[1m[Client #54] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.915957768758138,)
[INFO][09:09:36]: [Client #54] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
{'train_runtime': 32.3211, 'train_samples_per_second': 187.308, 'train_steps_per_second': 2.97, 'train_loss': 2.915957768758138, 'epoch': 3.0}
[INFO][09:09:37]: [Client #54] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
[INFO][09:09:37]: [Client #54] Model trained.
[INFO][09:09:37]: [Client #54] Inbound data has been processed.
[INFO][09:09:37]: [Client #54] Outbound data is ready to be sent after being processed.
[INFO][09:09:43]: [Client #54] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:09:44]: [Server #3995185] Received 507.38 MB of payload data from client #54 (simulated).
[INFO][09:09:44]: [Server #3995185] Selecting client #1 for training.
[INFO][09:09:44]: [Server #3995185] Sending the current model to client #1 (simulated).
[INFO][09:09:49]: [Server #3995185] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][09:09:49]: [Client #1] Selected by the server.
[INFO][09:09:49]: [Client #1] Loading its data source...
[INFO][09:09:49]: [Client #1] Dataset size: 2018
[INFO][09:09:49]: [Client #1] Sampler: iid
[INFO][09:09:50]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:09:50]: [Client #1] Start to process inbound data.
[INFO][09:09:50]: [93m[1m[Client #1] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7689689000447593,)
[INFO][09:10:28]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
{'train_runtime': 32.3197, 'train_samples_per_second': 187.316, 'train_steps_per_second': 2.97, 'train_loss': 2.7689689000447593, 'epoch': 3.0}
[INFO][09:10:29]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
[INFO][09:10:30]: [Client #1] Model trained.
[INFO][09:10:30]: [Client #1] Inbound data has been processed.
[INFO][09:10:30]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][09:10:35]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:10:37]: [Server #3995185] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][09:10:37]: [Server #3995185] Selecting client #77 for training.
[INFO][09:10:37]: [Server #3995185] Sending the current model to client #77 (simulated).
[INFO][09:10:42]: [Server #3995185] Sending 507.38 MB of payload data to client #77 (simulated).
[INFO][09:10:42]: [Client #77] Selected by the server.
[INFO][09:10:42]: [Client #77] Loading its data source...
[INFO][09:10:42]: [Client #77] Dataset size: 2018
[INFO][09:10:42]: [Client #77] Sampler: iid
[INFO][09:10:43]: [Client #77] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:10:43]: [Client #77] Start to process inbound data.
[INFO][09:10:43]: [93m[1m[Client #77] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:37,  1.66s/it]  2%|â–         | 2/96 [00:01<01:22,  1.14it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.59it/s]  4%|â–         | 4/96 [00:02<00:46,  1.98it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.96it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8918161392211914,)
[INFO][09:11:21]: [Client #77] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_77_3995237.pth.
{'train_runtime': 32.6893, 'train_samples_per_second': 185.198, 'train_steps_per_second': 2.937, 'train_loss': 2.8918161392211914, 'epoch': 3.0}
[INFO][09:11:22]: [Client #77] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_77_3995237.pth.
[INFO][09:11:23]: [Client #77] Model trained.
[INFO][09:11:23]: [Client #77] Inbound data has been processed.
[INFO][09:11:23]: [Client #77] Outbound data is ready to be sent after being processed.
[INFO][09:11:29]: [Client #77] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:11:30]: [Server #3995185] Received 507.38 MB of payload data from client #77 (simulated).
[INFO][09:11:30]: [Server #3995185] Selecting client #10 for training.
[INFO][09:11:30]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][09:11:35]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][09:11:35]: [Client #10] Selected by the server.
[INFO][09:11:35]: [Client #10] Loading its data source...
[INFO][09:11:35]: [Client #10] Dataset size: 2018
[INFO][09:11:35]: [Client #10] Sampler: iid
[INFO][09:11:36]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:11:36]: [Client #10] Start to process inbound data.
[INFO][09:11:37]: [93m[1m[Client #10] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.61it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.75it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.02it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.05it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.10it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.11it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.11it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.11it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.11it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.08it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.08it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.54it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.05it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9601869583129883,)
[INFO][09:12:15]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.0054, 'train_samples_per_second': 189.156, 'train_steps_per_second': 2.999, 'train_loss': 2.9601869583129883, 'epoch': 3.0}
[INFO][09:12:15]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][09:12:17]: [Client #10] Model trained.
[INFO][09:12:17]: [Client #10] Inbound data has been processed.
[INFO][09:12:17]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][09:12:22]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:12:23]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][09:12:23]: [Server #3995185] Selecting client #193 for training.
[INFO][09:12:23]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][09:12:28]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][09:12:28]: [Client #193] Selected by the server.
[INFO][09:12:28]: [Client #193] Loading its data source...
[INFO][09:12:28]: [Client #193] Dataset size: 2018
[INFO][09:12:28]: [Client #193] Sampler: iid
[INFO][09:12:29]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:12:29]: [Client #193] Start to process inbound data.
[INFO][09:12:30]: [93m[1m[Client #193] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.847848892211914,)
[INFO][09:13:08]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 32.5198, 'train_samples_per_second': 186.164, 'train_steps_per_second': 2.952, 'train_loss': 2.847848892211914, 'epoch': 3.0}
[INFO][09:13:09]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][09:13:10]: [Client #193] Model trained.
[INFO][09:13:10]: [Client #193] Inbound data has been processed.
[INFO][09:13:10]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][09:13:15]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:13:16]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][09:13:16]: [Server #3995185] Selecting client #27 for training.
[INFO][09:13:16]: [Server #3995185] Sending the current model to client #27 (simulated).
[INFO][09:13:21]: [Server #3995185] Sending 507.38 MB of payload data to client #27 (simulated).
[INFO][09:13:21]: [Client #27] Selected by the server.
[INFO][09:13:21]: [Client #27] Loading its data source...
[INFO][09:13:21]: [Client #27] Dataset size: 2018
[INFO][09:13:21]: [Client #27] Sampler: iid
[INFO][09:13:23]: [Client #27] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:13:23]: [Client #27] Start to process inbound data.
[INFO][09:13:23]: [93m[1m[Client #27] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:27,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.66it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.00it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.98it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.97it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.11it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.07it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.01it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.96it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.96it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.96it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.889972686767578,)
[INFO][09:14:01]: [Client #27] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_27_3995237.pth.
{'train_runtime': 32.7742, 'train_samples_per_second': 184.719, 'train_steps_per_second': 2.929, 'train_loss': 2.889972686767578, 'epoch': 3.0}
[INFO][09:14:02]: [Client #27] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_27_3995237.pth.
[INFO][09:14:03]: [Client #27] Model trained.
[INFO][09:14:03]: [Client #27] Inbound data has been processed.
[INFO][09:14:03]: [Client #27] Outbound data is ready to be sent after being processed.
[INFO][09:14:10]: [Client #27] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:14:11]: [Server #3995185] Received 507.38 MB of payload data from client #27 (simulated).
[INFO][09:14:11]: [Server #3995185] Selecting client #177 for training.
[INFO][09:14:11]: [Server #3995185] Sending the current model to client #177 (simulated).
[INFO][09:14:16]: [Server #3995185] Sending 507.38 MB of payload data to client #177 (simulated).
[INFO][09:14:16]: [Client #177] Selected by the server.
[INFO][09:14:16]: [Client #177] Loading its data source...
[INFO][09:14:16]: [Client #177] Dataset size: 2018
[INFO][09:14:16]: [Client #177] Sampler: iid
[INFO][09:14:17]: [Client #177] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:14:17]: [Client #177] Start to process inbound data.
[INFO][09:14:17]: [93m[1m[Client #177] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:31,  1.60s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.63it/s]  4%|â–         | 4/96 [00:02<00:45,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.838024457295736,)
[INFO][09:14:56]: [Client #177] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
{'train_runtime': 32.5483, 'train_samples_per_second': 186.0, 'train_steps_per_second': 2.949, 'train_loss': 2.838024457295736, 'epoch': 3.0}
[INFO][09:14:57]: [Client #177] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
[INFO][09:14:57]: [Client #177] Model trained.
[INFO][09:14:57]: [Client #177] Inbound data has been processed.
[INFO][09:14:57]: [Client #177] Outbound data is ready to be sent after being processed.
[INFO][09:15:03]: [Client #177] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:15:04]: [Server #3995185] Received 507.38 MB of payload data from client #177 (simulated).
[INFO][09:15:04]: [Server #3995185] Selecting client #163 for training.
[INFO][09:15:04]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][09:15:09]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][09:15:09]: [Client #163] Selected by the server.
[INFO][09:15:09]: [Client #163] Loading its data source...
[INFO][09:15:09]: [Client #163] Dataset size: 2018
[INFO][09:15:09]: [Client #163] Sampler: iid
[INFO][09:15:10]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:15:10]: [Client #163] Start to process inbound data.
[INFO][09:15:10]: [93m[1m[Client #163] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:27,  1.55s/it]  2%|â–         | 2/96 [00:01<01:18,  1.20it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.66it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.00it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  2.99it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  2.99it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.02it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.782870610555013,)
[INFO][09:15:49]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.7332, 'train_samples_per_second': 184.95, 'train_steps_per_second': 2.933, 'train_loss': 2.782870610555013, 'epoch': 3.0}
[INFO][09:15:49]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][09:15:50]: [Client #163] Model trained.
[INFO][09:15:50]: [Client #163] Inbound data has been processed.
[INFO][09:15:50]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][09:15:55]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:15:56]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][09:15:56]: [Server #3995185] Selecting client #41 for training.
[INFO][09:15:56]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][09:16:01]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][09:16:01]: [Client #41] Selected by the server.
[INFO][09:16:01]: [Client #41] Loading its data source...
[INFO][09:16:01]: [Client #41] Dataset size: 2018
[INFO][09:16:01]: [Client #41] Sampler: iid
[INFO][09:16:02]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:16:02]: [Client #41] Start to process inbound data.
[INFO][09:16:02]: [93m[1m[Client #41] Started training in communication round #33.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:28,  1.56s/it]  2%|â–         | 2/96 [00:01<01:19,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.97it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.98it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.99it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.98it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.96it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:13,  2.97it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.96it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  2.96it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.96it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.96it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.26it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.16it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.10it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.05it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.02it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.00it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6896015803019204,)
[INFO][09:16:41]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.8801, 'train_samples_per_second': 184.123, 'train_steps_per_second': 2.92, 'train_loss': 2.6896015803019204, 'epoch': 3.0}
[INFO][09:16:42]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][09:16:42]: [Client #41] Model trained.
[INFO][09:16:42]: [Client #41] Inbound data has been processed.
[INFO][09:16:42]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][09:16:47]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:16:48]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][09:16:48]: [Server #3995185] Adding client #13 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #57 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #85 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #132 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #149 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #151 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Adding client #188 to the list of clients for aggregation.
[INFO][09:16:48]: [Server #3995185] Aggregating 10 clients in total.
[INFO][09:16:48]: [Server #3995185] Updated weights have been received.
[INFO][09:16:49]: [Server #3995185] Aggregating model weight deltas.
[INFO][09:16:50]: [Server #3995185] Finished aggregating updated weights.
[INFO][09:16:50]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.41it/s]
[INFO][09:16:58]: [93m[1m[Server #3995185] Global model perplexity: 22.81
[0m
[INFO][09:16:58]: [Server #3995185] All client reports have been processed.
[INFO][09:16:58]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_33.pth.
[INFO][09:17:02]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_33.pth.
[INFO][09:17:02]: [93m[1m
[Server #3995185] Starting round 34/50.[0m
[INFO][09:17:02]: [Server #3995185] Selected clients: [33, 46, 9, 23, 81, 45, 132, 66, 188, 53]
[INFO][09:17:02]: [Server #3995185] Selecting client #33 for training.
[INFO][09:17:02]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][09:17:06]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][09:17:06]: [Client #33] Selected by the server.
[INFO][09:17:06]: [Client #33] Loading its data source...
[INFO][09:17:06]: [Client #33] Dataset size: 2018
[INFO][09:17:06]: [Client #33] Sampler: iid
[INFO][09:17:08]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:17:08]: [Client #33] Start to process inbound data.
[INFO][09:17:08]: [93m[1m[Client #33] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.71s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.44it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.80it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.86it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.96it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.82893435160319,)
[INFO][09:17:47]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 32.8209, 'train_samples_per_second': 184.456, 'train_steps_per_second': 2.925, 'train_loss': 2.82893435160319, 'epoch': 3.0}
[INFO][09:17:48]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][09:17:49]: [Client #33] Model trained.
[INFO][09:17:49]: [Client #33] Inbound data has been processed.
[INFO][09:17:49]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][09:17:53]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:17:54]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][09:17:54]: [Server #3995185] Selecting client #46 for training.
[INFO][09:17:54]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][09:17:59]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][09:17:59]: [Client #46] Selected by the server.
[INFO][09:17:59]: [Client #46] Loading its data source...
[INFO][09:17:59]: [Client #46] Dataset size: 2018
[INFO][09:17:59]: [Client #46] Sampler: iid
[INFO][09:18:00]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:18:00]: [Client #46] Start to process inbound data.
[INFO][09:18:01]: [93m[1m[Client #46] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.00it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.46it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.20it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.01it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.00it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  2.99it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:17,  2.99it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  2.99it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  2.98it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.98it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.98it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.97it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.97it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.97it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.98it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.98it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.97it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.98it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.44it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.97it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.96it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.97it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.96it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.835209846496582,)
[INFO][09:18:40]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.6777, 'train_samples_per_second': 185.264, 'train_steps_per_second': 2.938, 'train_loss': 2.835209846496582, 'epoch': 3.0}
[INFO][09:18:41]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][09:18:41]: [Client #46] Model trained.
[INFO][09:18:41]: [Client #46] Inbound data has been processed.
[INFO][09:18:41]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][09:18:46]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:18:47]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][09:18:47]: [Server #3995185] Selecting client #9 for training.
[INFO][09:18:47]: [Server #3995185] Sending the current model to client #9 (simulated).
[INFO][09:18:52]: [Server #3995185] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][09:18:52]: [Client #9] Selected by the server.
[INFO][09:18:52]: [Client #9] Loading its data source...
[INFO][09:18:52]: [Client #9] Dataset size: 2018
[INFO][09:18:52]: [Client #9] Sampler: iid
[INFO][09:18:53]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:18:53]: [Client #9] Start to process inbound data.
[INFO][09:18:53]: [93m[1m[Client #9] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.19it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.12it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.02it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.00it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.98it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.97it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.97it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.94it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.95it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.94it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.94it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.93it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.93it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.94it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.94it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.94it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.94it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.94it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.95it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.94it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.94it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.93it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.94it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7677125930786133,)
[INFO][09:19:32]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
{'train_runtime': 32.7412, 'train_samples_per_second': 184.905, 'train_steps_per_second': 2.932, 'train_loss': 2.7677125930786133, 'epoch': 3.0}
[INFO][09:19:33]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
[INFO][09:19:33]: [Client #9] Model trained.
[INFO][09:19:33]: [Client #9] Inbound data has been processed.
[INFO][09:19:33]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][09:19:39]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:19:40]: [Server #3995185] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][09:19:40]: [Server #3995185] Selecting client #23 for training.
[INFO][09:19:40]: [Server #3995185] Sending the current model to client #23 (simulated).
[INFO][09:19:45]: [Server #3995185] Sending 507.38 MB of payload data to client #23 (simulated).
[INFO][09:19:45]: [Client #23] Selected by the server.
[INFO][09:19:45]: [Client #23] Loading its data source...
[INFO][09:19:45]: [Client #23] Dataset size: 2018
[INFO][09:19:45]: [Client #23] Sampler: iid
[INFO][09:19:47]: [Client #23] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:19:47]: [Client #23] Start to process inbound data.
[INFO][09:19:47]: [93m[1m[Client #23] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.32it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.829679807027181,)
[INFO][09:20:25]: [Client #23] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
{'train_runtime': 32.6064, 'train_samples_per_second': 185.669, 'train_steps_per_second': 2.944, 'train_loss': 2.829679807027181, 'epoch': 3.0}
[INFO][09:20:26]: [Client #23] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_23_3995237.pth.
[INFO][09:20:27]: [Client #23] Model trained.
[INFO][09:20:27]: [Client #23] Inbound data has been processed.
[INFO][09:20:27]: [Client #23] Outbound data is ready to be sent after being processed.
[INFO][09:20:32]: [Client #23] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:20:33]: [Server #3995185] Received 507.38 MB of payload data from client #23 (simulated).
[INFO][09:20:33]: [Server #3995185] Selecting client #81 for training.
[INFO][09:20:33]: [Server #3995185] Sending the current model to client #81 (simulated).
[INFO][09:20:38]: [Server #3995185] Sending 507.38 MB of payload data to client #81 (simulated).
[INFO][09:20:38]: [Client #81] Selected by the server.
[INFO][09:20:38]: [Client #81] Loading its data source...
[INFO][09:20:38]: [Client #81] Dataset size: 2018
[INFO][09:20:38]: [Client #81] Sampler: iid
[INFO][09:20:39]: [Client #81] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:20:39]: [Client #81] Start to process inbound data.
[INFO][09:20:39]: [93m[1m[Client #81] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.97it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.98it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.854327837626139,)
[INFO][09:21:17]: [Client #81] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_81_3995237.pth.
{'train_runtime': 32.5694, 'train_samples_per_second': 185.88, 'train_steps_per_second': 2.948, 'train_loss': 2.854327837626139, 'epoch': 3.0}
[INFO][09:21:18]: [Client #81] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_81_3995237.pth.
[INFO][09:21:19]: [Client #81] Model trained.
[INFO][09:21:19]: [Client #81] Inbound data has been processed.
[INFO][09:21:19]: [Client #81] Outbound data is ready to be sent after being processed.
[INFO][09:21:24]: [Client #81] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:21:25]: [Server #3995185] Received 507.38 MB of payload data from client #81 (simulated).
[INFO][09:21:25]: [Server #3995185] Selecting client #45 for training.
[INFO][09:21:25]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][09:21:30]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][09:21:30]: [Client #45] Selected by the server.
[INFO][09:21:30]: [Client #45] Loading its data source...
[INFO][09:21:30]: [Client #45] Dataset size: 2018
[INFO][09:21:30]: [Client #45] Sampler: iid
[INFO][09:21:31]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:21:31]: [Client #45] Start to process inbound data.
[INFO][09:21:31]: [93m[1m[Client #45] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:44,  1.73s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.56it/s]  4%|â–         | 4/96 [00:02<00:47,  1.93it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.61it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6251134872436523,)
[INFO][09:22:10]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.8416, 'train_samples_per_second': 184.339, 'train_steps_per_second': 2.923, 'train_loss': 2.6251134872436523, 'epoch': 3.0}
[INFO][09:22:10]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][09:22:11]: [Client #45] Model trained.
[INFO][09:22:11]: [Client #45] Inbound data has been processed.
[INFO][09:22:11]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][09:22:16]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:22:17]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][09:22:17]: [Server #3995185] Selecting client #132 for training.
[INFO][09:22:17]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][09:22:22]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][09:22:22]: [Client #132] Selected by the server.
[INFO][09:22:22]: [Client #132] Loading its data source...
[INFO][09:22:22]: [Client #132] Dataset size: 2018
[INFO][09:22:22]: [Client #132] Sampler: iid
[INFO][09:22:23]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:22:23]: [Client #132] Start to process inbound data.
[INFO][09:22:23]: [93m[1m[Client #132] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8053112030029297,)
[INFO][09:23:01]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 32.5734, 'train_samples_per_second': 185.857, 'train_steps_per_second': 2.947, 'train_loss': 2.8053112030029297, 'epoch': 3.0}
[INFO][09:23:02]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][09:23:03]: [Client #132] Model trained.
[INFO][09:23:03]: [Client #132] Inbound data has been processed.
[INFO][09:23:03]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][09:23:08]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:23:09]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][09:23:09]: [Server #3995185] Selecting client #66 for training.
[INFO][09:23:09]: [Server #3995185] Sending the current model to client #66 (simulated).
[INFO][09:23:14]: [Server #3995185] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][09:23:14]: [Client #66] Selected by the server.
[INFO][09:23:14]: [Client #66] Loading its data source...
[INFO][09:23:14]: [Client #66] Dataset size: 2018
[INFO][09:23:14]: [Client #66] Sampler: iid
[INFO][09:23:16]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:23:16]: [Client #66] Start to process inbound data.
[INFO][09:23:16]: [93m[1m[Client #66] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.98it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:26,  2.98it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  2.98it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  2.99it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:25,  2.99it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.966719309488932,)
[INFO][09:23:54]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
{'train_runtime': 32.4463, 'train_samples_per_second': 186.585, 'train_steps_per_second': 2.959, 'train_loss': 2.966719309488932, 'epoch': 3.0}
[INFO][09:23:55]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
[INFO][09:23:55]: [Client #66] Model trained.
[INFO][09:23:55]: [Client #66] Inbound data has been processed.
[INFO][09:23:55]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][09:24:00]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:24:01]: [Server #3995185] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][09:24:01]: [Server #3995185] Selecting client #188 for training.
[INFO][09:24:01]: [Server #3995185] Sending the current model to client #188 (simulated).
[INFO][09:24:07]: [Server #3995185] Sending 507.38 MB of payload data to client #188 (simulated).
[INFO][09:24:07]: [Client #188] Selected by the server.
[INFO][09:24:07]: [Client #188] Loading its data source...
[INFO][09:24:07]: [Client #188] Dataset size: 2018
[INFO][09:24:07]: [Client #188] Sampler: iid
[INFO][09:24:08]: [Client #188] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:24:08]: [Client #188] Start to process inbound data.
[INFO][09:24:09]: [93m[1m[Client #188] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:42,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.10it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9073899586995444,)
[INFO][09:24:47]: [Client #188] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
{'train_runtime': 32.1527, 'train_samples_per_second': 188.289, 'train_steps_per_second': 2.986, 'train_loss': 2.9073899586995444, 'epoch': 3.0}
[INFO][09:24:48]: [Client #188] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
[INFO][09:24:49]: [Client #188] Model trained.
[INFO][09:24:49]: [Client #188] Inbound data has been processed.
[INFO][09:24:49]: [Client #188] Outbound data is ready to be sent after being processed.
[INFO][09:24:55]: [Client #188] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:24:56]: [Server #3995185] Received 507.38 MB of payload data from client #188 (simulated).
[INFO][09:24:56]: [Server #3995185] Selecting client #53 for training.
[INFO][09:24:56]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][09:25:01]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][09:25:01]: [Client #53] Selected by the server.
[INFO][09:25:01]: [Client #53] Loading its data source...
[INFO][09:25:01]: [Client #53] Dataset size: 2018
[INFO][09:25:01]: [Client #53] Sampler: iid
[INFO][09:25:02]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:25:02]: [Client #53] Start to process inbound data.
[INFO][09:25:03]: [93m[1m[Client #53] Started training in communication round #34.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.786143938700358,)
[INFO][09:25:41]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 32.5036, 'train_samples_per_second': 186.256, 'train_steps_per_second': 2.954, 'train_loss': 2.786143938700358, 'epoch': 3.0}
[INFO][09:25:42]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][09:25:43]: [Client #53] Model trained.
[INFO][09:25:43]: [Client #53] Inbound data has been processed.
[INFO][09:25:43]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][09:25:48]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:25:49]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][09:25:49]: [Server #3995185] Adding client #1 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #54 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #88 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #177 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #27 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Adding client #77 to the list of clients for aggregation.
[INFO][09:25:49]: [Server #3995185] Aggregating 10 clients in total.
[INFO][09:25:49]: [Server #3995185] Updated weights have been received.
[INFO][09:25:50]: [Server #3995185] Aggregating model weight deltas.
[INFO][09:25:51]: [Server #3995185] Finished aggregating updated weights.
[INFO][09:25:51]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.76it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.22it/s]
[INFO][09:25:59]: [93m[1m[Server #3995185] Global model perplexity: 22.57
[0m
[INFO][09:25:59]: [Server #3995185] All client reports have been processed.
[INFO][09:26:00]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_34.pth.
[INFO][09:26:03]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_34.pth.
[INFO][09:26:03]: [93m[1m
[Server #3995185] Starting round 35/50.[0m
[INFO][09:26:03]: [Server #3995185] Selected clients: [85, 60, 71, 43, 163, 14, 10, 151, 88, 62]
[INFO][09:26:03]: [Server #3995185] Selecting client #85 for training.
[INFO][09:26:03]: [Server #3995185] Sending the current model to client #85 (simulated).
[INFO][09:26:09]: [Server #3995185] Sending 507.38 MB of payload data to client #85 (simulated).
[INFO][09:26:09]: [Client #85] Selected by the server.
[INFO][09:26:09]: [Client #85] Loading its data source...
[INFO][09:26:09]: [Client #85] Dataset size: 2018
[INFO][09:26:09]: [Client #85] Sampler: iid
[INFO][09:26:10]: [Client #85] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:26:10]: [Client #85] Start to process inbound data.
[INFO][09:26:11]: [93m[1m[Client #85] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:25,  1.54s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.68it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.855553944905599,)
[INFO][09:26:49]: [Client #85] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
{'train_runtime': 32.5538, 'train_samples_per_second': 185.969, 'train_steps_per_second': 2.949, 'train_loss': 2.855553944905599, 'epoch': 3.0}
[INFO][09:26:50]: [Client #85] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
[INFO][09:26:51]: [Client #85] Model trained.
[INFO][09:26:51]: [Client #85] Inbound data has been processed.
[INFO][09:26:51]: [Client #85] Outbound data is ready to be sent after being processed.
[INFO][09:26:56]: [Client #85] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:26:57]: [Server #3995185] Received 507.38 MB of payload data from client #85 (simulated).
[INFO][09:26:57]: [Server #3995185] Selecting client #60 for training.
[INFO][09:26:57]: [Server #3995185] Sending the current model to client #60 (simulated).
[INFO][09:27:02]: [Server #3995185] Sending 507.38 MB of payload data to client #60 (simulated).
[INFO][09:27:03]: [Client #60] Selected by the server.
[INFO][09:27:03]: [Client #60] Loading its data source...
[INFO][09:27:03]: [Client #60] Dataset size: 2018
[INFO][09:27:03]: [Client #60] Sampler: iid
[INFO][09:27:04]: [Client #60] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:27:04]: [Client #60] Start to process inbound data.
[INFO][09:27:04]: [93m[1m[Client #60] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:24,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.30it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:19,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.03it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.01it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.00it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:11,  2.97it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.42it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.27it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.98it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.97it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9394823710123696,)
[INFO][09:27:43]: [Client #60] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_60_3995237.pth.
{'train_runtime': 32.7837, 'train_samples_per_second': 184.665, 'train_steps_per_second': 2.928, 'train_loss': 2.9394823710123696, 'epoch': 3.0}
[INFO][09:27:43]: [Client #60] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_60_3995237.pth.
[INFO][09:27:44]: [Client #60] Model trained.
[INFO][09:27:44]: [Client #60] Inbound data has been processed.
[INFO][09:27:44]: [Client #60] Outbound data is ready to be sent after being processed.
[INFO][09:27:51]: [Client #60] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:27:52]: [Server #3995185] Received 507.38 MB of payload data from client #60 (simulated).
[INFO][09:27:52]: [Server #3995185] Selecting client #71 for training.
[INFO][09:27:52]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][09:27:58]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][09:27:58]: [Client #71] Selected by the server.
[INFO][09:27:58]: [Client #71] Loading its data source...
[INFO][09:27:58]: [Client #71] Dataset size: 2018
[INFO][09:27:58]: [Client #71] Sampler: iid
[INFO][09:27:59]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:27:59]: [Client #71] Start to process inbound data.
[INFO][09:27:59]: [93m[1m[Client #71] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.01it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.01it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.00it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:17,  3.00it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.00it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  2.99it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.98it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7830886840820312,)
[INFO][09:28:38]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.5667, 'train_samples_per_second': 185.896, 'train_steps_per_second': 2.948, 'train_loss': 2.7830886840820312, 'epoch': 3.0}
[INFO][09:28:39]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][09:28:39]: [Client #71] Model trained.
[INFO][09:28:39]: [Client #71] Inbound data has been processed.
[INFO][09:28:39]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][09:28:45]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:28:46]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][09:28:46]: [Server #3995185] Selecting client #43 for training.
[INFO][09:28:46]: [Server #3995185] Sending the current model to client #43 (simulated).
[INFO][09:28:55]: [Server #3995185] Sending 507.38 MB of payload data to client #43 (simulated).
[INFO][09:28:55]: [Client #43] Selected by the server.
[INFO][09:28:55]: [Client #43] Loading its data source...
[INFO][09:28:55]: [Client #43] Dataset size: 2018
[INFO][09:28:55]: [Client #43] Sampler: iid
[INFO][09:28:56]: [Client #43] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:28:56]: [Client #43] Start to process inbound data.
[INFO][09:28:56]: [93m[1m[Client #43] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.42it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.18it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.12it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.11it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.11it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.04it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.05it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8499841690063477,)
[INFO][09:29:34]: [Client #43] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
{'train_runtime': 32.0435, 'train_samples_per_second': 188.931, 'train_steps_per_second': 2.996, 'train_loss': 2.8499841690063477, 'epoch': 3.0}
[INFO][09:29:35]: [Client #43] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
[INFO][09:29:35]: [Client #43] Model trained.
[INFO][09:29:35]: [Client #43] Inbound data has been processed.
[INFO][09:29:35]: [Client #43] Outbound data is ready to be sent after being processed.
[INFO][09:29:41]: [Client #43] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:29:42]: [Server #3995185] Received 507.38 MB of payload data from client #43 (simulated).
[INFO][09:29:42]: [Server #3995185] Selecting client #163 for training.
[INFO][09:29:42]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][09:29:51]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][09:29:51]: [Client #163] Selected by the server.
[INFO][09:29:51]: [Client #163] Loading its data source...
[INFO][09:29:51]: [Client #163] Dataset size: 2018
[INFO][09:29:51]: [Client #163] Sampler: iid
[INFO][09:29:52]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:29:52]: [Client #163] Start to process inbound data.
[INFO][09:29:53]: [93m[1m[Client #163] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.68316650390625,)
[INFO][09:30:31]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.4881, 'train_samples_per_second': 186.345, 'train_steps_per_second': 2.955, 'train_loss': 2.68316650390625, 'epoch': 3.0}
[INFO][09:30:32]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][09:30:33]: [Client #163] Model trained.
[INFO][09:30:33]: [Client #163] Inbound data has been processed.
[INFO][09:30:33]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][09:30:38]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:30:39]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][09:30:39]: [Server #3995185] Selecting client #14 for training.
[INFO][09:30:39]: [Server #3995185] Sending the current model to client #14 (simulated).
[INFO][09:30:48]: [Server #3995185] Sending 507.38 MB of payload data to client #14 (simulated).
[INFO][09:30:48]: [Client #14] Selected by the server.
[INFO][09:30:48]: [Client #14] Loading its data source...
[INFO][09:30:48]: [Client #14] Dataset size: 2018
[INFO][09:30:48]: [Client #14] Sampler: iid
[INFO][09:30:49]: [Client #14] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:30:49]: [Client #14] Start to process inbound data.
[INFO][09:30:49]: [93m[1m[Client #14] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9552059173583984,)
[INFO][09:31:27]: [Client #14] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
{'train_runtime': 32.1946, 'train_samples_per_second': 188.044, 'train_steps_per_second': 2.982, 'train_loss': 2.9552059173583984, 'epoch': 3.0}
[INFO][09:31:28]: [Client #14] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
[INFO][09:31:28]: [Client #14] Model trained.
[INFO][09:31:28]: [Client #14] Inbound data has been processed.
[INFO][09:31:28]: [Client #14] Outbound data is ready to be sent after being processed.
[INFO][09:31:34]: [Client #14] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:31:35]: [Server #3995185] Received 507.38 MB of payload data from client #14 (simulated).
[INFO][09:31:35]: [Server #3995185] Selecting client #10 for training.
[INFO][09:31:35]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][09:31:45]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][09:31:45]: [Client #10] Selected by the server.
[INFO][09:31:45]: [Client #10] Loading its data source...
[INFO][09:31:45]: [Client #10] Dataset size: 2018
[INFO][09:31:45]: [Client #10] Sampler: iid
[INFO][09:31:46]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:31:46]: [Client #10] Start to process inbound data.
[INFO][09:31:46]: [93m[1m[Client #10] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:40,  1.69s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.23it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.88131046295166,)
[INFO][09:32:25]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.7327, 'train_samples_per_second': 184.953, 'train_steps_per_second': 2.933, 'train_loss': 2.88131046295166, 'epoch': 3.0}
[INFO][09:32:26]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][09:32:27]: [Client #10] Model trained.
[INFO][09:32:27]: [Client #10] Inbound data has been processed.
[INFO][09:32:27]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][09:32:33]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:32:34]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][09:32:34]: [Server #3995185] Selecting client #151 for training.
[INFO][09:32:34]: [Server #3995185] Sending the current model to client #151 (simulated).
[INFO][09:32:40]: [Server #3995185] Sending 507.38 MB of payload data to client #151 (simulated).
[INFO][09:32:40]: [Client #151] Selected by the server.
[INFO][09:32:40]: [Client #151] Loading its data source...
[INFO][09:32:40]: [Client #151] Dataset size: 2018
[INFO][09:32:40]: [Client #151] Sampler: iid
[INFO][09:32:42]: [Client #151] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:32:42]: [Client #151] Start to process inbound data.
[INFO][09:32:43]: [93m[1m[Client #151] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:30,  1.58s/it]  2%|â–         | 2/96 [00:01<01:19,  1.18it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.27it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.01it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.00it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:22,  2.99it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  2.99it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.45it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.29it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.14it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.10it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.07it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  2.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:14,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  2.99it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.98it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.98it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.97it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.97it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.96it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.96it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.95it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.95it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.95it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.95it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.95it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.95it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.95it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.96it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.96it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7576573689778647,)
[INFO][09:33:21]: [Client #151] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
{'train_runtime': 32.8812, 'train_samples_per_second': 184.118, 'train_steps_per_second': 2.92, 'train_loss': 2.7576573689778647, 'epoch': 3.0}
[INFO][09:33:22]: [Client #151] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
[INFO][09:33:23]: [Client #151] Model trained.
[INFO][09:33:23]: [Client #151] Inbound data has been processed.
[INFO][09:33:23]: [Client #151] Outbound data is ready to be sent after being processed.
[INFO][09:33:29]: [Client #151] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:33:30]: [Server #3995185] Received 507.38 MB of payload data from client #151 (simulated).
[INFO][09:33:30]: [Server #3995185] Selecting client #88 for training.
[INFO][09:33:30]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][09:33:35]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][09:33:35]: [Client #88] Selected by the server.
[INFO][09:33:35]: [Client #88] Loading its data source...
[INFO][09:33:35]: [Client #88] Dataset size: 2018
[INFO][09:33:35]: [Client #88] Sampler: iid
[INFO][09:33:36]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:33:36]: [Client #88] Start to process inbound data.
[INFO][09:33:36]: [93m[1m[Client #88] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.19it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.17it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.16it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.15it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.14it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.14it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:16,  3.14it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.13it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.13it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:15,  3.13it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.13it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.13it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.13it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.13it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.12it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.12it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.12it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.12it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.12it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.13it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.13it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.13it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.12it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.13it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:10,  3.12it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.58it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.43it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:08,  3.33it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.27it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.23it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.18it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.16it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.15it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.14it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.14it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.14it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.13it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.13it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.13it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.12it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.12it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.12it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.55it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.02it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7976134618123374,)
[INFO][09:34:14]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 31.7413, 'train_samples_per_second': 190.729, 'train_steps_per_second': 3.024, 'train_loss': 2.7976134618123374, 'epoch': 3.0}
[INFO][09:34:15]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][09:34:16]: [Client #88] Model trained.
[INFO][09:34:16]: [Client #88] Inbound data has been processed.
[INFO][09:34:16]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][09:34:21]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:34:22]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][09:34:22]: [Server #3995185] Selecting client #62 for training.
[INFO][09:34:22]: [Server #3995185] Sending the current model to client #62 (simulated).
[INFO][09:34:27]: [Server #3995185] Sending 507.38 MB of payload data to client #62 (simulated).
[INFO][09:34:27]: [Client #62] Selected by the server.
[INFO][09:34:27]: [Client #62] Loading its data source...
[INFO][09:34:27]: [Client #62] Dataset size: 2018
[INFO][09:34:27]: [Client #62] Sampler: iid
[INFO][09:34:28]: [Client #62] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:34:28]: [Client #62] Start to process inbound data.
[INFO][09:34:29]: [93m[1m[Client #62] Started training in communication round #35.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.05it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9218403498331704,)
[INFO][09:35:07]: [Client #62] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
{'train_runtime': 32.3013, 'train_samples_per_second': 187.423, 'train_steps_per_second': 2.972, 'train_loss': 2.9218403498331704, 'epoch': 3.0}
[INFO][09:35:08]: [Client #62] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
[INFO][09:35:09]: [Client #62] Model trained.
[INFO][09:35:09]: [Client #62] Inbound data has been processed.
[INFO][09:35:09]: [Client #62] Outbound data is ready to be sent after being processed.
[INFO][09:35:14]: [Client #62] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:35:15]: [Server #3995185] Received 507.38 MB of payload data from client #62 (simulated).
[INFO][09:35:15]: [Server #3995185] Adding client #9 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #23 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #53 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #66 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #132 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #188 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Adding client #81 to the list of clients for aggregation.
[INFO][09:35:15]: [Server #3995185] Aggregating 10 clients in total.
[INFO][09:35:15]: [Server #3995185] Updated weights have been received.
[INFO][09:35:16]: [Server #3995185] Aggregating model weight deltas.
[INFO][09:35:17]: [Server #3995185] Finished aggregating updated weights.
[INFO][09:35:17]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.46it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.03it/s]
[INFO][09:35:25]: [93m[1m[Server #3995185] Global model perplexity: 22.46
[0m
[INFO][09:35:25]: [Server #3995185] All client reports have been processed.
[INFO][09:35:26]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_35.pth.
[INFO][09:35:31]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_35.pth.
[INFO][09:35:31]: [93m[1m
[Server #3995185] Starting round 36/50.[0m
[INFO][09:35:31]: [Server #3995185] Selected clients: [125, 119, 89, 188, 144, 46, 53, 149, 200, 45]
[INFO][09:35:31]: [Server #3995185] Selecting client #125 for training.
[INFO][09:35:31]: [Server #3995185] Sending the current model to client #125 (simulated).
[INFO][09:35:41]: [Server #3995185] Sending 507.38 MB of payload data to client #125 (simulated).
[INFO][09:35:41]: [Client #125] Selected by the server.
[INFO][09:35:41]: [Client #125] Loading its data source...
[INFO][09:35:41]: [Client #125] Dataset size: 2018
[INFO][09:35:41]: [Client #125] Sampler: iid
[INFO][09:35:42]: [Client #125] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:35:42]: [Client #125] Start to process inbound data.
[INFO][09:35:43]: [93m[1m[Client #125] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:42,  1.71s/it]  2%|â–         | 2/96 [00:02<01:24,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.96it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.47it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.65it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.11it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.15it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.05it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.05it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.06it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.06it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8156118392944336,)
[INFO][09:36:21]: [Client #125] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_125_3995237.pth.
{'train_runtime': 32.419, 'train_samples_per_second': 186.742, 'train_steps_per_second': 2.961, 'train_loss': 2.8156118392944336, 'epoch': 3.0}
[INFO][09:36:22]: [Client #125] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_125_3995237.pth.
[INFO][09:36:23]: [Client #125] Model trained.
[INFO][09:36:23]: [Client #125] Inbound data has been processed.
[INFO][09:36:23]: [Client #125] Outbound data is ready to be sent after being processed.
[INFO][09:36:32]: [Client #125] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:36:33]: [Server #3995185] Received 507.38 MB of payload data from client #125 (simulated).
[INFO][09:36:33]: [Server #3995185] Selecting client #119 for training.
[INFO][09:36:33]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][09:36:40]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][09:36:40]: [Client #119] Selected by the server.
[INFO][09:36:40]: [Client #119] Loading its data source...
[INFO][09:36:40]: [Client #119] Dataset size: 2018
[INFO][09:36:40]: [Client #119] Sampler: iid
[INFO][09:36:41]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:36:41]: [Client #119] Start to process inbound data.
[INFO][09:36:42]: [93m[1m[Client #119] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:23,  1.51s/it]  2%|â–         | 2/96 [00:01<01:16,  1.22it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:44,  2.05it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  2.99it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.99it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.29it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.96it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.720735232035319,)
[INFO][09:37:21]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 32.6623, 'train_samples_per_second': 185.351, 'train_steps_per_second': 2.939, 'train_loss': 2.720735232035319, 'epoch': 3.0}
[INFO][09:37:22]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][09:37:22]: [Client #119] Model trained.
[INFO][09:37:22]: [Client #119] Inbound data has been processed.
[INFO][09:37:22]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][09:37:29]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:37:30]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][09:37:30]: [Server #3995185] Selecting client #89 for training.
[INFO][09:37:30]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][09:37:35]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][09:37:35]: [Client #89] Selected by the server.
[INFO][09:37:35]: [Client #89] Loading its data source...
[INFO][09:37:35]: [Client #89] Dataset size: 2018
[INFO][09:37:35]: [Client #89] Sampler: iid
[INFO][09:37:37]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:37:37]: [Client #89] Start to process inbound data.
[INFO][09:37:37]: [93m[1m[Client #89] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:49,  1.78s/it]  2%|â–         | 2/96 [00:02<01:26,  1.08it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.20it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.60it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.89it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.92it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7204128901163735,)
[INFO][09:38:16]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 32.8528, 'train_samples_per_second': 184.277, 'train_steps_per_second': 2.922, 'train_loss': 2.7204128901163735, 'epoch': 3.0}
[INFO][09:38:16]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][09:38:18]: [Client #89] Model trained.
[INFO][09:38:18]: [Client #89] Inbound data has been processed.
[INFO][09:38:18]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][09:38:27]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:38:28]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][09:38:28]: [Server #3995185] Selecting client #188 for training.
[INFO][09:38:28]: [Server #3995185] Sending the current model to client #188 (simulated).
[INFO][09:38:34]: [Server #3995185] Sending 507.38 MB of payload data to client #188 (simulated).
[INFO][09:38:34]: [Client #188] Selected by the server.
[INFO][09:38:34]: [Client #188] Loading its data source...
[INFO][09:38:34]: [Client #188] Dataset size: 2018
[INFO][09:38:34]: [Client #188] Sampler: iid
[INFO][09:38:35]: [Client #188] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:38:35]: [Client #188] Start to process inbound data.
[INFO][09:38:36]: [93m[1m[Client #188] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:43,  1.73s/it]  2%|â–         | 2/96 [00:02<01:25,  1.11it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:47,  1.94it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.63it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8243026733398438,)
[INFO][09:39:14]: [Client #188] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
{'train_runtime': 32.4819, 'train_samples_per_second': 186.381, 'train_steps_per_second': 2.955, 'train_loss': 2.8243026733398438, 'epoch': 3.0}
[INFO][09:39:15]: [Client #188] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
[INFO][09:39:16]: [Client #188] Model trained.
[INFO][09:39:16]: [Client #188] Inbound data has been processed.
[INFO][09:39:16]: [Client #188] Outbound data is ready to be sent after being processed.
[INFO][09:39:23]: [Client #188] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:39:24]: [Server #3995185] Received 507.38 MB of payload data from client #188 (simulated).
[INFO][09:39:24]: [Server #3995185] Selecting client #144 for training.
[INFO][09:39:24]: [Server #3995185] Sending the current model to client #144 (simulated).
[INFO][09:39:28]: [Server #3995185] Sending 507.38 MB of payload data to client #144 (simulated).
[INFO][09:39:28]: [Client #144] Selected by the server.
[INFO][09:39:28]: [Client #144] Loading its data source...
[INFO][09:39:28]: [Client #144] Dataset size: 2018
[INFO][09:39:28]: [Client #144] Sampler: iid
[INFO][09:39:29]: [Client #144] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:39:29]: [Client #144] Start to process inbound data.
[INFO][09:39:30]: [93m[1m[Client #144] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:34,  1.63s/it]  2%|â–         | 2/96 [00:01<01:20,  1.16it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.62it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.49it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.09it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:17,  3.12it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.10it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.07it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9103479385375977,)
[INFO][09:40:08]: [Client #144] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
{'train_runtime': 32.3731, 'train_samples_per_second': 187.007, 'train_steps_per_second': 2.965, 'train_loss': 2.9103479385375977, 'epoch': 3.0}
[INFO][09:40:09]: [Client #144] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_144_3995237.pth.
[INFO][09:40:10]: [Client #144] Model trained.
[INFO][09:40:10]: [Client #144] Inbound data has been processed.
[INFO][09:40:10]: [Client #144] Outbound data is ready to be sent after being processed.
[INFO][09:40:16]: [Client #144] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:40:16]: [Server #3995185] Received 507.38 MB of payload data from client #144 (simulated).
[INFO][09:40:16]: [Server #3995185] Selecting client #46 for training.
[INFO][09:40:16]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][09:40:21]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][09:40:21]: [Client #46] Selected by the server.
[INFO][09:40:21]: [Client #46] Loading its data source...
[INFO][09:40:21]: [Client #46] Dataset size: 2018
[INFO][09:40:21]: [Client #46] Sampler: iid
[INFO][09:40:22]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:40:22]: [Client #46] Start to process inbound data.
[INFO][09:40:23]: [93m[1m[Client #46] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:52,  1.81s/it]  2%|â–         | 2/96 [00:02<01:27,  1.07it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.53it/s]  4%|â–         | 4/96 [00:02<00:48,  1.91it/s]  5%|â–Œ         | 5/96 [00:03<00:40,  2.22it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.45it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:04<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.75048828125,)
[INFO][09:41:01]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.6038, 'train_samples_per_second': 185.684, 'train_steps_per_second': 2.944, 'train_loss': 2.75048828125, 'epoch': 3.0}
[INFO][09:41:02]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][09:41:03]: [Client #46] Model trained.
[INFO][09:41:03]: [Client #46] Inbound data has been processed.
[INFO][09:41:03]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][09:41:10]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:41:11]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][09:41:11]: [Server #3995185] Selecting client #53 for training.
[INFO][09:41:11]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][09:41:16]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][09:41:16]: [Client #53] Selected by the server.
[INFO][09:41:16]: [Client #53] Loading its data source...
[INFO][09:41:16]: [Client #53] Dataset size: 2018
[INFO][09:41:16]: [Client #53] Sampler: iid
[INFO][09:41:17]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:41:17]: [Client #53] Start to process inbound data.
[INFO][09:41:18]: [93m[1m[Client #53] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:54,  1.84s/it]  2%|â–         | 2/96 [00:02<01:29,  1.05it/s]  3%|â–Ž         | 3/96 [00:02<01:01,  1.51it/s]  4%|â–         | 4/96 [00:02<00:48,  1.88it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.18it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.42it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:28,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.95it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  2.94it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.93it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.91it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.692305246988932,)
[INFO][09:41:57]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 32.9398, 'train_samples_per_second': 183.79, 'train_steps_per_second': 2.914, 'train_loss': 2.692305246988932, 'epoch': 3.0}
[INFO][09:41:58]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][09:41:58]: [Client #53] Model trained.
[INFO][09:41:58]: [Client #53] Inbound data has been processed.
[INFO][09:41:58]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][09:42:03]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:42:04]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][09:42:04]: [Server #3995185] Selecting client #149 for training.
[INFO][09:42:04]: [Server #3995185] Sending the current model to client #149 (simulated).
[INFO][09:42:15]: [Server #3995185] Sending 507.38 MB of payload data to client #149 (simulated).
[INFO][09:42:15]: [Client #149] Selected by the server.
[INFO][09:42:15]: [Client #149] Loading its data source...
[INFO][09:42:15]: [Client #149] Dataset size: 2018
[INFO][09:42:15]: [Client #149] Sampler: iid
[INFO][09:42:16]: [Client #149] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:42:16]: [Client #149] Start to process inbound data.
[INFO][09:42:17]: [93m[1m[Client #149] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.737854321797689,)
[INFO][09:42:55]: [Client #149] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
{'train_runtime': 32.4158, 'train_samples_per_second': 186.761, 'train_steps_per_second': 2.962, 'train_loss': 2.737854321797689, 'epoch': 3.0}
[INFO][09:42:56]: [Client #149] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
[INFO][09:42:57]: [Client #149] Model trained.
[INFO][09:42:57]: [Client #149] Inbound data has been processed.
[INFO][09:42:57]: [Client #149] Outbound data is ready to be sent after being processed.
[INFO][09:43:04]: [Client #149] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:43:05]: [Server #3995185] Received 507.38 MB of payload data from client #149 (simulated).
[INFO][09:43:05]: [Server #3995185] Selecting client #200 for training.
[INFO][09:43:05]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][09:43:12]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][09:43:12]: [Client #200] Selected by the server.
[INFO][09:43:12]: [Client #200] Loading its data source...
[INFO][09:43:12]: [Client #200] Dataset size: 2018
[INFO][09:43:12]: [Client #200] Sampler: iid
[INFO][09:43:14]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:43:14]: [Client #200] Start to process inbound data.
[INFO][09:43:15]: [93m[1m[Client #200] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.08it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.07it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.07it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8720881144205728,)
[INFO][09:43:53]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 32.1021, 'train_samples_per_second': 188.586, 'train_steps_per_second': 2.99, 'train_loss': 2.8720881144205728, 'epoch': 3.0}
[INFO][09:43:54]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][09:43:55]: [Client #200] Model trained.
[INFO][09:43:55]: [Client #200] Inbound data has been processed.
[INFO][09:43:55]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][09:44:05]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:44:07]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][09:44:07]: [Server #3995185] Selecting client #45 for training.
[INFO][09:44:07]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][09:44:16]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][09:44:16]: [Client #45] Selected by the server.
[INFO][09:44:16]: [Client #45] Loading its data source...
[INFO][09:44:16]: [Client #45] Dataset size: 2018
[INFO][09:44:16]: [Client #45] Sampler: iid
[INFO][09:44:17]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:44:17]: [Client #45] Start to process inbound data.
[INFO][09:44:18]: [93m[1m[Client #45] Started training in communication round #36.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.05it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.34it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.06it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.5368040402730307,)
[INFO][09:44:56]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.409, 'train_samples_per_second': 186.8, 'train_steps_per_second': 2.962, 'train_loss': 2.5368040402730307, 'epoch': 3.0}
[INFO][09:44:57]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][09:44:58]: [Client #45] Model trained.
[INFO][09:44:58]: [Client #45] Inbound data has been processed.
[INFO][09:44:58]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][09:45:06]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:45:07]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][09:45:07]: [Server #3995185] Adding client #10 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #14 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #43 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #62 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #85 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #88 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #151 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Adding client #45 to the list of clients for aggregation.
[INFO][09:45:07]: [Server #3995185] Aggregating 10 clients in total.
[INFO][09:45:07]: [Server #3995185] Updated weights have been received.
[INFO][09:45:09]: [Server #3995185] Aggregating model weight deltas.
[INFO][09:45:10]: [Server #3995185] Finished aggregating updated weights.
[INFO][09:45:10]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.34it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.33it/s]
[INFO][09:45:19]: [93m[1m[Server #3995185] Global model perplexity: 22.37
[0m
[INFO][09:45:19]: [Server #3995185] All client reports have been processed.
[INFO][09:45:19]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_36.pth.
[INFO][09:45:23]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_36.pth.
[INFO][09:45:23]: [93m[1m
[Server #3995185] Starting round 37/50.[0m
[INFO][09:45:23]: [Server #3995185] Selected clients: [42, 143, 69, 163, 9, 88, 177, 14, 5, 148]
[INFO][09:45:23]: [Server #3995185] Selecting client #42 for training.
[INFO][09:45:23]: [Server #3995185] Sending the current model to client #42 (simulated).
[INFO][09:45:28]: [Server #3995185] Sending 507.38 MB of payload data to client #42 (simulated).
[INFO][09:45:28]: [Client #42] Selected by the server.
[INFO][09:45:28]: [Client #42] Loading its data source...
[INFO][09:45:28]: [Client #42] Dataset size: 2018
[INFO][09:45:28]: [Client #42] Sampler: iid
[INFO][09:45:29]: [Client #42] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:45:29]: [Client #42] Start to process inbound data.
[INFO][09:45:29]: [93m[1m[Client #42] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.03it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.05it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:26,  3.09it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.10it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.11it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.10it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.10it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.11it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.10it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.22it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.11it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.09it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.06it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.04it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.917311986287435,)
[INFO][09:46:07]: [Client #42] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_42_3995237.pth.
{'train_runtime': 31.9884, 'train_samples_per_second': 189.256, 'train_steps_per_second': 3.001, 'train_loss': 2.917311986287435, 'epoch': 3.0}
[INFO][09:46:08]: [Client #42] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_42_3995237.pth.
[INFO][09:46:09]: [Client #42] Model trained.
[INFO][09:46:09]: [Client #42] Inbound data has been processed.
[INFO][09:46:09]: [Client #42] Outbound data is ready to be sent after being processed.
[INFO][09:46:14]: [Client #42] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:46:15]: [Server #3995185] Received 507.38 MB of payload data from client #42 (simulated).
[INFO][09:46:15]: [Server #3995185] Selecting client #143 for training.
[INFO][09:46:15]: [Server #3995185] Sending the current model to client #143 (simulated).
[INFO][09:46:22]: [Server #3995185] Sending 507.38 MB of payload data to client #143 (simulated).
[INFO][09:46:22]: [Client #143] Selected by the server.
[INFO][09:46:22]: [Client #143] Loading its data source...
[INFO][09:46:22]: [Client #143] Dataset size: 2018
[INFO][09:46:22]: [Client #143] Sampler: iid
[INFO][09:46:23]: [Client #143] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:46:23]: [Client #143] Start to process inbound data.
[INFO][09:46:24]: [93m[1m[Client #143] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.03it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.10it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.09it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.11it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7962700525919595,)
[INFO][09:47:02]: [Client #143] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
{'train_runtime': 32.1922, 'train_samples_per_second': 188.058, 'train_steps_per_second': 2.982, 'train_loss': 2.7962700525919595, 'epoch': 3.0}
[INFO][09:47:03]: [Client #143] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_143_3995237.pth.
[INFO][09:47:04]: [Client #143] Model trained.
[INFO][09:47:04]: [Client #143] Inbound data has been processed.
[INFO][09:47:04]: [Client #143] Outbound data is ready to be sent after being processed.
[INFO][09:47:09]: [Client #143] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:47:10]: [Server #3995185] Received 507.38 MB of payload data from client #143 (simulated).
[INFO][09:47:10]: [Server #3995185] Selecting client #69 for training.
[INFO][09:47:10]: [Server #3995185] Sending the current model to client #69 (simulated).
[INFO][09:47:15]: [Server #3995185] Sending 507.38 MB of payload data to client #69 (simulated).
[INFO][09:47:15]: [Client #69] Selected by the server.
[INFO][09:47:15]: [Client #69] Loading its data source...
[INFO][09:47:15]: [Client #69] Dataset size: 2018
[INFO][09:47:15]: [Client #69] Sampler: iid
[INFO][09:47:17]: [Client #69] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:47:17]: [Client #69] Start to process inbound data.
[INFO][09:47:17]: [93m[1m[Client #69] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.10it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.17it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.15it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8223253885904946,)
[INFO][09:47:55]: [Client #69] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3995237.pth.
{'train_runtime': 32.2312, 'train_samples_per_second': 187.831, 'train_steps_per_second': 2.978, 'train_loss': 2.8223253885904946, 'epoch': 3.0}
[INFO][09:47:55]: [Client #69] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_69_3995237.pth.
[INFO][09:47:56]: [Client #69] Model trained.
[INFO][09:47:56]: [Client #69] Inbound data has been processed.
[INFO][09:47:56]: [Client #69] Outbound data is ready to be sent after being processed.
[INFO][09:48:01]: [Client #69] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:48:02]: [Server #3995185] Received 507.38 MB of payload data from client #69 (simulated).
[INFO][09:48:02]: [Server #3995185] Selecting client #163 for training.
[INFO][09:48:02]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][09:48:07]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][09:48:07]: [Client #163] Selected by the server.
[INFO][09:48:07]: [Client #163] Loading its data source...
[INFO][09:48:07]: [Client #163] Dataset size: 2018
[INFO][09:48:07]: [Client #163] Sampler: iid
[INFO][09:48:08]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:48:08]: [Client #163] Start to process inbound data.
[INFO][09:48:08]: [93m[1m[Client #163] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  2.99it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:13,  2.99it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.00it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.98it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.98it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.97it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.97it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.97it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.97it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.97it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.97it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.97it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.97it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.97it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.97it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.600536028544108,)
[INFO][09:48:47]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.4935, 'train_samples_per_second': 186.314, 'train_steps_per_second': 2.954, 'train_loss': 2.600536028544108, 'epoch': 3.0}
[INFO][09:48:47]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][09:48:48]: [Client #163] Model trained.
[INFO][09:48:48]: [Client #163] Inbound data has been processed.
[INFO][09:48:48]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][09:48:54]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:48:55]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][09:48:55]: [Server #3995185] Selecting client #9 for training.
[INFO][09:48:55]: [Server #3995185] Sending the current model to client #9 (simulated).
[INFO][09:49:00]: [Server #3995185] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][09:49:00]: [Client #9] Selected by the server.
[INFO][09:49:00]: [Client #9] Loading its data source...
[INFO][09:49:00]: [Client #9] Dataset size: 2018
[INFO][09:49:00]: [Client #9] Sampler: iid
[INFO][09:49:01]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:49:01]: [Client #9] Start to process inbound data.
[INFO][09:49:01]: [93m[1m[Client #9] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.03it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.00it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.749296506245931,)
[INFO][09:49:40]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
{'train_runtime': 32.4019, 'train_samples_per_second': 186.841, 'train_steps_per_second': 2.963, 'train_loss': 2.749296506245931, 'epoch': 3.0}
[INFO][09:49:41]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
[INFO][09:49:42]: [Client #9] Model trained.
[INFO][09:49:42]: [Client #9] Inbound data has been processed.
[INFO][09:49:42]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][09:49:47]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:49:48]: [Server #3995185] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][09:49:48]: [Server #3995185] Selecting client #88 for training.
[INFO][09:49:48]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][09:49:53]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][09:49:53]: [Client #88] Selected by the server.
[INFO][09:49:53]: [Client #88] Loading its data source...
[INFO][09:49:53]: [Client #88] Dataset size: 2018
[INFO][09:49:53]: [Client #88] Sampler: iid
[INFO][09:49:54]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:49:54]: [Client #88] Start to process inbound data.
[INFO][09:49:54]: [93m[1m[Client #88] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.02it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.05it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  2.98it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.98it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.98it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7251625061035156,)
[INFO][09:50:32]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 32.5433, 'train_samples_per_second': 186.029, 'train_steps_per_second': 2.95, 'train_loss': 2.7251625061035156, 'epoch': 3.0}
[INFO][09:50:33]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][09:50:34]: [Client #88] Model trained.
[INFO][09:50:34]: [Client #88] Inbound data has been processed.
[INFO][09:50:34]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][09:50:39]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:50:39]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][09:50:39]: [Server #3995185] Selecting client #177 for training.
[INFO][09:50:39]: [Server #3995185] Sending the current model to client #177 (simulated).
[INFO][09:50:46]: [Server #3995185] Sending 507.38 MB of payload data to client #177 (simulated).
[INFO][09:50:46]: [Client #177] Selected by the server.
[INFO][09:50:46]: [Client #177] Loading its data source...
[INFO][09:50:46]: [Client #177] Dataset size: 2018
[INFO][09:50:46]: [Client #177] Sampler: iid
[INFO][09:50:47]: [Client #177] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:50:47]: [Client #177] Start to process inbound data.
[INFO][09:50:47]: [93m[1m[Client #177] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.00it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:16,  2.99it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  2.98it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  2.99it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.00it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.09it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.09it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.55it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.31it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.25it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.21it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.18it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.16it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:07,  3.15it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.14it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.13it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.13it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.12it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.12it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.11it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.10it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.11it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.11it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.11it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.12it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.12it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.12it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.12it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.12it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.10it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.10it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7136398951212564,)
[INFO][09:51:25]: [Client #177] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
{'train_runtime': 32.0226, 'train_samples_per_second': 189.054, 'train_steps_per_second': 2.998, 'train_loss': 2.7136398951212564, 'epoch': 3.0}
[INFO][09:51:26]: [Client #177] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_177_3995237.pth.
[INFO][09:51:26]: [Client #177] Model trained.
[INFO][09:51:26]: [Client #177] Inbound data has been processed.
[INFO][09:51:26]: [Client #177] Outbound data is ready to be sent after being processed.
[INFO][09:51:32]: [Client #177] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:51:33]: [Server #3995185] Received 507.38 MB of payload data from client #177 (simulated).
[INFO][09:51:33]: [Server #3995185] Selecting client #14 for training.
[INFO][09:51:33]: [Server #3995185] Sending the current model to client #14 (simulated).
[INFO][09:51:38]: [Server #3995185] Sending 507.38 MB of payload data to client #14 (simulated).
[INFO][09:51:38]: [Client #14] Selected by the server.
[INFO][09:51:38]: [Client #14] Loading its data source...
[INFO][09:51:38]: [Client #14] Dataset size: 2018
[INFO][09:51:38]: [Client #14] Sampler: iid
[INFO][09:51:39]: [Client #14] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:51:39]: [Client #14] Start to process inbound data.
[INFO][09:51:40]: [93m[1m[Client #14] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:20,  1.48s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.08it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.09it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.10it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.11it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.11it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.09it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.07it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.06it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8545427322387695,)
[INFO][09:52:18]: [Client #14] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
{'train_runtime': 32.1863, 'train_samples_per_second': 188.092, 'train_steps_per_second': 2.983, 'train_loss': 2.8545427322387695, 'epoch': 3.0}
[INFO][09:52:19]: [Client #14] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_14_3995237.pth.
[INFO][09:52:20]: [Client #14] Model trained.
[INFO][09:52:20]: [Client #14] Inbound data has been processed.
[INFO][09:52:20]: [Client #14] Outbound data is ready to be sent after being processed.
[INFO][09:52:25]: [Client #14] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:52:26]: [Server #3995185] Received 507.38 MB of payload data from client #14 (simulated).
[INFO][09:52:26]: [Server #3995185] Selecting client #5 for training.
[INFO][09:52:26]: [Server #3995185] Sending the current model to client #5 (simulated).
[INFO][09:52:31]: [Server #3995185] Sending 507.38 MB of payload data to client #5 (simulated).
[INFO][09:52:31]: [Client #5] Selected by the server.
[INFO][09:52:31]: [Client #5] Loading its data source...
[INFO][09:52:31]: [Client #5] Dataset size: 2018
[INFO][09:52:31]: [Client #5] Sampler: iid
[INFO][09:52:32]: [Client #5] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:52:32]: [Client #5] Start to process inbound data.
[INFO][09:52:33]: [93m[1m[Client #5] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:30,  1.58s/it]  2%|â–         | 2/96 [00:01<01:18,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.01it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.31it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.67it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.06it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6916303634643555,)
[INFO][09:53:11]: [Client #5] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
{'train_runtime': 32.5235, 'train_samples_per_second': 186.142, 'train_steps_per_second': 2.952, 'train_loss': 2.6916303634643555, 'epoch': 3.0}
[INFO][09:53:12]: [Client #5] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_5_3995237.pth.
[INFO][09:53:12]: [Client #5] Model trained.
[INFO][09:53:12]: [Client #5] Inbound data has been processed.
[INFO][09:53:12]: [Client #5] Outbound data is ready to be sent after being processed.
[INFO][09:53:17]: [Client #5] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:53:18]: [Server #3995185] Received 507.38 MB of payload data from client #5 (simulated).
[INFO][09:53:18]: [Server #3995185] Selecting client #148 for training.
[INFO][09:53:18]: [Server #3995185] Sending the current model to client #148 (simulated).
[INFO][09:53:23]: [Server #3995185] Sending 507.38 MB of payload data to client #148 (simulated).
[INFO][09:53:23]: [Client #148] Selected by the server.
[INFO][09:53:23]: [Client #148] Loading its data source...
[INFO][09:53:23]: [Client #148] Dataset size: 2018
[INFO][09:53:23]: [Client #148] Sampler: iid
[INFO][09:53:25]: [Client #148] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:53:25]: [Client #148] Start to process inbound data.
[INFO][09:53:25]: [93m[1m[Client #148] Started training in communication round #37.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:41,  1.70s/it]  2%|â–         | 2/96 [00:02<01:23,  1.12it/s]  3%|â–Ž         | 3/96 [00:02<00:59,  1.57it/s]  4%|â–         | 4/96 [00:02<00:46,  1.96it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.25it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.77it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.84it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.09it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.07it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.09it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9367844263712564,)
[INFO][09:54:03]: [Client #148] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_148_3995237.pth.
{'train_runtime': 32.539, 'train_samples_per_second': 186.054, 'train_steps_per_second': 2.95, 'train_loss': 2.9367844263712564, 'epoch': 3.0}
[INFO][09:54:04]: [Client #148] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_148_3995237.pth.
[INFO][09:54:04]: [Client #148] Model trained.
[INFO][09:54:04]: [Client #148] Inbound data has been processed.
[INFO][09:54:04]: [Client #148] Outbound data is ready to be sent after being processed.
[INFO][09:54:10]: [Client #148] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:54:11]: [Server #3995185] Received 507.38 MB of payload data from client #148 (simulated).
[INFO][09:54:11]: [Server #3995185] Adding client #46 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #53 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #60 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #119 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #144 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #149 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #188 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Adding client #125 to the list of clients for aggregation.
[INFO][09:54:11]: [Server #3995185] Aggregating 10 clients in total.
[INFO][09:54:11]: [Server #3995185] Updated weights have been received.
[INFO][09:54:16]: [Server #3995185] Aggregating model weight deltas.
[INFO][09:54:17]: [Server #3995185] Finished aggregating updated weights.
[INFO][09:54:17]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 48.18it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.44it/s]
[INFO][09:54:26]: [93m[1m[Server #3995185] Global model perplexity: 22.36
[0m
[INFO][09:54:26]: [Server #3995185] All client reports have been processed.
[INFO][09:54:26]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_37.pth.
[INFO][09:54:30]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_37.pth.
[INFO][09:54:30]: [93m[1m
[Server #3995185] Starting round 38/50.[0m
[INFO][09:54:30]: [Server #3995185] Selected clients: [41, 37, 183, 76, 151, 43, 89, 132, 119, 33]
[INFO][09:54:30]: [Server #3995185] Selecting client #41 for training.
[INFO][09:54:30]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][09:54:36]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][09:54:36]: [Client #41] Selected by the server.
[INFO][09:54:36]: [Client #41] Loading its data source...
[INFO][09:54:36]: [Client #41] Dataset size: 2018
[INFO][09:54:36]: [Client #41] Sampler: iid
[INFO][09:54:37]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:54:37]: [Client #41] Start to process inbound data.
[INFO][09:54:37]: [93m[1m[Client #41] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.09it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.09it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.14it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.11it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.07it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.10it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.09it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.08it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.07it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7560850779215493,)
[INFO][09:55:15]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.0675, 'train_samples_per_second': 188.789, 'train_steps_per_second': 2.994, 'train_loss': 2.7560850779215493, 'epoch': 3.0}
[INFO][09:55:16]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][09:55:17]: [Client #41] Model trained.
[INFO][09:55:17]: [Client #41] Inbound data has been processed.
[INFO][09:55:17]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][09:55:23]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:55:24]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][09:55:24]: [Server #3995185] Selecting client #37 for training.
[INFO][09:55:24]: [Server #3995185] Sending the current model to client #37 (simulated).
[INFO][09:55:29]: [Server #3995185] Sending 507.38 MB of payload data to client #37 (simulated).
[INFO][09:55:29]: [Client #37] Selected by the server.
[INFO][09:55:29]: [Client #37] Loading its data source...
[INFO][09:55:29]: [Client #37] Dataset size: 2018
[INFO][09:55:29]: [Client #37] Sampler: iid
[INFO][09:55:31]: [Client #37] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:55:31]: [Client #37] Start to process inbound data.
[INFO][09:55:31]: [93m[1m[Client #37] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.99it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.10it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.10it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.10it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.11it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.10it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.09it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.30it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.07it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.747976303100586,)
[INFO][09:56:10]: [Client #37] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
{'train_runtime': 32.1309, 'train_samples_per_second': 188.417, 'train_steps_per_second': 2.988, 'train_loss': 2.747976303100586, 'epoch': 3.0}
[INFO][09:56:10]: [Client #37] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
[INFO][09:56:12]: [Client #37] Model trained.
[INFO][09:56:12]: [Client #37] Inbound data has been processed.
[INFO][09:56:12]: [Client #37] Outbound data is ready to be sent after being processed.
[INFO][09:56:18]: [Client #37] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:56:19]: [Server #3995185] Received 507.38 MB of payload data from client #37 (simulated).
[INFO][09:56:19]: [Server #3995185] Selecting client #183 for training.
[INFO][09:56:19]: [Server #3995185] Sending the current model to client #183 (simulated).
[INFO][09:56:24]: [Server #3995185] Sending 507.38 MB of payload data to client #183 (simulated).
[INFO][09:56:24]: [Client #183] Selected by the server.
[INFO][09:56:24]: [Client #183] Loading its data source...
[INFO][09:56:24]: [Client #183] Dataset size: 2018
[INFO][09:56:24]: [Client #183] Sampler: iid
[INFO][09:56:26]: [Client #183] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:56:26]: [Client #183] Start to process inbound data.
[INFO][09:56:26]: [93m[1m[Client #183] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.08it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.10it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.11it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.10it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.09it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.08it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.10it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.36it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7505407333374023,)
[INFO][09:57:04]: [Client #183] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
{'train_runtime': 32.2122, 'train_samples_per_second': 187.941, 'train_steps_per_second': 2.98, 'train_loss': 2.7505407333374023, 'epoch': 3.0}
[INFO][09:57:05]: [Client #183] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_183_3995237.pth.
[INFO][09:57:05]: [Client #183] Model trained.
[INFO][09:57:05]: [Client #183] Inbound data has been processed.
[INFO][09:57:05]: [Client #183] Outbound data is ready to be sent after being processed.
[INFO][09:57:11]: [Client #183] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:57:12]: [Server #3995185] Received 507.38 MB of payload data from client #183 (simulated).
[INFO][09:57:12]: [Server #3995185] Selecting client #76 for training.
[INFO][09:57:12]: [Server #3995185] Sending the current model to client #76 (simulated).
[INFO][09:57:17]: [Server #3995185] Sending 507.38 MB of payload data to client #76 (simulated).
[INFO][09:57:17]: [Client #76] Selected by the server.
[INFO][09:57:17]: [Client #76] Loading its data source...
[INFO][09:57:17]: [Client #76] Dataset size: 2018
[INFO][09:57:17]: [Client #76] Sampler: iid
[INFO][09:57:18]: [Client #76] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:57:18]: [Client #76] Start to process inbound data.
[INFO][09:57:19]: [93m[1m[Client #76] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.43s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.04it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8989480336507163,)
[INFO][09:57:58]: [Client #76] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_76_3995237.pth.
{'train_runtime': 32.4227, 'train_samples_per_second': 186.721, 'train_steps_per_second': 2.961, 'train_loss': 2.8989480336507163, 'epoch': 3.0}
[INFO][09:57:58]: [Client #76] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_76_3995237.pth.
[INFO][09:57:59]: [Client #76] Model trained.
[INFO][09:57:59]: [Client #76] Inbound data has been processed.
[INFO][09:57:59]: [Client #76] Outbound data is ready to be sent after being processed.
[INFO][09:58:04]: [Client #76] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:58:05]: [Server #3995185] Received 507.38 MB of payload data from client #76 (simulated).
[INFO][09:58:05]: [Server #3995185] Selecting client #151 for training.
[INFO][09:58:05]: [Server #3995185] Sending the current model to client #151 (simulated).
[INFO][09:58:10]: [Server #3995185] Sending 507.38 MB of payload data to client #151 (simulated).
[INFO][09:58:10]: [Client #151] Selected by the server.
[INFO][09:58:10]: [Client #151] Loading its data source...
[INFO][09:58:10]: [Client #151] Dataset size: 2018
[INFO][09:58:10]: [Client #151] Sampler: iid
[INFO][09:58:11]: [Client #151] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:58:11]: [Client #151] Start to process inbound data.
[INFO][09:58:12]: [93m[1m[Client #151] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.47s/it]  2%|â–         | 2/96 [00:01<01:15,  1.25it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.72it/s]  4%|â–         | 4/96 [00:02<00:44,  2.07it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.05it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.03it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.03it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.03it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.03it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6974411010742188,)
[INFO][09:58:51]: [Client #151] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
{'train_runtime': 32.3282, 'train_samples_per_second': 187.267, 'train_steps_per_second': 2.97, 'train_loss': 2.6974411010742188, 'epoch': 3.0}
[INFO][09:58:51]: [Client #151] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_151_3995237.pth.
[INFO][09:58:53]: [Client #151] Model trained.
[INFO][09:58:53]: [Client #151] Inbound data has been processed.
[INFO][09:58:53]: [Client #151] Outbound data is ready to be sent after being processed.
[INFO][09:58:58]: [Client #151] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:58:59]: [Server #3995185] Received 507.38 MB of payload data from client #151 (simulated).
[INFO][09:58:59]: [Server #3995185] Selecting client #43 for training.
[INFO][09:58:59]: [Server #3995185] Sending the current model to client #43 (simulated).
[INFO][09:59:04]: [Server #3995185] Sending 507.38 MB of payload data to client #43 (simulated).
[INFO][09:59:04]: [Client #43] Selected by the server.
[INFO][09:59:04]: [Client #43] Loading its data source...
[INFO][09:59:04]: [Client #43] Dataset size: 2018
[INFO][09:59:04]: [Client #43] Sampler: iid
[INFO][09:59:05]: [Client #43] Received 507.38 MB of payload data from the server (simulated).
[INFO][09:59:05]: [Client #43] Start to process inbound data.
[INFO][09:59:06]: [93m[1m[Client #43] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:15,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.04it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.06it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.04it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.05it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.03it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7564217249552407,)
[INFO][09:59:44]: [Client #43] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
{'train_runtime': 32.2302, 'train_samples_per_second': 187.836, 'train_steps_per_second': 2.979, 'train_loss': 2.7564217249552407, 'epoch': 3.0}
[INFO][09:59:45]: [Client #43] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_43_3995237.pth.
[INFO][09:59:46]: [Client #43] Model trained.
[INFO][09:59:46]: [Client #43] Inbound data has been processed.
[INFO][09:59:46]: [Client #43] Outbound data is ready to be sent after being processed.
[INFO][09:59:52]: [Client #43] Sent 507.38 MB of payload data to the server (simulated).
[INFO][09:59:52]: [Server #3995185] Received 507.38 MB of payload data from client #43 (simulated).
[INFO][09:59:52]: [Server #3995185] Selecting client #89 for training.
[INFO][09:59:52]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][09:59:59]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][09:59:59]: [Client #89] Selected by the server.
[INFO][09:59:59]: [Client #89] Loading its data source...
[INFO][09:59:59]: [Client #89] Dataset size: 2018
[INFO][09:59:59]: [Client #89] Sampler: iid
[INFO][10:00:01]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:00:01]: [Client #89] Start to process inbound data.
[INFO][10:00:01]: [93m[1m[Client #89] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<03:01,  1.91s/it]  2%|â–         | 2/96 [00:02<01:32,  1.02it/s]  3%|â–Ž         | 3/96 [00:02<01:03,  1.46it/s]  4%|â–         | 4/96 [00:02<00:50,  1.83it/s]  5%|â–Œ         | 5/96 [00:03<00:42,  2.14it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.37it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.55it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.68it/s]  9%|â–‰         | 9/96 [00:04<00:31,  2.78it/s] 10%|â–ˆ         | 10/96 [00:04<00:30,  2.85it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.90it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.94it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:28,  2.96it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.00it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:23,  3.00it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:12<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:13<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:14<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:15<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:16<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:17<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:18<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:19<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:20<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:21<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.03it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:26<00:07,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:27<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:28<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:29<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:30<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:31<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:32<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:33<00:00,  2.90it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6280342737833657,)
[INFO][10:00:41]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 33.05, 'train_samples_per_second': 183.177, 'train_steps_per_second': 2.905, 'train_loss': 2.6280342737833657, 'epoch': 3.0}
[INFO][10:00:41]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][10:00:43]: [Client #89] Model trained.
[INFO][10:00:43]: [Client #89] Inbound data has been processed.
[INFO][10:00:43]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][10:00:49]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:00:50]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][10:00:50]: [Server #3995185] Selecting client #132 for training.
[INFO][10:00:50]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][10:00:55]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][10:00:55]: [Client #132] Selected by the server.
[INFO][10:00:55]: [Client #132] Loading its data source...
[INFO][10:00:55]: [Client #132] Dataset size: 2018
[INFO][10:00:55]: [Client #132] Sampler: iid
[INFO][10:00:56]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:00:56]: [Client #132] Start to process inbound data.
[INFO][10:00:57]: [93m[1m[Client #132] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:32,  1.61s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:57,  1.63it/s]  4%|â–         | 4/96 [00:02<00:46,  2.00it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.28it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.48it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.75it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.00it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.723483085632324,)
[INFO][10:01:36]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 32.6737, 'train_samples_per_second': 185.287, 'train_steps_per_second': 2.938, 'train_loss': 2.723483085632324, 'epoch': 3.0}
[INFO][10:01:36]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][10:01:37]: [Client #132] Model trained.
[INFO][10:01:37]: [Client #132] Inbound data has been processed.
[INFO][10:01:37]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][10:01:42]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:01:43]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][10:01:43]: [Server #3995185] Selecting client #119 for training.
[INFO][10:01:43]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][10:01:49]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][10:01:49]: [Client #119] Selected by the server.
[INFO][10:01:49]: [Client #119] Loading its data source...
[INFO][10:01:49]: [Client #119] Dataset size: 2018
[INFO][10:01:49]: [Client #119] Sampler: iid
[INFO][10:01:50]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:01:50]: [Client #119] Start to process inbound data.
[INFO][10:01:51]: [93m[1m[Client #119] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:47,  1.76s/it]  2%|â–         | 2/96 [00:02<01:25,  1.09it/s]  3%|â–Ž         | 3/96 [00:02<01:00,  1.55it/s]  4%|â–         | 4/96 [00:02<00:48,  1.92it/s]  5%|â–Œ         | 5/96 [00:03<00:41,  2.21it/s]  6%|â–‹         | 6/96 [00:03<00:37,  2.43it/s]  7%|â–‹         | 7/96 [00:03<00:34,  2.59it/s]  8%|â–Š         | 8/96 [00:04<00:32,  2.72it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.81it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:05<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:06<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:07<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:08<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.01it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:09<00:24,  3.01it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:10<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.01it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.01it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:11<00:22,  3.01it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:23<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:24<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:25<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.02it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.93it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6381117502848306,)
[INFO][10:02:30]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 32.8192, 'train_samples_per_second': 184.465, 'train_steps_per_second': 2.925, 'train_loss': 2.6381117502848306, 'epoch': 3.0}
[INFO][10:02:30]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][10:02:32]: [Client #119] Model trained.
[INFO][10:02:32]: [Client #119] Inbound data has been processed.
[INFO][10:02:32]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][10:02:37]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:02:38]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][10:02:38]: [Server #3995185] Selecting client #33 for training.
[INFO][10:02:38]: [Server #3995185] Sending the current model to client #33 (simulated).
[INFO][10:02:43]: [Server #3995185] Sending 507.38 MB of payload data to client #33 (simulated).
[INFO][10:02:43]: [Client #33] Selected by the server.
[INFO][10:02:43]: [Client #33] Loading its data source...
[INFO][10:02:43]: [Client #33] Dataset size: 2018
[INFO][10:02:43]: [Client #33] Sampler: iid
[INFO][10:02:44]: [Client #33] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:02:44]: [Client #33] Start to process inbound data.
[INFO][10:02:45]: [93m[1m[Client #33] Started training in communication round #38.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.96it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  2.99it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.02it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.12it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7088600794474282,)
[INFO][10:03:24]: [Client #33] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
{'train_runtime': 32.4759, 'train_samples_per_second': 186.415, 'train_steps_per_second': 2.956, 'train_loss': 2.7088600794474282, 'epoch': 3.0}
[INFO][10:03:25]: [Client #33] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_33_3995237.pth.
[INFO][10:03:26]: [Client #33] Model trained.
[INFO][10:03:26]: [Client #33] Inbound data has been processed.
[INFO][10:03:26]: [Client #33] Outbound data is ready to be sent after being processed.
[INFO][10:03:31]: [Client #33] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:03:32]: [Server #3995185] Received 507.38 MB of payload data from client #33 (simulated).
[INFO][10:03:32]: [Server #3995185] Adding client #5 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #9 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #14 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #88 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #143 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #177 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #42 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #69 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Adding client #148 to the list of clients for aggregation.
[INFO][10:03:32]: [Server #3995185] Aggregating 10 clients in total.
[INFO][10:03:32]: [Server #3995185] Updated weights have been received.
[INFO][10:03:36]: [Server #3995185] Aggregating model weight deltas.
[INFO][10:03:37]: [Server #3995185] Finished aggregating updated weights.
[INFO][10:03:37]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.37it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.12it/s]
[INFO][10:03:45]: [93m[1m[Server #3995185] Global model perplexity: 22.07
[0m
[INFO][10:03:45]: [Server #3995185] All client reports have been processed.
[INFO][10:03:45]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_38.pth.
[INFO][10:03:50]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_38.pth.
[INFO][10:03:50]: [93m[1m
[Server #3995185] Starting round 39/50.[0m
[INFO][10:03:50]: [Server #3995185] Selected clients: [200, 1, 66, 62, 193, 142, 104, 71, 163, 188]
[INFO][10:03:50]: [Server #3995185] Selecting client #200 for training.
[INFO][10:03:50]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][10:03:58]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][10:03:58]: [Client #200] Selected by the server.
[INFO][10:03:58]: [Client #200] Loading its data source...
[INFO][10:03:58]: [Client #200] Dataset size: 2018
[INFO][10:03:58]: [Client #200] Sampler: iid
[INFO][10:03:59]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:03:59]: [Client #200] Start to process inbound data.
[INFO][10:03:59]: [93m[1m[Client #200] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.92it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.99it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.03it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.06it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.21it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.15it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.10it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.09it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.09it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.08it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.09it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.09it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.10it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.10it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.09it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.11it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.09it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.09it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.08it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.08it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.07it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.08it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.06it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.53it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.08it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.04it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.06it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.05it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.05it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.06it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.05it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.00it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8554512659708657,)
[INFO][10:04:37]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 31.949, 'train_samples_per_second': 189.49, 'train_steps_per_second': 3.005, 'train_loss': 2.8554512659708657, 'epoch': 3.0}
[INFO][10:04:38]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][10:04:38]: [Client #200] Model trained.
[INFO][10:04:38]: [Client #200] Inbound data has been processed.
[INFO][10:04:38]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][10:04:47]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:04:48]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][10:04:48]: [Server #3995185] Selecting client #1 for training.
[INFO][10:04:48]: [Server #3995185] Sending the current model to client #1 (simulated).
[INFO][10:04:55]: [Server #3995185] Sending 507.38 MB of payload data to client #1 (simulated).
[INFO][10:04:55]: [Client #1] Selected by the server.
[INFO][10:04:55]: [Client #1] Loading its data source...
[INFO][10:04:55]: [Client #1] Dataset size: 2018
[INFO][10:04:55]: [Client #1] Sampler: iid
[INFO][10:04:56]: [Client #1] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:04:56]: [Client #1] Start to process inbound data.
[INFO][10:04:56]: [93m[1m[Client #1] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.05it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.06it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.08it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.06it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.02it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.02it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.07it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.06it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.05it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.03it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.624879519144694,)
[INFO][10:05:34]: [Client #1] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
{'train_runtime': 32.1496, 'train_samples_per_second': 188.307, 'train_steps_per_second': 2.986, 'train_loss': 2.624879519144694, 'epoch': 3.0}
[INFO][10:05:35]: [Client #1] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_1_3995237.pth.
[INFO][10:05:35]: [Client #1] Model trained.
[INFO][10:05:35]: [Client #1] Inbound data has been processed.
[INFO][10:05:35]: [Client #1] Outbound data is ready to be sent after being processed.
[INFO][10:05:46]: [Client #1] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:05:47]: [Server #3995185] Received 507.38 MB of payload data from client #1 (simulated).
[INFO][10:05:47]: [Server #3995185] Selecting client #66 for training.
[INFO][10:05:47]: [Server #3995185] Sending the current model to client #66 (simulated).
[INFO][10:05:52]: [Server #3995185] Sending 507.38 MB of payload data to client #66 (simulated).
[INFO][10:05:52]: [Client #66] Selected by the server.
[INFO][10:05:52]: [Client #66] Loading its data source...
[INFO][10:05:52]: [Client #66] Dataset size: 2018
[INFO][10:05:52]: [Client #66] Sampler: iid
[INFO][10:05:54]: [Client #66] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:05:54]: [Client #66] Start to process inbound data.
[INFO][10:05:54]: [93m[1m[Client #66] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.38it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.09it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.08it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.06it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.03it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.17it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.06it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.06it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.788888931274414,)
[INFO][10:06:32]: [Client #66] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
{'train_runtime': 32.2556, 'train_samples_per_second': 187.689, 'train_steps_per_second': 2.976, 'train_loss': 2.788888931274414, 'epoch': 3.0}
[INFO][10:06:32]: [Client #66] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_66_3995237.pth.
[INFO][10:06:33]: [Client #66] Model trained.
[INFO][10:06:33]: [Client #66] Inbound data has been processed.
[INFO][10:06:33]: [Client #66] Outbound data is ready to be sent after being processed.
[INFO][10:06:40]: [Client #66] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:06:41]: [Server #3995185] Received 507.38 MB of payload data from client #66 (simulated).
[INFO][10:06:41]: [Server #3995185] Selecting client #62 for training.
[INFO][10:06:41]: [Server #3995185] Sending the current model to client #62 (simulated).
[INFO][10:06:49]: [Server #3995185] Sending 507.38 MB of payload data to client #62 (simulated).
[INFO][10:06:49]: [Client #62] Selected by the server.
[INFO][10:06:49]: [Client #62] Loading its data source...
[INFO][10:06:49]: [Client #62] Dataset size: 2018
[INFO][10:06:49]: [Client #62] Sampler: iid
[INFO][10:06:50]: [Client #62] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:06:50]: [Client #62] Start to process inbound data.
[INFO][10:06:51]: [93m[1m[Client #62] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.97it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.13it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.98it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8190863927205405,)
[INFO][10:07:29]: [Client #62] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
{'train_runtime': 32.4225, 'train_samples_per_second': 186.722, 'train_steps_per_second': 2.961, 'train_loss': 2.8190863927205405, 'epoch': 3.0}
[INFO][10:07:30]: [Client #62] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_62_3995237.pth.
[INFO][10:07:30]: [Client #62] Model trained.
[INFO][10:07:30]: [Client #62] Inbound data has been processed.
[INFO][10:07:30]: [Client #62] Outbound data is ready to be sent after being processed.
[INFO][10:07:36]: [Client #62] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:07:37]: [Server #3995185] Received 507.38 MB of payload data from client #62 (simulated).
[INFO][10:07:37]: [Server #3995185] Selecting client #193 for training.
[INFO][10:07:37]: [Server #3995185] Sending the current model to client #193 (simulated).
[INFO][10:07:46]: [Server #3995185] Sending 507.38 MB of payload data to client #193 (simulated).
[INFO][10:07:46]: [Client #193] Selected by the server.
[INFO][10:07:46]: [Client #193] Loading its data source...
[INFO][10:07:46]: [Client #193] Dataset size: 2018
[INFO][10:07:46]: [Client #193] Sampler: iid
[INFO][10:07:47]: [Client #193] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:07:47]: [Client #193] Start to process inbound data.
[INFO][10:07:48]: [93m[1m[Client #193] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.51it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6757322947184243,)
[INFO][10:08:26]: [Client #193] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
{'train_runtime': 32.4381, 'train_samples_per_second': 186.632, 'train_steps_per_second': 2.959, 'train_loss': 2.6757322947184243, 'epoch': 3.0}
[INFO][10:08:26]: [Client #193] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_193_3995237.pth.
[INFO][10:08:27]: [Client #193] Model trained.
[INFO][10:08:27]: [Client #193] Inbound data has been processed.
[INFO][10:08:27]: [Client #193] Outbound data is ready to be sent after being processed.
[INFO][10:08:35]: [Client #193] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:08:36]: [Server #3995185] Received 507.38 MB of payload data from client #193 (simulated).
[INFO][10:08:36]: [Server #3995185] Selecting client #142 for training.
[INFO][10:08:36]: [Server #3995185] Sending the current model to client #142 (simulated).
[INFO][10:08:42]: [Server #3995185] Sending 507.38 MB of payload data to client #142 (simulated).
[INFO][10:08:42]: [Client #142] Selected by the server.
[INFO][10:08:42]: [Client #142] Loading its data source...
[INFO][10:08:42]: [Client #142] Dataset size: 2018
[INFO][10:08:42]: [Client #142] Sampler: iid
[INFO][10:08:43]: [Client #142] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:08:43]: [Client #142] Start to process inbound data.
[INFO][10:08:43]: [93m[1m[Client #142] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:26,  1.54s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.03it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.52it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.99it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.01it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.98it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.9093166987101235,)
[INFO][10:09:22]: [Client #142] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_142_3995237.pth.
{'train_runtime': 32.6203, 'train_samples_per_second': 185.59, 'train_steps_per_second': 2.943, 'train_loss': 2.9093166987101235, 'epoch': 3.0}
[INFO][10:09:22]: [Client #142] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_142_3995237.pth.
[INFO][10:09:23]: [Client #142] Model trained.
[INFO][10:09:23]: [Client #142] Inbound data has been processed.
[INFO][10:09:23]: [Client #142] Outbound data is ready to be sent after being processed.
[INFO][10:09:30]: [Client #142] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:09:31]: [Server #3995185] Received 507.38 MB of payload data from client #142 (simulated).
[INFO][10:09:31]: [Server #3995185] Selecting client #104 for training.
[INFO][10:09:31]: [Server #3995185] Sending the current model to client #104 (simulated).
[INFO][10:09:36]: [Server #3995185] Sending 507.38 MB of payload data to client #104 (simulated).
[INFO][10:09:36]: [Client #104] Selected by the server.
[INFO][10:09:36]: [Client #104] Loading its data source...
[INFO][10:09:36]: [Client #104] Dataset size: 2018
[INFO][10:09:36]: [Client #104] Sampler: iid
[INFO][10:09:37]: [Client #104] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:09:37]: [Client #104] Start to process inbound data.
[INFO][10:09:37]: [93m[1m[Client #104] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:30,  1.58s/it]  2%|â–         | 2/96 [00:01<01:19,  1.19it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.65it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.95it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  3.01it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:27,  3.05it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.08it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:26,  3.11it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.12it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:25,  3.13it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.13it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.14it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:24,  3.14it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.14it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.14it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:23,  3.14it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.14it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.14it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:22,  3.15it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.15it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.14it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:21,  3.14it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.14it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.14it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.13it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.13it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.58it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.43it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.34it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.28it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.21it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:17,  3.18it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.17it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.17it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.16it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.15it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.14it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.14it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:15,  3.14it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.14it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.13it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.13it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.13it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.13it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.13it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.13it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.12it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.12it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:18<00:12,  3.12it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.12it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:19<00:11,  3.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.12it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.12it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.12it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.12it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.58it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.43it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:08,  3.33it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.27it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.23it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:22<00:08,  3.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.18it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.16it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:23<00:07,  3.15it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.15it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.14it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:24<00:06,  3.14it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.13it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.13it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.13it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.13it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.12it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.12it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.12it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.11it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.10it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.05it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8769121170043945,)
[INFO][10:10:15]: [Client #104] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_104_3995237.pth.
{'train_runtime': 31.5185, 'train_samples_per_second': 192.078, 'train_steps_per_second': 3.046, 'train_loss': 2.8769121170043945, 'epoch': 3.0}
[INFO][10:10:15]: [Client #104] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_104_3995237.pth.
[INFO][10:10:16]: [Client #104] Model trained.
[INFO][10:10:16]: [Client #104] Inbound data has been processed.
[INFO][10:10:16]: [Client #104] Outbound data is ready to be sent after being processed.
[INFO][10:10:21]: [Client #104] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:10:22]: [Server #3995185] Received 507.38 MB of payload data from client #104 (simulated).
[INFO][10:10:22]: [Server #3995185] Selecting client #71 for training.
[INFO][10:10:22]: [Server #3995185] Sending the current model to client #71 (simulated).
[INFO][10:10:27]: [Server #3995185] Sending 507.38 MB of payload data to client #71 (simulated).
[INFO][10:10:27]: [Client #71] Selected by the server.
[INFO][10:10:27]: [Client #71] Loading its data source...
[INFO][10:10:27]: [Client #71] Dataset size: 2018
[INFO][10:10:27]: [Client #71] Sampler: iid
[INFO][10:10:29]: [Client #71] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:10:29]: [Client #71] Start to process inbound data.
[INFO][10:10:29]: [93m[1m[Client #71] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.77it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.60it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.76it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.02it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.02it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.22it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.05it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.98it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.98it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.642995516459147,)
[INFO][10:11:07]: [Client #71] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
{'train_runtime': 32.4662, 'train_samples_per_second': 186.471, 'train_steps_per_second': 2.957, 'train_loss': 2.642995516459147, 'epoch': 3.0}
[INFO][10:11:08]: [Client #71] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_71_3995237.pth.
[INFO][10:11:09]: [Client #71] Model trained.
[INFO][10:11:09]: [Client #71] Inbound data has been processed.
[INFO][10:11:09]: [Client #71] Outbound data is ready to be sent after being processed.
[INFO][10:11:14]: [Client #71] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:11:15]: [Server #3995185] Received 507.38 MB of payload data from client #71 (simulated).
[INFO][10:11:15]: [Server #3995185] Selecting client #163 for training.
[INFO][10:11:15]: [Server #3995185] Sending the current model to client #163 (simulated).
[INFO][10:11:22]: [Server #3995185] Sending 507.38 MB of payload data to client #163 (simulated).
[INFO][10:11:22]: [Client #163] Selected by the server.
[INFO][10:11:22]: [Client #163] Loading its data source...
[INFO][10:11:22]: [Client #163] Dataset size: 2018
[INFO][10:11:22]: [Client #163] Sampler: iid
[INFO][10:11:23]: [Client #163] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:11:23]: [Client #163] Start to process inbound data.
[INFO][10:11:24]: [93m[1m[Client #163] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.40s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.58it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.84it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.05it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.36it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.21it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.14it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.07it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.03it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.50it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.511748790740967,)
[INFO][10:12:02]: [Client #163] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
{'train_runtime': 32.2467, 'train_samples_per_second': 187.74, 'train_steps_per_second': 2.977, 'train_loss': 2.511748790740967, 'epoch': 3.0}
[INFO][10:12:03]: [Client #163] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_163_3995237.pth.
[INFO][10:12:03]: [Client #163] Model trained.
[INFO][10:12:03]: [Client #163] Inbound data has been processed.
[INFO][10:12:03]: [Client #163] Outbound data is ready to be sent after being processed.
[INFO][10:12:08]: [Client #163] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:12:09]: [Server #3995185] Received 507.38 MB of payload data from client #163 (simulated).
[INFO][10:12:09]: [Server #3995185] Selecting client #188 for training.
[INFO][10:12:09]: [Server #3995185] Sending the current model to client #188 (simulated).
[INFO][10:12:15]: [Server #3995185] Sending 507.38 MB of payload data to client #188 (simulated).
[INFO][10:12:15]: [Client #188] Selected by the server.
[INFO][10:12:15]: [Client #188] Loading its data source...
[INFO][10:12:15]: [Client #188] Dataset size: 2018
[INFO][10:12:15]: [Client #188] Sampler: iid
[INFO][10:12:16]: [Client #188] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:12:16]: [Client #188] Start to process inbound data.
[INFO][10:12:17]: [93m[1m[Client #188] Started training in communication round #39.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:09,  1.36s/it]  2%|â–         | 2/96 [00:01<01:10,  1.34it/s]  3%|â–Ž         | 3/96 [00:02<00:51,  1.80it/s]  4%|â–         | 4/96 [00:02<00:43,  2.14it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:02<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:03<00:30,  2.88it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.09it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.11it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:24,  3.13it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.13it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.13it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:23,  3.13it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.13it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.13it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:22,  3.13it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.13it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.13it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.14it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.14it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.14it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.14it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.14it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.59it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.44it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.34it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.28it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.22it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.20it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:17,  3.18it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.17it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.16it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.15it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.15it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.15it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.14it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:15,  3.14it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:15<00:15,  3.14it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.14it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:14,  3.14it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:16<00:14,  3.14it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.14it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.14it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:17<00:13,  3.13it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.13it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.13it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:18<00:12,  3.13it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.13it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.12it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:19<00:11,  3.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.13it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.13it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.13it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.13it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.58it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.43it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:21<00:09,  3.33it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.27it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.23it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:22<00:08,  3.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.17it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.16it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:23<00:07,  3.15it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.14it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.14it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:24<00:06,  3.13it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.13it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.13it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.12it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.12it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.12it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.12it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.12it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.11it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.11it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.11it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:28<00:02,  3.11it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.11it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.11it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:29<00:01,  3.11it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:30<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.05it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8572400410970054,)
[INFO][10:12:54]: [Client #188] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
{'train_runtime': 31.4321, 'train_samples_per_second': 192.605, 'train_steps_per_second': 3.054, 'train_loss': 2.8572400410970054, 'epoch': 3.0}
[INFO][10:12:55]: [Client #188] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_188_3995237.pth.
[INFO][10:12:56]: [Client #188] Model trained.
[INFO][10:12:56]: [Client #188] Inbound data has been processed.
[INFO][10:12:56]: [Client #188] Outbound data is ready to be sent after being processed.
[INFO][10:13:02]: [Client #188] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:13:03]: [Server #3995185] Received 507.38 MB of payload data from client #188 (simulated).
[INFO][10:13:03]: [Server #3995185] Adding client #33 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #37 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #41 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #43 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #89 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #119 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #132 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #151 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #183 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Adding client #76 to the list of clients for aggregation.
[INFO][10:13:03]: [Server #3995185] Aggregating 10 clients in total.
[INFO][10:13:03]: [Server #3995185] Updated weights have been received.
[INFO][10:13:04]: [Server #3995185] Aggregating model weight deltas.
[INFO][10:13:05]: [Server #3995185] Finished aggregating updated weights.
[INFO][10:13:05]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 5/15 [00:00<00:00, 49.55it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 10/15 [00:00<00:00, 41.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.04it/s]
[INFO][10:13:14]: [93m[1m[Server #3995185] Global model perplexity: 22.48
[0m
[INFO][10:13:14]: [Server #3995185] All client reports have been processed.
[INFO][10:13:14]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_39.pth.
[INFO][10:13:21]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_39.pth.
[INFO][10:13:21]: [93m[1m
[Server #3995185] Starting round 40/50.[0m
[INFO][10:13:21]: [Server #3995185] Selected clients: [10, 119, 149, 53, 46, 41, 45, 132, 85, 88]
[INFO][10:13:21]: [Server #3995185] Selecting client #10 for training.
[INFO][10:13:21]: [Server #3995185] Sending the current model to client #10 (simulated).
[INFO][10:13:27]: [Server #3995185] Sending 507.38 MB of payload data to client #10 (simulated).
[INFO][10:13:27]: [Client #10] Selected by the server.
[INFO][10:13:27]: [Client #10] Loading its data source...
[INFO][10:13:27]: [Client #10] Dataset size: 2018
[INFO][10:13:27]: [Client #10] Sampler: iid
[INFO][10:13:29]: [Client #10] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:13:29]: [Client #10] Start to process inbound data.
[INFO][10:13:30]: [93m[1m[Client #10] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:33,  1.62s/it]  2%|â–         | 2/96 [00:01<01:20,  1.17it/s]  3%|â–Ž         | 3/96 [00:02<00:56,  1.64it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.30it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.53it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.81it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.96it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.04it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.06it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.09it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.09it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.07it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.18it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.10it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.08it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.08it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.07it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.04it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.04it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.51it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.38it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.19it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.05it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.03it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.02it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.02it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.729578653971354,)
[INFO][10:14:08]: [Client #10] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
{'train_runtime': 32.251, 'train_samples_per_second': 187.715, 'train_steps_per_second': 2.977, 'train_loss': 2.729578653971354, 'epoch': 3.0}
[INFO][10:14:08]: [Client #10] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_10_3995237.pth.
[INFO][10:14:10]: [Client #10] Model trained.
[INFO][10:14:10]: [Client #10] Inbound data has been processed.
[INFO][10:14:10]: [Client #10] Outbound data is ready to be sent after being processed.
[INFO][10:14:19]: [Client #10] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:14:20]: [Server #3995185] Received 507.38 MB of payload data from client #10 (simulated).
[INFO][10:14:20]: [Server #3995185] Selecting client #119 for training.
[INFO][10:14:20]: [Server #3995185] Sending the current model to client #119 (simulated).
[INFO][10:14:26]: [Server #3995185] Sending 507.38 MB of payload data to client #119 (simulated).
[INFO][10:14:26]: [Client #119] Selected by the server.
[INFO][10:14:26]: [Client #119] Loading its data source...
[INFO][10:14:26]: [Client #119] Dataset size: 2018
[INFO][10:14:26]: [Client #119] Sampler: iid
[INFO][10:14:27]: [Client #119] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:14:27]: [Client #119] Start to process inbound data.
[INFO][10:14:28]: [93m[1m[Client #119] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:19,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.08it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.83it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.04it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.09it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.08it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.06it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.11it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.08it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.98it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.533606211344401,)
[INFO][10:15:06]: [Client #119] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
{'train_runtime': 32.2447, 'train_samples_per_second': 187.752, 'train_steps_per_second': 2.977, 'train_loss': 2.533606211344401, 'epoch': 3.0}
[INFO][10:15:07]: [Client #119] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_119_3995237.pth.
[INFO][10:15:07]: [Client #119] Model trained.
[INFO][10:15:07]: [Client #119] Inbound data has been processed.
[INFO][10:15:07]: [Client #119] Outbound data is ready to be sent after being processed.
[INFO][10:15:12]: [Client #119] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:15:13]: [Server #3995185] Received 507.38 MB of payload data from client #119 (simulated).
[INFO][10:15:13]: [Server #3995185] Selecting client #149 for training.
[INFO][10:15:13]: [Server #3995185] Sending the current model to client #149 (simulated).
[INFO][10:15:20]: [Server #3995185] Sending 507.38 MB of payload data to client #149 (simulated).
[INFO][10:15:20]: [Client #149] Selected by the server.
[INFO][10:15:20]: [Client #149] Loading its data source...
[INFO][10:15:20]: [Client #149] Dataset size: 2018
[INFO][10:15:20]: [Client #149] Sampler: iid
[INFO][10:15:21]: [Client #149] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:15:21]: [Client #149] Start to process inbound data.
[INFO][10:15:22]: [93m[1m[Client #149] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:12,  1.39s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.01it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.02it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.02it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.02it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.06it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.00it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  2.99it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.99it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.00it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.00it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6129959424336753,)
[INFO][10:16:00]: [Client #149] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
{'train_runtime': 32.4971, 'train_samples_per_second': 186.294, 'train_steps_per_second': 2.954, 'train_loss': 2.6129959424336753, 'epoch': 3.0}
[INFO][10:16:01]: [Client #149] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_149_3995237.pth.
[INFO][10:16:02]: [Client #149] Model trained.
[INFO][10:16:02]: [Client #149] Inbound data has been processed.
[INFO][10:16:02]: [Client #149] Outbound data is ready to be sent after being processed.
[INFO][10:16:08]: [Client #149] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:16:09]: [Server #3995185] Received 507.38 MB of payload data from client #149 (simulated).
[INFO][10:16:09]: [Server #3995185] Selecting client #53 for training.
[INFO][10:16:09]: [Server #3995185] Sending the current model to client #53 (simulated).
[INFO][10:16:14]: [Server #3995185] Sending 507.38 MB of payload data to client #53 (simulated).
[INFO][10:16:14]: [Client #53] Selected by the server.
[INFO][10:16:14]: [Client #53] Loading its data source...
[INFO][10:16:14]: [Client #53] Dataset size: 2018
[INFO][10:16:14]: [Client #53] Sampler: iid
[INFO][10:16:15]: [Client #53] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:16:15]: [Client #53] Start to process inbound data.
[INFO][10:16:17]: [93m[1m[Client #53] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.75it/s]  4%|â–         | 4/96 [00:02<00:43,  2.12it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.01it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.05it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.05it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.05it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.09it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.55it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.41it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.31it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.25it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.19it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.13it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.13it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.09it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.10it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.10it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.08it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.08it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.04it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.05it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.05it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.52it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.15it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.14it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.12it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:08,  3.09it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.02it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.01it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.5831262270609536,)
[INFO][10:16:54]: [Client #53] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
{'train_runtime': 32.1183, 'train_samples_per_second': 188.491, 'train_steps_per_second': 2.989, 'train_loss': 2.5831262270609536, 'epoch': 3.0}
[INFO][10:16:55]: [Client #53] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_53_3995237.pth.
[INFO][10:16:56]: [Client #53] Model trained.
[INFO][10:16:56]: [Client #53] Inbound data has been processed.
[INFO][10:16:56]: [Client #53] Outbound data is ready to be sent after being processed.
[INFO][10:17:02]: [Client #53] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:17:03]: [Server #3995185] Received 507.38 MB of payload data from client #53 (simulated).
[INFO][10:17:03]: [Server #3995185] Selecting client #46 for training.
[INFO][10:17:03]: [Server #3995185] Sending the current model to client #46 (simulated).
[INFO][10:17:08]: [Server #3995185] Sending 507.38 MB of payload data to client #46 (simulated).
[INFO][10:17:08]: [Client #46] Selected by the server.
[INFO][10:17:08]: [Client #46] Loading its data source...
[INFO][10:17:08]: [Client #46] Dataset size: 2018
[INFO][10:17:08]: [Client #46] Sampler: iid
[INFO][10:17:09]: [Client #46] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:17:09]: [Client #46] Start to process inbound data.
[INFO][10:17:10]: [93m[1m[Client #46] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.13it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.74it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.85it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.90it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.07it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.06it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.08it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.10it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.28it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.24it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.12it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.03it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.04it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.02it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.02it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.02it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.02it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.04it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.02it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.02it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6697298685709634,)
[INFO][10:17:47]: [Client #46] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
{'train_runtime': 32.2514, 'train_samples_per_second': 187.713, 'train_steps_per_second': 2.977, 'train_loss': 2.6697298685709634, 'epoch': 3.0}
[INFO][10:17:48]: [Client #46] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_46_3995237.pth.
[INFO][10:17:49]: [Client #46] Model trained.
[INFO][10:17:49]: [Client #46] Inbound data has been processed.
[INFO][10:17:49]: [Client #46] Outbound data is ready to be sent after being processed.
[INFO][10:17:57]: [Client #46] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:17:58]: [Server #3995185] Received 507.38 MB of payload data from client #46 (simulated).
[INFO][10:17:58]: [Server #3995185] Selecting client #41 for training.
[INFO][10:17:58]: [Server #3995185] Sending the current model to client #41 (simulated).
[INFO][10:18:03]: [Server #3995185] Sending 507.38 MB of payload data to client #41 (simulated).
[INFO][10:18:03]: [Client #41] Selected by the server.
[INFO][10:18:03]: [Client #41] Loading its data source...
[INFO][10:18:03]: [Client #41] Dataset size: 2018
[INFO][10:18:03]: [Client #41] Sampler: iid
[INFO][10:18:04]: [Client #41] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:18:04]: [Client #41] Start to process inbound data.
[INFO][10:18:05]: [93m[1m[Client #41] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  3.00it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.07it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.07it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.09it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.39it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.20it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.16it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.14it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.10it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.09it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.03it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.04it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.03it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.03it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.34it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.05it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.03it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.03it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.02it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.646423657735189,)
[INFO][10:18:43]: [Client #41] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
{'train_runtime': 32.268, 'train_samples_per_second': 187.616, 'train_steps_per_second': 2.975, 'train_loss': 2.646423657735189, 'epoch': 3.0}
[INFO][10:18:44]: [Client #41] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_41_3995237.pth.
[INFO][10:18:44]: [Client #41] Model trained.
[INFO][10:18:44]: [Client #41] Inbound data has been processed.
[INFO][10:18:44]: [Client #41] Outbound data is ready to be sent after being processed.
[INFO][10:18:52]: [Client #41] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:18:53]: [Server #3995185] Received 507.38 MB of payload data from client #41 (simulated).
[INFO][10:18:53]: [Server #3995185] Selecting client #45 for training.
[INFO][10:18:53]: [Server #3995185] Sending the current model to client #45 (simulated).
[INFO][10:18:59]: [Server #3995185] Sending 507.38 MB of payload data to client #45 (simulated).
[INFO][10:18:59]: [Client #45] Selected by the server.
[INFO][10:18:59]: [Client #45] Loading its data source...
[INFO][10:18:59]: [Client #45] Dataset size: 2018
[INFO][10:18:59]: [Client #45] Sampler: iid
[INFO][10:19:00]: [Client #45] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:19:00]: [Client #45] Start to process inbound data.
[INFO][10:19:01]: [93m[1m[Client #45] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:25,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.21it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.67it/s]  4%|â–         | 4/96 [00:02<00:45,  2.02it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.29it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.50it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.64it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.74it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.83it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.88it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.93it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:27,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.00it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  2.99it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.00it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.00it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.00it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.01it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.00it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.00it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.01it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.01it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.00it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  2.99it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.07it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:14,  3.08it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.08it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.09it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.08it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.07it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.53it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.37it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.17it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.04it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.98it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.98it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.99it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.98it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.508533159891764,)
[INFO][10:19:40]: [Client #45] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
{'train_runtime': 32.5121, 'train_samples_per_second': 186.208, 'train_steps_per_second': 2.953, 'train_loss': 2.508533159891764, 'epoch': 3.0}
[INFO][10:19:41]: [Client #45] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_45_3995237.pth.
[INFO][10:19:42]: [Client #45] Model trained.
[INFO][10:19:42]: [Client #45] Inbound data has been processed.
[INFO][10:19:42]: [Client #45] Outbound data is ready to be sent after being processed.
[INFO][10:19:52]: [Client #45] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:19:53]: [Server #3995185] Received 507.38 MB of payload data from client #45 (simulated).
[INFO][10:19:53]: [Server #3995185] Selecting client #132 for training.
[INFO][10:19:53]: [Server #3995185] Sending the current model to client #132 (simulated).
[INFO][10:19:59]: [Server #3995185] Sending 507.38 MB of payload data to client #132 (simulated).
[INFO][10:19:59]: [Client #132] Selected by the server.
[INFO][10:19:59]: [Client #132] Loading its data source...
[INFO][10:19:59]: [Client #132] Dataset size: 2018
[INFO][10:19:59]: [Client #132] Sampler: iid
[INFO][10:20:00]: [Client #132] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:20:00]: [Client #132] Start to process inbound data.
[INFO][10:20:01]: [93m[1m[Client #132] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:25,  1.53s/it]  2%|â–         | 2/96 [00:01<01:17,  1.22it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.33it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.56it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.72it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.95it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.02it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.08it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.09it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.10it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.56it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.20it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.08it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.08it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.07it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.04it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.06it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.04it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.04it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.04it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.48it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.35it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.14it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.07it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.06it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.05it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.06it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.04it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.03it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.03it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.05it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.04it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.04it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.03it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6558252970377603,)
[INFO][10:20:39]: [Client #132] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
{'train_runtime': 32.2572, 'train_samples_per_second': 187.679, 'train_steps_per_second': 2.976, 'train_loss': 2.6558252970377603, 'epoch': 3.0}
[INFO][10:20:39]: [Client #132] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_132_3995237.pth.
[INFO][10:20:41]: [Client #132] Model trained.
[INFO][10:20:41]: [Client #132] Inbound data has been processed.
[INFO][10:20:41]: [Client #132] Outbound data is ready to be sent after being processed.
[INFO][10:20:46]: [Client #132] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:20:47]: [Server #3995185] Received 507.38 MB of payload data from client #132 (simulated).
[INFO][10:20:47]: [Server #3995185] Selecting client #85 for training.
[INFO][10:20:47]: [Server #3995185] Sending the current model to client #85 (simulated).
[INFO][10:20:52]: [Server #3995185] Sending 507.38 MB of payload data to client #85 (simulated).
[INFO][10:20:52]: [Client #85] Selected by the server.
[INFO][10:20:52]: [Client #85] Loading its data source...
[INFO][10:20:52]: [Client #85] Dataset size: 2018
[INFO][10:20:52]: [Client #85] Sampler: iid
[INFO][10:20:54]: [Client #85] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:20:54]: [Client #85] Start to process inbound data.
[INFO][10:20:55]: [93m[1m[Client #85] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:11,  1.39s/it]  2%|â–         | 2/96 [00:01<01:11,  1.31it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.78it/s]  4%|â–         | 4/96 [00:02<00:42,  2.15it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.41it/s]  6%|â–‹         | 6/96 [00:02<00:34,  2.62it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.76it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:03<00:29,  2.93it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.97it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.03it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.04it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.05it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.06it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.08it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.08it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.08it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.09it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.04it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.24it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.17it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.07it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.04it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.04it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.03it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.00it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:15,  2.99it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  2.99it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.05it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.07it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.04it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.04it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.03it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.24it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.16it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.06it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.07it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.08it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.08it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.07it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.07it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.06it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.02it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.98it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.97it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.6650091807047525,)
[INFO][10:21:33]: [Client #85] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
{'train_runtime': 32.2207, 'train_samples_per_second': 187.892, 'train_steps_per_second': 2.979, 'train_loss': 2.6650091807047525, 'epoch': 3.0}
[INFO][10:21:34]: [Client #85] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_85_3995237.pth.
[INFO][10:21:35]: [Client #85] Model trained.
[INFO][10:21:35]: [Client #85] Inbound data has been processed.
[INFO][10:21:35]: [Client #85] Outbound data is ready to be sent after being processed.
[INFO][10:21:40]: [Client #85] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:21:42]: [Server #3995185] Received 507.38 MB of payload data from client #85 (simulated).
[INFO][10:21:42]: [Server #3995185] Selecting client #88 for training.
[INFO][10:21:42]: [Server #3995185] Sending the current model to client #88 (simulated).
[INFO][10:21:47]: [Server #3995185] Sending 507.38 MB of payload data to client #88 (simulated).
[INFO][10:21:47]: [Client #88] Selected by the server.
[INFO][10:21:47]: [Client #88] Loading its data source...
[INFO][10:21:47]: [Client #88] Dataset size: 2018
[INFO][10:21:47]: [Client #88] Sampler: iid
[INFO][10:21:48]: [Client #88] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:21:48]: [Client #88] Start to process inbound data.
[INFO][10:21:48]: [93m[1m[Client #88] Started training in communication round #40.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:37,  2.40it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.59it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.84it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  2.98it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  3.00it/s] 12%|â–ˆâ–Ž        | 12/96 [00:04<00:27,  3.02it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.04it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.06it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.07it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.07it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.08it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.07it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.07it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.06it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.04it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.06it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.13it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.12it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:18,  3.11it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.11it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.10it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:17,  3.08it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.07it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.06it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.07it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.05it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.05it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.05it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.05it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.07it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.07it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.05it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.06it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.07it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.05it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.05it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.03it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.04it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.25it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.16it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.07it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.08it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.07it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.09it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.10it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.10it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.08it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.06it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.03it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.03it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.99it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.8698174158732095,)
[INFO][10:22:26]: [Client #88] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
{'train_runtime': 32.1034, 'train_samples_per_second': 188.578, 'train_steps_per_second': 2.99, 'train_loss': 2.8698174158732095, 'epoch': 3.0}
[INFO][10:22:27]: [Client #88] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_88_3995237.pth.
[INFO][10:22:27]: [Client #88] Model trained.
[INFO][10:22:27]: [Client #88] Inbound data has been processed.
[INFO][10:22:27]: [Client #88] Outbound data is ready to be sent after being processed.
[INFO][10:22:32]: [Client #88] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:22:34]: [Server #3995185] Received 507.38 MB of payload data from client #88 (simulated).
[INFO][10:22:34]: [Server #3995185] Adding client #1 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #62 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #66 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #71 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #163 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #188 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #193 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #200 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #104 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Adding client #142 to the list of clients for aggregation.
[INFO][10:22:34]: [Server #3995185] Aggregating 10 clients in total.
[INFO][10:22:34]: [Server #3995185] Updated weights have been received.
[INFO][10:22:36]: [Server #3995185] Aggregating model weight deltas.
[INFO][10:22:37]: [Server #3995185] Finished aggregating updated weights.
[INFO][10:22:37]: [Server #3995185] Started model testing.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
***** Running Evaluation *****
  Num examples = 120
  Batch size = 8
  0%|          | 0/15 [00:00<?, ?it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 6/15 [00:00<00:00, 47.45it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 11/15 [00:00<00:00, 41.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 39.29it/s]
[INFO][10:22:45]: [93m[1m[Server #3995185] Global model perplexity: 21.86
[0m
[INFO][10:22:45]: [Server #3995185] All client reports have been processed.
[INFO][10:22:45]: [Server #3995185] Saving the checkpoint to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_40.pth.
[INFO][10:22:49]: [Server #3995185] Model saved to /data/ykang/plato/checkpoints/huggingface/fedavg/checkpoint_bert-base-uncased_40.pth.
[INFO][10:22:49]: [93m[1m
[Server #3995185] Starting round 41/50.[0m
[INFO][10:22:49]: [Server #3995185] Selected clients: [89, 200, 113, 54, 3, 37, 159, 9, 7, 62]
[INFO][10:22:49]: [Server #3995185] Selecting client #89 for training.
[INFO][10:22:49]: [Server #3995185] Sending the current model to client #89 (simulated).
[INFO][10:22:54]: [Server #3995185] Sending 507.38 MB of payload data to client #89 (simulated).
[INFO][10:22:54]: [Client #89] Selected by the server.
[INFO][10:22:54]: [Client #89] Loading its data source...
[INFO][10:22:54]: [Client #89] Dataset size: 2018
[INFO][10:22:54]: [Client #89] Sampler: iid
[INFO][10:22:55]: [Client #89] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:22:55]: [Client #89] Start to process inbound data.
[INFO][10:22:56]: [93m[1m[Client #89] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:21,  1.49s/it]  2%|â–         | 2/96 [00:01<01:15,  1.24it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.70it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.54it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.03it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.05it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.04it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.04it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.06it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.05it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.04it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.06it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.52it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.25it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.18it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.14it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.10it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.06it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.06it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.05it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.04it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.06it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.06it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.06it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.08it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.06it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.05it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.06it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.05it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.05it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.06it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.06it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.06it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.07it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.53it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.39it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.20it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.18it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.10it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.08it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.03it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.04it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.05it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.06it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.04it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.05it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.06it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.04it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.05it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.03it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.04it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.04it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.02it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.98it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.618018309275309,)
[INFO][10:23:34]: [Client #89] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
{'train_runtime': 32.2563, 'train_samples_per_second': 187.684, 'train_steps_per_second': 2.976, 'train_loss': 2.618018309275309, 'epoch': 3.0}
[INFO][10:23:35]: [Client #89] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_89_3995237.pth.
[INFO][10:23:36]: [Client #89] Model trained.
[INFO][10:23:36]: [Client #89] Inbound data has been processed.
[INFO][10:23:36]: [Client #89] Outbound data is ready to be sent after being processed.
[INFO][10:23:41]: [Client #89] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:23:42]: [Server #3995185] Received 507.38 MB of payload data from client #89 (simulated).
[INFO][10:23:42]: [Server #3995185] Selecting client #200 for training.
[INFO][10:23:42]: [Server #3995185] Sending the current model to client #200 (simulated).
[INFO][10:23:47]: [Server #3995185] Sending 507.38 MB of payload data to client #200 (simulated).
[INFO][10:23:47]: [Client #200] Selected by the server.
[INFO][10:23:47]: [Client #200] Loading its data source...
[INFO][10:23:47]: [Client #200] Dataset size: 2018
[INFO][10:23:47]: [Client #200] Sampler: iid
[INFO][10:23:49]: [Client #200] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:23:49]: [Client #200] Start to process inbound data.
[INFO][10:23:49]: [93m[1m[Client #200] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:24,  1.52s/it]  2%|â–         | 2/96 [00:01<01:17,  1.22it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.69it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.35it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.96it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.98it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.02it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.02it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.01it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.01it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.05it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.06it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.07it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.07it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.08it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.08it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.54it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.38it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.29it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.22it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.15it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.12it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.09it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.07it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.05it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.04it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.03it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.02it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:14,  2.99it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  2.99it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.00it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.00it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.31it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.02it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.01it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.00it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.00it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.01it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7582664489746094,)
[INFO][10:24:27]: [Client #200] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
{'train_runtime': 32.4787, 'train_samples_per_second': 186.399, 'train_steps_per_second': 2.956, 'train_loss': 2.7582664489746094, 'epoch': 3.0}
[INFO][10:24:28]: [Client #200] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_200_3995237.pth.
[INFO][10:24:29]: [Client #200] Model trained.
[INFO][10:24:29]: [Client #200] Inbound data has been processed.
[INFO][10:24:29]: [Client #200] Outbound data is ready to be sent after being processed.
[INFO][10:24:35]: [Client #200] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:24:36]: [Server #3995185] Received 507.38 MB of payload data from client #200 (simulated).
[INFO][10:24:36]: [Server #3995185] Selecting client #113 for training.
[INFO][10:24:36]: [Server #3995185] Sending the current model to client #113 (simulated).
[INFO][10:24:41]: [Server #3995185] Sending 507.38 MB of payload data to client #113 (simulated).
[INFO][10:24:41]: [Client #113] Selected by the server.
[INFO][10:24:41]: [Client #113] Loading its data source...
[INFO][10:24:41]: [Client #113] Dataset size: 2018
[INFO][10:24:41]: [Client #113] Sampler: iid
[INFO][10:24:42]: [Client #113] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:24:42]: [Client #113] Start to process inbound data.
[INFO][10:24:43]: [93m[1m[Client #113] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:17,  1.45s/it]  2%|â–         | 2/96 [00:01<01:14,  1.27it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.73it/s]  4%|â–         | 4/96 [00:02<00:44,  2.09it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.36it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.70it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.80it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.86it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.91it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.94it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.99it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.00it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.02it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.02it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.03it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.03it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.04it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.02it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.01it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.47it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:19,  3.31it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.02it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.01it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.32it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.14it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.05it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.01it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.01it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.00it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.00it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.01it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.00it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.99it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.00it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.783891042073568,)
[INFO][10:25:21]: [Client #113] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_113_3995237.pth.
{'train_runtime': 32.5259, 'train_samples_per_second': 186.129, 'train_steps_per_second': 2.951, 'train_loss': 2.783891042073568, 'epoch': 3.0}
[INFO][10:25:22]: [Client #113] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_113_3995237.pth.
[INFO][10:25:23]: [Client #113] Model trained.
[INFO][10:25:23]: [Client #113] Inbound data has been processed.
[INFO][10:25:23]: [Client #113] Outbound data is ready to be sent after being processed.
[INFO][10:25:28]: [Client #113] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:25:29]: [Server #3995185] Received 507.38 MB of payload data from client #113 (simulated).
[INFO][10:25:29]: [Server #3995185] Selecting client #54 for training.
[INFO][10:25:29]: [Server #3995185] Sending the current model to client #54 (simulated).
[INFO][10:25:34]: [Server #3995185] Sending 507.38 MB of payload data to client #54 (simulated).
[INFO][10:25:34]: [Client #54] Selected by the server.
[INFO][10:25:34]: [Client #54] Loading its data source...
[INFO][10:25:34]: [Client #54] Dataset size: 2018
[INFO][10:25:34]: [Client #54] Sampler: iid
[INFO][10:25:36]: [Client #54] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:25:36]: [Client #54] Start to process inbound data.
[INFO][10:25:36]: [93m[1m[Client #54] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:39,  1.68s/it]  2%|â–         | 2/96 [00:02<01:23,  1.13it/s]  3%|â–Ž         | 3/96 [00:02<00:58,  1.58it/s]  4%|â–         | 4/96 [00:02<00:47,  1.95it/s]  5%|â–Œ         | 5/96 [00:02<00:40,  2.24it/s]  6%|â–‹         | 6/96 [00:03<00:36,  2.46it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.62it/s]  8%|â–Š         | 8/96 [00:03<00:32,  2.73it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.82it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.87it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.98it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.00it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.05it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.04it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.05it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.04it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.03it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.03it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.03it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.02it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.48it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:12<00:18,  3.32it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.21it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.15it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:13<00:19,  3.11it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.08it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:14<00:18,  3.04it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.03it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:15<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:16<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:17<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.01it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:18<00:14,  3.02it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.03it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.05it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:19<00:13,  3.05it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.03it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.04it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:20<00:12,  3.03it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.04it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.03it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:21<00:11,  3.03it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.02it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.02it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:22<00:10,  3.02it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.49it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.33it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.18it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.13it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.09it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.06it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.06it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.05it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.03it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.02it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.02it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.01it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.02it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.01it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  3.02it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:03,  3.01it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  3.02it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  3.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:02,  3.01it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  3.02it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.01it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.01it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.01it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  3.01it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.94it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.766626993815104,)
[INFO][10:26:14]: [Client #54] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
{'train_runtime': 32.6606, 'train_samples_per_second': 185.361, 'train_steps_per_second': 2.939, 'train_loss': 2.766626993815104, 'epoch': 3.0}
[INFO][10:26:15]: [Client #54] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_54_3995237.pth.
[INFO][10:26:16]: [Client #54] Model trained.
[INFO][10:26:16]: [Client #54] Inbound data has been processed.
[INFO][10:26:16]: [Client #54] Outbound data is ready to be sent after being processed.
[INFO][10:26:21]: [Client #54] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:26:22]: [Server #3995185] Received 507.38 MB of payload data from client #54 (simulated).
[INFO][10:26:22]: [Server #3995185] Selecting client #3 for training.
[INFO][10:26:22]: [Server #3995185] Sending the current model to client #3 (simulated).
[INFO][10:26:27]: [Server #3995185] Sending 507.38 MB of payload data to client #3 (simulated).
[INFO][10:26:27]: [Client #3] Selected by the server.
[INFO][10:26:27]: [Client #3] Loading its data source...
[INFO][10:26:27]: [Client #3] Dataset size: 2018
[INFO][10:26:27]: [Client #3] Sampler: iid
[INFO][10:26:28]: [Client #3] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:26:28]: [Client #3] Start to process inbound data.
[INFO][10:26:29]: [93m[1m[Client #3] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:14,  1.42s/it]  2%|â–         | 2/96 [00:01<01:12,  1.29it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.39it/s]  6%|â–‹         | 6/96 [00:03<00:34,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.89it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.93it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.99it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.01it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.07it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.08it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.07it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.07it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.07it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.06it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.08it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.06it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.05it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.04it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.03it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.03it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.33it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.23it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.16it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.12it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.09it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.06it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.05it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.04it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.03it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.02it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.01it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.01it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.03it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.01it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.01it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.07it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.06it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.04it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.03it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.02it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.01it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  3.00it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.00it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  2.99it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  2.99it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.99it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  2.99it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  3.00it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  2.99it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.96it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.7506017684936523,)
[INFO][10:27:08]: [Client #3] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3995237.pth.
{'train_runtime': 32.4224, 'train_samples_per_second': 186.723, 'train_steps_per_second': 2.961, 'train_loss': 2.7506017684936523, 'epoch': 3.0}
[INFO][10:27:08]: [Client #3] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_3_3995237.pth.
[INFO][10:27:09]: [Client #3] Model trained.
[INFO][10:27:09]: [Client #3] Inbound data has been processed.
[INFO][10:27:09]: [Client #3] Outbound data is ready to be sent after being processed.
[INFO][10:27:15]: [Client #3] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:27:16]: [Server #3995185] Received 507.38 MB of payload data from client #3 (simulated).
[INFO][10:27:16]: [Server #3995185] Selecting client #37 for training.
[INFO][10:27:16]: [Server #3995185] Sending the current model to client #37 (simulated).
[INFO][10:27:21]: [Server #3995185] Sending 507.38 MB of payload data to client #37 (simulated).
[INFO][10:27:21]: [Client #37] Selected by the server.
[INFO][10:27:21]: [Client #37] Loading its data source...
[INFO][10:27:21]: [Client #37] Dataset size: 2018
[INFO][10:27:21]: [Client #37] Sampler: iid
[INFO][10:27:22]: [Client #37] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:27:22]: [Client #37] Start to process inbound data.
[INFO][10:27:23]: [93m[1m[Client #37] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:18,  1.46s/it]  2%|â–         | 2/96 [00:01<01:14,  1.26it/s]  3%|â–Ž         | 3/96 [00:02<00:54,  1.71it/s]  4%|â–         | 4/96 [00:02<00:44,  2.06it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.34it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.73it/s]  8%|â–Š         | 8/96 [00:03<00:30,  2.86it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.94it/s] 10%|â–ˆ         | 10/96 [00:04<00:28,  3.00it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:27,  3.04it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:27,  3.07it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:26,  3.09it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:26,  3.11it/s] 16%|â–ˆâ–Œ        | 15/96 [00:05<00:25,  3.12it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:25,  3.13it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:25,  3.13it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:24,  3.14it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:24,  3.14it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.14it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:23,  3.14it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:23,  3.14it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.14it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:22,  3.14it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:22,  3.14it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.14it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:21,  3.14it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.14it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.14it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.14it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:20,  3.14it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:17,  3.60it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.45it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:11<00:18,  3.35it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.29it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.24it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:12<00:18,  3.21it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.19it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:17,  3.18it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:13<00:17,  3.17it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.16it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.15it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:14<00:16,  3.14it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.14it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.14it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:15,  3.14it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:15,  3.14it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.14it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:14,  3.14it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:16<00:14,  3.14it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.13it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.13it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:17<00:13,  3.13it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.12it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.12it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:18<00:12,  3.12it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.12it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.12it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:19<00:11,  3.12it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.11it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.11it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:20<00:10,  3.11it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.11it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:08,  3.56it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:21<00:09,  3.41it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:21<00:09,  3.32it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.25it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:22<00:08,  3.21it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:22<00:08,  3.19it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.16it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:23<00:07,  3.15it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:23<00:07,  3.14it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.13it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:24<00:07,  3.12it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:24<00:06,  3.12it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.11it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:25<00:06,  3.11it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:25<00:05,  3.10it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.11it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:26<00:05,  3.11it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:26<00:04,  3.11it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.11it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.11it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:27<00:03,  3.11it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  3.11it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:28<00:03,  3.11it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:28<00:02,  3.11it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.11it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:29<00:02,  3.10it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:29<00:01,  3.10it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.10it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:30<00:01,  3.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:30<00:00,  3.11it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:30<00:00,  3.11it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:31<00:00,  3.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:31<00:00,  3.05it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.711583137512207,)
[INFO][10:28:00]: [Client #37] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
{'train_runtime': 31.4804, 'train_samples_per_second': 192.31, 'train_steps_per_second': 3.05, 'train_loss': 2.711583137512207, 'epoch': 3.0}
[INFO][10:28:01]: [Client #37] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_37_3995237.pth.
[INFO][10:28:02]: [Client #37] Model trained.
[INFO][10:28:02]: [Client #37] Inbound data has been processed.
[INFO][10:28:02]: [Client #37] Outbound data is ready to be sent after being processed.
[INFO][10:28:07]: [Client #37] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:28:08]: [Server #3995185] Received 507.38 MB of payload data from client #37 (simulated).
[INFO][10:28:08]: [Server #3995185] Selecting client #159 for training.
[INFO][10:28:08]: [Server #3995185] Sending the current model to client #159 (simulated).
[INFO][10:28:13]: [Server #3995185] Sending 507.38 MB of payload data to client #159 (simulated).
[INFO][10:28:13]: [Client #159] Selected by the server.
[INFO][10:28:13]: [Client #159] Loading its data source...
[INFO][10:28:13]: [Client #159] Dataset size: 2018
[INFO][10:28:13]: [Client #159] Sampler: iid
[INFO][10:28:15]: [Client #159] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:28:15]: [Client #159] Start to process inbound data.
[INFO][10:28:16]: [93m[1m[Client #159] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:16,  1.44s/it]  2%|â–         | 2/96 [00:01<01:13,  1.28it/s]  3%|â–Ž         | 3/96 [00:02<00:53,  1.74it/s]  4%|â–         | 4/96 [00:02<00:43,  2.10it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.57it/s]  7%|â–‹         | 7/96 [00:03<00:32,  2.71it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.82it/s]  9%|â–‰         | 9/96 [00:04<00:29,  2.91it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.94it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.98it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.99it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.01it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.03it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.03it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.04it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:24,  3.06it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.06it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:23,  3.07it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.06it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.08it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.10it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.09it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:21,  3.11it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.09it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.06it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.05it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.50it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.37it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:19,  3.26it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:19,  3.15it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:19,  3.10it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.08it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.08it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.07it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.07it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:16,  3.06it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.05it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:15<00:16,  3.06it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.05it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.06it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:16<00:15,  3.05it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.03it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.02it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.02it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.03it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.02it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.01it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.01it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  3.01it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.01it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.01it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  3.01it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.01it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.47it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.30it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.20it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:09,  3.13it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.08it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.06it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  3.03it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.01it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.01it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  3.01it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.00it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:07,  2.99it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  2.99it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  2.99it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:06,  2.99it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  2.99it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.00it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:05,  3.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.00it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  3.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  3.00it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  3.00it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  3.00it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  3.00it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:01,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  3.02it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:00,  3.04it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:31<00:00,  3.04it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  3.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.97it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.743678092956543,)
[INFO][10:28:53]: [Client #159] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_159_3995237.pth.
{'train_runtime': 32.336, 'train_samples_per_second': 187.222, 'train_steps_per_second': 2.969, 'train_loss': 2.743678092956543, 'epoch': 3.0}
[INFO][10:28:54]: [Client #159] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_159_3995237.pth.
[INFO][10:28:55]: [Client #159] Model trained.
[INFO][10:28:55]: [Client #159] Inbound data has been processed.
[INFO][10:28:55]: [Client #159] Outbound data is ready to be sent after being processed.
[INFO][10:29:02]: [Client #159] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:29:03]: [Server #3995185] Received 507.38 MB of payload data from client #159 (simulated).
[INFO][10:29:03]: [Server #3995185] Selecting client #9 for training.
[INFO][10:29:03]: [Server #3995185] Sending the current model to client #9 (simulated).
[INFO][10:29:08]: [Server #3995185] Sending 507.38 MB of payload data to client #9 (simulated).
[INFO][10:29:08]: [Client #9] Selected by the server.
[INFO][10:29:08]: [Client #9] Loading its data source...
[INFO][10:29:08]: [Client #9] Dataset size: 2018
[INFO][10:29:08]: [Client #9] Sampler: iid
[INFO][10:29:10]: [Client #9] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:29:10]: [Client #9] Start to process inbound data.
[INFO][10:29:10]: [93m[1m[Client #9] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:22,  1.50s/it]  2%|â–         | 2/96 [00:01<01:16,  1.23it/s]  3%|â–Ž         | 3/96 [00:02<00:55,  1.68it/s]  4%|â–         | 4/96 [00:02<00:45,  2.04it/s]  5%|â–Œ         | 5/96 [00:02<00:39,  2.32it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.51it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.66it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.78it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.85it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.90it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:29,  2.92it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.95it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  2.97it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  2.98it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.01it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.01it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.01it/s] 19%|â–ˆâ–‰        | 18/96 [00:07<00:25,  3.03it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.02it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:08<00:24,  3.05it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.04it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.04it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:09<00:23,  3.03it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.02it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:23,  3.02it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:10<00:22,  3.03it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.02it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:22,  3.03it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:11<00:21,  3.05it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.04it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.49it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.35it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:19,  3.19it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.11it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.09it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.07it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.05it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:18,  3.04it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.03it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.02it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.02it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.02it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.01it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.01it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.02it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.02it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.01it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:18<00:14,  3.00it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:14,  3.00it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.00it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:19<00:13,  3.01it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:13,  3.01it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.00it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:20<00:12,  2.99it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:12,  2.99it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:12,  3.00it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:21<00:11,  2.98it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:11,  2.98it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:11,  2.98it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:22<00:09,  3.43it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.28it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.21it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:23<00:09,  3.15it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:09,  3.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:24<00:08,  3.08it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  3.05it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:07,  3.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:25<00:07,  3.04it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  3.01it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.00it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:26<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.03it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.03it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:27<00:05,  3.04it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.02it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.01it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:28<00:04,  2.99it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:28<00:04,  2.99it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.99it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:29<00:03,  2.99it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.99it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.99it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:30<00:02,  2.99it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.99it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  3.00it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:31<00:01,  3.01it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [00:31<00:01,  3.00it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [00:31<00:01,  2.98it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [00:32<00:00,  2.97it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [00:32<00:00,  2.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]

Training completed. Do not forget to share your model on huggingface.co/models =)


                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  3.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [00:32<00:00,  2.95it/s]
--- Logging error ---
Traceback (most recent call last):
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
TypeError: not enough arguments for format string
Call stack:
  File "<string>", line 1, in <module>
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 116, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/spawn.py", line 129, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/plato/trainers/basic.py", line 155, in train_process
    self.train_model(config, trainset, sampler.get(), **kwargs)
  File "/home/ykang/plato/examples/oort/oort_trainer_huggingface.py", line 46, in train_model
    logging.info("Client [#%d] here's the metrics: %f ", matrics[1])
Message: "Client [#%d] here's the metrics: %f "
Arguments: (2.64008363087972,)
[INFO][10:29:49]: [Client #9] Model saved to /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
{'train_runtime': 32.5935, 'train_samples_per_second': 185.743, 'train_steps_per_second': 2.945, 'train_loss': 2.64008363087972, 'epoch': 3.0}
[INFO][10:29:50]: [Client #9] Loading a model from /data/ykang/plato/models/huggingface/fedavg/bert-base-uncased_9_3995237.pth.
[INFO][10:29:50]: [Client #9] Model trained.
[INFO][10:29:50]: [Client #9] Inbound data has been processed.
[INFO][10:29:50]: [Client #9] Outbound data is ready to be sent after being processed.
[INFO][10:29:56]: [Client #9] Sent 507.38 MB of payload data to the server (simulated).
[INFO][10:29:57]: [Server #3995185] Received 507.38 MB of payload data from client #9 (simulated).
[INFO][10:29:57]: [Server #3995185] Selecting client #7 for training.
[INFO][10:29:57]: [Server #3995185] Sending the current model to client #7 (simulated).
[INFO][10:30:02]: [Server #3995185] Sending 507.38 MB of payload data to client #7 (simulated).
[INFO][10:30:02]: [Client #7] Selected by the server.
[INFO][10:30:02]: [Client #7] Loading its data source...
[INFO][10:30:02]: [Client #7] Dataset size: 2018
[INFO][10:30:02]: [Client #7] Sampler: iid
[INFO][10:30:03]: [Client #7] Received 507.38 MB of payload data from the server (simulated).
[INFO][10:30:03]: [Client #7] Start to process inbound data.
[INFO][10:30:04]: [93m[1m[Client #7] Started training in communication round #41.[0m
/home/ykang/miniforge3/envs/federated/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 2018
  Num Epochs = 3
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 96
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:13,  1.41s/it]  2%|â–         | 2/96 [00:01<01:12,  1.30it/s]  3%|â–Ž         | 3/96 [00:02<00:52,  1.76it/s]  4%|â–         | 4/96 [00:02<00:43,  2.11it/s]  5%|â–Œ         | 5/96 [00:02<00:38,  2.37it/s]  6%|â–‹         | 6/96 [00:03<00:35,  2.55it/s]  7%|â–‹         | 7/96 [00:03<00:33,  2.69it/s]  8%|â–Š         | 8/96 [00:03<00:31,  2.79it/s]  9%|â–‰         | 9/96 [00:04<00:30,  2.87it/s] 10%|â–ˆ         | 10/96 [00:04<00:29,  2.92it/s] 11%|â–ˆâ–        | 11/96 [00:04<00:28,  2.95it/s] 12%|â–ˆâ–Ž        | 12/96 [00:05<00:28,  2.97it/s] 14%|â–ˆâ–Ž        | 13/96 [00:05<00:27,  3.00it/s] 15%|â–ˆâ–        | 14/96 [00:05<00:27,  3.03it/s] 16%|â–ˆâ–Œ        | 15/96 [00:06<00:26,  3.05it/s] 17%|â–ˆâ–‹        | 16/96 [00:06<00:26,  3.04it/s] 18%|â–ˆâ–Š        | 17/96 [00:06<00:26,  3.04it/s] 19%|â–ˆâ–‰        | 18/96 [00:06<00:25,  3.06it/s] 20%|â–ˆâ–‰        | 19/96 [00:07<00:25,  3.05it/s] 21%|â–ˆâ–ˆ        | 20/96 [00:07<00:25,  3.04it/s] 22%|â–ˆâ–ˆâ–       | 21/96 [00:07<00:24,  3.03it/s] 23%|â–ˆâ–ˆâ–Ž       | 22/96 [00:08<00:24,  3.03it/s] 24%|â–ˆâ–ˆâ–       | 23/96 [00:08<00:24,  3.03it/s] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:08<00:23,  3.02it/s] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:09<00:23,  3.01it/s] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:09<00:22,  3.05it/s] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:09<00:22,  3.07it/s] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:10<00:22,  3.08it/s] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:10<00:21,  3.07it/s] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:10<00:21,  3.07it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:11<00:21,  3.08it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 32/96 [00:11<00:18,  3.53it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:11<00:18,  3.40it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:12<00:18,  3.27it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:12<00:18,  3.23it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:12<00:18,  3.16it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:13<00:18,  3.12it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [00:13<00:18,  3.11it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [00:13<00:18,  3.11it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [00:14<00:18,  3.08it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 41/96 [00:14<00:17,  3.06it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [00:14<00:17,  3.05it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [00:15<00:17,  3.06it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [00:15<00:17,  3.05it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [00:15<00:16,  3.04it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [00:16<00:16,  3.03it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [00:16<00:16,  3.02it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [00:16<00:15,  3.02it/s]slurmstepd-sim: error: *** JOB 5763 ON sim CANCELLED AT 2023-02-06T10:30:25 ***
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [00:17<00:15,  3.01it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [00:17<00:15,  3.04it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 51/96 [00:17<00:14,  3.07it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [00:17<00:14,  3.08it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [00:18<00:13,  3.09it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [00:18<00:13,  3.10it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [00:18<00:13,  3.10it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [00:19<00:12,  3.10it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [00:19<00:12,  3.10it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [00:19<00:12,  3.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [00:20<00:11,  3.10it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 60/96 [00:20<00:11,  3.10it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 61/96 [00:20<00:11,  3.10it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [00:21<00:10,  3.10it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [00:21<00:10,  3.10it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [00:21<00:09,  3.55it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [00:22<00:09,  3.40it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [00:22<00:09,  3.30it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [00:22<00:08,  3.24it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [00:23<00:08,  3.20it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [00:23<00:08,  3.17it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 70/96 [00:23<00:08,  2.90it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [00:24<00:08,  2.94it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [00:24<00:08,  2.88it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [00:24<00:07,  2.95it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [00:25<00:07,  2.99it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [00:25<00:06,  3.02it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [00:25<00:06,  3.03it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [00:26<00:06,  3.05it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [00:26<00:05,  3.07it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [00:26<00:05,  3.07it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 80/96 [00:27<00:05,  3.08it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [00:27<00:04,  3.09it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [00:27<00:04,  3.09it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [00:27<00:04,  3.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [00:28<00:04,  2.81it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [00:28<00:04,  2.72it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [00:29<00:03,  2.82it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [00:29<00:03,  2.88it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [00:29<00:02,  2.85it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 89/96 [00:30<00:02,  2.75it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [00:30<00:02,  2.83it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [00:30<00:01,  2.87it/s]